[
    {
        "Abstract": "Teams of mobile robots often need to divide up subtasks efficiently. In spatial domains, a key criterion for doing so may depend on distances between robots and the subtasks' locations. This paper considers a specific such criterion, namely how to assign interchangeable robots, represented as point masses, to a set of target goal locations within an open two dimensional space such that the makespan (time for all robots to reach their target locations) is minimized while also preventing collisions among robots. We present scaleable (computable in polynomial time) role assignment algorithms that we classify as being SCRAM (Scalable Collision-avoiding Role Assignment with Minimal-makespan). SCRAM role assignment algorithms use a graph theoretic approach to map agents to target goal locations such that our objectives for both minimizing the makespan and avoiding agent collisions are met.  A system using SCRAM role assignment was originally designed to allow for decentralized coordination among physically realistic simulated humanoid soccer playing robots in the partially observable, non-deterministic, noisy, dynamic, and limited communication setting of the RoboCup 3D simulation league. In its current form, SCRAM role assignment generalizes well to many realistic and real-world multiagent systems, and scales to thousands of agents.",
        "A1": "We present scaleable (computable in polynomial time) role assignment algorithms that we classify as being SCRAM (Scalable Collision-avoiding Role Assignment with Minimal-makespan). ",
        "A2": "to assign interchangeable robots, represented as point masses, to a set of target goal locations within an open two dimensional space such that the makespan (time for all robots to reach their target locations) is minimized while also preventing collisions among robots. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "A system",
        "A83": "",
        "A82": "",
        "A81": "SCRAM role assignment generalizes well to many realistic and real-world multiagent systems, and scales to thousands of agents.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "a graph theoretic approach",
        "A43": "SCRAM (Scalable Collision-avoiding Role Assignment with Minimal-makespan)",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 275981227
    },
    {
        "Abstract": "With the rise of social media, learning from informal text has become increasingly important. We present a novel semantic lexicon induction approach that is able to learn new vocabulary from social media. Our method is robust to the idiosyncrasies of informal and open-domain text corpora. Unlike previous work, it does not impose restrictions on the lexical features of candidate terms \u2014 e.g. by restricting entries to nouns or noun phrases \u2014while still being able to accurately learn multiword phrases of variable length. Starting with a few seed terms for a semantic category, our method first explores the context around seed terms in a corpus, and identifies context patterns that are relevant to the category. These patterns are used to extract candidate terms \u2014 i.e. multiword segments that are further analyzed to ensure meaningful term boundary segmentation. We show that our approach is able to learn high quality semantic lexicons from informally written social media text of Twitter, and can achieve accuracy as high as 92% in the top 100 learned category members.",
        "A1": " present a novel semantic lexicon induction approach that is able to learn new vocabulary from social media",
        "A2": "learning from informal text has become increasingly important",
        "A41": "present a novel semantic lexicon induction approach that is able to learn new vocabulary from social media",
        "A51": "",
        "A61": "it does not impose restrictions on the lexical features of candidate terms",
        "A10": "",
        "A7": " informally written social media text of Twitter",
        "A83": "",
        "A82": "achieve accuracy as high as 92% in the top 100 learned category members.",
        "A81": " able to learn high quality semantic lexicons",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 120695737
    },
    {
        "Abstract": "Most real-world games and many recreational games are games of incomplete information. Over the last dozen years, abstraction has emerged as a key enabler for solving large incomplete-information games. First, the game is abstracted to generate a smaller, abstract game that is strategically similar to the original game. Second, an approximate equilibrium is computed in the abstract game. Third, the strategy from the abstract game is mapped back to the original game. In this paper, I will review key developments in the field. I present reasons for abstracting games, and point out the issue of abstraction pathology. I then review the practical algorithms for information abstraction and action abstraction. I then cover recent theoretical breakthroughs that beget bounds on the quality of the strategy from the abstract game, when measured in the original game. I then discuss how to reverse map the opponent's action into the abstraction if the opponent makes a move that is not in the abstraction. Finally, I discuss other topics of current and future research.",
        "A1": "abstracting games",
        "A2": "abstracting games",
        "A41": "abstracting games",
        "A51": "abstracting games",
        "A61": "abstracting games",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "discuss other topics of current and future research.",
        "A81": " discuss how to reverse map the opponent's action into the abstraction if the opponent makes a move that is not in the abstraction.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 294535837
    },
    {
        "Abstract": "Stackelberg security games have been widely deployed to protect real-word assets. The main solution concept there is the Strong Stackelberg Equilibrium (SSE), which optimizes the defender's random allocation of limited security resources. However, solely deploying the SSE mixed strategy has limitations. In the extreme case, there are security games where the defender is able to defend all the assets ``almost perfectly\" at the SSE, but she still sustains significant loss. In this paper, we propose an approach for improving the defender's utility in such scenarios. Perhaps surprisingly, our approach is to strategically reveal to the attacker information about the sampled pure strategy. Specifically, we propose a two-stage security game model, where in the first stage the defender allocates resources and the attacker selects a target to attack, and in the second stage the defender strategically reveals local information about that target, potentially deterring the attacker's attack plan. We then study how the defender can play optimally in both stages. We show, theoretically and experimentally, that the two-stage security game model allows the defender to gain strictly better utility than SSE.",
        "A1": "improving the defender's utility in such scenarios",
        "A2": "there are security games where the defender is able to defend all the assets ``almost perfectly\" at the SSE, but she still sustains significant loss",
        "A41": "an approach for improving the defender's utility in such scenarios",
        "A51": "Stackelberg Equilibrium (SSE)",
        "A61": "",
        "A10": "the two-stage security game model allows the defender to gain strictly better utility than SSE",
        "A7": "We show, theoretically and experimentally",
        "A83": "",
        "A82": "",
        "A81": "gain strictly better utility",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "in the first stage the defender allocates resources and the attacker selects a target to attack, and in the second stage the defender strategically reveals local information about that target",
        "A52": "security game",
        "A42": "a two-stage security game model",
        "A45": "",
        "am_id": 338513513
    },
    {
        "Abstract": "Lifted probabilistic inference algorithms have been successfully applied to a large number of symmetric graphical models. Unfortunately, the majority of real-world graphical models is asymmetric. This is even the case for relational representations when evidence is given. Therefore, more recent work in the community moved to making the models symmetric and then applying existing lifted inference algorithms. However, this approach has two shortcomings. First, all existing over-symmetric approximations require a relational representation such as Markov logic networks. Second, the induced symmetries often change the distribution significantly, making the computed probabilities highly biased. We present a framework for probabilistic sampling-based inference that only uses the induced approximate symmetries to propose steps in a Metropolis-Hastings style Markov chain. The framework, therefore, leads to improved probability estimates while remaining unbiased. Experiments demonstrate that the approach outperforms existing MCMC algorithms.",
        "A1": "present a framework for probabilistic sampling-based inference ",
        "A2": " uses the induced approximate symmetries to propose steps in a Metropolis-Hastings style Markov chain.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "leads to improved probability estimates while remaining unbiased.",
        "A7": "the induced symmetries often change the distribution significantly,",
        "A83": "uses the induced approximate symmetries to propose steps in a Metropolis-Hastings style Markov chain",
        "A82": "present a framework for probabilistic sampling-based inference ",
        "A81": "making the computed probabilities highly biased",
        "A64": "existing over-symmetric approximations require a relational representation such as Markov logic networks.",
        "A54": "Metropolis-Hastings style Markov chain.",
        "A44": "leads to improved probability estimates while remaining unbiased. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 153827633
    },
    {
        "Abstract": "In computer vision, a complex entity such as an image or video is often represented as a set of instance vectors, which are extracted from different parts of that entity. Thus, it is essential to design a representation to encode information in a set of instances robustly. Existing methods such as FV and VLAD are designed based on a generative perspective, and their performances fluctuate when difference types of instance vectors are used (i.e., they are not robust). The proposed D3 method effectively compares two sets as two distributions, and proposes a directional total variation distance (DTVD) to measure their dissimilarity. Furthermore, a robust classifier-based method is proposed to estimate DTVD robustly, and to efficiently represent these sets. D3 is evaluated in action and image recognition tasks. It achieves excellent robustness, accuracy and speed.",
        "A1": "In computer vision, a complex entity such as an image or video is often represented as a set of instance vectors, which are extracted from different parts of that entity. Thus, it is essential to design a representation to encode information in a set of instances robustly",
        "A2": "",
        "A41": "proposed D3 method effectively compares two sets as two distributions, and proposes a directional total variation distance (DTVD) to measure their dissimilarity",
        "A51": "",
        "A61": "a robust classifier-based method is proposed to estimate DTVD robustly, and to efficiently represent these sets",
        "A10": "",
        "A7": "evaluated in action and image recognition tasks",
        "A83": "",
        "A82": "",
        "A81": "achieves excellent robustness, accuracy and speed.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 99070318
    },
    {
        "Abstract": "Text and Knowledge Bases are complementary sources of information. Given the success of distributed word representations learned from text, several techniques to infuse additional information from sources like WordNet into word representations have been proposed. In this paper, we follow an alternative route. We learn word representations from text and WordNet independently, and then explore simple and sophisticated methods to combine them. The combined representations are applied to an extensive set of datasets on word similarity and relatedness. Simple combination methods happen to perform better that more complex methods like CCA or retrofitting, showing that, in the case of WordNet, learning word representations separately is preferable to learning one single representation space or adding WordNet information directly. A key factor, which we illustrate with examples, is that the WordNet-based representations captures similarity relations encoded in WordNet better than retrofitting. In addition, we show that the average of the similarities from six word representations yields results beyond the state-of-the-art in several datasets, reinforcing the opportunities to explore further combination techniques.",
        "A1": "Text and Knowledge Bases",
        "A2": "Text and Knowledge Bases",
        "A41": "an alternative route",
        "A51": "",
        "A61": "We learn word representations from text and WordNet independently, and then explore simple and sophisticated methods to combine them.",
        "A10": " the average of the similarities from six word representations yields results beyond the state-of-the-art in several datasets",
        "A7": "",
        "A83": "",
        "A82": " the average of the similarities from six word representations yields results beyond the state-of-the-art in several datasets",
        "A81": "in the case of WordNet, learning word representations separately is preferable to learning one single representation space or adding WordNet information directly",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 7779040
    },
    {
        "Abstract": "We present an algorithm (LsNet2Vec) that, given a large-scale network (millions of nodes), embeds the structural features of node into a lower and fixed dimensions of vector in the set of real numbers. We experiment and evaluate our proposed approach with twelve datasets collected from SNAP. Results show that our model performs comparably with state-of-the-art methods, such as Katz method and Random Walk Restart method, in various experiment settings.",
        "A1": "given a large-scale network (millions of nodes), embeds the structural features of node into a lower and fixed dimensions of vector in the set of real numbers",
        "A2": "given a large-scale network (millions of nodes), embeds the structural features of node into a lower and fixed dimensions of vector in the set of real numbers",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our model performs comparably with state-of-the-art methods, such as Katz method and Random Walk Restart method, in various experiment settings",
        "A7": "twelve datasets collected from SNAP",
        "A83": "",
        "A82": "",
        "A81": "our model performs comparably with state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "embeds the structural features of node into a lower and fixed dimensions of vector in the set of real numbers",
        "A53": "a large-scale network (millions of nodes)",
        "A43": "algorithm (LsNet2Vec) ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 477869166
    },
    {
        "Abstract": "In supervised machine learning, model performance can decrease significantly when the distribution generating the new data varies from the distribution that generated the training data. One of the situations is covariate shift which happens a lot when labeled training data is missing, hard to get access to or very expensive to uniformly collect. All (probabilistic) classifiers will suffer from covariate shift. This motivates our research. Generally, we try to answer this question: how can we deal with covariate shift and generate predictions that are robust and reliable? We propose to develop a general framework for classification under covariate shift that is robust, flexible and accurate.",
        "A1": "We propose to develop a general framework for classification under covariate shift that is robust, flexible and accurate.",
        "A2": "how can we deal with covariate shift and generate predictions that are robust and reliable?",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " robust, flexible and accurate",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "robust, flexible and accurate",
        "A54": "",
        "A44": "a general framework for classification under covariate shift that is robust, flexible and accurate",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 293750488
    },
    {
        "Abstract": "Transportation and mobility are central to sustainable urban development, where multiagent-based route guidance is widely applied. Traditional multiagent-based route guidance always seeks LET (least expected travel time) paths. However, drivers usually have specific expectations, i.e., tight or loose deadlines, which may not be all met by LET paths. We thus adopt and extend the probability tail model that aims to maximize the probability of reaching destinations before deadlines. Specifically, we propose a decentralized multiagent approach, where infrastructure agents locally collect intentions of concerned vehicle agents and formulate route guidance as a route assignment problem, to guarantee their arrival on time. Experimental results on real road networks justify its ability to increase the chance of arrival on time.",
        "A1": "",
        "A2": "drivers usually have specific expectations, i.e., tight or loose deadlines, which may not be all met by LET paths",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on real road networks",
        "A83": "",
        "A82": "",
        "A81": "justify its ability to increase the chance of arrival on time.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "adopt and extend the probability tail model that aims to maximize the probability of reaching destinations before deadlines",
        "A45": "",
        "am_id": 21897429
    },
    {
        "Abstract": "General zero-shot learning (ZSL) approaches exploit transfer learning via semantic knowledge space. In this paper, we reveal a novel relational knowledge transfer (RKT) mechanism for ZSL, which is simple, generic and effective. RKT resolves the inherent semantic shift problem existing in ZSL through restoring the missing manifold structure of unseen categories via optimizing semantic mapping. It extracts the relational knowledge from data manifold structure in semantic knowledge space based on sparse coding theory. The extracted knowledge is then transferred backwards to generate virtual data for unseen categories in the feature space. On the one hand, the generalizing ability of the semantic mapping function can be enhanced with the added data. On the other hand, the mapping function for unseen categories can be learned directly from only these generated data, achieving inspiring performance. Incorporated with RKT, even simple baseline methods can achieve good results. Extensive experiments on three challenging datasets show prominent performance obtained by RKT, and we obtain 82.43% accuracy on the Animals with Attributes dataset.",
        "A1": "reveal a novel relational knowledge transfer (RKT) mechanism for ZSL",
        "A2": " It extracts the relational knowledge from data manifold structure in semantic knowledge space based on sparse coding theory",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "obtain 82.43% accuracy on the Animals with Attributes dataset",
        "A81": "prominent performance obtained by RKT",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "three challenging datasets show prominent performance obtained by RKT",
        "am_id": 103021298
    },
    {
        "Abstract": "Clickbaits are articles with misleading titles, exaggerating the content on the landing page. Their goal is to entice users to click on the title in order to monetize the landing page. The content on the landing page is usually of low quality. Their presence in user homepage stream of news aggregator sites (e.g., Yahoo news, Google news) may adversely impact user experience. Hence, it is important to identify and demote or block them on homepages. In this paper, we present a machine-learning model to detect clickbaits. We use a variety of features and show that the degree of informality of a webpage (as measured by different metrics) is a strong indicator of it being a clickbait. We conduct extensive experiments to evaluate our approach and analyze properties of clickbait and non-clickbait articles. Our model achieves high performance (74.9% F-1 score) in predicting clickbaits.",
        "A1": "we present a machine-learning model to detect clickbaits.",
        "A2": "Hence, it is important to identify and demote or block them on homepages.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our model achieves high performance (74.9% F-1 score) in predicting clickbaits.",
        "A7": "We conduct extensive experiments to evaluate our approach and analyze properties of clickbait and non-clickbait articles.",
        "A83": "",
        "A82": "",
        "A81": "Our model achieves high performance (74.9% F-1 score) in predicting clickbaits.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "We use a variety of features and show that the degree of informality of a webpage (as measured by different metrics) is a strong indicator of it being a clickbait.",
        "A52": "",
        "A42": "a machine-learning model to detect clickbaits",
        "A45": "",
        "am_id": 7440837
    },
    {
        "Abstract": "Recent years have witnessed the success of deep neural networks in dealing with a plenty of practical problems. The invention of effective training techniques largely contributes to this success. The so-called \"Dropout\" training scheme is one of the most powerful tool to reduce over-fitting. From the statistic point of view, Dropout works by implicitly imposing an L2 regularizer on the weights. In this paper, we present a new training scheme: Shakeout. Instead of randomly discarding units as Dropout does at the training stage, our method randomly chooses to enhance or inverse the contributions of each unit to the next layer. We show that our scheme leads to a combination of L1 regularization and L2 regularization imposed on the weights, which has been proved effective by the Elastic Net models in practice.We have empirically evaluated the Shakeout scheme and demonstrated that sparse network weights are obtained via Shakeout training. Our classification experiments on real-life image datasets MNIST and CIFAR-10 show that Shakeout deals with over-fitting effectively.",
        "A1": "In this paper, we present a new training scheme: Shakeout.",
        "A2": "",
        "A41": "we present a new training scheme: Shakeout",
        "A51": "implicitly imposing an L2 regularizer on the weights.",
        "A61": "Instead of randomly discarding units as Dropout does at the training stage, our method randomly chooses to enhance or inverse the contributions of each unit to the next layer.",
        "A10": "",
        "A7": "",
        "A83": "We have empirically evaluated the Shakeout scheme and demonstrated that sparse network weights are obtained via Shakeout training.",
        "A82": "our scheme leads to a combination of L1 regularization and L2 regularization imposed on the weights, which has been proved effective by the Elastic Net models in practice",
        "A81": "Shakeout deals with over-fitting effectively.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 6053342
    },
    {
        "Abstract": "We introduce a broad family of decision trees, Composite Trees, whose leaf classifiers are selected out of a hypothesis set composed of p subfamilies with different complexities. We prove new data-dependent learning guarantees for this family in the multi-class setting. These learning bounds provide a quantitative guidance for the choice of the hypotheses at each leaf. Remarkably, they depend on the Rademacher complexities of the sub-families of the predictors and the fraction of sample points correctly classified at each leaf. We further introduce random composite trees and derive learning guarantees for random composite trees which also apply to Random Forests. Using our theoretical analysis, we devise a new algorithm, RANDOMCOMPOSITEFORESTS (RCF), that is based on forming an ensemble of random composite trees. We report the results of experiments demonstrating that RCF yields significant performance improvements over both Random Forests and a variant of RCF in several tasks.",
        "A1": "We introduce a broad family of decision trees, Composite Trees, whose leaf classifiers are selected out of a hypothesis set composed of p subfamilies with different complexities.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the results of experiments demonstrating that RCF yields significant performance improvements over both Random Forests and a variant of RCF in several tasks.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the results of experiments demonstrating that RCF yields significant performance improvements over both Random Forests and a variant of RCF in several tasks.",
        "A64": "",
        "A54": "",
        "A44": "a broad family of decision trees, Composite Trees, whose leaf classifiers are selected out of a hypothesis set composed of p subfamilies with different complexities.",
        "A63": "",
        "A53": "",
        "A43": " a new algorithm, RANDOMCOMPOSITEFORESTS (RCF), that is based on forming an ensemble of random composite trees.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 415328531
    },
    {
        "Abstract": "Survival prediction is crucial to healthcare research, but is confined primarily to specific types of data involving only the present measurements. This paper considers the more general class of healthcare data found in practice, which includes a wealth of intermittently varying historical measurements in addition to the present measurements. Making survival predictions on such data bristles with challenges to the existing prediction models. For this reason, we propose a new semi-proportional hazards model using locally time-varying coefficients, and a novel complete-data model learning criterion for coefficient optimization. Experiments on the healthcare data demonstrate the effectiveness and generalizability of our model and its promise in practical applications.",
        "A1": "Making survival predictions on such data bristles with challenges to the existing prediction models",
        "A2": "propose a new semi-proportional hazards model using locally time-varying coefficients, and a novel complete-data model learning criterion for coefficient optimization",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experiments on the healthcare data demonstrate the effectiveness and generalizability of our model and its promise in practical applications.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experiments on the healthcare data demonstrate the effectiveness and generalizability of our model and its promise in practical applications.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "using locally time-varying coefficients,",
        "A42": "a new semi-proportional hazards model using locally time-varying coefficients, and a novel complete-data model learning criterion for coefficient optimization",
        "A45": "",
        "am_id": 481313588
    },
    {
        "Abstract": "Sketch-based 3D shape retrieval, which returns a set of relevant 3D shapes based on users' input sketch queries, has been receiving increasing attentions in both graphics community and vision community. In this work, we address the sketch-based 3D shape retrieval problem with a novel Cross-Domain Neural Networks (CDNN) approach, which is further extended to Pyramid Cross-Domain Neural Networks (PCDNN) by cooperating with a hierarchical structure. In order to alleviate the discrepancies between sketch features and 3D shape features, a neural network pair that forces identical representations at the target layer for instances of the same class is trained for sketches and 3D shapes respectively. By constructing cross-domain neural networks at multiple pyramid levels, a many-to-one relationship is established between a 3D shape feature and sketch features extracted from different scales. We evaluate the effectiveness of both CDNN and PCDNN approach on the extended large-scale SHREC 2014 benchmark and compare with some other well established methods. Experimental results suggest that both CDNN and PCDNN can outperform state-of-the-art performance, where PCDNN can further improve CDNN when employing a hierarchical structure.",
        "A1": "Sketch-based 3D shape retrieval",
        "A2": "Sketch-based 3D shape retrieval",
        "A41": "a novel Cross-Domain Neural Networks (CDNN) approach",
        "A51": "Pyramid Cross-Domain Neural Networks",
        "A61": "",
        "A10": "alleviate the discrepancies between sketch features and 3D shape features",
        "A7": "evaluate the effectiveness of both CDNN and PCDNN approach on the extended large-scale SHREC 2014 benchmark",
        "A83": "",
        "A82": "PCDNN can further improve CDNN when employing a hierarchical structure",
        "A81": "both CDNN and PCDNN can outperform state-of-the-art performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 450404607
    },
    {
        "Abstract": "Retrieving faces from large mess of videos is an attractive research topic with wide range of applications. Its challenging problems are large intra-class variations, and tremendous time and space complexity. In this paper, we develop a new deep convolutional neural network (deep CNN) to learn discriminative and compact binary representations of faces for face video retrieval. The network integrates feature extraction and hash learning into a unified optimization framework for the optimal compatibility of feature extractor and hash functions. In order to better initialize the network, the low-rank discriminative binary hashing is proposed to pre-learn hash functions during the training procedure. Our method achieves excellent performances on two challenging TV-Series datasets.",
        "A1": "learn discriminative and compact binary representations of faces for face video retrieval",
        "A2": "large intra-class variations, and tremendous time and space complexity",
        "A41": "the low-rank discriminative binary hashing",
        "A51": "two challenging TV-Series datasets",
        "A61": "",
        "A10": "",
        "A7": " two challenging TV-Series datasets",
        "A83": "",
        "A82": "",
        "A81": "Our method achieves excellent performances on two challenging TV-Series datasets",
        "A64": "",
        "A54": "",
        "A44": " a unified optimization framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a new deep convolutional neural network (deep CNN) to learn discriminative and compact binary representations of faces for face video retrieval",
        "A45": "",
        "am_id": 293589899
    },
    {
        "Abstract": "We present differentially private algorithms for the stochastic Multi-Armed Bandit (MAB) problem. This is a problem for applications such as adaptive clinical trials, experiment design, and user-targeted advertising where private information is connected to individual rewards. Our major contribution is to show that there exist (\u03b5,\u03b4) differentially private variants of Upper Confidence Bound algorithms which have optimal regret, O(\u03b5\u22121 + log T ). This is a significant improvement over previous results, which only achieve poly-log regret O(\u03b5\u22122 log3 T), because of our use of a novel interval based mechanism. We also substantially improve the bounds of previous family of algorithms which use a continual release mechanism. Experiments clearly validate our theoretical bounds.",
        "A1": "",
        "A2": "This is a problem for applications such as adaptive clinical trials, experiment design, and user-targeted advertising where private information is connected to individual rewards.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "substantially improve the bounds of previous family of algorithms which use a continual release mechanism",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "clearly validate our theoretical bounds",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "show that there exist (\u03b5,\u03b4) differentially private variants of Upper Confidence Bound algorithms which have optimal regret, O(\u03b5\u22121 + log T )",
        "A53": "",
        "A43": "algorithms for the stochastic Multi-Armed Bandit (MAB) problem",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 134618885
    },
    {
        "Abstract": "In graph-oriented machine learning research, L1 graph is an efficient way to represent the connections of input data samples. Its construction algorithm is based on a numerical optimization motivated by Compressive Sensing theory. As a result, It is a nonparametric method which is highly demanded. However, the information of data such as geometry structure and density distribution are ignored. In this paper, we propose a Structure Aware (SA) L1 graph to improve the data clustering performance by capturing the manifold structure of input data. We use a local dictionary for each datum while calculating its sparse coefficients. SA-L1 graph not only preserves the locality of data but also captures the geometry structure of data. The experimental results show that our new algorithm has better clustering performance than L1 graph.",
        "A1": "propose a Structure Aware (SA) L1 graph to improve the data clustering performance ",
        "A2": " improve the data clustering performance by capturing the manifold structure of input data",
        "A41": " We use a local dictionary for each datum while calculating its sparse coefficients",
        "A51": "However, the information of data such as geometry structure and density distribution are ignored",
        "A61": "",
        "A10": "",
        "A7": "The experimental results show that our new algorithm has better clustering performance than L1 graph",
        "A83": "",
        "A82": "",
        "A81": "our new algorithm has better clustering performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "our new algorithm has better clustering performance than L1 graph.",
        "A53": "based on a numerical optimization motivated by Compressive Sensing theory",
        "A43": "Structure Aware (SA) L1 graph",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 372558672
    },
    {
        "Abstract": "Convolutional neural networks (CNNs) have achieved impressive performance in a wide range of computer vision areas. However, the application on mobile devices remains intractable due to the high computation complexity. In this demo, we propose the Quantized CNN (Q-CNN), an efficient framework for CNN models, to fulfill efficient and accurate image classification on mobile devices. Our Q-CNN framework dramatically accelerates the computation and reduces the storage/memory consumption, so that mobile devices can independently run an ImageNet-scale CNN model. Experiments on the ILSVRC-12 dataset demonstrate 4~6x speed-up and 15~20x compression, with merely one percentage drop in the classification accuracy. Based on the Q-CNN framework, even mobile devices can accurately classify images within one second.",
        "A1": "we propose the Quantized CNN (Q-CNN), an efficient framework for CNN models",
        "A2": "to fulfill efficient and accurate image classification on mobile devices",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "demonstrate 4~6x speed-up and 15~20x compression",
        "A7": "Experiments on the ILSVRC-12 dataset",
        "A83": "",
        "A82": "mobile devices can accurately classify images within one second",
        "A81": "4~6x speed-up and 15~20x compression, with merely one percentage drop in the classification accuracy",
        "A64": "dramatically accelerates the computation and reduces the storage/memory consumption",
        "A54": "",
        "A44": "Q-CNN framework dramatically accelerates the computation and reduces the storage/memory consumption",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 21235400
    },
    {
        "Abstract": "It has been shown that learning distributed word representations is highly useful for Twitter sentiment classification.Most existing models rely on a single distributed representation for each word.This is problematic for sentiment classification because words are often polysemous and each word can contain different sentiment polarities under different topics.We address this issue by learning topic-enriched multi-prototype word embeddings (TMWE).In particular, we develop two neural networks which 1) learn word embeddings that better capture tweet context by incorporating topic information, and 2) learn topic-enriched multiple prototype embeddings for each word.Experiments on Twitter sentiment benchmark datasets in SemEval 2013 show that TMWE outperforms the top system with hand-crafted features, and the current best neural network model.",
        "A1": "address this issue by learning topic-enriched multi-prototype word embeddings (TMWE)",
        "A2": "words are often polysemous and each word can contain different sentiment polarities under different topics",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "TMWE outperforms the top system with hand-crafted features, and the current best neural network model",
        "A7": "Experiments on Twitter sentiment benchmark datasets in SemEval 2013",
        "A83": "",
        "A82": "",
        "A81": "TMWE outperforms the top system with hand-crafted features, and the current best neural network model",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "learning topic-enriched multi-prototype word embeddings (TMWE)",
        "A52": "",
        "A42": "two neural networks which 1) learn word embeddings that better capture tweet context by incorporating topic information, and 2) learn topic-enriched multiple prototype embeddings for each word",
        "A45": "",
        "am_id": 482641915
    },
    {
        "Abstract": "Query-Focused Summarization (QFS) summarizes a document cluster in response to a specific input query. QFS algorithms must combine query relevance assessment, central content identification, and redundancy avoidance. Frustratingly, state of the art algorithms designed for QFS do not significantly improve upon generic summarization methods, which ignore query relevance, when evaluated on traditional QFS datasets. We hypothesize this lack of success stems from the nature of the dataset. We define a task-based method to quantify topic concentration in datasets, i.e., the ratio of sentences within the dataset that are relevant to the query, and observe that the DUC 2005, 2006 and 2007 datasets suffer from very high topic concentration. We introduce TD-QFS, a new QFS dataset with controlled levels of topic concentration. We compare competitive baseline algorithms on TD-QFS and report strong improvement in ROUGE performance for algorithms that properly model query relevance as opposed to generic summarizers. We further present three new and simple QFS algorithms, RelSum, ThresholdSum, and TFIDF-KLSum that outperform state of the art QFS algorithms on the TD-QFS dataset by a large margin.",
        "A1": "define a task-based method to quantify topic concentration in datasets",
        "A2": "define a task-based method to quantify topic concentration in datasets",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "strong improvement in ROUGE performance for algorithms that properly model query relevance as opposed to generic summarizers",
        "A81": "outperform state of the art QFS algorithms on the TD-QFS dataset by a large margin",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "RelSum, ThresholdSum, and TFIDF-KLSum",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a new QFS dataset with controlled levels of topic concentration",
        "am_id": 440011101
    },
    {
        "Abstract": "We present preliminary work to construct a knowledge curation system to advance research in the study of regional economics. The proposed system exploits natural language processing (NLP) techniques to automatically implement business event extraction, provides a user-facing interface to assist human curators, and a feedback loop to improve the performance of the Information Extraction Model for the automated parts of the system. Progress to date has shown that we can improve standard NLP approaches for entity and relationship extraction through heuristic means and provide indexing of extracted relationships to aid curation.",
        "A1": "construct a knowledge curation system to advance research in the study of regional economics",
        "A2": "construct a knowledge curation system to advance research in the study of regional economics",
        "A41": "exploits natural language processing (NLP) techniques to automatically implement business event extraction, provides a user-facing interface to assist human curators, and a feedback loop to improve the performance of the Information Extraction Model for the automated parts of the system",
        "A51": "natural language processing (NLP)",
        "A61": "",
        "A10": "improve the performance of the Information Extraction Model for the automated parts of the system",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "we can improve standard NLP approaches for entity and relationship extraction through heuristic means and provide indexing of extracted relationships to aid curation",
        "A64": "",
        "A54": "natural language processing (NLP)",
        "A44": "The proposed system exploits natural language processing (NLP) techniques to automatically implement business event extraction, provides a user-facing interface to assist human curators, and a feedback loop to improve the performance of the Information Extraction Model for the automated parts of the system",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 416328779
    },
    {
        "Abstract": "We investigate the problem of learning description logic (DL) ontologies in Angluin et al.\u2019s framework of exact learning via queries posed to an oracle. We consider membership queries of the form \u201cis a tuple a of individuals a certain answer to a data retrieval query q in a given ABox and the unknown target ontology?\u201d and completeness queries of the form \u201cdoes a hypothesis ontology entail the unknown target ontology?\u201d Given a DL L and a data retrieval query language Q, we study polynomial learnability of ontologies in L using data retrieval queries in Q and provide an almost complete classification for DLs that are fragments of EL with role inclusions and of DL-Lite and for data retrieval queries that range from atomic queries and EL/ELI-instance queries to conjunctive queries. Some results are proved by non-trivial reductions to learning from subsumption examples.",
        "A1": " study polynomial learnability of ontologies",
        "A2": "learning description logic (DL) ontologies in Angluin et al.\u2019s framework of exact learning via queries posed to an oracle",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "membership queries",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "polynomial learnability of ontologies",
        "A42": "learning description logic (DL) ontologies",
        "A45": "",
        "am_id": 445122647
    },
    {
        "Abstract": "This paper considers prescriptive evacuation planning for a region threatened by a natural disaster such a flood, a wildfire, or a hurricane. It proposes a Benders decomposition that generalizes the two-stage approach proposed in earlier work for convergent evacuation plans. Experimental results show that Benders decomposition provides significant improvements in solution quality in reasonable time: It finds provably optimal solutions to scenarios considered in prior work, closing these instances, and increases the number of evacuees by 10 to 15% on average on more complex flood scenarios.",
        "A1": "considers prescriptive evacuation planning for a region threatened by a natural disaster such a flood, a wildfire, or a hurricane",
        "A2": "evacuation planning for a region threatened by a natural disaster such a flood, a wildfire, or a hurricane",
        "A41": " a Benders decomposition that generalizes the two-stage approach proposed in earlier work for convergent evacuation plans",
        "A51": "a Benders decomposition",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "It finds provably optimal solutions to scenarios considered in prior work, closing these instances, and increases the number of evacuees by 10 to 15% on average on more complex flood scenarios",
        "A81": "Benders decomposition provides significant improvements in solution quality in reasonable time",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 457235580
    },
    {
        "Abstract": "We consider the problem of modeling temporal textual data taking endogenous and exogenous processes into account. Such text documents arise in real world applications, including job advertisements and economic news articles, which are influenced by the fluctuations of the general economy. We propose a hierarchical Bayesian topic model which imposes a \"group-correlated\" hierarchical structure on the evolution of topics over time incorporating both processes, and show that this model can be estimated from Markov chain Monte Carlo sampling methods. We further demonstrate that this model captures the intrinsic relationships between the topic distribution and the time-dependent factors, and compare its performance with latent Dirichlet allocation (LDA) and two other related models. The model is applied to two collections of documents to illustrate its empirical performance: online job advertisements from DirectEmployers Association and journalists' postings on BusinessInsider.com.",
        "A1": "consider the problem of modeling temporal textual data taking endogenous and exogenous processes into account",
        "A2": "the problem of modeling temporal textual data taking endogenous and exogenous processes into account",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "The model is applied to two collections of documents to illustrate its empirical performance: online job advertisements from DirectEmployers Association and journalists' postings on BusinessInsider.com.",
        "A83": "",
        "A82": "",
        "A81": " this model captures the intrinsic relationships between the topic distribution and the time-dependent factors, and compare its performance with latent Dirichlet allocation (LDA) and two other related models. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " imposes a \"group-correlated\" hierarchical structure on the evolution of topics over time incorporating both processes, and show that this model can be estimated from Markov chain Monte Carlo sampling methods.",
        "A52": "hierarchical Bayesian topic",
        "A42": " hierarchical Bayesian topic model which imposes a \"group-correlated\" hierarchical structure on the evolution of topics over time incorporating both processes,",
        "A45": "",
        "am_id": 235519680
    },
    {
        "Abstract": "What capabilities are required for an AI system to pass standard 4th Grade Science Tests? Previous work has examined the use of Markov Logic Networks (MLNs) to represent the requisite background knowledge and interpret test questions, but did not improve upon an information retrieval (IR) baseline. In this paper, we describe an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base, to achieve substantially improved results. We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions), and show that our overall system\u2019s score is 71.3%, an improvement of 23.8% (absolute) over the MLN-based method described in previous work. We conclude with a detailed analysis, illustrating the complementary strengths of each method in the ensemble. Our datasets are being released to enable further research.",
        "A1": "What capabilities are required for an AI system to pass standard 4th Grade Science Tests",
        "A2": "What capabilities are required for an AI system to pass standard 4th Grade Science Tests",
        "A41": "an alternative approach that operates at three levels of representation and reasoning: information retrieval, corpus statistics, and simple inference over a semi-automatically constructed knowledge base",
        "A51": " information retrieval, corpus statistics, and simple inference",
        "A61": "",
        "A10": " an improvement of 23.8% (absolute) over the MLN-based method described in previous work",
        "A7": " We evaluate the methods on six years of unseen, unedited exam questions from the NY Regents Science Exam (using only non-diagram, multiple choice questions)",
        "A83": "",
        "A82": " an improvement of 23.8% (absolute) over the MLN-based method described in previous work",
        "A81": "our overall system\u2019s score is 71.3%",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 426748669
    },
    {
        "Abstract": "Zero-shot Recognition (ZSR) is to learn recognition models for novel classes without labeled data. It is a challenging task and has drawn considerable attention in recent years. The basic idea is to transfer knowledge from seen classes via the shared attributes. This paper focus on the transductive ZSR, i.e., we have unlabeled data for novel classes. Instead of learning models for seen and novel classes separately as in existing works, we put forward a novel joint learning approach which learns the shared model space (SMS) for models such that the knowledge can be effectively transferred between classes using the attributes. An effective algorithm is proposed for optimization. We conduct comprehensive experiments on three benchmark datasets for ZSR. The results demonstrates that the proposed SMS can significantly outperform the state-of-the-art related approaches which validates its efficacy for the ZSR task.",
        "A1": "transductive ZSR",
        "A2": " the knowledge can be effectively transferred between classes using the attributes",
        "A41": "a novel joint learning approach which learns the shared model space (SMS) for models such that the knowledge can be effectively transferred between classes using the attributes",
        "A51": "",
        "A61": "",
        "A10": " the proposed SMS can significantly outperform the state-of-the-art related approaches which validates its efficacy for the ZSR task",
        "A7": "three benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": " the proposed SMS can significantly outperform the state-of-the-art related approaches which validates its efficacy for the ZSR task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 153569047
    },
    {
        "Abstract": "Semi-definite rank minimization problems model a wide range of applications in both signal processing and machine learning fields. This class of problem is NP-hard in general. In this paper, we propose a proximal Alternating Direction Method (ADM) for the well-known semi-definite rank regularized minimization problem. Specifically, we first reformulate this NP-hard problem as an equivalent biconvex MPEC (Mathematical Program with Equilibrium Constraints), and then solve it using proximal ADM, which involves solving a sequence of structured convex semi-definite subproblems to find a desirable solution to the original rank regularized optimization problem. Moreover, based on the Kurdyka-Lojasiewicz inequality, we prove that the proposed method always converges to a KKT stationary point under mild conditions. We apply the proposed method to the widely studied and popular sensor network localization problem. Our extensive experiments demonstrate that the proposed algorithm outperforms state-of-the-art low-rank semi-definite minimization algorithms in terms of solution quality.",
        "A1": "propose a proximal Alternating Direction Method (ADM) for the well-known semi-definite rank regularized minimization problem",
        "A2": "",
        "A41": "proximal Alternating Direction Method",
        "A51": "",
        "A61": "",
        "A10": "the proposed algorithm outperforms state-of-the-art low-rank semi-definite minimization algorithms in terms of solution quality",
        "A7": "sensor network localization problem",
        "A83": "",
        "A82": "",
        "A81": "the proposed algorithm outperforms state-of-the-art low-rank semi-definite minimization algorithms in terms of solution quality",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 228837763
    },
    {
        "Abstract": "We cast the Proactive Learning (PAL) problem\u2014Active Learning (AL) with multiple reluctant, fallible, cost-varying oracles\u2014as a Partially Observable Markov Decision Process (POMDP). The agent selects an oracle at each time step to label a data point, while it maintains a belief over the true underlying correctness of its current dataset\u2019s labels. The goal is to minimize labeling costs while considering the value of obtaining correct labels, thus maximizing final resultant classifier accuracy. We prove three properties that show our particular formulation leads to a structured and bounded-size set of belief points, enabling strong performance of point-based methods to solve the POMDP. Our method is compared with the original three algorithms proposed by Donmez and Carbonell and a simple baseline. We demonstrate that our approach matches or improves upon the original approach within five different oracle scenarios, each on two datasets. Finally, our algorithm provides a general, well-defined mathematical foundation to build upon.",
        "A1": "We cast the Proactive Learning (PAL) problem\u2014Active Learning (AL) with multiple reluctant, fallible, cost-varying oracles\u2014as a Partially Observable Markov Decision Process (POMDP).",
        "A2": "The goal is to minimize labeling costs while considering the value of obtaining correct labels, thus maximizing final resultant classifier accuracy. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our particular formulation leads to a structured and bounded-size set of belief points, enabling strong performance of point-based methods to solve the POMDP. Our method is compared with the original three algorithms proposed by Donmez and Carbonell and a simple baseline.",
        "A7": ". We demonstrate that our approach matches or improves upon the original approach within five different oracle scenarios, each on two datasets. ",
        "A83": "",
        "A82": "our algorithm provides a general, well-defined mathematical foundation to build upon.",
        "A81": "enabling strong performance of point-based methods to solve the POMDP",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "our particular formulation leads to a structured and bounded-size set of belief points, enabling strong performance of point-based methods to solve the POMDP.",
        "A53": "he original three algorithms proposed by Donmez and Carbonell and a simple baseline.",
        "A43": " The agent selects an oracle at each time step to label a data point, while it maintains a belief over the true underlying correctness of its current dataset\u2019s label",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 386846831
    },
    {
        "Abstract": "Within the framework of probably approximately correct Markov decision processes (PAC-MDP), much theoretical work has focused on methods to attain near optimality after a relatively long period of learning and exploration. However, practical concerns require the attainment of satisfactory behavior within a short period of time. In this paper, we relax the PAC-MDP conditions to reconcile theoretically driven exploration methods and practical needs. We propose simple algorithms for discrete and continuous state spaces, and illustrate the benefits of our proposed relaxation via theoretical analyses and numerical examples. Our algorithms also maintain anytime error bounds and average loss bounds. Our approach accommodates both Bayesian and non-Bayesian methods.",
        "A1": "the attainment of satisfactory behavior within a short period of time",
        "A2": "probably approximately correct Markov decision processes (PAC-MDP)",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "attainment of satisfactory behavior within a short period of time",
        "A7": "theoretical analyses and numerical examples",
        "A83": "Our approach accommodates both Bayesian and non-Bayesian methods",
        "A82": "Our algorithms also maintain anytime error bounds and average loss bounds",
        "A81": "practical concerns require the attainment of satisfactory behavior within a short period of time.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "relax the PAC-MDP conditions to reconcile theoretically driven exploration methods and practical needs",
        "A53": "relax the PAC-MDP conditions",
        "A43": " simple algorithms for discrete and continuous state spaces",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 233308594
    },
    {
        "Abstract": "We consider the following problem in which a given number of items has to be chosen from a predefined set. Each item is described by a vector of attributes and for each attribute there is a desired distribution that the selected set should fit. We look for a set that fits as much as possible the desired distributions on all attributes. Examples of applications include choosing members of a representative committee, where candidates are described by attributes such as sex, age and profession, and where we look for a committee that for each attribute offers a certain representation, i.e., a single committee that contains a certain number of young and old people, certain number of men and women, certain number of people with different professions, etc. With a single attribute the problem boils down to the apportionment problem for party-list proportional representation systems (in such case the value of the single attribute is the political affiliation of a candidate). We study some properties of the associated subset selection rules, and address their computation.",
        "A1": "We consider the following problem in which a given number of items has to be chosen from a predefined set.",
        "A2": "We consider the following problem in which a given number of items has to be chosen from a predefined set",
        "A41": "ook for a set that fits as much as possible the desired distributions on all attributes. ",
        "A51": " Each item is described by a vector of attributes and for each attribute there is a desired distribution that the selected set should fit. ",
        "A61": "",
        "A10": "",
        "A7": "Examples of applications include choosing members of a representative committee, where candidates are described by attributes such as sex, age and profession,",
        "A83": "",
        "A82": "",
        "A81": "We study some properties of the associated subset selection rules, and address their computation.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "With a single attribute the problem boils down to the apportionment problem for party-list proportional representation systems (in such case the value of the single attribute is the political affiliation of a candidate).",
        "A43": " We study some properties of the associated subset selection rules, and address their computation.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 124784239
    },
    {
        "Abstract": "We address the problem of learning behaviour policies to optimise online metrics from heterogeneous usage data. While online metrics, e.g., click-through rate, can be optimised effectively using exploration data, such data is costly to collect in practice, as it temporarily degrades the user experience. Leveraging related data sources to improve online performance would be extremely valuable, but is not possible using current approaches. We formulate this task as a policy transfer learning problem, and propose a first solution, called collective noise contrastive estimation (collective NCE). NCE is an efficient solution to approximating the gradient of a log-softmax objective. Our approach jointly optimises embeddings of heterogeneous data to transfer knowledge from the source domain to the target domain. We demonstrate the effectiveness of our approach by learning an effective policy for an online radio station jointly from user-generated playlists, and usage data collected in an exploration bucket.",
        "A1": "We address the problem of learning behaviour policies to optimise online metrics from heterogeneous usage data. ",
        "A2": "the problem of learning behaviour policies to optimise online metrics from heterogeneous usage data",
        "A41": "collective noise contrastive estimation",
        "A51": "",
        "A61": " NCE is an efficient solution to approximating the gradient of a log-softmax objective. ",
        "A10": " NCE is an efficient solution",
        "A7": "learning an effective policy for an online radio station jointly from user-generated playlists, and usage data collected in an exploration bucket",
        "A83": "",
        "A82": "NCE is an efficient solution to approximating the gradient of a log-softmax objective",
        "A81": "the effectiveness of our approach",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Leveraging related data sources to improve online performance",
        "A42": "policy transfer learning problem",
        "A45": "",
        "am_id": 371196577
    },
    {
        "Abstract": "Real-time bidding has become one of the largest online advertising markets in the world. Today the bid price per ad impression is typically decided by the expected value of how it can lead to a desired action event to the advertiser. However, this industry standard approach to decide the bid price does not consider the actual effect of the ad shown to the user, which should be measured based on the performance lift among users who have been or have not been exposed to a certain treatment of ads. In this paper, we propose a new bidding strategy and prove that if the bid price is decided based on the performance lift rather than absolute performance value, advertisers can actually gain more action events. We describe the modeling methodology to predict the performance lift and demonstrate the actual performance gain through blind A/B test with real ad campaigns. We also show that to move the demand-side platforms to bid based on performance lift, they should be rewarded based on the relative performance lift they contribute.",
        "A1": "a new bidding strategy and prove that if the bid price is decided based on the performance lift rather than absolute performance value",
        "A2": "advertisers can actually gain more action events",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "blind A/B test with real ad campaigns",
        "A42": "We describe the modeling methodology to predict the performance lift and demonstrate the actual performance gain",
        "A45": "",
        "am_id": 114655269
    },
    {
        "Abstract": "The Temporal Network with Uncertainty (TNU) modeling framework is used to represent temporal knowledge in presence of qualitative temporal uncertainty. Dynamic Controllability (DC) is the problem of deciding the existence of a strategy for scheduling the controllable time points of the network observing past happenings only. In this paper, we address the DC problem for a very general class of TNU, namely Disjunctive Temporal Network with Uncertainty. We make the following contributions. First, we define strategies in the form of an executable language; second, we propose the first decision procedure to check whether a given strategy is a solution for the DC problem; third we present an efficient algorithm for strategy synthesis based on techniques derived from Timed Games and Satisfiability Modulo Theory. The experimental evaluation shows that the approach is superior to the state-of-the-art.",
        "A1": "",
        "A2": " the DC problem for a very general class of TNU",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the approach is superior to the state-of-the-art.",
        "A7": "",
        "A83": "present an efficient algorithm for strategy synthesis based on techniques derived from Timed Games and Satisfiability Modulo Theory",
        "A82": "propose the first decision procedure to check whether a given strategy is a solution for the DC problem",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": " Temporal Network with Uncertainty (TNU) modeling framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 495265552
    },
    {
        "Abstract": "Unsupervised feature selection (UFS) aims to reduce the time complexity and storage burden, as well as improve the generalization performance. Most existing methods convert UFS to supervised learning problem by generating labels with specific techniques (e.g., spectral analysis, matrix factorization and linear predictor). Instead, we proposed a novel coupled analysis-synthesis dictionary learning method, which is free of generating labels. The representation coefficients are used to model the cluster structure and data distribution. Specifically, the synthesis dictionary is used to reconstruct samples, while the analysis dictionary analytically codes the samples and assigns probabilities to the samples. Afterwards, the analysis dictionary is used to select features that can well preserve the data distribution.xa0The effective L2p-norm (0 < p <1) regularization is imposed on the analysis dictionary to get much sparse solution and is more effective in feature selection.We proposed an iterative reweighted least squares algorithm to solve the L2p-norm optimization problem and proved it can converge to a fixed point. Experiments on benchmark datasets validated the effectiveness of the proposed method",
        "A1": "Instead, we proposed a novel coupled analysis-synthesis dictionary learning method, which is free of generating labels. ",
        "A2": "",
        "A41": "Instead, we proposed a novel coupled analysis-synthesis dictionary learning method, which is free of generating labels. ",
        "A51": "The representation coefficients are used to model the cluster structure and data distribution.",
        "A61": "Specifically, the synthesis dictionary is used to reconstruct samples, while the analysis dictionary analytically codes the samples and assigns probabilities to the samples. ",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "Afterwards, the analysis dictionary is used to select features that can well preserve the data distribution.xa0The effective L2p-norm (0 < p ",
        "A81": "Specifically, the synthesis dictionary is used to reconstruct samples, while the analysis dictionary analytically codes the samples and assigns probabilities to the samples.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 52356218
    },
    {
        "Abstract": "People believe that depth plays an important role in success of deep neural networks (DNN). However, this belief lacks solid theoretical justifications as far as we know. We investigate role of depth from perspective of margin bound. In margin bound, expected error is upper bounded by empirical margin error plus Rademacher Average (RA) based capacity term. First, we derive an upper bound for RA of DNN, and show that it increases with increasing depth. This indicates negative impact of depth on test performance. Second, we show that deeper networks tend to have larger representation power (measured by Betti numbers based complexity) than shallower networks in multi-class setting, and thus can lead to smaller empirical margin error. This implies positive impact of depth. The combination of these two results shows that for DNN with restricted number of hidden units, increasing depth is not always good since there is a tradeoff between positive and negative impacts. These results inspire us to seek alternative ways to achieve positive impact of depth, e.g., imposing margin-based penalty terms to cross entropy loss so as to reduce empirical margin error without increasing depth. Our experiments show that in this way, we achieve significantly better test performance.",
        "A1": "investigate role of depth from perspective of margin bound",
        "A2": "investigate role of depth from perspective of margin bound",
        "A41": "investigate role of depth from perspective of margin bound",
        "A51": "deep neural networks",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "we achieve significantly better test performance",
        "A81": "increasing depth is not always good since there is a tradeoff between positive and negative impacts",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 320723895
    },
    {
        "Abstract": "Targeted sentiment analysis classifies the sentiment polarity towards each target entity mention in given text documents. Seminal methods extract manual discrete features from automatic syntactic parse trees in order to capture semantic information of the enclosing sentence with respect to a target entity mention. Recently, it has been shown that competitive accuracies can be achieved without using syntactic parsers, which can be highly inaccurate on noisy text such as tweets. This is achieved by applying distributed word representations and rich neural pooling functions over a simple and intuitive segmentation of tweets according to target entity mentions. In this paper, we extend this idea by proposing a sentence-level neural model to address the limitation of pooling functions, which do not explicitly model tweet-level semantics. First, a bi-directional gated neural network is used to connect the words in a tweet so that pooling functions can be applied over the hidden layer instead of words for better representing the target and its contexts. Second, a three-way gated neural network structure is used to model the interaction between the target mention and its surrounding contexts. Experiments show that our proposed model gives significantly higher accuracies compared to the current best method for targeted sentiment analysis.",
        "A1": " address the limitation of pooling functions, which do not explicitly model tweet-level semantics. ",
        "A2": "limitation of pooling functions, which do not explicitly model tweet-level semantics. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "gives significantly higher accuracies",
        "A7": "targeted sentiment analysis.",
        "A83": "",
        "A82": "",
        "A81": "gives significantly higher accuracies",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "First, a bi-directional gated neural network is used to connect the words in a tweet so that pooling functions can be applied over the hidden layer instead of words for better representing the target and its contexts. Second, a three-way gated neural network structure is used to model the interaction between the target mention and its surrounding contexts",
        "A52": "applying distributed word representations and rich neural pooling functions over a simple and intuitive segmentation of tweets according to target entity mentions",
        "A42": "a sentence-level neural model",
        "A45": "",
        "am_id": 496921281
    },
    {
        "Abstract": "Despite recent improvements in search techniques for cost-optimal classical planning, the exponential growth of the size of the search frontier in A* is unavoidable. We investigate tiebreaking strategies for A*, experimentally analyzing the performance of standard tiebreaking strategies that break ties according to the heuristic value of the nodes. We find that tiebreaking has a significant impact on search algorithm performance when there are zero-cost operators that induce large plateau regions in the search space. We develop a new framework for tiebreaking based on a depth metric which measures distance from the entrance to the plateau, and propose a new, randomized strategy which significantly outperforms standard strategies on domains with zero-cost actions.",
        "A1": "investigate tiebreaking strategies for A*",
        "A2": "",
        "A41": "a new, randomized strategy ",
        "A51": "a depth metric which measures distance from the entrance to the plateau",
        "A61": "",
        "A10": "significantly outperforms standard strategies on domains with zero-cost actions.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 289133717
    },
    {
        "Abstract": "Boolean functions in Answer Set Programming have proven a useful modelling tool. They are usually specified by means of aggregates or external atoms. A crucial step in computing answer sets for logic programs containing Boolean functions is verifying whether partial interpretations satisfy a Boolean function for all possible values of its undefined atoms. In this paper, we develop a new methodology for showing when such checks can be done in deterministic polynomial time. This provides a unifying view on all currently known polynomial-time decidability results, and furthermore identifies promising new classes that go well beyond the state of the art. Our main technique consists of using an ordering on the atoms to significantly reduce the necessary number of model checks. For many standard aggregates, we show how this ordering can be automatically obtained.",
        "A1": "",
        "A2": " verifying whether partial interpretations satisfy a Boolean function for all possible values of its undefined atoms",
        "A41": "using an ordering on the atoms to significantly reduce the necessary number of model checks",
        "A51": "",
        "A61": "",
        "A10": "identifies promising new classes that go well beyond the state of the art",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "a unifying view on all currently known polynomial-time decidability results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 135037205
    },
    {
        "Abstract": "Metric learning has become a critical tool in many machine learning tasks. This paper focuses on learning an optimal Mahalanobis distance matrix (parameterized by a positive semi-definite matrix W) in the setting of supervised learning. Recently, particular research attention has been attracted by low-rank metric learning, which requires that matrix W is dominated by a few large singular values. In the era of high feature dimensions, low-rank metric learning effectively reduces the storage and computation overheads. However, existing low-rank metric learning algorithms usually adopt sophisticated regularization (such as LogDet divergence) for encouraging matrix low-rankness, which unfortunately incur iterative computations of matrix SVD. In this paper, we tackle low-rank metric learning by enforcing fixed-rank constraint on the matrix W. We harness the Riemannian manifold geometry of the collection of fixed-rank matrices and devise a novel second-order Riemannian retraction operator. The proposed operator is efficient and ensures that W always resides on the manifold. Comprehensive numerical experiments conducted on benchmarks clearly suggest that the proposed algorithm is substantially superior or on par with the state-of-the-art in terms of k-NN classification accuracy. Moreover, the proposed manifold retraction operator can be also naturally applied in generic rank-constrained machine learning algorithms.",
        "A1": " learning an optimal Mahalanobis distance matrix",
        "A2": "existing low-rank metric learning algorithms usually adopt sophisticated regularization",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the proposed algorithm is substantially superior or on par with the state-of-the-art in terms of k-NN classification accuracy",
        "A7": "the proposed algorithm is substantially superior or on par with the state-of-the-art in terms of k-NN classification accuracy",
        "A83": "",
        "A82": "can be also naturally applied in generic rank-constrained machine learning algorithms",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "tackle low-rank metric learning by enforcing fixed-rank constraint on the matrix W",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 480175659
    },
    {
        "Abstract": "Due to the nonlinear but highly interpretable representations,decision tree (DT) models have significantly attracted a lot of attention of researchers. However, DT models usually suffer from the curse of dimensionality and achieve degenerated performance when there are many noisy features. To address these issues, this paper first presents a novel data-dependent generalization error bound for the perceptron decision tree(PDT), which provides the theoretical justification to learn a sparse linear hyperplane in each decision node and to prune the tree. Following our analysis, we introduce the notion of sparse perceptron decision node (SPDN) with a budget constraint on the weight coefficients, and propose a sparse perceptron decision tree (SPDT) algorithm to achieve nonlinear prediction performance. To avoid generating an unstable and complicated decision tree and improve the generalization of the SPDT, we present a pruning strategy by learning classifiers to minimize cross-validation errors on each SPDN. Extensive empirical studies verify that our SPDT is more resilient to noisy features and effectively generates a small,yet accurate decision tree. Compared with state-of-the-art DT methods and SVM, our SPDT achieves better generalization performance on ultrahigh dimensional problems with more than 1 million features.",
        "A1": "this paper first presents a novel data-dependent generalization error bound for the perceptron decision tree(PDT),",
        "A2": "DT models usually suffer from the curse of dimensionality and achieve degenerated performance when there are many noisy features.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Compared with state-of-the-art DT methods and SVM, our SPDT achieves better generalization performance on ultrahigh dimensional problems with more than 1 million features.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " our SPDT is more resilient to noisy features and effectively generates a small,yet accurate decision tree",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "provides the theoretical justification to learn a sparse linear hyperplane in each decision node and to prune the tree",
        "A43": "a sparse perceptron decision tree (SPDT) algorithm to achieve nonlinear prediction performance. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 214480759
    },
    {
        "Abstract": "We study how to communicate findings of Bayesian inference to third parties, while preserving the strong guarantee of differential privacy. Our main contributions are four different algorithms for private Bayesian inference on probabilistic graphical models. These include two mechanisms for adding noise to the Bayesian updates, either directly to the posterior parameters, or to their Fourier transform so as to preserve update consistency. We also utilise a recently introduced posterior sampling mechanism, for which we prove bounds for the specific but general case of discrete Bayesian networks; and we introduce a maximum-a-posteriori private mechanism. Our analysis includes utility and privacy bounds, with a novel focus on the influence of graph structure on privacy. Worked examples and experiments with Bayesian naive Bayes and Bayesian linear regression illustrate the application of our mechanisms.",
        "A1": " communicate findings of Bayesian inference to third parties",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Worked examples and experiments with Bayesian naive Bayes and Bayesian linear regression",
        "A83": "",
        "A82": "",
        "A81": " illustrate the application of our mechanisms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": " Bayesian inference",
        "A43": "algorithms for private Bayesian inference on probabilistic graphical models",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 281006830
    },
    {
        "Abstract": "Instead of using a uniform metric, instance specific distance learning methods assign multiple metrics for different localities, which take data heterogeneity into consideration. Therefore, they may improve the performance of distance based classifiers, e.g., kNN. Existing methods obtain multiple metrics of test data by either transductively assigning metrics for unlabeled instances or designing distance functions manually, which are with limited generalization ability. In this paper, we propose isMets (Instance Specific METric Subspace) framework which can automatically span the whole metric space in a generative manner and is able to inductively learn a specific metric subspace for each instance via inferring the expectation over the metric bases in a Bayesian manner. The whole framework can be solved with Variational Bayes (VB). Experiment on synthetic data shows that the learned results are with good interpretability. Moreover, comprehensive results on real world datasets validate the effectiveness and robustness of isMets.",
        "A1": "",
        "A2": "Existing methods obtain multiple metrics of test data by either transductively assigning metrics for unlabeled instances or designing distance functions manually, which are with limited generalization ability.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiment on synthetic data",
        "A83": "",
        "A82": "comprehensive results on real world datasets validate the effectiveness and robustness of isMets.",
        "A81": "the learned results are with good interpretability",
        "A64": "can automatically span the whole metric space in a generative manner",
        "A54": "Bayesian manner",
        "A44": "isMets (Instance Specific METric Subspace) framework which can automatically span the whole metric space in a generative manner and is able to inductively learn a specific metric subspace for each instance via inferring the expectation over the metric bases in a Bayesian manner.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 281317290
    },
    {
        "Abstract": "Binary code learning, a.k.a., hashing, has been recently popular due to its high efficiency in large-scale similarity search and recognition. It typically maps high-dimensional data points to binary codes, where data similarity can be efficiently computed via rapid Hamming distance. Most existing unsupervised hashing schemes pursue binary codes by reducing the quantization error from an original real-valued data space to a resulting Hamming space. On the other hand, most existing supervised hashing schemes constrain binary code learning to correlate with pairwise similarity labels. However, few methods consider ordinal relations in the binary code learning process, which serve as a very significant cue to learn the optimal binary codes for similarity search. In this paper, we propose a novel hashing scheme, dubbed Ordinal Embedding Hashing (OEH), which embeds given ordinal relations among data points to learn the ranking-preserving binary codes. The core idea is to construct a directed unweighted graph to capture the ordinal relations, and then train the hash functions using this ordinal graph to preserve the permutation relations in the Hamming space. To learn such hash functions effectively, we further relax the discrete constraints and design a stochastic gradient decent algorithm to obtain the optimal solution. Experimental results on two large-scale benchmark datasets demonstrate that the proposed OEH method can achieve superior performance over the state-of-the-arts approaches.At last, the evaluation on query by humming dataset demonstrates the OEH also has good performance for music retrieval by using user's humming or singing.",
        "A1": "we propose a novel hashing scheme, dubbed Ordinal Embedding Hashing (OEH)",
        "A2": "few methods consider ordinal relations in the binary code learning process, which serve as a very significant cue to learn the optimal binary codes for similarity search.",
        "A41": "a novel hashing scheme, dubbed Ordinal Embedding Hashing (OEH), which embeds given ordinal relations among data points to learn the ranking-preserving binary codes. ",
        "A51": "to construct a directed unweighted graph to capture the ordinal relations, and then train the hash functions using this ordinal graph to preserve the permutation relations in the Hamming space",
        "A61": "few methods consider ordinal relations in the binary code learning process, which serve as a very significant cue to learn the optimal binary codes for similarity search.",
        "A10": "",
        "A7": "on two large-scale benchmark datasets ",
        "A83": "",
        "A82": "the evaluation on query by humming dataset demonstrates the OEH also has good performance for music retrieval by using user's humming or singing.",
        "A81": "the proposed OEH method can achieve superior performance over the state-of-the-arts approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 409231510
    },
    {
        "Abstract": "Entity Set Expansion (ESE) and Attribute Extraction (AE) are usually treated as two separate tasks in Information Extraction (IE). However, the two tasks are tightly coupled, and each task can benefit significantly from the other by leveraging the inherent relationship between entities and attributes. That is, 1) an attribute is important if it is shared by many typical entities of a class; 2) an entity is typical if it owns many important attributes of a class. Based on this observation, we propose a joint model for ESE and AE, which models the inherent relationship between entities and attributes as a graph. Then a graph reinforcement algorithm is proposed to jointly mine entities and attributes of a specific class. Experimental results demonstrate the superiority of our method for discovering both new entities and new attributes.",
        "A1": "we propose a joint model for ESE and AE,",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experimental results demonstrate the superiority of our method for discovering both new entities and new attributes.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experimental results demonstrate the superiority of our method for discovering both new entities and new attributes.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a graph reinforcement algorithm is proposed to jointly mine entities and attributes of a specific class",
        "A62": "",
        "A52": "",
        "A42": "a joint model for ESE and AE, which models the inherent relationship between entities and attributes as a graph",
        "A45": "",
        "am_id": 128739421
    },
    {
        "Abstract": "We present a siamese adaptation of the Long Short-Term Memory (LSTM) network for labeled data comprised of pairs of variable-length sequences. Our model is applied to assess semantic similarity between sentences, where we exceed state of the art, outperforming carefully handcrafted features and recently proposed neural network systems of greater complexity. For these applications, we provide word-embedding vectors supplemented with synonymic information to the LSTMs, which use a fixed size vector to encode the underlying meaning expressed in a sentence (irrespective of the particular wording/syntax). By restricting subsequent operations to rely on a simple Manhattan metric, we compel the sentence representations learned by our model to form a highly structured space whose geometry reflects complex semantic relationships. Our results are the latest in a line of findings that showcase LSTMs as powerful language models capable of tasks requiring intricate understanding.",
        "A1": "present a siamese adaptation of the Long Short-Term Memory (LSTM) network for labeled data comprised of pairs of variable-length sequences",
        "A2": "assess semantic similarity between sentences",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " LSTMs as powerful language models capable of tasks requiring intricate understanding.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " LSTMs as powerful language models capable of tasks requiring intricate understanding.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "we exceed state of the art, outperforming carefully handcrafted features and recently proposed neural network systems of greater complexity.",
        "A52": "",
        "A42": "a siamese adaptation of the Long Short-Term Memory (LSTM) network for labeled data comprised of pairs of variable-length sequences. ",
        "A45": "",
        "am_id": 250843396
    },
    {
        "Abstract": "The lack of reliable data in developing countries is a major obstacle to sustainable development, food security, and disaster relief. Poverty data, for example, is typically scarce, sparse in coverage, and labor-intensive to obtain. Remote sensing data such as high-resolution satellite imagery, on the other hand, is becoming increasingly available and inexpensive. Unfortunately, such data is highly unstructured and currently no techniques exist to automatically extract useful insights to inform policy decisions and help direct humanitarian efforts. We propose a novel machine learning approach to extract large-scale socioeconomic indicators from high-resolution satellite imagery. The main challenge is that training data is very scarce, making it difficult to apply modern techniques such as Convolutional Neural Networks (CNN). We therefore propose a transfer learning approach where nighttime light intensities are used as a data-rich proxy. We train a fully convolutional CNN model to predict nighttime lights from daytime imagery, simultaneously learning features that are useful for poverty prediction. The model learns filters identifying different terrains and man-made structures, including roads, buildings, and farmlands, without any supervision beyond nighttime lights. We demonstrate that these learned features are highly informative for poverty mapping, even approaching the predictive performance of survey data collected in the field.",
        "A1": "",
        "A2": "The lack of reliable data in developing countries is a major obstacle to sustainable development, food security, and disaster relief.",
        "A41": "a novel machine learning approach to extract large-scale socioeconomic indicators from high-resolution satellite imagery",
        "A51": "transfer learning",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " these learned features are highly informative for poverty mapping,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 316178456
    },
    {
        "Abstract": "Representation learning (RL) of knowledge graphs aims to project both entities and relations into a continuous low-dimensional space. Most methods concentrate on learning representations with knowledge triples indicating relations between entities. In fact, in most knowledge graphs there are usually concise descriptions for entities, which cannot be well utilized by existing methods. In this paper, we propose a novel RL method for knowledge graphs taking advantages of entity descriptions. More specifically, we explore two encoders, including continuous bag-of-words and deep convolutional neural models to encode semantics of entity descriptions. We further learn knowledge representations with both triples and descriptions. We evaluate our method on two tasks, including knowledge graph completion and entity classification. Experimental results on real-world datasets show that, our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions. The source code of this paper can be obtained from https://github.com/xrb92/DKRL.",
        "A1": "propose a novel RL method for knowledge graphs taking advantages of entity descriptions",
        "A2": "Representation learning (RL) of knowledge graphs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions",
        "A7": "We evaluate our method on two tasks, including knowledge graph completion and entity classification",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms other baselines on the two tasks, especially under the zero-shot setting, which indicates that our method is capable of building representations for novel entities according to their descriptions.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "our method is capable of building representations for novel entities according to their descriptions",
        "A52": "",
        "A42": "continuous bag-of-words and deep convolutional neural models",
        "A45": "",
        "am_id": 119946144
    },
    {
        "Abstract": "We address the problem of robust decision making for stochastic network design. Our work is motivated by spatial conservation planning where the goal is to take management decisions within a fixed budget to maximize the expected spread of a population of species over a network of land parcels. Most previous work for this problem assumes that accurate estimates of different network parameters (edge activation probabilities, habitat suitability scores) are available, which is an unrealistic assumption. To address this shortcoming, we assume that network parameters are only partially known, specified via interval bounds. We then develop a decision making approach that computes the solution with minimax regret. We provide new theoretical results regarding the structure of the minmax regret solution which help develop a computationally efficient approach. Empirically, we show that previous approaches that work on point estimates of network parameters result in high regret on several standard benchmarks, while our approach provides significantly more robust solutions.",
        "A1": "robust decision making for stochastic network design",
        "A2": "robust decision making for stochastic network design",
        "A41": "a decision making approach that computes the solution with minimax regret",
        "A51": "assume that network parameters are only partially known, specified via interval bounds",
        "A61": "Most previous work for this problem assumes that accurate estimates of different network parameters (edge activation probabilities, habitat suitability scores) are available, which is an unrealistic assumption.",
        "A10": "previous approaches that work on point estimates of network parameters result in high regret on several standard benchmarks, while our approach provides significantly more robust solutions",
        "A7": "provide new theoretical results regarding the structure of the minmax regret solution ",
        "A83": "",
        "A82": "our approach provides significantly more robust solutions",
        "A81": "previous approaches that work on point estimates of network parameters result in high regret on several standard benchmarks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 356048696
    },
    {
        "Abstract": "The task of tweet timeline generation (TTG) aims at selecting a small set of representative tweets to generate a meaningful timeline and providing enough coverage for a given topical query. This paper presents an approach based on determinantal point processes (DPPs) by jointly modeling the topical relevance of each selected tweet and overall selectional diversity. Aiming at better treatment for balancing relevance and diversity, we introduce two novel strategies, namely spectral rescaling and topical prior. Extensive experiments on the public TREC 2014 dataset demonstrate that our proposed DPP model along with the two strategies can achieve fairly competitive results against the state-of-the-art TTG systems.",
        "A1": "tweet timeline generation (TTG)",
        "A2": " better treatment for balancing relevance and diversity",
        "A41": "an approach based on determinantal point processes (DPPs) by jointly modeling the topical relevance of each selected tweet and overall selectional diversity",
        "A51": "determinantal point processes (DPPs)",
        "A61": "",
        "A10": "DPP model along with the two strategies can achieve fairly competitive results against the state-of-the-art TTG systems",
        "A7": "xperiments on the public TREC 2014 dataset",
        "A83": "",
        "A82": "",
        "A81": "DPP model along with the two strategies can achieve fairly competitive results against the state-of-the-art TTG systems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 317120900
    },
    {
        "Abstract": "Ontology-based data access (OBDA) is a novel paradigm facilitating access to relational data, realized by linking data sources to an ontology by means of declarative mappings. DL-Lite_R, which is the logic underpinning the W3C ontology language OWL 2 QL and the current language of choice for OBDA, has been designed with the goal of delegating query answering to the underlying database engine, and thus is restricted in expressive power. E.g., it does not allow one to express disjunctive information, and any form of recursion on the data. The aim of this paper is to overcome these limitations of DL-Lite_R, and extend OBDA to more expressive ontology languages, while still leveraging the underlying relational technology for query answering. We achieve this by relying on two well-known mechanisms, namely conservative rewriting and approximation, but significantly extend their practical impact by bringing into the picture the mapping, an essential component of OBDA. Specifically, we develop techniques to rewrite OBDA specifications with an expressive ontology to \"equivalent\" ones with a DL-Lite_R ontology, if possible, and to approximate them otherwise. We do so by exploiting the high expressive power of the mapping layer to capture part of the domain semantics of rich ontology languages. We have implemented our techniques in the prototype system OntoProx, making use of the state-of-the-art OBDA system Ontop and the query answering system Clipper, and we have shown their feasibility and effectiveness with experiments on synthetic and real-world data.",
        "A1": "overcome these limitations of DL-Lite_R, and extend OBDA to more expressive ontology languages, while still leveraging the underlying relational technology for query answering",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we have shown their feasibility and effectiveness with experiments on synthetic and real-world data.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "we have shown their feasibility and effectiveness with experiments on synthetic and real-world data.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "significantly extend their practical impact by bringing into the picture the mapping, an essential component of OBDA",
        "A52": "conservative rewriting and approximation",
        "A42": "conservative rewriting and approximation",
        "A45": "",
        "am_id": 365026415
    },
    {
        "Abstract": "In a landmark paper in the mechanism design literature, Cremer and McLean (1985) (CM for short) show that when a bidder\u2019s valuation is correlated with an external signal, a monopolistic seller is able to extract the full social surplus as revenue. In the original paper and subsequent literature, the focus has been on ex-post incentive compatible (or IC) mechanisms, where truth telling is an ex-post Nash equilibrium. In this paper, we explore the implications of Bayesian versus ex-post IC in a correlated valuation setting. We generalize the full extraction result to settings that do not satisfy the assumptions of CM. In particular, we give necessary and sufficient conditions for full extraction that strictly relax the original conditions given in CM. These more general conditions characterize the situations under which requiring ex-post IC leads to a decrease in expected revenue relative to Bayesian IC. We also demonstrate that the expected revenue from the optimal ex-post IC mechanism guarantees at most a (|\u0398| + 1)/4 approximation to that of a Bayesian IC mechanism, where |\u0398| is the number of bidder types. Finally, using techniques from automated mechanism design, we show that, for randomly generated distributions, the average expected revenue achieved by Bayesian IC mechanisms is significantly larger than that for ex-post IC mechanisms.",
        "A1": "for randomly generated distributions, the average expected revenue achieved by Bayesian IC mechanisms is significantly larger than that for ex-post IC mechanisms.",
        "A2": "or randomly generated distributions, the average expected revenue achieved by Bayesian IC mechanisms is significantly larger than that for ex-post IC mechanisms.",
        "A41": "using techniques from automated mechanism design,",
        "A51": " when a bidder\u2019s valuation is correlated with an external signal, a monopolistic seller is able to extract the full social surplus as revenue.",
        "A61": "we give necessary and sufficient conditions for full extraction that strictly relax the original conditions given in CM",
        "A10": "We also demonstrate that the expected revenue from the optimal ex-post IC mechanism guarantees at most a (|\u0398| + 1)/4 approximation to that of a Bayesian IC mechanism, where |\u0398| is the number of bidder types. ",
        "A7": "we give necessary and sufficient conditions for full extraction that strictly relax the original conditions given in CM. These more general conditions characterize the situations under which requiring ex-post IC leads to a decrease in expected revenue relative to Bayesian IC. We also demonstrate that the expected revenue from the optimal ex-post IC mechanism guarantees at most a (|\u0398| + 1)/4 approximation to that of a Bayesian IC mechanism, where |\u0398| is the number of bidder types. ",
        "A83": "",
        "A82": " when a bidder\u2019s valuation is correlated with an external signal, a monopolistic seller is able to extract the full social surplus as revenue",
        "A81": " for randomly generated distributions, the average expected revenue achieved by Bayesian IC mechanisms is significantly larger than that for ex-post IC mechanisms.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "from the optimal ex-post IC mechanism guarantees at most a (|\u0398| + 1)/4 approximation to that of a Bayesian IC mechanism",
        "A53": " when a bidder\u2019s valuation is correlated with an external signal, a monopolistic seller is able to extract the full social surplus as revenue.",
        "A43": "We also demonstrate that the expected revenue from the optimal ex-post IC mechanism guarantees at most a (|\u0398| + 1)/4 approximation to that of a Bayesian IC mechanism, where |\u0398| is the number of bidder types.",
        "A62": "",
        "A52": " when a bidder\u2019s valuation is correlated with an external signal, a monopolistic seller is able to extract the full social surplus as revenue.",
        "A42": "he situations under which requiring ex-post IC leads to a decrease in expected revenue relative to Bayesian IC",
        "A45": "",
        "am_id": 117435151
    },
    {
        "Abstract": "Vast quantities of videos are now being captured at astonishing rates, but the majority of these are not labelled. To cope with such data, we consider the task of content-based activity recognition in videos without any manually labelled examples, also known as zero-shot video recognition. To achieve this, videos are represented in terms of detected visual concepts, which are then scored as relevant or irrelevant according to their similarity with a given textual query. In this paper, we propose a more robust approach for scoring concepts in order to alleviate many of the brittleness and low precision problems of previous work. Not only do we jointly consider semantic relatedness, visual reliability, and discriminative power. To handle noise and non-linearities in the ranking scores of the selected concepts, we propose a novel pairwise order matrix approach for score aggregation. Extensive experiments on the large-scale TRECVID Multimedia Event Detection data show the superiority of our approach.",
        "A1": "the task of content-based activity recognition in videos without any manually labelled examples",
        "A2": "Vast quantities of videos are now being captured at astonishing rates, but the majority of these are not labelled.",
        "A41": " a more robust approach for scoring concepts",
        "A51": "",
        "A61": "",
        "A10": "the superiority of our approach.",
        "A7": "experiments on the large-scale TRECVID Multimedia Event Detection data ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 443053043
    },
    {
        "Abstract": "Feature selection is essential for effective visual recognition. We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation. Our method requires only the following knowledge, which we call the feature sign - whether or not a particular feature has on average stronger values over positive samples than over negatives. We show how this can be estimated using as few as a single labeled training sample per class. Then, using these feature signs, we extend an initial supervised learning problem into an (almost) unsupervised clustering formulation that can incorporate new data without requiring ground truth labels. Our method works both as a feature selection mechanism and as a fully competitive classifier. It has important properties, low computational cost annd excellent accuracy, especially in difficult cases of very limited training data. We experiment on large-scale recognition in video and show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.",
        "A1": "We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation.",
        "A2": "It has important properties, low computational cost annd excellent accuracy, especially in difficult cases of very limited training data.",
        "A41": " an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation.",
        "A51": " feature sign - whether or not a particular feature has on average stronger values over positive samples than over negatives.",
        "A61": "Our method works both as a feature selection mechanism and as a fully competitive classifier. It has important properties, low computational cost annd excellent accuracy, especially in difficult cases of very limited training data.",
        "A10": "It has important properties, low computational cost annd excellent accuracy, especially in difficult cases of very limited training data. We experiment on large-scale recognition in video and show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.",
        "A7": "We experiment on large-scale recognition in video",
        "A83": "",
        "A82": "",
        "A81": "show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 53499933
    },
    {
        "Abstract": "Only knowing captures the intuitive notion that the beliefs of an agent are precisely those that follow from its knowledge base. It has previously been shown to be useful in characterizing knowledge-based reasoners, especially in a quantified setting. While this allows us to reason about incomplete knowledge in the sense of not knowing whether a formula is true or not, there are many applications where one would like to reason about the degree of belief in a formula. In this work, we propose a new general first-order account of probability and only knowing that admits knowledge bases with incomplete and probabilistic specifications. Beliefs and non-beliefs are then shown to emerge as a direct logical consequence of the sentences of the knowledge base at a corresponding level of specificity.",
        "A1": " propose a new general first-order account of probability",
        "A2": "only knowing that admits knowledge bases with incomplete and probabilistic specifications",
        "A41": "a new general first-order account of probability",
        "A51": "only knowing that admits knowledge bases with incomplete and probabilistic specifications",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 129629870
    },
    {
        "Abstract": "Computational agents often need to learn policies that involve many control variables, e.g., a robot needs to control several joints simultaneously. Learning a policy with a high number of parameters, however, usually requires a large number of training samples. We introduce a reinforcement learning method for sample-efficient policy search that exploits correlations between control variables. Such correlations are particularly frequent in motor skill learning tasks. The introduced method uses Variational Inference to estimate policy parameters, while at the same time uncovering a low-dimensional latent space of controls. Prior knowledge about the task and the structure of the learning agent can be provided by specifying groups of potentially correlated parameters. This information is then used to impose sparsity constraints on the mapping between the high-dimensional space of controls and a lower-dimensional latent space. In experiments with a simulated bi-manual manipulator, the new approach effectively identifies synergies between joints, performs efficient low-dimensional policy search, and outperforms state-of-the-art policy search methods.",
        "A1": "introduced method uses Variational Inference to estimate policy parameters, while at the same time uncovering a low-dimensional latent space of controls",
        "A2": "Learning a policy with a high number of parameters, however, usually requires a large number of training samples.",
        "A41": "method uses Variational Inference to estimate policy parameters, while at the same time uncovering a low-dimensional latent space of controls",
        "A51": "Variational Inference",
        "A61": "simulated bi-manual manipulator",
        "A10": "outperforms state-of-the-art policy search methods.",
        "A7": "In experiments with a simulated bi-manual manipulator",
        "A83": "outperforms state-of-the-art policy search methods",
        "A82": "performs efficient low-dimensional policy search",
        "A81": " the new approach effectively identifies synergies between joint",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 363458636
    },
    {
        "Abstract": "Proper epistemic knowledge bases (PEKBs) are syntactic knowledge bases that use multi-agent epistemic logic to represent nested multi-agent knowledge and belief. PEKBs have certain syntactic restrictions that lead to desirable computational properties; primarily, a PEKB is a conjunction of modal literals, and therefore contains no disjunction. Sound entailment can be checked in polynomial time, and is complete for a large set of arbitrary formulae in logics Kn and KDn. In this paper, we extend PEKBs to deal with a restricted form of disjunction: 'knowing whether.' An agent i knows whether Q iff agent i knows Q or knows not Q; that is, []Q or []not(Q). In our experience, the ability to represent that an agent knows whether something holds is useful in many multi-agent domains. We represent knowing whether with a modal operator, and present sound polynomial-time entailment algorithms on PEKBs with the knowing whether operator in Kn and KDn, but which are complete for a smaller class of queries than standard PEKBs.",
        "A1": "",
        "A2": "PEKBs have certain syntactic restrictions that lead to desirable computational properties",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "ability to represent that an agent knows whether something holds is useful in many multi-agent domains",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "which are complete for a smaller class of queries than standard PEKBs.",
        "A53": "",
        "A43": "present sound polynomial-time entailment algorithms on PEKBs with the knowing whether operator in Kn and KDn, ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 186312067
    },
    {
        "Abstract": "Modeling complex crowd behaviour for tasks such as rare event detection has received increasing interest. However, existing methods are limited because (1) they are sensitive to noise often resulting in a large number of false alarms; and (2) they rely on elaborate models leading to high computational cost thus unsuitable for processing a large number of video inputs in real-time. In this paper, we overcome these limitations by introducing a novel complex behaviour modeling framework, which consists of a Binarized Cumulative Directional (BCD) feature as representation, novel spatial and temporal context modeling via an iterative correlation maximization, and a set of behaviour models, each being a simple Bernoulli distribution. Despite its simplicity, our experiments on three benchmark datasets show that it significantly outperforms the state-of-the-art for both temporal video segmentation and rare event detection. Importantly, it is extremely efficient \u2014 reaches 90Hz on a normal PC platform using MATLAB.",
        "A1": "Modeling complex crowd behaviour for tasks such as rare event detection has received increasing interest. ",
        "A2": "existing methods are limited ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "it is extremely efficient \u2014 reaches 90Hz on a normal PC platform using MATLAB",
        "A7": "experiments on three benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "it significantly outperforms the state-of-the-art for both temporal video segmentation and rare event detection",
        "A64": "",
        "A54": "",
        "A44": "consists of a Binarized Cumulative Directional (BCD) feature as representation, novel spatial and temporal context modeling via an iterative correlation maximization, and a set of behaviour models, each being a simple Bernoulli distribution. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 387613827
    },
    {
        "Abstract": "In recent data mining research, the graph clustering methods, such as normalized cut and ratio cut, have been well studied and applied to solve many unsupervised learning applications. The original graph clustering methods are NP-hard problems. Traditional approaches used spectral relaxation to solve the graph clustering problems. The main disadvantage of these approaches is that the obtained spectral solutions could severely deviate from the true solution. To solve this problem, in this paper, we propose a new relaxation mechanism for graph clustering methods. Instead of minimizing the squared distances of clustering results, we use the l1-norm distance. More important, considering the normalized consistency, we also use the l1-norm for the normalized terms in the new graph clustering relaxations. Due to the sparse result from the l1-norm minimization, the solutions of our new relaxed graph clustering methods get discrete values with many zeros, which are close to the ideal solutions. Our new objectives are difficult to be optimized, because the minimization problem involves the ratio of nonsmooth terms. The existing sparse learning optimization algorithms cannot be applied to solve this problem. In this paper, we propose a new optimization algorithm to solve this difficult non-smooth ratio minimization problem. The extensive experiments have been performed on three two-way clustering and eight multi-way clustering benchmark data sets. All empirical results show that our new relaxation methods consistently enhance the normalized cut and ratio cut clustering results.",
        "A1": "propose a new relaxation mechanism",
        "A2": "the obtained spectral solutions could severely deviate from the true solution",
        "A41": "a new relaxation mechanism for graph clustering methods",
        "A51": " use the l1-norm distance",
        "A61": "our new relaxed graph clustering methods get discrete values with many zeros, which are close to the ideal solutions",
        "A10": "our new relaxation methods consistently enhance the normalized cut and ratio cut clustering results.",
        "A7": " The extensive experiments have been performed on three two-way clustering and eight multi-way clustering benchmark data sets",
        "A83": "",
        "A82": "",
        "A81": "our new relaxation methods consistently enhance the normalized cut and ratio cut clustering results.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "the ratio of nonsmooth terms",
        "A53": "",
        "A43": "a new optimization algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 11540057
    },
    {
        "Abstract": "In Foursquare or Google+ Local, emerging spatial entities, such as new business or venue, are reported to grow by 1% every day. As information on such spatial entities is initially limited (e.g., only name), we need to quickly harvest related information from social media such as Flickr photos. Especially, achieving high-recall in photo population is essential for emerging spatial entities, which suffer from data sparseness (e.g., 71% restaurants of TripAdvisor in Seattle do not have any photo, as of Sep 03, 2015). Our goal is thus to address this limitation by identifying effective linking techniques for emerging spatial entities and photos. Compared with state-of-the-art baselines, our proposed approach improves recall and F1 score by up to 24% and 18%, respectively. To show the effectiveness and robustness of our approach, we have conducted extensive experiments in three different cities, Seattle, Washington D.C., and Taipei, of varying characteristics such as geographical density and language.",
        "A1": "address this limitation by identifying effective linking techniques for emerging spatial entities and photos",
        "A2": "address this limitation",
        "A41": "to address this limitation by identifying effective linking techniques for emerging spatial entities and photos",
        "A51": "identifying effective linking techniques for emerging spatial entities and photos",
        "A61": "our proposed approach improves recall and F1 score by up to 24% and 18%, respectively",
        "A10": "Compared with state-of-the-art baselines, our proposed approach improves recall and F1 score by up to 24% and 18%, respectively.",
        "A7": "extensive experiments in three different cities, Seattle, Washington D.C., and Taipei",
        "A83": "",
        "A82": "the effectiveness and robustness of our approach",
        "A81": "our proposed approach improves recall and F1 score by up to 24% and 18%, respectively.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 168011885
    },
    {
        "Abstract": "There are two classes of average reward reinforcement learning (RL) algorithms: model-based ones that explicitly maintain MDP models and model-free ones that do not learn such models. Though model-free algorithms are known to be more efficient, they often cannot converge to optimal policies due to the perturbation of parameters. In this paper, a novel model-free algorithm is proposed, which makes use of constant shifting values (CSVs) estimated from prior knowledge. To encourage exploration during the learning process, the algorithm constantly subtracts the CSV from the rewards. A terminating condition is proposed to handle the unboundedness of Q-values caused by such substraction. The convergence of the proposed algorithm is proved under very mild assumptions. Furthermore, linear function approximation is investigated to generalize our method to handle large-scale tasks. Extensive experiments on representative MDPs and the popular game Tetris show that the proposed algorithms significantly outperform the state-of-the-art ones.",
        "A1": "a novel model-free algorithm is proposed",
        "A2": "converge to optimal policies",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "experiments on representative MDPs and the popular game Tetris",
        "A83": "",
        "A82": "",
        "A81": "the proposed algorithms significantly outperform the state-of-the-art ones",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "constantly subtracts the CSV from the rewards",
        "A53": "",
        "A43": "a novel model-free algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 497909374
    },
    {
        "Abstract": "Retrieving past egocentric videos about personal daily life is important to support and augment human memory. Most previous retrieval approaches have ignored the crucial feature of human-physical world interactions, which is greatly related to our memory and experience of daily activities. In this paper, we propose a gesture-based egocentric video retrieval framework, which retrieves past visual experience using body gestures as non-verbal queries. We use a probabilistic framework based on a canonical correlation analysis that models physical interactions through a latent space and uses them for egocentric video retrieval and re-ranking search results. By incorporating physical interactions into the retrieval models, we address the problems resulting from the variability of human motions. We evaluate our proposed method on motion and egocentric video datasets about daily activities in household settings and demonstrate that our egocentric video retrieval framework robustly improves retrieval performance when retrieving past videos from personal and even other persons' video archives.",
        "A1": "Retrieving past egocentric videos about personal daily life",
        "A2": "address the problems resulting from the variability of human motions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "evaluate our proposed method on motion and egocentric video datasets about daily activities in household settings",
        "A83": "",
        "A82": "",
        "A81": "our egocentric video retrieval framework robustly improves retrieval performance",
        "A64": "",
        "A54": "gesture-based",
        "A44": "retrieves past visual experience using body gestures as non-verbal queries",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 481826361
    },
    {
        "Abstract": "In multiagent e-marketplaces, buying agents need to select good sellers by querying other buyers (called advisors). Partially Observable Markov Decision Processes (POMDPs) have shown to be an effective framework for optimally selecting sellers by selectively querying advisors. However, current solution methods do not scale to hundreds or even tens of agents operating in the e-market. In this paper, we propose the Mixture of POMDP Experts (MOPE) technique, which exploits the inherent structure of trust-based domains, such as the seller selection problem in e-markets, by aggregating the solutions of smaller sub-POMDPs. We propose a number of variants of the MOPE approach that we analyze theoretically and empirically. Experiments show that MOPE can scale up to a hundred agents thereby leveraging the presence of more advisors to significantly improve buyer satisfaction.",
        "A1": "propose the Mixture of POMDP Experts (MOPE) technique",
        "A2": " current solution methods do not scale to hundreds or even tens of agents operating in the e-market",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " MOPE can scale up to a hundred agents ",
        "A7": "Experiments ",
        "A83": "",
        "A82": "",
        "A81": "leveraging the presence of more advisors to significantly improve buyer satisfaction",
        "A64": "MOPE can scale up to a hundred agents thereby leveraging the presence of more advisors to significantly improve buyer satisfaction.",
        "A54": "exploits the inherent structure of trust-based domains",
        "A44": "the Mixture of POMDP Experts (MOPE) technique",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 78810740
    },
    {
        "Abstract": "Continuous Time Bayesian Networks (CTBNs) provide a powerful means to model complex network dynamics. How- ever, their inference is computationally demanding \u2014 especially if one considers incomplete and noisy time-series data. The latter gives rise to a joint state- and parameter estimation problem, which can only be solved numerically. Yet, finding the exact parameterization of the CTBN has often only secondary importance in practical scenarios. We therefore focus on the structure learning problem and present a way to analytically marginalize the Markov chain underlying the CTBN model with respect its parameters. Since the resulting stochastic process is parameter-free, its inference reduces to an optimal filtering problem. We solve the latter using an efficient parallel implementation of a sequential Monte Carlo scheme. Our framework enables CTBN inference to be applied to incomplete noisy time-series data frequently found in molecular biology and other disciplines.",
        "A1": "We therefore focus on the structure learning problem and present a way to analytically marginalize the Markov chain underlying the CTBN model with respect its parameters.",
        "A2": "We therefore focus on the structure learning problem and present a way to analytically marginalize the Markov chain underlying the CTBN model with respect its parameters.",
        "A41": "",
        "A51": "",
        "A61": "Continuous Time Bayesian Networks (CTBNs)",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "Continuous Time Bayesian Networks (CTBNs)",
        "A44": "a way to analytically marginalize the Markov chain underlying the CTBN model with respect its parameters. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 347688396
    },
    {
        "Abstract": "Food safety is vital to the well-being of society; therefore, it is important to inspect food products to ensure minimal health risks are present. The presence of certain species of insects, especially storage beetles, is a reliable indicator of possible contamination during storage and food processing. However, the current approach of identifying species by visual examination of insect fragments is rather subjective and time-consuming. To aid this inspection process, we have developed in collaboration with FDA food analysts some image analysis-based machine intelligence to achieve species identification with up to 90% accuracy. The current project is a continuation of this development effort. Here we present an image analysis environment that allows practical deployment of the machine intelligence on computers with limited processing power and memory. Using this environment, users can prepare input sets by selecting images for analysis, and inspect these images through the integrated panning and zooming capabilities. After species analysis, the results panel allows the user to compare the analyzed images with reference images of the proposed species. Further additions to this environment should include a log of previously analyzed images, and eventually extend to interaction with a central cloud repository of images through a web-based interface.",
        "A1": " inspect food products to ensure minimal health risks are present",
        "A2": "the current approach of identifying species by visual examination of insect fragments is rather subjective and time-consuming",
        "A41": " an image analysis environment that allows practical deployment of the machine intelligence on computers with limited processing power and memory",
        "A51": "collaboration with FDA food analysts some image analysis-based machine intelligence",
        "A61": "the current approach of identifying species by visual examination of insect fragments is rather subjective and time-consuming",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 403049515
    },
    {
        "Abstract": "Hedonic games are a well-studied model of coalition formation, in which selfish agents are partitioned into disjoint sets and agents care about the make-up of the coalition they end up in. The computational problems of finding stable, optimal, or fair outcomes tend to be computationally intractable in even severely restricted instances of hedonic games. We introduce the notion of a graphical hedonic game and show that, in contrast, on classes of graphical hedonic games whose underlying graphs are of bounded treewidth and degree, such problems become easy. In particular, problems that can be specified through quantification over agents, coalitions, and (connected) partitions can be decided in linear time. The proof is by reduction to monadic second order logic. We also provide faster algorithms in special cases, and show that the extra condition of the degree bound cannot be dropped. Finally, we note that the problem of allocating indivisible goods can be modelled as a hedonic game, so that our results imply tractability of finding fair and efficient allocations on appropriately restricted instances.",
        "A1": "Hedonic game",
        "A2": "selfish agents are partitioned into disjoint sets and agents care about the make-up of the coalition they end up in",
        "A41": "the notion of a graphical hedonic game and show that, in contrast, on classes of graphical hedonic games whose underlying graphs are of bounded treewidth and degree, such problems become easy",
        "A51": "Hedonic games",
        "A61": "",
        "A10": " the problem of allocating indivisible goods can be modelled as a hedonic game",
        "A7": "",
        "A83": "",
        "A82": "our results imply tractability of finding fair and efficient allocations on appropriately restricted instances",
        "A81": "the extra condition of the degree bound cannot be dropped",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 319663257
    },
    {
        "Abstract": "Most human behaviors consist of multiple parts, steps, or subtasks. These structures guide our ac- tion planning and execution, but when we observe others, the latent structure of their actions is typ- ically unobservable, and must be inferred in order to learn new skills by demonstration, or to as- sist others in completing their tasks. For example, an assistant who has learned the subgoal struc- ture of a colleague\u2019s task can more rapidly rec- ognize and support their actions as they unfold. Here we model how humans infer subgoals from observations of complex action sequences using a nonparametric Bayesian model, which assumes that observed actions are generated by approxi- mately rational planning over unknown subgoal sequences. We test this model with a behavioral experiment in which humans observed di\ufb00erent se- ries of goal-directed actions, and inferred both the number and composition of the subgoal sequences associated with each goal. The Bayesian model predicts human subgoal inferences with high ac- curacy, and signi\ufb01cantly better than several al- ternative models and straightforward heuristics. Motivated by this result, we simulate how learn- ing and inference of subgoals can improve perfor- mance in an arti\ufb01cial user assistance task. The Bayesian model learns the correct subgoals from fewer observations, and better assists users by more rapidly and accurately inferring the goal of their actions than alternative approaches.",
        "A1": " model how humans infer subgoals from observations of complex action sequences ",
        "A2": " how humans infer subgoals from observations of complex action sequences ",
        "A41": "how humans infer subgoals from observations of complex action sequences ",
        "A51": "",
        "A61": "",
        "A10": "The Bayesian model learns the correct subgoals from fewer observations, and better assists users by more rapidly and accurately inferring the goal of their actions than alternative approaches.",
        "A7": " a behavioral experiment in which humans observed di\ufb00erent se- ries of goal-directed actions, and inferred both the number and composition of the subgoal sequences associated with each goal",
        "A83": "",
        "A82": " signi\ufb01cantly better than several al- ternative models and straightforward heuristics",
        "A81": "The Bayesian model predicts human subgoal inferences with high ac- curacy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "a nonparametric Bayesian model",
        "A42": " model how humans infer subgoals from observations of complex action sequences ",
        "A45": "",
        "am_id": 70558018
    },
    {
        "Abstract": "We address two key challenges in end-to-end event coreference resolution research: (1) the error propagation problem, where an event coreference resolver has to assume as input the noisy outputs produced by its upstream components in the standard information extraction (IE) pipeline; and (2) the data annotation bottleneck, where manually annotating data for all the components in the IE pipeline is prohibitively expensive. This is the case in the vast majority of the world's natural languages, where such annotated resources are not readily available. To address these problems, we propose to perform joint inference over a lightly supervised IE pipeline, where all the models are trained using either active learning or unsupervised learning. Using our approach, only 25% of the training sentences in the Chinese portion of the ACE 2005 corpus need to be annotated with entity and event mentions in order for our event coreference resolver to surpass its fully supervised counterpart in performance.",
        "A1": "address two key challenges in end-to-end event coreference resolution research",
        "A2": "(1) the error propagation problem, where an event coreference resolver has to assume as input the noisy outputs produced by its upstream components in the standard information extraction (IE) pipeline; and (2) the data annotation bottleneck",
        "A41": " perform joint inference over a lightly supervised IE pipeline",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "only 25% of the training sentences in the Chinese portion of the ACE 2005 corpus need to be annotated with entity and event mentions in order for our event coreference resolver to surpass its fully supervised counterpart in performance.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 376726176
    },
    {
        "Abstract": "Similar to the satisfiability (SAT) problem, which can be seen to be the archetypical problem for NP, the quantified Boolean formula problem (QBF) is the archetypical problem for PSPACE. Recently, Atserias and Oliva (2014) showed that, unlike for SAT, many of the well-known decompositional parameters (such as treewidth and pathwidth) do not allow efficient algorithms for QBF. The main reason for this seems to be the lack of awareness of these parameters towards the dependencies between variables of a QBF formula. In this paper we extend the ordinary pathwidth to the QBF-setting by introducing prefix pathwidth, which takes into account the dependencies between variables in a QBF, and show that it leads to an efficient algorithm for QBF. We hope that our approach will help to initiate the study of novel tailor-made decompositional parameters for QBF and thereby help to lift the success of these decompositional parameters from SAT to QBF.",
        "A1": "extend the ordinary pathwidth to the QBF-setting by introducing prefix pathwidth",
        "A2": "an efficient algorithm for QBF",
        "A41": "an efficient algorithm for QBF",
        "A51": "",
        "A61": "extend the ordinary pathwidth to the QBF-setting by introducing prefix pathwidth, which takes into account the dependencies between variables in a QBF",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 116404664
    },
    {
        "Abstract": "Normal form games are one of the most familiar representations for modeling interactions among multiple agent. However, modeling many realistic interactions between agents results in games that are extremely large. In these cases computing standard solutions like Nash equilibrium may be intractable. To overcome this issue the idea of abstraction has been investigated, most prominently in research on computer Poker. Solving a game using abstraction requires using some method to simplify the game before it is analyzed. We study a new variation for solving normal form games using abstraction that is based on finding and solving suitable sub games. We compare this method with several variations of a common type of abstraction based on clustering similar strategies.",
        "A1": "To overcome this issue",
        "A2": "modeling many realistic interactions between agents results in games that are extremely large",
        "A41": "the idea of abstraction has been investigated, most prominently in research on computer Poker",
        "A51": "abstraction",
        "A61": "using abstraction",
        "A10": "",
        "A7": "We compare this method with several variations of a common type of abstraction based on clustering similar strategies",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 444493629
    },
    {
        "Abstract": "The Sentential Decision Diagram (SDD) is a prominent knowledge representation language that subsumes the Ordered Binary Decision Diagram (OBDD) as a strict subset. Like OBDDs, SDDs have canonical forms and support bottom-up operations for combining SDDs, but they are more succinct than OBDDs. In this paper we introduce an SDD variant, called the Zero-suppressed Sentential Decision Diagram (ZSDD). The key idea of ZSDD is to employ new trimming rules for obtaining a canonical form. As a result, ZSDD subsumes the Zero-suppressed Binary Decision Diagram (ZDD) as a strict subset. ZDDs are known for their effectiveness on representing sparse Boolean functions. Likewise, ZSDDs can be more succinct than SDDs when representing sparse Boolean functions. We propose several polytime bottom-up operations over ZSDDs, and a technique for reducing ZSDD size, while maintaining applicability to important queries. We also specify two distinct upper bounds on ZSDD sizes; one is derived from the treewidth of a CNF and the other from the size of a family of sets. Experiments show that ZSDDs are smaller than SDDs or ZDDs for a standard benchmark dataset.",
        "A1": "introduce an SDD variant",
        "A2": "employ new trimming rules for obtaining a canonical form",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ZSDDs are smaller than SDDs or ZDDs for a standard benchmark dataset.",
        "A7": "",
        "A83": "",
        "A82": " be more succinct than SDDs when representing sparse Boolean functions",
        "A81": " known for their effectiveness on representing sparse Boolean functions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " the Zero-suppressed Sentential Decision Diagram (ZSDD)",
        "am_id": 317231615
    },
    {
        "Abstract": "We study transportation problems where robots have to deliver packages and can transfer the packages among each other. Specifically, we study the package-exchange robot-routing problem (PERR), where each robot carries one package, any two robots in adjacent locations can exchange their packages, and each package needs to be delivered to a given destination. We prove that exchange operations make all PERR instances solvable. Yet, we also show that PERR is NP-hard to approximate within any factor less than 4/3 for makespan minimization and is NP-hard to solve for flowtime minimization, even when there are only two types of packages. Our proof techniques also generate new insights into other transportation problems, for example, into the hardness of approximating optimal solutions to the standard multi-agent path-finding problem (MAPF). Finally, we present optimal and suboptimal PERR solvers that are inspired by MAPF solvers, namely a flow-based ILP formulation and an adaptation of conflict-based search. Our empirical results demonstrate that these solvers scale well and that PERR instances often have smaller makespans and flowtimes than the corresponding MAPF instances.",
        "A1": "we study the package-exchange robot-routing problem (PERR",
        "A2": "study transportation problems where robots have to deliver packages and can transfer the packages among each other. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "PERR instances often have smaller makespans and flowtimes than the corresponding MAPF instances.",
        "A7": "",
        "A83": "",
        "A82": "PERR instances often have smaller makespans and flowtimes than the corresponding MAPF instances.",
        "A81": " these solvers scale well ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "inspired by MAPF solvers, namely a flow-based ILP formulation and an adaptation of conflict-based search.",
        "A43": "we present optimal and suboptimal PERR solver",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 63464984
    },
    {
        "Abstract": "In this paper, we first analyze the semantic composition of word embeddings by cross-referencing their clusters with the manual lexical database, WordNet. We then evaluate a variety of word embedding approaches by comparing their contributions to two NLP tasks. Our experiments show that the word embedding clusters give high correlations to the synonym and hyponym sets in WordNet, and give 0.88% and 0.17% absolute improvements in accuracy to named entity recognition and part-of-speech tagging, respectively.",
        "A1": "analyze the semantic composition of word embeddings by cross-referencing their clusters with the manual lexical database, WordNet",
        "A2": "",
        "A41": "analyze the semantic composition of word embeddings by cross-referencing their clusters with the manual lexical database, WordNet.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "analyze the semantic composition of word embeddings by cross-referencing their clusters with the manual lexical database, WordNet",
        "A83": "",
        "A82": " give 0.88% and 0.17% absolute improvements in accuracy to named entity recognition and part-of-speech tagging",
        "A81": "the word embedding clusters give high correlations to the synonym and hyponym sets in WordNe",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 385909490
    },
    {
        "Abstract": "We present a new, efficient PAC optimal exploration algorithm that is able to explore in multiple, continuous or discrete state MDPs simultaneously. Our algorithm does not assume that value function updates can be completed instantaneously, and maintains PAC guarantees in realtime environments. Not only do we extend the applicability of PAC optimal exploration algorithms to new, realistic settings, but even when instant value function updates are possible, our bounds present a significant improvement over previous single MDP exploration bounds, and a drastic improvement over previous concurrent PAC bounds. We also present TCE, a new, fine grained metric for the cost of exploration.",
        "A1": "present a new, efficient PAC optimal exploration algorithm that is able to explore in multiple, continuous or discrete state MDPs simultaneously",
        "A2": "present a new, efficient PAC optimal exploration algorithm that is able to explore in multiple, continuous or discrete state MDPs simultaneously",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Our algorithm does not assume that value function updates can be completed instantaneously, and maintains PAC guarantees in realtime environments",
        "A53": "",
        "A43": "a new, efficient PAC optimal exploration algorithm that is able to explore in multiple, continuous or discrete state MDPs simultaneously",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 324652785
    },
    {
        "Abstract": "An important use of machine learning is to learn what people value. What posts or photos should a user be shown? Which jobs or activities would a person find rewarding? In each case, observations of people's past choices can inform our inferences about their likes and preferences. If we assume that choices are approximately optimal according to some utility function, we can treat preference inference as Bayesian inverse planning. That is, given a prior on utility functions and some observed choices, we invert an optimal decision-making process to infer a posterior distribution on utility functions. However, people often deviate from approximate optimality. They have false beliefs, their planning is sub-optimal, and their choices may be temporally inconsistent due to hyperbolic discounting and other biases. We demonstrate how to incorporate these deviations into algorithms for preference inference by constructing generative models of planning for agents who are subject to false beliefs and time inconsistency. We explore the inferences these models make about preferences, beliefs, and biases. We present a behavioral experiment in which human subjects perform preference inference given the same observations of choices as our model. Results show that human subjects (like our model) explain choices in terms of systematic deviations from optimal behavior and suggest that they take such deviations into account when inferring preferences.",
        "A1": "incorporate these deviations into algorithms for preference inference ",
        "A2": "They have false beliefs, their planning is sub-optimal, and their choices may be temporally inconsistent due to hyperbolic discounting and other biases",
        "A41": "constructing generative models of planning for agents who are subject to false beliefs and time inconsistency",
        "A51": "",
        "A61": "incorporate these deviations into algorithms for preference inference",
        "A10": "",
        "A7": "a behavioral experiment",
        "A83": "",
        "A82": "",
        "A81": " human subjects (like our model) explain choices in terms of systematic deviations from optimal behavior and suggest that they take such deviations into account when inferring preferences",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 257983340
    },
    {
        "Abstract": "Kidney exchange is a type of barter market where patients exchange willing but incompatible donors. These exchanges are conducted via cycles---where each incompatible patient-donor pair in the cycle both gives and receives a kidney---and chains, which are started by an altruist donor who does not need a kidney in return. Finding the best combination of cycles and chains is hard. The leading algorithms for this optimization problem use either branch and price \u2014 a combination of branch and bound and column generation \u2014 or constraint generation. We show a correctness error in the leading prior branch-and-price-based approach [Glorie et al. 2014]. We develop a provably correct fix to it, which also necessarily changes the algorithm's complexity, as well as other improvements to the search algorithm. Next, we compare our solver to the leading constraint-generation-based solver and to the best prior correct branch-and-price-based solver. We focus on the setting where chains have a length cap. A cap is desirable in practice since if even one edge in the chain fails, the rest of the chain fails: the cap precludes very long chains that are extremely unlikely to execute and instead causes the solution to have more parallel chains and cycles that are more likely to succeed. We work with the UNOS nationwide kidney exchange, which uses a chain cap. Algorithms from our group autonomously make the transplant plans for that exchange. On that real data and demographically-accurate generated data, our new solver scales significantly better than the prior leading approaches.",
        "A1": "Kidney exchange",
        "A2": " We show a correctness error in the leading prior branch-and-price-based approach [Glorie et al. 2014]",
        "A41": "use either branch and price",
        "A51": "a combination of branch and bound and column generation",
        "A61": "",
        "A10": "On that real data and demographically-accurate generated data, our new solver scales significantly better than the prior leading approaches.",
        "A7": "compare our solver to the leading constraint-generation-based solver and to the best prior correct branch-and-price-based solver.",
        "A83": "",
        "A82": "Algorithms from our group autonomously make the transplant plans for that exchange.",
        "A81": "A cap is desirable in practice since if even one edge in the chain fails, the rest of the chain fails",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "our new solver scales significantly better than the prior leading approaches.",
        "A53": "focus on the setting where chains have a length cap",
        "A43": "The leading algorithms for this optimization problem use either branch and price ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 164230499
    },
    {
        "Abstract": "In this paper, we focus on automatically detecting events in unconstrained videos without the use of any visual training exemplars. In principle, zero-shot learning makes it possible to train an event detection model based on the assumption that events (e.g. birthday party) can be described by multiple mid-level semantic concepts (e.g. ``blowing candle'', ``birthday cake''). Towards this goal, we first pre-train a bundle of concept classifiers using data from other sources. Then we evaluate the semantic correlation of each concept w.r.t. the event of interest and pick up the relevant concept classifiers, which are applied on all test videos to get multiple prediction score vectors. While most existing systems combine the predictions of the concept classifiers with fixed weights, we propose to learn the optimal weights of the concept classifiers for each testing video by exploring a set of online available videos with free-form text descriptions of their content. To validate the effectiveness of the proposed approach, we have conducted extensive experiments on the latest TRECVID MEDTest 2014, MEDTest 2013 and CCV dataset. The experimental results confirm the superiority of the proposed approach.",
        "A1": "zero-shot learning makes it possible to train an event detection model based on the assumption that events (e.g. birthday party) can be described by multiple mid-level semantic concepts",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The experimental results confirm the superiority of the proposed approach.",
        "A7": "we have conducted extensive experiments on the latest TRECVID MEDTest 2014, MEDTest 2013 and CCV dataset.",
        "A83": "",
        "A82": "",
        "A81": "The experimental results confirm the superiority of the proposed approach.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "to learn the optimal weights of the concept classifiers for each testing video by exploring a set of online available videos with free-form text descriptions of their content.",
        "A52": "",
        "A42": "a bundle of concept classifiers using data from other sources.",
        "A45": "",
        "am_id": 497248152
    },
    {
        "Abstract": "The design of strategies for branching in Mixed Integer Programming (MIP) is guided by cycles of parameter tuning and offline experimentation on an extremely heterogeneous testbed, using the average performance. Once devised, these strategies (and their parameter settings) are essentially input-agnostic. To address these issues, we propose a machine learning (ML) framework for variable branching in MIP.Our method observes the decisions made by Strong Branching (SB), a time-consuming strategy that produces small search trees, collecting features that characterize the candidate branching variables at each node of the tree. Based on the collected data, we learn an easy-to-evaluate surrogate function that mimics the SB strategy, by means of solving a learning-to-rank problem, common in ML. The learned ranking function is then used for branching. The learning is instance-specific, and is performed on-the-fly while executing a branch-and-bound search to solve the MIP instance. Experiments on benchmark instances indicate that our method produces significantly smaller search trees than existing heuristics, and is competitive with a state-of-the-art commercial solver.",
        "A1": "To address these issues, we propose a machine learning (ML) framework for variable branching in MIP.",
        "A2": "Once devised, these strategies (and their parameter settings) are essentially input-agnostic.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experiments on benchmark instances indicate that our method produces significantly smaller search trees than existing heuristics, and is competitive with a state-of-the-art commercial solver.",
        "A7": "Experiments on benchmark instances",
        "A83": "",
        "A82": "",
        "A81": "our method produces significantly smaller search trees than existing heuristics, and is competitive with a state-of-the-art commercial solver.",
        "A64": "Our method observes the decisions made by Strong Branching (SB), a time-consuming strategy that produces small search trees, collecting features that characterize the candidate branching variables at each node of the tree.",
        "A54": "observes the decisions made by Strong Branching (SB)",
        "A44": "framework for variable branching in MIP.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 305375993
    },
    {
        "Abstract": "Morphological segmentation, which aims to break words into meaning-bearing morphemes, is an important task in natural language processing. Most previous work relies heavily on linguistic preprocessing. In this paper, we instead propose novel neural network architectures that learn the structure of input sequences directly from raw input words and are subsequently able to predict morphological boundaries. Our architectures rely on Long Short Term Memory (LSTM) units to accomplish this, but exploit windows of characters to capture more contextual information. Experiments on multiple languages confirm the effectiveness of our models on this task.",
        "A1": "Morphological segmentation",
        "A2": "Most previous work relies heavily on linguistic preprocessing",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on multiple languages",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of our models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " learn the structure of input sequences directly from raw input words",
        "A52": " Long Short Term Memory (LSTM) units",
        "A42": "novel neural network architectures that learn the structure of input sequences directly from raw input words and are subsequently able to predict morphological boundaries",
        "A45": "",
        "am_id": 344934434
    },
    {
        "Abstract": "Organ transplants can improve the life expectancy and quality of life for the recipient but carry the risk of serious post-operative complications, such as septic shock and organ rejection. The probability of a successful transplant depends in a very subtle fashion on compatibility between the donor and the recipient - but current medical practice is short of domain knowledge regarding the complex nature of recipient-donor compatibility. Hence a data-driven approach for learning compatibility has the potential for significant improvements in match quality. This paper proposes a novel system (ConfidentMatch) that is trained using data from electronic health records. ConfidentMatch predicts the success of an organ transplant (in terms of the 3-year survival rates) on the basis of clinical and demographic traits of the donor and recipient. ConfidentMatch captures the heterogeneity of the donor and recipient traits by optimally dividing the feature space into clusters and constructing different optimal predictive models to each cluster. The system controls the complexity of the learned predictive model in a way that allows for assuring more granular and accurate predictions for a larger number of potential recipient-donor pairs, thereby ensuring that predictions are \"personalized\" and tailored to individual characteristics to the finest possible granularity. Experiments conducted on the UNOS heart transplant dataset show the superiority of the prognostic value of ConfidentMatch to other competing benchmarks; ConfidentMatch can provide predictions of success with 95% accuracy for 5,489 patients of a total population of 9,620 patients, which corresponds to 410 more patients than the most competitive benchmark algorithm (DeepBoost).",
        "A1": "predicts the success of an organ transplant (in terms of the 3-year survival rates) on the basis of clinical and demographic traits of the donor and recipient. ",
        "A2": "predicts the success of an organ transplant (in terms of the 3-year survival rates) on the basis of clinical and demographic traits of the donor and recipient. ",
        "A41": "predicts the success of an organ transplant (in terms of the 3-year survival rates) on the basis of clinical and demographic traits of the donor and recipient",
        "A51": "clinical and demographic traits of the donor and recipient",
        "A61": "",
        "A10": "ConfidentMatch can provide predictions of success with 95% accuracy for 5,489 patients of a total population of 9,620 patients, which corresponds to 410 more patients than the most competitive benchmark algorithm (DeepBoost).",
        "A7": "Experiments conducted on the UNOS heart transplant dataset ",
        "A83": "",
        "A82": "",
        "A81": "predictions of success",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "controls the complexity of the learned predictive model in a way that allows for assuring more granular and accurate predictions for a larger number of potential recipient-donor pairs",
        "A62": "",
        "A52": "the heterogeneity of the donor and recipient traits",
        "A42": "ConfidentMatch captures the heterogeneity of the donor and recipient traits by optimally dividing the feature space into clusters and constructing different optimal predictive models to each cluster",
        "A45": "",
        "am_id": 396670460
    },
    {
        "Abstract": "Information source detection, which is the reverse problem of information diffusion, has attracted considerable research effort recently. Most existing approaches assume that the underlying propagation model is fixed and given as input, which may limit their application range. In this paper, we study the multiple source detection problem when the underlying propagation model is unknown. Our basic idea is source prominence, namely the nodes surrounded by larger proportions of infected nodes are more likely to be infection sources. As such, we propose a multiple source detection method called Label Propagation based Source Identification (LPSI). Our method lets infection status iteratively propagate in the network as labels, and finally uses local peaks of the label propagation result as source nodes. In addition, both the convergent and iterative versions of LPSI are given. Extensive experiments are conducted on several real-world datasets to demonstrate the effectiveness of the proposed method.",
        "A1": "study the multiple source detection problem when the underlying propagation model is unknown",
        "A2": "Most existing approaches assume that the underlying propagation model is fixed and given as input, which may limit their application range",
        "A41": "lets infection status iteratively propagate in the network as labels, and finally uses local peaks of the label propagation result as source nodes",
        "A51": "",
        "A61": "Most existing approaches assume that the underlying propagation model is fixed and given as input, which may limit their application range",
        "A10": "",
        "A7": "Extensive experiments are conducted on several real-world datasets",
        "A83": "",
        "A82": "",
        "A81": " effectiveness of the proposed method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 401416675
    },
    {
        "Abstract": "Multi-label classification is a practical yet challenging task in machine learning related fields, since it requires the prediction of more than one label category for each input instance. We propose a novel deep neural networks (DNN) based model, Canonical Correlated AutoEncoder (C2AE), for solving this task. Aiming at better relating feature and label domain data for improved classification, we uniquely perform joint feature and label embedding by deriving a deep latent space, followed by the introduction of label-correlation sensitive loss function for recovering the predicted label outputs. Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. Moreover, our C2AE can be easily extended to address the learning problem with missing labels. Our experiments on multiple datasets with different scales confirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.",
        "A1": "Multi-label classification",
        "A2": "Multi-label classification",
        "A41": " Canonical Correlated AutoEncoder (C2AE),",
        "A51": "deep neural networks (DNN)",
        "A61": "Our C2AE is achieved by integrating the DNN architectures of canonical correlation analysis and autoencoder, which allows end-to-end learning and prediction with the ability to exploit label dependency. ",
        "A10": "",
        "A7": "on multiple datasets with different scales",
        "A83": "",
        "A82": "",
        "A81": "onfirm the effectiveness and robustness of our proposed method, which is shown to perform favorably against state-of-the-art methods for multi-label classification.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 344658600
    },
    {
        "Abstract": "It has been well known that the user-provided tags of social images are imperfect, i.e., there exist noisy, irrelevant or incomplete tags. It heavily degrades the performance of many multimedia tasks. To alleviate this problem, we propose a Weakly-supervised Deep Nonnegative Low-rank model (WDNL) to improve the quality of tags by integrating the low-rank model with deep feature learning. A nonnegative low-rank model is introduced to uncover the intrinsic relationships between images and tags by simultaneously removing noisy or irrelevant tags and complementing missing tags. The deep architecture is leveraged to seamlessly connect the visual content and the semantic tag. That is, the proposed model can well handle the scalability by assigning tags to new images. Extensive experiments conducted on two real-world datasets demonstrate the effectiveness of the proposed method compared with some state-of-the-art methods.",
        "A1": "the user-provided tags of social images are imperfect",
        "A2": "improve the quality of tags",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of the proposed method compared with some state-of-the-art methods",
        "A7": "Extensive experiments conducted on two real-world datasets",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of the proposed method compared with some state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "can well handle the scalability by assigning tags to new images",
        "A52": "integrating the low-rank model with deep feature learning",
        "A42": " a Weakly-supervised Deep Nonnegative Low-rank model",
        "A45": "",
        "am_id": 254459413
    },
    {
        "Abstract": "We propose a new active learning (AL) method for text classification with convolutional neural networks (CNNs). In AL, one selects the instances to be manually labeled with the aim of maximizing model performance with minimal effort. Neural models capitalize on word embeddings as representations (features), tuning these to the task at hand. We argue that AL strategies for multi-layered neural models should focus on selecting instances that most affect the embedding space (i.e., induce discriminative word representations). This is in contrast to traditional AL approaches (e.g., entropy-based uncertainty sampling), which specify higher level objectives. We propose a simple approach for sentence classification that selects instances containing words whose embeddings are likely to be updated with the greatest magnitude, thereby rapidly learning discriminative, task-specific embeddings. We extend this approach to document classification by jointly considering: (1) the expected changes to the constituent word representations; and (2) the model\u2019s current overall uncertainty regarding the instance. The relative emphasis placed on these criteria is governed by a stochastic process that favors selecting instances likely to improve representations at the outset of learning, and then shifts toward general uncertainty sampling as AL progresses. Empirical results show that our method outperforms baseline AL approaches on both sentence and document classification tasks. We also show that, as expected, the method quickly learns discriminative word embeddings. To the best of our knowledge, this is the first work on AL addressing neural models for text classification.",
        "A1": "text classification ",
        "A2": "rapidly learning discriminative, task-specific embeddings",
        "A41": "selects instances containing words whose embeddings are likely to be updated with the greatest magnitude",
        "A51": "",
        "A61": "AL strategies for multi-layered neural models should focus on selecting instances that most affect the embedding space",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "he method quickly learns discriminative word embeddings",
        "A81": "our method outperforms baseline AL approaches on both sentence and document classification tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 230977553
    },
    {
        "Abstract": "Handwriting is a skill learned by humans from a very early age. The ability to develop one\u2019s own unique handwriting as well as mimic another person\u2019s handwriting is a task learned by the brain with practice. This paper deals with this very problem where an intelligent system tries to learn the handwriting of an entity using Generative Adversarial Networks (GANs). We propose a modified architecture of DCGAN (Radford, Metz, and Chintala 2015) to achieve this. We also discuss about applying reinforcement learning techniques to achieve faster learning. Our algorithm hopes to give new insights in this area and its uses include identification of forged documents, signature verification, computer generated art, digitization of documents among others. Our early implementation of the algorithm illustrates a good performance with MNIST datasets.",
        "A1": " propose a modified architecture of DCGAN ",
        "A2": "learn the handwriting of an entity using Generative Adversarial Networks ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our early implementation of the algorithm illustrates a good performance ",
        "A7": "MNIST datasets",
        "A83": "",
        "A82": "",
        "A81": "Our early implementation of the algorithm illustrates a good performance ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "GANs",
        "A43": "We also discuss about applying reinforcement learning techniques to achieve faster learning",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 213888449
    },
    {
        "Abstract": "Neural network-based BOW models reveal that word-embedding vectors encode strong semantic regularities. However, such models are insensitive to word polarity. We show that, coupled with simple information such as word spellings, word-embedding vectors can preserve both semantic regularity and conceptual polarity without supervision. We then describe a nontrivial modification to the t-distributed stochastic neighbor embedding (t-SNE) algorithm that visualizes these semantic- and polarity-preserving vectors in reduced dimensions. On a real Facebook corpus, our experiments show significant improvement in t-SNE visualization as a result of the proposed modification.",
        "A1": "show that, coupled with simple information such as word spellings, word-embedding vectors can preserve both semantic regularity and conceptual polarity without supervision",
        "A2": "models are insensitive to word polarity",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significant improvement",
        "A7": "a nontrivial modification to the t-distributed stochastic neighbor embedding (t-SNE) algorithm that visualizes these semantic- and polarity-preserving vectors in reduced dimensions",
        "A83": "",
        "A82": "",
        "A81": "significant improvement in t-SNE visualization as a result of the proposed modification",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "coupled with simple information such as word spellings",
        "A52": "",
        "A42": "We show that, coupled with simple information such as word spellings, word-embedding vectors can preserve both semantic regularity and conceptual polarity without supervision",
        "A45": "",
        "am_id": 291048098
    },
    {
        "Abstract": "Kernel learning is a fundamental problem both in recent research and application of kernel methods. Existing kernel learning methods commonly use some measures of generalization errors to learn the optimal kernel in a convex (or conic) combination of prescribed basic kernels. However, the generalization bounds derived by these measures usually have slow convergence rates, and the basic kernels are finite and should be specified in advance. In this paper, we propose a new kernel learning method based on a novel measure of generalization error, called principal eigenvalue proportion (PEP), which can learn the optimal kernel with sharp generalization bounds over the convex hull of a possibly infinite set of basic kernels. We first derive sharp generalization bounds based on the PEP measure. Then we design two kernel learning algorithms for finite kernels and infinite kernels respectively, in which the derived sharp generalization bounds are exploited to guarantee faster convergence rates, moreover, basic kernels can be learned automatically for infinite kernel learning instead of being prescribed in advance. Theoretical analysis and empirical results demonstrate that the proposed kernel learning method outperforms the state-of-the-art kernel learning methods.",
        "A1": " learn the optimal kernel ",
        "A2": "",
        "A41": " new kernel learning method ",
        "A51": " a novel measure of generalization error, called principal eigenvalue proportion (PEP),",
        "A61": "can learn the optimal kernel with sharp generalization bounds over the convex hull of a possibly infinite set of basic kernels.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "he proposed kernel learning method outperforms the state-of-the-art kernel learning methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " guarantee faster convergence rates, ",
        "A53": "",
        "A43": "two kernel learning algorithms for finite kernels and infinite kernels ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 483115608
    },
    {
        "Abstract": "We propose a novel incomplete cooperative algorithm for distributed constraint optimization problems (DCOPs) denoted as Cooperative Constraint Approximation (CoCoA). The key strategy of the algorithm is to use a semi-greedy approach in which knowledge is distributed amongst neighboring agents, and assigning a value only once instead of an iterative approach. Furthermore, CoCoA uses a unique-first approach to improve the solution quality. It is designed such that it can solve DCOPs as well as Asymmetric DCOPS, with only few messages being communicated between neighboring agents. Experimentally, through evaluating graph coloring problems, randomized (A)DCOPs, and a sensor network communication problem, we show that CoCoA is able to very quickly find solutions of high quality with a smaller communication overhead than state-of-the-art DCOP solvers such as DSA, MGM-2, ACLS, MCS-MGM and Max-Sum. In our asymmetric use case problem of a sensor network, we show that CoCoA not only finds the best solution, but also finds this solution faster than any other algorithm.",
        "A1": "propose a novel incomplete cooperative algorithm for distributed constraint optimization problems (DCOPs) denoted as Cooperative Constraint Approximation (CoCoA).",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "CoCoA is able to very quickly find solutions of high quality with a smaller communication overhead than state-of-the-art DCOP solvers such as DSA, MGM-2, ACLS, MCS-MGM and Max-Sum",
        "A7": "through evaluating graph coloring problems, randomized (A)DCOPs, and a sensor network communication problem",
        "A83": "",
        "A82": "In our asymmetric use case problem of a sensor network, we show that CoCoA not only finds the best solution, but also finds this solution faster than any other algorithm.",
        "A81": "CoCoA is able to very quickly find solutions of high quality with a smaller communication overhead than state-of-the-art DCOP solvers such as DSA, MGM-2, ACLS, MCS-MGM and Max-Sum",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "CoCoA uses a unique-first approach to improve the solution quality",
        "A53": " semi-greedy approach in which knowledge is distributed amongst neighboring agents, and assigning a value only once instead of an iterative approach.",
        "A43": "novel incomplete cooperative algorithm for distributed constraint optimization problems (DCOPs) denoted as Cooperative Constraint Approximation (CoCoA)",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 284253250
    },
    {
        "Abstract": "Denoising autoencoders (DAE) are trained to reconstruct their clean inputs with noise injected at the input level, while variational autoencoders (VAE) are trained with noise injected in their stochastic hidden layer, with a regularizer that encourages this noise injection. In this paper, we show that injecting noise both in input and in the stochastic hidden layer can be advantageous and we propose a modified variational lower bound as an improved objective function in this setup. When input is corrupted, then the standard VAE lower bound involves marginalizing the encoder conditional distribution over the input noise, which makes the training criterion intractable. Instead, we propose a modified training criterion which corresponds to a tractable bound when input is corrupted. Experimentally, we find that the proposed denoising variational autoencoder (DVAE) yields better average log-likelihood than the VAE and the importance weighted autoencoder on the MNIST and Frey Face datasets.",
        "A1": "we propose a modified variational lower bound as an improved objective function in this setup",
        "A2": "show that injecting noise both in input and in the stochastic hidden layer can be advantageou",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "he proposed denoising variational autoencoder (DVAE) yields better average log-likelihood than the VAE and the importance weighted autoencoder",
        "A7": " the MNIST and Frey Face datasets.",
        "A83": "",
        "A82": "",
        "A81": "the proposed denoising variational autoencoder (DVAE) yields better average log-likelihood than the VAE and the importance weighted autoencoder",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "we propose a modified training criterion which corresponds to a tractable bound when input is corrupted",
        "A53": "",
        "A43": "a modified variational lower bound as an improved objective function in this setup",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 321520223
    },
    {
        "Abstract": "Diagnosis of a clinical condition is a challenging task, which often requires significant medical investigation. Previous work related to diagnostic inferencing problems mostly consider multivariate observational data (e.g. physiological signals, lab tests etc.). In contrast, we explore the problem using free-text medical notes recorded in an electronic health record (EHR). Complex tasks like these can benefit from structured knowledge bases, but those are not scalable. We instead exploit raw text from Wikipedia as a knowledge source. Memory networks have been demonstrated to be effective in tasks which require comprehension of free-form text. They use the final iteration of the learned representation to predict probable classes. We introduce condensed memory neural networks (C-MemNNs), a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory. Experiments on the MIMIC-III dataset show that the proposed model outperforms other variants of memory networks to predict the most probable diagnoses given a complex clinical scenario.",
        "A1": "We introduce condensed memory neural networks (C-MemNNs), a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory.",
        "A2": "Diagnosis of a clinical condition is a challenging task",
        "A41": "we explore the problem using free-text medical notes recorded in an electronic health record (EHR)",
        "A51": "raw text from Wikipedia as a knowledge source",
        "A61": "Complex tasks like these can benefit from structured knowledge bases, but those are not scalable.",
        "A10": " a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory.",
        "A7": " Experiments on the MIMIC-III dataset",
        "A83": ", a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory.",
        "A82": "Memory networks have been demonstrated to be effective in tasks which require comprehension of free-form text. ",
        "A81": "Complex tasks like these can benefit from structured knowledge bases, but those are not scalable. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the proposed model outperforms other variants of memory networks to predict the most probable diagnoses given a complex clinical scenario.",
        "A52": "a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory.",
        "A42": "C-MemNNs",
        "A45": " Wikipedia ",
        "am_id": 3773097
    },
    {
        "Abstract": "Network and other computer administrators typically have access to a rich set of logs tracking actions by users. However, they often lack metadata such as user role, age, and gender that can provide valuable context for users' actions. Inferring user attributes automatically has wide ranging implications; among others, for customization (anticipating user needs and priorities), for managing resources (anticipating demand) and for security (interpreting anomalous behavior).",
        "A1": "Inferring user ",
        "A2": "However, they often lack metadata such as user role, age, and gender that can provide valuable context for users' actions.",
        "A41": " Inferring user ",
        "A51": "",
        "A61": " for customization (anticipating user needs and priorities), for managing resources (anticipating demand) and for security (interpreting anomalous behavior).",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 277019192
    },
    {
        "Abstract": "Data classification and tag recommendation are both important and challenging tasks in social media. These two tasks are often considered independently and most efforts have been made to tackle them separately. However, labels in data classification and tags in tag recommendation are inherently related. For example, a Youtube video annotated with NCAA, stadium, pac12 is likely to be labeled as football, while a video/image with the class label of coast is likely to be tagged with beach, sea, water and sand. The existence of relations between labels and tags motivates us to jointly perform classification and tag recommendation for social media data in this paper. In particular, we provide a principled way to capture the relations between labels and tags, and propose a novel framework CLARE, which fuses data CLAssification and tag REcommendation into a coherent model. With experiments on three social media datasets, we demonstrate that the proposed framework CLARE achieves superior performance on both tasks compared to the state-of-the-art methods.",
        "A1": "jointly perform classification and tag recommendation for social media data ",
        "A2": " fuses data CLAssification and tag REcommendation into a coherent model",
        "A41": " a principled way to capture the relations between labels and tags",
        "A51": "",
        "A61": "fuses data CLAssification and tag REcommendation into a coherent model",
        "A10": " fuses data CLAssification and tag REcommendation into a coherent model",
        "A7": "experiments on three social media datasets",
        "A83": "",
        "A82": "",
        "A81": "the proposed framework CLARE achieves superior performance on both tasks compared to the state-of-the-art methods.",
        "A64": " fuses data CLAssification and tag REcommendation into a coherent model",
        "A54": "",
        "A44": "a novel framework CLARE",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 342911562
    },
    {
        "Abstract": "Image captioning is an important problem in artificial intelligence, related to both computer vision and natural language processing. There are two main problems in existing methods: in the training phase, it is difficult to find which parts of the captions are more essential to the image; in the caption generation phase, the objects or the scenes are sometimes misrecognized. In this paper, we consider the training images as the references and propose a Reference based Long Short Term Memory (R-LSTM) model, aiming to solve these two problems in one goal. When training the model, we assign different weights to different words, which enables the network to better learn the key information of the captions. When generating a caption, the consensus score is utilized to exploit the reference information of neighbor images, which might fix the misrecognition and make the descriptions more natural-sounding. The proposed R-LSTM model outperforms the state-of-the-art approaches on the benchmark dataset MS COCO and obtains top 2 position on 11 of the 14 metrics on the online test server.",
        "A1": " propose a Reference based Long Short Term Memory (R-LSTM) model",
        "A2": "in the training phase, it is difficult to find which parts of the captions are more essential to the image; in the caption generation phase, the objects or the scenes are sometimes misrecognized.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " R-LSTM model outperforms the state-of-the-art approaches on the benchmark dataset MS COCO",
        "A7": "the online test",
        "A83": "",
        "A82": "",
        "A81": "obtains top 2 position on 11 of the 14 metrics on the online test server.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "fix the misrecognition and make the descriptions more natural-sounding",
        "A52": "Reference",
        "A42": "a Reference based Long Short Term Memory (R-LSTM) model",
        "A45": "",
        "am_id": 314875697
    },
    {
        "Abstract": "One fundamental problem in causal inference is the treatment effect estimation in observational studies when variables are confounded. Control for confounding effect is generally handled by propensity score. But it treats all observed variables as confounders and ignores the adjustment variables, which have no influence on treatment but are predictive of the outcome. Recently, it has been demonstrated that the adjustment variables are effective in reducing the variance of the estimated treatment effect. However, how to automatically separate the confounders and adjustment variables in observational studies is still an open problem, especially in the scenarios of high dimensional variables, which are common in big data era. In this paper, we propose a Data-Driven Variable Decomposition (D$^2$VD) algorithm, which can 1) automatically separate confounders and adjustment variables with a data driven approach, and 2) simultaneously estimate treatment effect in observational studies with high dimensional variables. Under standard assumptions, we show experimentally that the proposed D$^2$VD algorithm can automatically separate the variables precisely, and estimate treatment effect more accurately and with tighter confidence intervals than the state-of-the-art methods on both synthetic data and real online advertising dataset.",
        "A1": "separate the confounders and adjustment variables",
        "A2": "how to automatically separate the confounders and adjustment variables in observational studies",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "automatically separate the variables precisely, and estimate treatment effect more accurately and with tighter confidence intervals than the state-of-the-art methods on both synthetic data and real online advertising dataset.",
        "A7": "",
        "A83": "",
        "A82": "estimate treatment effect more accurately and with tighter confidence intervals than the state-of-the-art methods on both synthetic data and real online advertising dataset",
        "A81": "the proposed D$^2$VD algorithm can automatically separate the variables precisely",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "1) automatically separate confounders and adjustment variables with a data driven approach, and 2) simultaneously estimate treatment effect in observational studies with high dimensional variables",
        "A53": "big data",
        "A43": "Data-Driven Variable Decomposition ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 39840689
    },
    {
        "Abstract": "In this paper we present a novel geometric method for the problem of global pairwise alignment of protein-protein interaction (PPI) networks. A PPI network can be viewed as a node-edge graph and its alignment often needs to solve some generalized version of the subgraph isomorphism problem which is notoriously challenging and NP-hard. All existing research has focused on designing algorithms with good practical performance. In this paper we propose a two-step algorithm for the global pairwise PPI network alignment which consists of a Geometric Step and an MCMF Step. Our algorithm first applies a graph embedding technique that preserves the topological structure of the original PPI networks and maps the problem from graph domain to geometric domain, and computes a rigid transformation for one of the embedded PPI networks so as to minimize its Earth Mover's Distance (EMD) to the other PPI network. It then solves a Min-Cost Max-Flow problem using the (scaled) inverse of sequence similarity scores as edge weight. By using the flow values from the two steps (i.e., EMD and Min-Cost Max-Flow) as the matching scores, we are able to combine the two matching results to obtain the desired alignment. Unlike other popular alignment algorithms which are either greedy or incremental, our algorithm globally optimizes the problem to yield an alignment with better quality.",
        "A1": "propose a two-step algorithm for the global pairwise PPI network alignment",
        "A2": " the problem of global pairwise alignment of protein-protein interaction (PPI) networks",
        "A41": "a novel geometric method for the problem of global pairwise alignment of protein-protein interaction (PPI) networks",
        "A51": "the topological structure of the original PPI networks",
        "A61": "Unlike other popular alignment algorithms which are either greedy or incremental, our algorithm globally optimizes the problem to yield an alignment with better quality.",
        "A10": "Unlike other popular alignment algorithms which are either greedy or incremental, our algorithm globally optimizes the problem to yield an alignment with better quality.",
        "A7": "a Min-Cost Max-Flow problem using the (scaled) inverse of sequence similarity scores as edge weight",
        "A83": "",
        "A82": "",
        "A81": "Unlike other popular alignment algorithms which are either greedy or incremental, our algorithm globally optimizes the problem to yield an alignment with better quality.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Unlike other popular alignment algorithms which are either greedy or incremental, our algorithm globally optimizes the problem to yield an alignment with better quality.",
        "A53": "a graph embedding technique that preserves the topological structure of the original PPI networks",
        "A43": "a two-step algorithm for the global pairwise PPI network alignment which consists of a Geometric Step and an MCMF Step. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 478078045
    },
    {
        "Abstract": "Feature selection is an important technique in machine learning research. An effective and robust feature selection method is desired to simultaneously identify the informative features and eliminate the noisy ones of data. In this paper, we consider the unsupervised feature selection problem which is particularly difficult as there is not any class labels that would guide the search for relevant features. To solve this, we propose a novel algorithmic framework which performs unsupervised feature selection. Firstly, the proposed framework implements structure learning, where the data structures (including intrinsic distribution structure and the data segment) are found via a combination of the alternative optimization and clustering. Then, both the intrinsic data structure and data segmentation are formulated as regularization terms for discriminant feature selection. The results of the feature selection also affect the structure learning step in the following iterations. By leveraging the interactions between structure learning and feature selection, we are able to capture more accurate structure of data and select more informative features. Clustering and classification experiments on real world image data sets demonstrate the effectiveness of our method.",
        "A1": "propose a novel algorithmic framework which performs unsupervised feature selection",
        "A2": "simultaneously identify the informative features and eliminate the noisy ones of data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "performs unsupervised feature selection",
        "A7": "Clustering and classification experiments on real world image data sets",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of our method",
        "A64": "performs unsupervised feature selection",
        "A54": "",
        "A44": "a novel algorithmic framework which performs unsupervised feature selection",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 11214041
    },
    {
        "Abstract": "In this paper, we consider the scene parsing problem and propose a novel Multi-Path Feedback recurrent neural network (MPF-RNN) for parsing scene images. MPF-RNN can enhance the capability of RNNs in modeling long-range context information at multiple levels and better distinguish pixels that are easy to confuse. Different from feedforward CNNs and RNNs with only single feedback, MPF-RNN propagates the contextual features learned at top layer through multiple weighted recurrent connections to learn bottom features. For better training MPF-RNN, we propose a new strategy that considers accumulative loss at multiple recurrent steps to improve performance of the MPF-RNN on parsing small objects. With these two novel components, MPF-RNN has achieved significant improvement over strong baselines (VGG16 and Res101) on five challenging scene parsing benchmarks, including traditional SiftFlow, Barcelona, CamVid, Stanford Background as well as the recently released large-scale ADE20K.",
        "A1": "",
        "A2": "the scene parsing problem",
        "A41": "a new strategy that considers accumulative loss at multiple recurrent steps",
        "A51": "",
        "A61": "",
        "A10": " MPF-RNN has achieved significant improvement ",
        "A7": "strong baselines (VGG16 and Res101) on five challenging scene parsing benchmarks, including traditional SiftFlow, Barcelona, CamVid, Stanford Background as well as the recently released large-scale ADE20K.",
        "A83": "",
        "A82": "",
        "A81": " MPF-RNN has achieved significant improvement ",
        "A64": "Different from feedforward CNNs and RNNs with only single feedback, MPF-RNN propagates the contextual features learned at top layer through multiple weighted recurrent connections to learn bottom features.",
        "A54": "MPF-RNN can enhance the capability of RNNs in modeling long-range context information at multiple levels and better distinguish pixels that are easy to confuse.",
        "A44": "a novel Multi-Path Feedback recurrent neural network (MPF-RNN) for parsing scene images",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 153138363
    },
    {
        "Abstract": "We propose an algorithm for enumerating solutions to the Lasso regression problem.In ordinary Lasso regression, one global optimum is obtained and the resulting features are interpreted as task-relevant features.However, this can overlook possibly relevant features not selected by the Lasso.With the proposed method, we can enumerate many possible feature sets for human inspection, thus recording all the important features.We prove that by enumerating solutions, we can recover a true feature set exactly under less restrictive conditions compared with the ordinary Lasso.We confirm our theoretical results also in numerical simulations.Finally, in the gene expression and the text data, we demonstrate that the proposed method can enumerate a wide variety of meaningful feature sets, which are overlooked by the global optima.",
        "A1": "algorithm for enumerating solutions to the Lasso regression problem",
        "A2": " this can overlook possibly relevant features not selected by the Lasso",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "in the gene expression and the text data",
        "A83": " theoretical results also in numerical simulations",
        "A82": "recover a true feature set exactly under less restrictive conditions compared with the ordinary Lasso",
        "A81": " proposed method can enumerate a wide variety of meaningful feature sets, which are overlooked by the global optima.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "enumerate many possible feature sets for human inspection, thus recording all the important feature",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 298190795
    },
    {
        "Abstract": "Binary optimization is a central problem in mathematical optimization and its applications are abundant. To solve this problem, we propose a new class of continuous optimization techniques, which is based on Mathematical Programming with Equilibrium Constraints (MPECs). We first reformulate the binary program as an equivalent augmented biconvex optimization problem with a bilinear equality constraint, then we propose an exact penalty method to solve it. The resulting algorithm seeks a desirable solution to the original problem via solving a sequence of linear programming convex relaxation subproblems. In addition, we prove that the penalty function, induced by adding the complementarity constraint to the objective, is exact, i.e., it has the same local and global minima with those of the original binary program when the penalty parameter is over some threshold. The convergence of the algorithm can be guaranteed, since it essentially reduces to block coordinate descent in the literature. Finally, we demonstrate the effectiveness of our method on the problem of dense subgraph discovery. Extensive experiments show that our method outperforms existing techniques, such as iterative hard thresholding and linear programming relaxation.",
        "A1": "propose a new class of continuous optimization techniques",
        "A2": "Binary optimization",
        "A41": "continuous optimization techniques",
        "A51": "Mathematical Programming with Equilibrium Constraints (MPECs)",
        "A61": " outperforms existing techniques",
        "A10": " iterative hard thresholding and linear programming relaxation.",
        "A7": "the problem of dense subgraph discovery",
        "A83": "",
        "A82": "it has the same local and global minima with those of the original binary program",
        "A81": " our method outperforms existing techniques",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "MPECs",
        "A43": "seeks a desirable solution to the original problem via solving a sequence of linear programming convex relaxation subproblems",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 131554149
    },
    {
        "Abstract": "Cosegmentation jointly segments the common objects from multiple images. In this paper, a novel clustering algorithm, called Saliency-Guided Constrained Clustering approach with Cosine similarity (SGC3), is proposed for the image cosegmentation task, where the common foregrounds are extracted via a one-step clustering process. In our method, the unsupervised saliency prior is utilized as a partition-level side information to guide the clustering process. To guarantee the robustness to noise and outlier in the given prior, the similarities of instance-level and partition-level are jointly computed for cosegmentation. Specifically, we employ cosine distance to calculate the feature similarity between data point and its cluster centroid, and introduce a cosine utility function to measure the similarity between clustering result and the side information. These two parts are both based on the cosine similarity, which is able to capture the intrinsic structure of data, especially for the non-spherical cluster structure. Finally, a K-means-like optimization is designed to solve our objective function in an efficient way. Experimental results on two widely-used datasets demonstrate our approach achieves competitive performance over the state-of-the-art cosegmentation methods.",
        "A1": "a novel clustering algorithm, called Saliency-Guided Constrained Clustering approach with Cosine similarity (SGC3), is proposed for the image cosegmentation task",
        "A2": "image cosegmentation task",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves competitive performance over the state-of-the-art cosegmentation methods",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "achieves competitive performance over the state-of-the-art cosegmentation methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "the unsupervised saliency prior is utilized as a partition-level side information to guide the clustering process.",
        "A53": "unsupervised saliency prior ",
        "A43": "SGC3",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 136983493
    },
    {
        "Abstract": "Hashing has been proven a promising technique for fast nearest neighbor search over massive databases. In many practical tasks it usually builds multiple hash tables for a desired level of recall performance. However, existing multi-table hashing methods suffer from the heavy table redundancy, without strong table complementarity and effective hash code learning. To address the problem, this paper proposes a multi-table learning method which pursues a specified number of complementary and informative hash tables from a perspective of ensemble learning. By regarding each hash table as a neighbor prediction model, the multi-table search procedure boils down to a linear assembly of predictions stemming from multiple tables. Therefore, a sequential updating and learning framework is naturally established in a boosting mechanism, theoretically guaranteeing the table complementarity and algorithmic convergence. Furthermore, each boosting round pursues the discriminative hash functions for each table by a discrete optimization in the binary code space. Extensive experiments carried out on two popular tasks including Euclidean and semantic nearest neighbor search demonstrate that the proposed boosted complementary hash-tables method enjoys the strong table complementarity and significantly outperforms the state-of-the-arts.",
        "A1": "To address the problem",
        "A2": "pursues a specified number of complementary and informative hash tables ",
        "A41": "pursues a specified number of complementary and informative hash tables from a perspective of ensemble learning",
        "A51": "a perspective of ensemble learning",
        "A61": " enjoys the strong table complementarity and significantly outperforms the state-of-the-arts.",
        "A10": "pursues a specified number of complementary and informative hash tables ",
        "A7": " two popular tasks including Euclidean and semantic nearest neighbor search",
        "A83": "",
        "A82": " significantly outperforms the state-of-the-arts.",
        "A81": "the proposed boosted complementary hash-tables method enjoys the strong table complementarity",
        "A64": " guaranteeing the table complementarity and algorithmic convergence",
        "A54": "a boosting mechanism",
        "A44": " a sequential updating and learning framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "enjoys the strong table complementarity and significantly outperforms the state-of-the-arts.",
        "A52": "a sequential updating and learning framework",
        "A42": "By regarding each hash table as a neighbor prediction model, the multi-table search procedure boils down to a linear assembly of predictions stemming from multiple tables",
        "A45": "",
        "am_id": 43807810
    },
    {
        "Abstract": "Conventional face hallucination methods rely heavily on accurate alignment of low-resolution (LR) faces before upsampling them. Misalignment often leads to deficient results and unnatural artifacts for large upscaling factors. However, due to the diverse range of poses and different facial expressions, aligning an LR input image, in particular when it is tiny, is severely difficult. To overcome this challenge, here we present an end-to-end transformative discriminative neural network (TDN) devised for super-resolving unaligned and very small face images with an extreme upscaling factor of 8. Our method employs an upsampling network where we embed spatial transformation layers to allow local receptive fields to line-up with similar spatial supports. Furthermore, we incorporate a class-specific loss in our objective through a successive discriminative network to improve the alignment and upsampling performance with semantic information. Extensive experiments on large face datasets show that the proposed method significantly outperforms the state-of-the-art.",
        "A1": "Conventional face hallucination methods",
        "A2": "aligning an LR input image, in particular when it is tiny, is severely difficult",
        "A41": "an end-to-end transformative discriminative neural network (TDN) devised for super-resolving unaligned and very small face images with an extreme upscaling factor of 8",
        "A51": " an upsampling network ",
        "A61": "",
        "A10": "hat the proposed method significantly outperforms the state-of-the-art",
        "A7": "Extensive experiments on large face datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 400021845
    },
    {
        "Abstract": "The dynamic Boltzmann machine (DyBM) has been proposed as a stochastic generative model of multi-dimensional time series, with an exact, learning rule that maximizes the log-likelihood of a given time series. The DyBM, however, is defined only for binary valued data, without any nonlinear hidden units. Here, in our first contribution, we extend the DyBM to deal with real valued data. We present a formulation called Gaussian DyBM, that can be seen as an extension of a vector autoregressive (VAR) model. This uses, in addition to standard (explanatory) variables, components that captures long term dependencies in the time series. In our second contribution, we extend the Gaussian DyBM model with a recurrent neural network (RNN) that controls the bias input to the DyBM units. We derive a stochastic gradient update rule such that, the output weights from the RNN can also be trained online along with other DyBM parameters. Furthermore, this acts as nonlinear hidden layer extending the capacity of DyBM and allows it to model nonlinear components in a given time-series. Numerical experiments with synthetic datasets show that the RNN-Gaussian DyBM improves predictive accuracy upon standard VAR by up to 35%. On real multi-dimensional time-series prediction, consisting of high nonlinearity and non-stationarity, we demonstrate that this nonlinear DyBM model achieves significant improvement upon state of the art baseline methods like VAR and long short-term memory (LSTM) networks at a reduced computational cost.",
        "A1": "",
        "A2": "DyBM, however, is defined only for binary valued data, without any nonlinear hidden units.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we demonstrate that this nonlinear DyBM model achieves significant improvement upon state of the art baseline methods like VAR and long short-term memory (LSTM) networks at a reduced computational cost.",
        "A7": "Numerical experiments with synthetic datasets",
        "A83": "",
        "A82": "",
        "A81": "show that the RNN-Gaussian DyBM improves predictive accuracy upon standard VAR by up to 35%",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "in addition to standard (explanatory) variables, components that captures long term dependencies in the time series.",
        "A52": " DyBM",
        "A42": "Gaussian DyBM, that can be seen as an extension of a vector autoregressive (VAR) model",
        "A45": "",
        "am_id": 498663970
    },
    {
        "Abstract": "Answer Set Programming (ASP) is a well-established formalism for nonmonotonic reasoning. An ASP program can have no answer set due to cyclic default negation. In this case, it is not possible to draw any conclusion, even if this is not intended. Recently, several paracoherent semantics have been proposed that address this issue,and several potential applications for these semantics have been identified. However, paracoherent semantics have essentially been inapplicable in practice, due to the lack of efficient algorithms and implementations. In this paper, this lack is addressed, and several different algorithms to compute semi-stable and semi-equilibrium models are proposed and implemented into an answer set solving framework. An empirical performance comparison among the new algorithms on benchmarks from ASP competitions is given as well.",
        "A1": "several different algorithms to compute semi-stable and semi-equilibrium models are proposed",
        "A2": " the lack of efficient algorithms and implementations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "An empirical performance comparison",
        "A83": "",
        "A82": "An empirical performance comparison among the new algorithms on benchmarks from ASP competitions",
        "A81": "this lack is addressed",
        "A64": "",
        "A54": "",
        "A44": "an answer set solving framework",
        "A63": "",
        "A53": "",
        "A43": "compute semi-stable and semi-equilibrium models",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 473970359
    },
    {
        "Abstract": "When learning from instances whose output labels may be partial, the problem of knowing which of these output labels should be made precise to improve the accuracy of predictions arises. This problem can be seen as the intersection of two tasks: the one of learning from partial labels and the one of active learning, where the goal is to provide the labels of additional instances to improve the model accuracy. In this paper, we propose querying strategies of partial labels for the well-known K-nn classifier. We propose different criteria of increasing complexity, using among other things the amount of ambiguity that partial labels introduce in the K-nn decision rule. We then show that our strategies usually outperform simple baseline schemes, and that more complex strategies provide a faster improvement of the model accuracies.",
        "A1": "",
        "A2": "he problem of knowing which of these output labels should be made precise to improve the accuracy of predictions arises",
        "A41": "querying strategies of partial labels for the well-known K-nn classifier",
        "A51": "",
        "A61": "",
        "A10": "usually outperform simple baseline schemes",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "more complex strategies provide a faster improvement of the model accuracies",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 217449529
    },
    {
        "Abstract": "Powerful formalisms for abstract argumentation have been proposed. Their complexity is often located beyond NP and ranges up to the third level of the polynomial hierarchy. The combined complexity of Answer-Set Programming (ASP) exactly matches this complexity when programs are restricted to predicates of bounded arity. In this paper, we exploit this coincidence and present novel efficient translations from abstract dialectical frameworks (ADFs) and GRAPPA to ASP.We also empirically compare our approach to other systems for ADF reasoning and report promising results.",
        "A1": "exploit this coincidence and present novel efficient translations from abstract dialectical frameworks (ADFs) and GRAPPA to ASP",
        "A2": "",
        "A41": "novel efficient translations from abstract dialectical frameworks (ADFs) and GRAPPA to ASP",
        "A51": "",
        "A61": "",
        "A10": "promising",
        "A7": "empirically compare",
        "A83": "",
        "A82": "",
        "A81": "promising results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 332852985
    },
    {
        "Abstract": "Evolutionary game theory focuses on the fitness differences between simple discrete or probabilistic strategies to explain the evolution of particular decision-making behavior within strategic situations. Although this approach has provided substantial insights into the presence of fairness or generosity in gift-giving games, it does not fully resolve the question of which cognitive mechanisms are required to produce the choices observed in experiments. One such mechanism that humans have acquired, is the capacity to anticipate. Prior work showed that forward-looking behavior, using a recurrent neural network to model the cognitive mechanism, are essential to produce the actions of human participants in behavioral experiments. In this paper, we evaluate whether this conclusion extends also to gift-giving games, more concretely, to a game that combines the dictator game with a partner selection process. The recurrent neural network model used here for dictators, allows them to reason about a best response to past actions of the receivers (reactive model) or to decide which action will lead to a more successful outcome in the future (anticipatory model). We show for both models the decision dynamics while training, as well as the average behavior. We find that the anticipatory model is the only one capable of accounting for changes in the context of the game, a behavior also observed in experiments, expanding previous conclusions to this more sophisticated game.",
        "A1": "evaluate whether this conclusion extends also to gift-giving games",
        "A2": "which cognitive mechanisms are required to produce the choices observed in experiments",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a behavior also observed in experiments",
        "A83": "",
        "A82": "",
        "A81": "expanding previous conclusions to this more sophisticated game",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the anticipatory model is the only one capable of accounting for changes in the context of the game",
        "A52": "recurrent neural network ",
        "A42": "The recurrent neural network model used here for dictators",
        "A45": "",
        "am_id": 401937284
    },
    {
        "Abstract": "Security agencies have found security games to be useful models to understand how to better protect their assets. The key practical elements in this work are: (i) the attacker can simultaneously attack multiple targets, and (ii) different targets exhibit different types of dependencies based on the assets being protected (e.g., protection of critical infrastructure, network security, etc.). However, little is known about the computational complexity of these problems, especially when there exist dependencies among the targets. Moreover, previous security game models do not in general scale well. In this paper, we investigate a general security game where the utility function is defined on a collection of subsets of all targets, and provide a novel theoretical framework to show how to compactly represent such a game, efficiently compute the optimal (minimax) strategies, and characterize the complexity of this problem. We apply our theoretical framework to the network security game. We characterize settings under which we find a polynomial time algorithm for computing optimal strategies. In other settings we prove the problem is NP-hard and provide an approximation algorithm.",
        "A1": "investigate a general security game",
        "A2": "little is known about the computational complexity of these problems, especially when there exist dependencies among the targets. Moreover, previous security game models do not in general scale well",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We characterize settings under which we find a polynomial time algorithm for computing optimal strategies. In other settings we prove the problem is NP-hard and provide an approximation algorithm.",
        "A7": "apply our theoretical framework to the network security game",
        "A83": "",
        "A82": "In other settings we prove the problem is NP-hard and provide an approximation algorithm",
        "A81": " find a polynomial time algorithm for computing optimal strategies",
        "A64": "",
        "A54": "",
        "A44": "show how to compactly represent such a game, efficiently compute the optimal (minimax) strategies, and characterize the complexity of this problem",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 460950771
    },
    {
        "Abstract": "Patents are widely regarded as a proxy for inventive output which is valuable and can be commercialized by various means. Individual patent information such as technology field, classification, claims, application jurisdictions are increasingly available as released by different venues. This work has relied on a long-standing hypothesis that the citation received by a patent is a proxy for knowledge flows or impacts of the patent thus is directly related to patent value. This paper does not fall into the line of intensive existing work that test or apply this hypothesis, rather we aim to address the limitation of using so-far received citations for patent valuation. By devising a point process based patent citation type aware (self-citation and non-self-citation) prediction model which incorporates the various information of a patent, we open up the possibility for performing predictive patent valuation which can be especially useful for newly granted patents with emerging technology. Study on real-world data corroborates the efficacy of our approach. Our initiative may also have policy implications for technology markets, patent systems and all other stakeholders. The code and curated data will be available to the research community.",
        "A1": "we aim to address the limitation of using so-far received citations for patent valuation",
        "A2": " the limitation of using so-far received citations for patent valuation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "open up the possibility for performing predictive patent valuation which can be especially useful for newly granted patents with emerging technology.",
        "A7": " Study on real-world data corroborates the efficacy of our approach.",
        "A83": "",
        "A82": "",
        "A81": "corroborates the efficacy of our approach. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "open up the possibility for performing predictive patent valuation which can be especially useful for newly granted patents with emerging technology.",
        "A52": "point process",
        "A42": " a point process based patent citation type aware (self-citation and non-self-citation) prediction model ",
        "A45": "",
        "am_id": 154476314
    },
    {
        "Abstract": "There are many successful spectral based unsupervised dimensionality reduction methods, including Laplacian Eigenmap (LE), Locality Preserving Projection (LPP), Spectral Regression (SR), etc. LPP and SR are two different linear spectral based methods, however, we discover that LPP and SR are equivalent, if the symmetric similarity matrix is doubly stochastic, Positive Semi-Definite (PSD) and with rank p, where p is the reduced dimension. The discovery promotes us to seek low-rank and doubly stochastic similarity matrix, we then propose an unsupervised linear dimensionality reduction method, called Unsupervised Large Graph Embedding (ULGE). ULGE starts with similar idea as LPP, it adopts an efficient approach to construct similarity matrix and then performs spectral analysis efficiently, the computational complexity can reduce to O(ndm), which is a significant improvement compared to conventional spectral based methods which need O(n^2d) at least, where n, d and m are the number of samples, dimensions and anchors, respectively. Extensive experiments on several public available data sets demonstrate the efficiency and effectiveness of the proposed method.",
        "A1": "propose an unsupervised linear dimensionality reduction method",
        "A2": " the computational complexity can reduce to O(ndm)",
        "A41": "ULGE",
        "A51": "dimensionality reduction",
        "A61": "the computational complexity can reduce to O(ndm), ",
        "A10": "efficiency and effectiveness of the proposed method",
        "A7": "experiments on several public available data sets ",
        "A83": "",
        "A82": "",
        "A81": "efficiency and effectiveness of the proposed method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 432520874
    },
    {
        "Abstract": "Inferring the latent emotive content of a narrative requires consideration of para-linguistic cues (e.g. pitch), linguistic content (e.g. vocabulary) and the physiological state of the narrator (e.g. heart-rate). In this study we utilized a combination of auditory, text, and physiological signals to predict the mood (happy or sad) of 31 narrations from subjects engaged in personal story-telling. We extracted 386 audio and 222 physiological features (using the Samsung Simband) from the data. A subset of 4 audio, 1 text, and 5 physiologic features were identified using Sequential Forward Selection (SFS) for inclusion in a Neural Network (NN). These features included subject movement, cardiovascular activity, energy in speech, probability of voicing, and linguistic sentiment (i.e. negative or positive). We explored the effects of introducing our selected features at various layers of the NN and found that the location of these features in the network topology had a significant impact on model performance. To ensure the real-time utility of the model, classification was performed over 5 second intervals. We evaluated our model\u2019s performance using leave-one-subject-out crossvalidation and compared the performance to 20 baseline models and a NN with all features included in the input layer.",
        "A1": "Inferring the latent emotive content of a narrative",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "predict the mood (happy or sad) of 31 narrations from subjects engaged in personal story-telling",
        "A83": "",
        "A82": "ensure the real-time utility",
        "A81": "the location of these features in the network topology had a significant impact on model performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Sequential Forward Selection (SFS) for inclusion in a Neural Network (NN)",
        "A42": "features were identified",
        "A45": "",
        "am_id": 406276780
    },
    {
        "Abstract": "Nowadays, asynchronous parallel algorithms have received much attention in the optimization field due to the crucial demands for modern large-scale optimization problems. However, most asynchronous algorithms focus on convex problems. Analysis on nonconvex problems is lacking. For the Asynchronous Stochastic Descent (ASGD) algorithm, the best result from (Lian et al., 2015) can only achieve an asymptotic O(\\frac{1}{\\epsilon^2}) rate (convergence to the stationary points) on nonconvex problems. In this paper, we study Stochastic Variance Reduced Gradient (SVRG) in the asynchronous setting. We propose the Asynchronous Stochastic Variance Reduced Gradient (ASVRG) algorithm for nonconvex finite-sum problems. We develop two schemes for ASVRG, depending on whether the parameters are updated as an atom or not. We prove that both of the two schemes can achieve linear speed up (a non-asymptotic O(\\frac{n^\\frac{2}{3}}{\\epsilon}) rate to the stationary points) for nonconvex problems when the delay parameter \\tau\\leq n^{\\frac{1}{3}}, where n is the number of training samples. We also establish a non-asymptotic O(\\frac{n^\\frac{2}{3}\\tau^\\frac{1}{3}}{\\epsilon}) rate (convergence to the stationary points) for our algorithm without assumptions on \\tau. This further demonstrates that even with asynchronous updating, SVRG has less number of Incremental First-order Oracles (IFOs) compared with Stochastic Gradient Descent and Gradient Descent. We also experiment on a shared memory multi-core system to demonstrate the efficiency of our algorithm.",
        "A1": "",
        "A2": "In this paper, we study Stochastic Variance Reduced Gradient (SVRG) in the asynchronous setting.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " We also experiment on a shared memory multi-core system to demonstrate the efficiency of our algorithm.",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the efficiency of our algorithm.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "We propose the Asynchronous Stochastic Variance Reduced Gradient (ASVRG) algorithm for nonconvex finite-sum problems. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 181480054
    },
    {
        "Abstract": "Agricultural monitoring, especially in developing countries, can help prevent famine and support humanitarian efforts. A central challenge is yield estimation, i.e., predicting crop yields before harvest. We introduce a scalable, accurate, and inexpensive method to predict crop yields using publicly available remote sensing data. Our approach improves existing techniques in three ways. First, we forego hand-crafted features traditionally used in the remote sensing community and propose an approach based on modern representation learning ideas. We also introduce a novel dimensionality reduction technique that allows us to train a Convolutional Neural Network or Long-short Term Memory network and automatically learn useful features even when labeled training data are scarce. Finally, we incorporate a Gaussian Process component to explicitly model the spatio-temporal structure of the data and further improve accuracy. We evaluate our approach on county-level soybean yield prediction in the U.S. and show that it outperforms competing techniques.",
        "A1": "yield estimation",
        "A2": " predicting crop yields before harvest",
        "A41": "",
        "A51": " modern representation learning ideas",
        "A61": "Our approach improves existing techniques in three ways",
        "A10": "outperforms competing techniques",
        "A7": "on county-level soybean yield prediction in the U.S. ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 390943278
    },
    {
        "Abstract": "Customer volume prediction, which predicts the volume from a customer source to a service place, is a very important technique for location selection, market investigation, and other related applications. Most of traditional methods only make use of partial information for either supervised or unsupervised modeling, which cannot well integrate overall available knowledge. In this paper, we propose a method titled GR-NMF for jointly modeling both implicit correlations hidden inside customer volumes and explicit geographical knowledge via an integrated probabilistic framework. The effectiveness of GR-NMF in coupling all-round knowledge is verified over a real-life outpatient dataset under different scenarios. GR-NMF shows particularly evident advantages to all baselines in location selection with the cold-start challenge.",
        "A1": " integrate overall available knowledge",
        "A2": " In this paper, we propose a method titled GR-NMF for jointly modeling both implicit correlations hidden inside customer volumes and explicit geographical knowledge via an integrated probabilistic framework. ",
        "A41": " In this paper, we propose a method titled GR-NMF for jointly modeling both implicit correlations hidden inside customer volumes and explicit geographical knowledge via an integrated probabilistic framework. ",
        "A51": " an integrated probabilistic framework",
        "A61": "",
        "A10": "GR-NMF shows particularly evident advantages to all baselines in location selection with the cold-start challenge.",
        "A7": "The effectiveness of GR-NMF in coupling all-round knowledge is verified over a real-life outpatient dataset under different scenarios. GR-NMF shows particularly evident advantages to all baselines in location selection with the cold-start challenge.",
        "A83": "",
        "A82": "",
        "A81": "GR-NMF shows particularly evident advantages to all baselines in location selection with the cold-start challenge.",
        "A64": "",
        "A54": "",
        "A44": " In this paper, we propose a method titled GR-NMF for jointly modeling both implicit correlations hidden inside customer volumes and explicit geographical knowledge via an integrated probabilistic framework. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 133659341
    },
    {
        "Abstract": "Neural Machine Translation (NMT) is a new approach to machine translation that has made great progress in recent years. However, recent studies show that NMT generally produces fluent but inadequate translations (Tu et al. 2016b; 2016a; He et al. 2016; Tu et al. 2017). This is in contrast to conventional Statistical Machine Translation (SMT), which usually yields adequate but non-fluent translations. It is natural, therefore, to leverage the advantages of both models for better translations, and in this work we propose to incorporate SMT model into NMT framework. More specifically, at each decoding step, SMT offers additional recommendations of generated words based on the decoding information from NMT (e.g., the generated partial translation and attention history). Then we employ an auxiliary classifier to score the SMT recommendations and a gating function to combine the SMT recommendations with NMT generations, both of which are jointly trained within the NMT architecture in an end-to-end manner. Experimental results on Chinese-English translation show that the proposed approach achieves significant and consistent improvements over state-of-the-art NMT and SMT systems on multiple NIST test sets.",
        "A1": "to leverage the advantages of both models for better translations",
        "A2": " recent studies show that NMT generally produces fluent but inadequate translations",
        "A41": "incorporate SMT model into NMT framework",
        "A51": "SMT model into NMT framework",
        "A61": "",
        "A10": "the proposed approach achieves significant and consistent improvements over state-of-the-art NMT and SMT systems on multiple NIST test sets.",
        "A7": "on Chinese-English translation",
        "A83": "",
        "A82": "",
        "A81": "the proposed approach achieves significant and consistent improvements over state-of-the-art NMT and SMT systems on multiple NIST test sets.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 443854242
    },
    {
        "Abstract": "Traditional topic model with maximum likelihood estimate inevitably suffers from the conditional independence of words given the document\u2019s topic distribution. In this paper, we follow the generative procedure of topic model and learn the topic-word distribution and topics distribution via directly approximating the word-document co-occurrence matrix with matrix decomposition technique. These methods include: (1) Approximating the normalized document-word conditional distribution with the documents probability matrix and words probability matrix based on probabilistic non-negative matrix factorization (NMF); (2) Since the standard NMF is well known to be non-robust to noises and outliers, we extended the probabilistic NMF of the topic model to its robust versions using l21-norm and capped l21-norm based loss functions, respectively. The proposed framework inherits the explicit probabilistic meaning of factors in topic models and simultaneously makes the conditional independence assumption on words unnecessary. Straightforward and efficient algorithms are exploited to solve the corresponding non-smooth and non-convex problems. Experimental results over several benchmark datasets illustrate the effectiveness and superiority of the proposed methods.",
        "A1": "learn the topic-word distribution and topics distribution",
        "A2": "the conditional independence of words given the document\u2019s topic distribution",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results over several benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "he effectiveness and superiority of the proposed methods",
        "A64": "directly approximating the word-document co-occurrence matrix with matrix decomposition technique",
        "A54": "the generative procedure of topic model",
        "A44": "inherits the explicit probabilistic meaning of factors in topic models and simultaneously makes the conditional independence assumption on words unnecessary",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 80626826
    },
    {
        "Abstract": "Single Index Models (SIMs) are simple yet flexible semi-parametric models for machine learning, where the response variable is modeled as a monotonic function of a linear combination of features. Estimation in this context requires learning both the feature weights and the nonlinear function that relates features to observations. While methods have been described to learn SIMs in the low dimensional regime, a method that can efficiently learn SIMs in high dimensions, and under general structural assumptions, has not been forthcoming. In this paper, we propose computationally efficient algorithms for SIM inference in high dimensions with structural constraints. Our general approach specializes to sparsity, group sparsity, and low-rank assumptions among others. Experiments show that the proposed method enjoys superior predictive performance when compared to generalized linear models, and achieves results comparable to or better than single layer feedforward neural networks with significantly less computational cost.",
        "A1": "propose computationally efficient algorithms for SIM inference in high dimensions with structural constraints",
        "A2": "Our general approach specializes to sparsity, group sparsity, and low-rank assumptions among others",
        "A41": "Our general approach specializes to sparsity, group sparsity, and low-rank assumptions among others",
        "A51": "",
        "A61": "",
        "A10": "achieves results comparable to or better than single layer feedforward neural networks with significantly less computational cost",
        "A7": "",
        "A83": "",
        "A82": "achieves results comparable to or better than single layer feedforward neural networks with significantly less computational cost",
        "A81": "the proposed method enjoys superior predictive performance when compared to generalized linear models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "we propose computationally efficient algorithms for SIM inference in high dimensions with structural constraints",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 239156461
    },
    {
        "Abstract": "Automatic caption generation is a key research field in the machine learning community. However, most of the current research is performed on English caption generation ignoring other languages like Arabic and Persian. In this paper, we propose a novel technique leveraging the heavy influence of root words in Arabic to automatically generate captions in Arabic. Fragments of the images are associated with root words and deep belief network pre-trained using Restricted Boltzmann Machines are used to extract words associated with image. Finally, dependency tree relations are used to generate sentence-captions by using the dependency on root words. Our approach is robust and attains BLEU-1 score of 34.8.",
        "A1": "we propose a novel technique leveraging the heavy influence of root words in Arabic to automatically generate captions in Arabic.",
        "A2": "most of the current research is performed on English caption generation ignoring other languages like Arabic and Persian",
        "A41": "a novel technique leveraging the heavy influence of root words in Arabic to automatically generate captions in Arabic",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " Our approach is robust and attains BLEU-1 score of 34.8.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 334832067
    },
    {
        "Abstract": "Online joint parameter and state estimation is a core problem for temporal models.Most existing methods are either restricted to a particular class of models (e.g., the Storvik filter) or computationally expensive (e.g., particle MCMC). We propose a novel nearly-black-box algorithm, the Assumed Parameter Filter (APF), a hybrid of particle filtering for state variables and assumed density filtering for parameter variables.It has the following advantages:(a) it is online and computationally efficient;(b) it is applicable to both discrete and continuous parameter spaces with arbitrary transition dynamics.On a variety of toy and real models, APF generates more accurate results within a fixed computation budget compared to several standard algorithms from the literature.",
        "A1": "propose a novel nearly-black-box algorithm",
        "A2": "(a) it is online and computationally efficient;(b) it is applicable to both discrete and continuous parameter spaces with arbitrary transition dynamics.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "APF generates more accurate results within a fixed computation budget compared to several standard algorithms from the literature.",
        "A7": "On a variety of toy and real models",
        "A83": "",
        "A82": "",
        "A81": "APF generates more accurate results within a fixed computation budget compared to several standard algorithms from the literature.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": ":(a) it is online and computationally efficient;(b) it is applicable to both discrete and continuous parameter spaces with arbitrary transition dynamics.",
        "A53": "",
        "A43": "a novel nearly-black-box algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 372421167
    },
    {
        "Abstract": "A clique model is one of the most important techniques on the cohesive subgraph detection; however, its applications are rather limited due to restrictive conditions of the model. Hence much research resorts to k-plex \u2014 a graph in which any vertex is adjacent to all but at most k vertices \u2014 which is a relaxation model of the clique. In this paper, we study the maximum k-plex problem and propose a fast algorithm to compute maximum k-plexes by exploiting structural properties of the problem. In an n-vertex graph, the algorithm computes optimal solutions in cnnO(1) time for a constant c < 2 depending only on k. To the best of our knowledge, this is the first algorithm that breaks the trivial theoretical bound of 2n for each k \u2265 3. We also provide experimental results over multiple real-world social network instances in support.",
        "A1": "study the maximum k-plex problem ",
        "A2": "propose a fast algorithm to compute maximum k-plexes by exploiting structural properties of the problem",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the first algorithm that breaks the trivial theoretical bound of 2n for each k \u2265 3. ",
        "A7": "experimental results over multiple real-world social network instances",
        "A83": "",
        "A82": "",
        "A81": "experimental results over multiple real-world social network instances in support.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": null
    },
    {
        "Abstract": "Driven by recent developments in Artificial Intelligence research, a promising new technology for building intelligent agents has evolved. The approach is termed Deep Reinforcement Learning and combines the classic field of Reinforcement Learning (RL) with the representational power of modern Deep Learning approaches. It is very well suited for single task learning but needs a long time to learn any new task. To speed up this process, we propose to extend the concept to multi-task learning by adapting Policy Reuse, a Transfer Learning approach from classic RL, to use with Deep Q-Networks.",
        "A1": " It is very well suited for single task learning but needs a long time to learn any new task. To speed up this process, ",
        "A2": "we propose to extend the concept to multi-task learning by adapting Policy Reuse, a Transfer Learning approach from classic RL, to use with Deep Q-Networks.",
        "A41": "we propose to extend the concept to multi-task learning by adapting Policy Reuse, a Transfer Learning approach from classic RL, to use with Deep Q-Networks.",
        "A51": " Policy Reuse",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 351544891
    },
    {
        "Abstract": "Dictionary learning has played an important role in the success of sparse representation, which triggers the rapid developments of unsupervised and supervised dictionary learning methods. However, in most practical applications, there are usually quite limited labeled training samples while it is relatively easy to acquire abundant unlabeled training samples. Thus semi-supervised dictionary learning that aims to effectively explore the discrimination of unlabeled training data has attracted much attention of researchers. Although various regularizations have been introduced in the prevailing semi-supervised dictionary learning, how to design an effective unified model of dictionary learning and unlabeled-data class estimating and how to well explore the discrimination in the labeled and unlabeled data are still open. In this paper, we propose a novel discriminative semi-supervised dictionary learning model (DSSDL) by introducing discriminative representation, an identical coding of unlabeled data to the coding of testing data final classification, and an entropy regularization term. The coding strategy of unlabeled data can not only avoid the affect of its incorrect class estimation, but also make the learned discrimination be well exploited in the final classification. The introduced regularization of entropy can avoid overemphasizing on some uncertain estimated classes for unlabeled samples. Apart from the enhanced discrimination in the learned dictionary by the discriminative representation, an extended dictionary is used to mainly explore the discrimination embedded in the unlabeled data. Extensive experiments on face recognition, digit recognition and texture classification show the effectiveness of the proposed method.",
        "A1": "Dictionary learning",
        "A2": "how to design an effective unified model of dictionary learning and unlabeled-data class estimating and how to well explore the discrimination in the labeled and unlabeled data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the effectiveness of the proposed method.",
        "A7": "on face recognition, digit recognition and texture classification ",
        "A83": "",
        "A82": "",
        "A81": " the effectiveness of the proposed method.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " The coding strategy of unlabeled data can not only avoid the affect of its incorrect class estimation, but also make the learned discrimination be well exploited in the final classification. The introduced regularization of entropy can avoid overemphasizing on some uncertain estimated classes for unlabeled samples. Apart from the enhanced discrimination in the learned dictionary by the discriminative representation, an extended dictionary is used to mainly explore the discrimination embedded in the unlabeled data",
        "A52": "",
        "A42": "a novel discriminative semi-supervised dictionary learning model (DSSDL) by introducing discriminative representation, an identical coding of unlabeled data to the coding of testing data final classification, and an entropy regularization term.",
        "A45": "",
        "am_id": 326551988
    },
    {
        "Abstract": "Modeling stochastic multiagent behavior such as fish schooling is challenging for fixed-estimate prediction techniques because they fail to reliably reproduce the stochastic aspects of the agents\u2019 behavior. We show how standard fixed-estimate predictors fit within a probabilistic framework, and suggest the reason they work for certain classes of behaviors and not others. We quantify the degree of mismatch and offer alternative sampling-based modeling techniques. We are specifically interested in building executable models (as opposed to statistical or descriptive models) because we want to reproduce and study multiagent behavior in simulation. Such models can be used by biologists, sociologists, and economists to explain and predict individual and group behavior in novel scenarios, and to test hypotheses regarding group behavior. Developing models from observation of real systems is an obvious application of machine learning. Learning directly from data eliminates expensive hand processing and tuning, but introduces unique challenges that violate certain assumptions common in standard machine learning approaches. Our framework suggests a new class of sampling-based methods, which we implement and apply to simulated deterministic and stochastic schooling behaviors, as well as the observed schooling behavior of real fish. Experimental results show that our implementation performs comparably with standard learning techniques for deterministic behaviors, and better on stochastic behaviors.",
        "A1": "Modeling stochastic multiagent behavior",
        "A2": "they fail to reliably reproduce the stochastic aspects of the agents\u2019 behavior",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our implementation performs comparably with standard learning techniques for deterministic behaviors, and better on stochastic behaviors.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our implementation performs comparably with standard learning techniques for deterministic behaviors, and better on stochastic behaviors.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "quantify the degree of mismatch and offer alternative sampling-based modeling techniques",
        "A52": "standard fixed-estimate predictors fit within a probabilistic framework",
        "A42": "executable models",
        "A45": "",
        "am_id": 382470549
    },
    {
        "Abstract": "Understanding commonsense reasoning is one of the core challenges of AI. We are exploring an approach inspired by cognitive science, called analogical chaining, to create cognitive systems that can perform commonsense reasoning. Just as rules are chained in deductive systems, multiple analogies build upon each other\u2019s inferences in analogical chaining. The cases used in analogical chaining \u2013 called common sense units \u2013 are small, to provide inferential focus and broader transfer. Importantly, such common sense units can be learned via natural language instruction, thereby increasing the ease of extending such systems. This paper describes analogical chaining, natural language instruction via microstories, and some subtleties that arise in controlling reasoning. The utility of this technique is demonstrated by performance of an implemented system on problems from the Choice of Plausible Alternatives test of commonsense causal reasoning.",
        "A1": "describes analogical chaining, natural language instruction via microstories, and some subtleties that arise in controlling reasoning.",
        "A2": "Understanding commonsense reasoning ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The utility of this technique is demonstrated by performance of an implemented system on problems from the Choice of Plausible Alternatives test of commonsense causal reasoning.",
        "A7": "performance of an implemented system on problems from the Choice of Plausible Alternatives test of commonsense causal reasoning.",
        "A83": "",
        "A82": "",
        "A81": "performance of an implemented system",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 368371208
    },
    {
        "Abstract": "When an agent cannot represent a perfectly accurate model of its environment's dynamics, model-based reinforcement learning (MBRL) can fail catastrophically. Planning involves composing the predictions of the model; when flawed predictions are composed, even minor errors can compound and render the model useless for planning. Hallucinated Replay (Talvitie 2014) trains the model to \"correct\" itself when it produces errors, substantially improving MBRL with flawed models. This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error. These results inspire an MBRL algorithm for deterministic MDPs with performance guarantees that are robust to model class limitations.",
        "A1": "This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error.",
        "A2": "This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "presents a novel error bound",
        "A82": "illuminates settings in which it is likely to be effective or ineffective",
        "A81": "a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "This paper theoretically analyzes this approach, illuminates settings in which it is likely to be effective or ineffective, and presents a novel error bound, showing that a model's ability to self-correct is more tightly related to MBRL performance than one-step prediction error.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 375376003
    },
    {
        "Abstract": "We present three results on the complexity of MINIMAX APPROVAL VOTING. First, we study MINIMAX APPROVAL VOTING parameterized by the Hamming distance d from the solution to the votes. We show MINIMAX APPROVAL VOTING admits no algorithm running in time O\u22c6(2o(d log d), unless the Exponential Time Hypothesis (ETH) fails. This means that the O\u22c6(d2d) algorithm of Misra et al. (AAMAS 2015) is essentially optimal. Motivated by this, we then show a parameterized approximation scheme, running in time O\u22c6((3/\u03b5)2d), which is essentially tight assuming ETH. Finally, we get a new polynomial-time randomized approximation scheme for MINIMAX APPROVAL VOTING, which runs in time nO(1/\u03b52\u00b7log(1/\u03b5))\u00b7 poly(m), almost matching the running time of the fastest known PTAS for CLOSEST STRING due to Ma and Sun (SIAM J. Comp. 2009).",
        "A1": "present three results on the complexity of MINIMAX APPROVAL VOTING",
        "A2": "the complexity of MINIMAX APPROVAL VOTING",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "almost matching the running time of the fastest known PTAS for CLOSEST STRING due to Ma and Sun (SIAM J. Comp. 2009)",
        "A7": "",
        "A83": "we get a new polynomial-time randomized approximation scheme for MINIMAX APPROVAL VOTING, which runs in time nO(1/\u03b52\u00b7log(1/\u03b5))\u00b7 poly(m)",
        "A82": "a parameterized approximation scheme, running in time O\u22c6((3/\u03b5)2d), which is essentially tight assuming ETH",
        "A81": "MINIMAX APPROVAL VOTING admits no algorithm running in time O\u22c6(2o(d log d), unless the Exponential Time Hypothesis (ETH) fails",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 400092063
    },
    {
        "Abstract": "The Robotics Program at Oregon State University has beenrunning an NSF-funded summer Research Experiences forUndergraduates (REU) site since 2014. Over twenty studentsper year (on average) have participated in the site, spendingten weeks embedded in the OSU Robotics Program. Our mainfocus with this REU Site is to give the participants a com-plete research experience, from problem definition to the fi-nal presentation of results, \"in miniature\". Our secondary ed-ucational objectives are: 1) Teach basic non-technical skillsneeded for graduate work, such as time management and lit-erature review, 2) Provide details on how to apply to gradu-ate school and for funding, 3) Clarify what we look for in agraduate student, and 4) Detail what to expect from the grad-uate student experience. In this paper, we describe the over-all structure of the participants\u2019 summer experience, outlinesome of the training materials that we use, describe the moti-vations for our approach, and discuss the lessons that we havelearned after running the program for a number of years.",
        "A1": "to give the participants a com-plete research experience, from problem definition to the fi-nal presentation of results, \"in miniature\".",
        "A2": "1) Teach basic non-technical skillsneeded for graduate work, such as time management and lit-erature review, 2) Provide details on how to apply to gradu-ate school and for funding, 3) Clarify what we look for in agraduate student, and 4) Detail what to expect from the grad-uate student experience. ",
        "A41": "to give the participants a com-plete research experience, from problem definition to the fi-nal presentation of results, \"in miniature\". ",
        "A51": " embedded in the OSU Robotics Program.",
        "A61": " embedded in the OSU Robotics Program.",
        "A10": "we describe the over-all structure of the participants\u2019 summer experience, outlinesome of the training materials that we use, describe the moti-vations for our approach, and discuss the lessons that we havelearned after running the program for a number of years.",
        "A7": "discuss the lessons that we havelearned after running the program for a number of years.",
        "A83": "Clarify what we look for in agraduate student, ",
        "A82": "Provide details on how to apply to gradu-ate school and for funding, ",
        "A81": "Teach basic non-technical skillsneeded for graduate work, such as time management and lit-erature review, ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 344108298
    },
    {
        "Abstract": "We consider incorporating topic information into a sequence-to-sequence framework to generate informative and interesting responses for chatbots. To this end, we propose a topic aware sequence-to-sequence (TA-Seq2Seq) model. The model utilizes topics to simulate prior human knowledge that guides them to form informative and interesting responses in conversation, and leverages topic information in generation by a joint attention mechanism and a biased generation probability. The joint attention mechanism summarizes the hidden vectors of an input message as context vectors by message attention and synthesizes topic vectors by topic attention from the topic words of the message obtained from a pre-trained LDA model, with these vectors jointly affecting the generation of words in decoding. To increase the possibility of topic words appearing in responses, the model modifies the generation probability of topic words by adding an extra probability item to bias the overall distribution. Empirical studies on both automatic evaluation metrics and human annotations show that TA-Seq2Seq can generate more informative and interesting responses, significantly outperforming state-of-the-art response generation models.",
        "A1": "incorporating topic information into a sequence-to-sequence framework to generate informative and interesting responses for chatbots",
        "A2": "generate informative and interesting responses for chatbots",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significantly",
        "A7": "Empirical studies on both automatic evaluation metrics and human annotations",
        "A83": "",
        "A82": "",
        "A81": "generate more informative and interesting responses",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "utilizes topics to simulate prior human knowledge that guides them to form informative and interesting responses in conversation, and leverages topic information in generation by a joint attention mechanism and a biased generation probability",
        "A52": "topics",
        "A42": "a topic aware sequence-to-sequence (TA-Seq2Seq) model",
        "A45": "",
        "am_id": 456739127
    },
    {
        "Abstract": "Many similarity-based clustering methods work in two separate steps including similarity matrix computation and subsequent spectral clustering. However similarity measurement is challenging because it is usually impacted by many factors, e.g., the choice of similarity metric, neighborhood size, scale of data, noise and outliers. Thus the learned similarity matrix is often not suitable, let alone optimal, for the subsequent clustering. In addition, nonlinear similarity often exists in many real world data which, however, has not been effectively considered by most existing methods. To tackle these two challenges, we propose a model to simultaneously learn cluster indicator matrix and similarity information in kernel spaces in a principled way. We show theoretical relationships to kernel k-means, k-means, and spectral clustering methods. Then, to address the practical issue of how to select the most suitable kernel for a particular clustering task, we further extend our model with a multiple kernel learning ability. With this joint model, we can automatically accomplish three subtasks of finding the best cluster indicator matrix, the most accurate similarity relations and the optimal combination of multiple kernels. By leveraging the interactions between these three subtasks in a joint framework, each subtask can be iteratively boosted by using the results of the others towards an overall optimal solution. Extensive experiments are performed to demonstrate the effectiveness of our method.",
        "A1": "we propose a model to simultaneously learn cluster indicator matrix and similarity information in kernel spaces in a principled way",
        "A2": "To tackle these two challenges,",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "to simultaneously learn cluster indicator matrix and similarity information in kernel spaces in a principled way",
        "A42": "similarity-based clustering ",
        "A45": "",
        "am_id": 152026781
    },
    {
        "Abstract": "Network embedding, aiming to learn the low-dimensional representations of nodes in networks, is of paramount importance in many real applications. One basic requirement of network embedding is to preserve the structure and inherent properties of the networks. While previous network embedding methods primarily preserve the microscopic structure, such as the first- and second-order proximities of nodes, the mesoscopic community structure, which is one of the most prominent feature of networks, is largely ignored. In this paper, we propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model to incorporate the community structure into network embedding. We exploit the consensus relationship between the representations of nodes and community structure, and then jointly optimize NMF based representation learning model and modularity based community detection model in a unified framework, which enables the learned representations of nodes to preserve both of the microscopic and community structures. We also provide efficient updating rules to infer the parameters of our model, together with the correctness and convergence guarantees. Extensive experimental results on a variety of real-world networks show the superior performance of the proposed method over the state-of-the-arts.",
        "A1": "propose a novel Modularized Nonnegative Matrix Factorization (M-NMF) model",
        "A2": " incorporate the community structure into network embedding",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the superior performance of the proposed method over the state-of-the-arts",
        "A7": "Extensive experimental results on a variety of real-world networks",
        "A83": "",
        "A82": "",
        "A81": "the superior performance of the proposed method over the state-of-the-arts",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "enables the learned representations of nodes to preserve both of the microscopic and community structures",
        "A52": "Modularized Nonnegative Matrix Factorization",
        "A42": "a novel Modularized Nonnegative Matrix Factorization (M-NMF) model",
        "A45": "",
        "am_id": 266089641
    },
    {
        "Abstract": "With the development of the information technology, the amount of data, e.g. text, image and video, has been increased rapidly. Efficiently clustering those large scale data sets is a challenge. To address this problem, this paper proposes a novel co-clustering method named bilateral k-means algorithm (BKM) for fast co-clustering. Different from traditional k-means algorithms, the proposed method has two indicator matrices P and Q and a diagonal matrix S to be solved, which represent the cluster memberships of samples and features, and the co-cluster centres, respectively. Therefore, it could implement different clustering tasks on the samples and features simultaneously. We also introduce an effective approach to solve the proposed method, which involves less multiplication. The computational complexity is analyzed. Extensive experiments on various types of data sets are conducted. Compared with the state-of-the-art clustering methods, the proposed BKM not only has faster computational speed, but also achieves promising clustering results.",
        "A1": "",
        "A2": " Efficiently clustering those large scale data sets is a challenge",
        "A41": "a novel co-clustering method named bilateral k-means algorithm (BKM) for fast co-clustering",
        "A51": "",
        "A61": "the proposed method has two indicator matrices P and Q and a diagonal matrix S to be solved, which represent the cluster memberships of samples and features, and the co-cluster centres, respectivel",
        "A10": "",
        "A7": "Extensive experiments on various types of data sets are conducted.",
        "A83": "",
        "A82": "",
        "A81": ", the proposed BKM not only has faster computational speed, but also achieves promising clustering results.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 419773581
    },
    {
        "Abstract": "How to train a binary neural network (BinaryNet) with both high compression rate and high accuracy on large scale dataset? We answer this question through a careful analysis of previous work on BinaryNets, in terms of training strategies, regularization, and activation approximation. Our findings first reveal that a low learning rate is highly preferred to avoid frequent sign changes of the weights, which often makes the learning of BinaryNets unstable. Secondly, we propose to use PReLU instead of ReLU in a BinaryNet to conveniently absorb the scale factor for weights to the activation function, which enjoys high computation efficiency for binarized layers while maintains high approximation accuracy. Thirdly, we reveal that instead of imposing L2 regularization, driving all weights to zero which contradicts with the setting of BinaryNets, we introduce a regularization term that encourages the weights to be bipolar. Fourthly, we discover that the failure of binarizing the last layer, which is essential for high compression rate, is due to the improper output range. We propose to use a scale layer to bring it to normal. Last but not least, we propose multiple binarizations to improve the approximation of the activations. The composition of all these enables us to train BinaryNets with both high compression rate and high accuracy, which is strongly supported by our extensive empirical study.",
        "A1": "train a binary neural network (BinaryNet) with both high compression rate and high accuracy on large scale dataset",
        "A2": "train a binary neural network (BinaryNet) with both high compression rate and high accuracy on large scale dataset",
        "A41": " in terms of training strategies, regularization, and activation approximation.",
        "A51": "BinaryNet",
        "A61": " in terms of training strategies, regularization, and activation approximation. ",
        "A10": "The composition of all these enables us to train BinaryNets with both high compression rate and high accuracy,",
        "A7": "which is strongly supported by our extensive empirical study.",
        "A83": "",
        "A82": "",
        "A81": "The composition of all these enables us to train BinaryNets with both high compression rate and high accuracy,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 10808596
    },
    {
        "Abstract": "Fine-grained image classification is challenging due to the large intra-class variance and small inter-class variance, aiming at recognizing hundreds of sub-categories belonging to the same basic-level category. Since two different sub-categories is distinguished only by the subtle differences in some specific parts, semantic part localization is crucial for fine-grained image classification. Most previous works improve the accuracy by looking for the semantic parts, but rely heavily upon the use of the object or part annotations of images whose labeling are costly. Recently, some researchers begin to focus on recognizing sub-categories via weakly supervised part detection instead of using the expensive annotations. However, these works ignore the spatial relationship between the object and its parts as well as the interaction of the parts, both of them are helpful to promote part selection. Therefore, this paper proposes a weakly supervised part selection method with spatial constraints for fine-grained image classification, which is free of using any bounding box or part annotations. We first learn a whole-object detector automatically to localize the object through jointly using saliency extraction and co-segmentation. Then two spatial constraints are proposed to select the distinguished parts. The first spatial constraint, called box constraint, defines the relationship between the object and its parts, and aims to ensure that the selected parts are definitely located in the object region, and have the largest overlap with the object region. The second spatial constraint, called parts constraint, defines the relationship of the object's parts, is to reduce the parts' overlap with each other to avoid the information redundancy and ensure the selected parts are the most distinguishing parts from other categories. Combining two spatial constraints promotes parts selection significantly as well as achieves a notable improvement on fine-grained image classification. Experimental results on CUB-200-2011 dataset demonstrate the superiority of our method even compared with those methods using expensive annotations.",
        "A1": "this paper proposes a weakly supervised part selection method with spatial constraints for fine-grained image classification,",
        "A2": "Most previous works improve the accuracy by looking for the semantic parts, but rely heavily upon the use of the object or part annotations of images whose labeling are costly. Recently, some researchers begin to focus on recognizing sub-categories via weakly supervised part detection instead of using the expensive annotations. However, these works ignore the spatial relationship between the object and its parts as well as the interaction of the parts",
        "A41": "this paper proposes a weakly supervised part selection method with spatial constraints for fine-grained image classification,",
        "A51": "weakly supervised part selection",
        "A61": "free of using any bounding box or part annotations.",
        "A10": "demonstrate the superiority of our method even compared with those methods using expensive annotations.",
        "A7": "Experimental results on CUB-200-2011 dataset ",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the superiority of our method even compared with those methods using expensive annotations.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 112810054
    },
    {
        "Abstract": "Determinantal point processes (DPPs) have garnered attention as an elegant probabilistic model of set diversity. They are useful for a number of subset selection tasks, including product recommendation. DPPs are parametrized by a positive semi-definite kernel matrix. In this work we present a new method for learning the DPP kernel from observed data using a low-rank factorization of this kernel. We show that this low-rank factorization enables a learning algorithm that is nearly an order of magnitude faster than previous approaches, while also providing for a method for computing product recommendation predictions that is far faster (up to 20x faster or more for large item catalogs) than previous techniques that involve a full-rank DPP kernel. Furthermore, we show that our method provides equivalent or sometimes better test log-likelihood than prior full-rank DPP approaches.",
        "A1": "present a new method for learning the DPP kernel from observed data using a low-rank factorization of this kernel",
        "A2": "We show that this low-rank factorization enables a learning algorithm that is nearly an order of magnitude faster than previous approaches, while also providing for a method for computing product recommendation predictions that is far faster (up to 20x faster or more for large item catalogs) than previous techniques that involve a full-rank DPP kernel",
        "A41": " a new method for learning the DPP kernel from observed data using a low-rank factorization of this kernel.",
        "A51": " low-rank factorization",
        "A61": "",
        "A10": "we show that our method provides equivalent or sometimes better test log-likelihood than prior full-rank DPP approaches",
        "A7": "we show that our method provides equivalent or sometimes better test log-likelihood than prior full-rank DPP approaches",
        "A83": "",
        "A82": "",
        "A81": "we show that our method provides equivalent or sometimes better test log-likelihood than prior full-rank DPP approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 228156301
    },
    {
        "Abstract": "This paper studies the problem of locating multiple diffusion sources in networks with partial observations. We propose a new source localization algorithm, named Optimal-Jordan-Cover (OJC). The algorithm first extracts a subgraph using a candidate selection algorithm that selects source candidates based on the number of observed infected nodes in their neighborhoods. Then, in the extracted subgraph, OJC finds a set of nodes that \"cover\" all observed infected nodes with the minimum radius. The set of nodes is called the Jordan cover, and is regarded as the set of diffusion sources. Considering the heterogeneous susceptible-infected-recovered (SIR) diffusion in the Erdos-Renyi (ER) random graph, we prove that OJC can locate all sources with probability one asymptotically with partial observations. OJC is a polynomial-time algorithm in terms of network size. However, the computational complexity increases exponentially in m; the number of sources. We further propose a low-complexity heuristic based on the K-Means for approximating the Jordan cover, named Approximate-Jordan-Cover (AJC). Simulations on random graphs and real networks demonstrate that both AJC and OJC significantly outperform other heuristic algorithms.",
        "A1": "propose a new source localization algorithm, named Optimal-Jordan-Cover (OJC)",
        "A2": "locating multiple diffusion sources in networks with partial observations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "in the extracted subgraph, OJC finds a set of nodes that \"cover\" all observed infected nodes with the minimum radius",
        "A53": "candidate selection algorithm",
        "A43": "a new source localization algorithm, named Optimal-Jordan-Cover (OJC)",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 407858169
    },
    {
        "Abstract": "Embedded feature selection is effective when both prediction and interpretation are needed. The Lasso and its extensions are standard methods for selecting a subset of features while optimizing a prediction function. In this paper, we are interested in embedded feature selection for multidimensional data, wherein (1) there is no need to reshape the multidimensional data into vectors and (2) structural information from multiple dimensions are taken into account. Our main contribution is a new method called Regularized multilinear regression and selection (Remurs) for automatically selecting a subset of features while optimizing prediction for multidimensional data. Both nuclear norm and the \u21131-norm are carefully incorporated to derive a multi-block optimization algorithm with proved convergence. In particular, Remurs is motivated by fMRI analysis where the data are multidimensional and it is important to find the connections of raw brain voxels with functional activities. Experiments on synthetic and real data show the advantages of Remurs compared to Lasso, Elastic Net, and their multilinear extensions.",
        "A1": "Regularized multilinear regression and selection (Remurs) for automatically selecting a subset of features",
        "A2": "optimizing prediction for multidimensional data.",
        "A41": "Regularized multilinear regression and selection ",
        "A51": " fMRI analysis",
        "A61": "Experiments on synthetic and real data show the advantages of Remurs ",
        "A10": "show the advantages of Remurs compared to Lasso, Elastic Net, and their multilinear extensions.",
        "A7": "Experiments on synthetic and real dat",
        "A83": "multilinear extensions.",
        "A82": " Elastic Net",
        "A81": "the advantages of Remurs compared to Lasso,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "find the connections of raw brain voxels with functional activities.",
        "A53": " nuclear norm and the \u21131-norm ",
        "A43": "Regularized multilinear regression and selection (Remurs) for automatically selecting a subset of features",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 476022124
    },
    {
        "Abstract": "In this paper, we tackle the problem of emotion tagging of multimedia data by modeling the dependencies among multiple emotions in both the feature and label spaces. These dependencies, which carry crucial top-down and bottom-up evidence for improving multimedia affective content analysis, have not been thoroughly exploited yet. To this end, we propose two hierarchical models that independently and dependently learn the shared features and global semantic relationships among emotion labels to jointly tag multiple emotion labels of multimedia data. Efficient learning and inference algorithms of the proposed models are also developed. Experiments on three benchmark emotion databases demonstrate the superior performance of our methods to existing methods.",
        "A1": "tackle the problem of emotion tagging of multimedia data by modeling the dependencies among multiple emotions in both the feature and label spaces",
        "A2": "These dependencies, which carry crucial top-down and bottom-up evidence for improving multimedia affective content analysis, have not been thoroughly exploited yet",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on three benchmark emotion databases",
        "A83": "",
        "A82": "",
        "A81": " the superior performance of our methods to existing methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "two hierarchical models that independently and dependently learn the shared features and global semantic relationships among emotion labels",
        "A45": "",
        "am_id": 496938398
    },
    {
        "Abstract": "Faced with the requirements of huge amounts of data processing nowadays, hashing techniques have attracted much attention due to their efficient storage and searching ability. Among these techniques, the ones based on spectral graph show remarkable performance as they could embed the data on a low-dimensional manifold and maintain the neighborhood structure via a non-linear spectral eigenmap. However, the spectral solution in real value of such methods may deviate from the discrete solution. The common practice is just performing a simple rounding operation to obtain the final binary codes, which could break constraints and even result in worse condition. In this paper, we propose to impose a so-called spectral rotation technique to the spectral hashing objective, which could transform the candidate solution into a new one that better approximates the discrete one. Moreover, the binary codes are obtained from the modified solution via minimizing the Euclidean distance, which could result in more semantical correlation within the manifold, where the constraints for codes are always held. We provide an efficient alternative algorithm to solve the above problems. And a manifold learning perceptive for motivating the proposed method is also shown. Extensive experiments are conducted on three large-scale benchmark datasets and the results show our method outperforms state-of-the-art hashing methods, especially the spectral graph ones.",
        "A1": " the requirements of huge amounts of data processing nowadays",
        "A2": "The common practice is just performing a simple rounding operation to obtain the final binary codes, which could break constraints and even result in worse condition. ",
        "A41": "spectral rotation technique to the spectral hashing objective, which could transform the candidate solution into a new one that better approximates the discrete one.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Extensive experiments are conducted on three large-scale benchmark datasets",
        "A83": "",
        "A82": "our method outperforms state-of-the-art hashing methods, especially the spectral graph ones.",
        "A81": "more semantical correlation within the manifold, where the constraints for codes are always held",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "could transform the candidate solution into a new one that better approximates the discrete one",
        "A53": "",
        "A43": "spectral rotation technique",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 18848296
    },
    {
        "Abstract": "We study the problem of recovering a t-sparse real vector from m quadratic equations yi=(ai*x)^2 with noisy measurements yi's. This is known as the problem of compressive phase retrieval, and has been widely applied to X-ray diffraction imaging, microscopy, quantum mechanics, etc. The challenge is to design a a) fast and b) noise-tolerant algorithms with c) near-optimal sample complexity. Prior work in this direction typically achieved one or two of these goals, but none of them enjoyed the three performance guarantees simultaneously. In this work, with a particular set of sensing vectors ai's, we give a provable algorithm that is robust to any bounded yet unstructured deterministic noise. Our algorithm requires roughly O(t) measurements and runs in O(tn*log (1/epsilon)) time, where epsilon is the error. This result advances the state-of-the-art work, and guarantees the applicability of our method to large datasets. Experiments on synthetic and real data verify our theory.",
        "A1": "give a provable algorithm that is robust to any bounded yet unstructured deterministic noise",
        "A2": "recovering a t-sparse real vector from m quadratic equations yi=(ai*x)^2 with noisy measurements yi's",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " none of them enjoyed the three performance guarantees simultaneously",
        "A7": "Experiments on synthetic and real data ",
        "A83": " advances the state-of-the-art work, and guarantees the applicability of our method to large datasets",
        "A82": " Experiments on synthetic and real data verify our theory.",
        "A81": " give a provable algorithm that is robust to any bounded yet unstructured deterministic noise",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "is robust to any bounded yet unstructured deterministic noise.",
        "A53": "",
        "A43": "is robust to any bounded yet unstructured deterministic noise.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 473923898
    },
    {
        "Abstract": "Metric learning has been widely employed, especially in various computer vision tasks, with the fundamental assumption that all samples (e.g., regions/superpixels in images/videos) are independent and identically distributed (IID). However, since the samples are usually spatially-connected or temporally-correlated with their physically-connected neighbours, they are not IID (non-IID for short), which cannot be directly handled by existing methods. Thus, we propose to learn and integrate non-IID metrics (NIME). To incorporate the non-IID spatial/temporal relations, instead of directly using non-IID features and metric learning as previous methods, NIME first builds several non-IID representations on original (non-IID) features by various graph kernel functions, and then automatically learns the metric under the best combination of various non-IID representations. NIME is applied to solve two typical computer vision tasks: interactive image segmentation and histology image identification. The results show that learning and integrating non-IID metrics improves the performance, compared to the IID methods. Moreover, our method achieves results comparable or better than that of the state-of-the-arts.",
        "A1": "Metric learning ",
        "A2": "since the samples are usually spatially-connected or temporally-correlated with their physically-connected neighbours, they are not IID (non-IID for short), which cannot be directly handled by existing methods",
        "A41": "learn and integrate non-IID metrics (NIME)",
        "A51": "graph kernel functions",
        "A61": "",
        "A10": "comparable or better",
        "A7": "two typical computer vision tasks: interactive image segmentation and histology image identification",
        "A83": "",
        "A82": "",
        "A81": "learning and integrating non-IID metrics improves the performance, compared to the IID methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 256380960
    },
    {
        "Abstract": "This paper proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way. The test is computationally simple, relying on no external resources and only uses a set of trained word vectors. Experiments show that the proposed method is competitive with state of the art and displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages. The key insight is to connect compositionality to a curious geometric property of word embeddings, which is of independent interest.",
        "A1": "proposes a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way",
        "A2": "compositionality (i.e., literal usage) of a word or phrase in a context-specific way",
        "A41": "a simple test for compositionality (i.e., literal usage) of a word or phrase in a context-specific way",
        "A51": "a set of trained word vectors",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "displays high accuracy in context-specific compositionality detection of a variety of natural language phenomena (idiomaticity, sarcasm, metaphor) for different datasets in multiple languages",
        "A81": "the proposed method is competitive with state of the art ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 256794868
    },
    {
        "Abstract": "Maximum Entropy (ME), as a general-purpose machine learning model, has been successfully applied to various fields such as text mining and natural language processing. It has been used as a classification technique and recently also applied to learn word embedding. ME establishes a distribution of the exponential form over items (classes/words). When training such a model, learning efficiency is guaranteed by globally updating the entire set of model parameters associated with all items at each training instance. This creates a significant computational challenge when the number of items is large. To achieve learning efficiency with affordable computational cost, we propose an approach named Dual-Clustering Maximum Entropy (DCME). Exploiting the primal-dual form of ME, it conducts clustering in the dual space and approximates each dual distribution by the corresponding cluster center. This naturally enables a hybrid online-offline optimization algorithm whose time complexity per instance only scales as the product of the feature/word vector dimensionality and the cluster number. Experimental studies on text classification and word embedding learning demonstrate that DCME effectively strikes a balance between training speed and model quality, substantially outperforming state-of-the-art methods.",
        "A1": "To achieve learning efficiency with affordable computational cost",
        "A2": " DCME effectively strikes a balance between training speed and model quality",
        "A41": "To achieve learning efficiency with affordable computational cost, we propose an approach named Dual-Clustering Maximum Entropy (DCME).",
        "A51": "Exploiting the primal-dual form of ME, it conducts clustering in the dual space and approximates each dual distribution by the corresponding cluster center.",
        "A61": " DCME effectively strikes a balance between training speed and model quality, substantially outperforming state-of-the-art methods.",
        "A10": "Experimental studies on text classification and word embedding learning demonstrate that DCME effectively strikes a balance between training speed and model quality, substantially outperforming state-of-the-art methods.",
        "A7": "Experimental studies on text classification and word embedding learning demonstrate that DCME effectively strikes a balance between training speed and model quality, substantially outperforming state-of-the-art methods.",
        "A83": "",
        "A82": "",
        "A81": "Experimental studies on text classification and word embedding learning demonstrate that DCME effectively strikes a balance between training speed and model quality, substantially outperforming state-of-the-art methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 231165197
    },
    {
        "Abstract": "Recommender systems have achieved great success in recent years, and matrix approximation (MA) is one of the most popular techniques for collaborative filtering (CF) based recommendation. However, a major issue is that MA methods perform poorly at detecting strong localized associations among closely related users and items. Recently, some MA-based CF methods adopt clustering methods to discover meaningful user-item subgroups and perform ensemble on different clusterings to improve the recommendation accuracy. However, ensemble learning suffers from lower efficiency due to the increased overall computation overhead. In this paper, we propose GLOMA, a new clustering-based matrix approximation method, which can embed global information in local matrix approximation models to improve recommendation accuracy. In GLOMA, a MA model is first trained on the entire data to capture global information. The global MA model is then utilized to guide the training of cluster-based local MA models, such that the local models can detect strong localized associations shared within clusters and at the same time preserve global associations shared among all users/items. Evaluation results using MovieLens and Netflix datasets demonstrate that, by integrating global information in local models, GLOMA can outperform five state-of-the-art MA-based CF methods in recommendation accuracy while achieving descent efficiency.",
        "A1": "embed global information in local matrix approximation models to improve recommendation accuracy.",
        "A2": "MA methods perform poorly at detecting strong localized associations among closely related users and items",
        "A41": "matrix approximation method",
        "A51": "clustering",
        "A61": "embed global information in local matrix approximation models",
        "A10": "GLOMA can outperform five state-of-the-art MA-based CF methods in recommendation accuracy while achieving descent efficiency.",
        "A7": "MovieLens and Netflix datasets",
        "A83": "",
        "A82": "",
        "A81": "GLOMA can outperform five state-of-the-art MA-based CF methods in recommendation accuracy while achieving descent efficiency",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 380642056
    },
    {
        "Abstract": "We address the problem of general function release under differential privacy, by developing a functional mechanism that applies under the weak assumptions of oracle access to target function evaluation and sensitivity. These conditions permit treatment of functions described explicitly or implicitly as algorithmic black boxes. We achieve this result by leveraging the iterated Bernstein operator for polynomial approximation of the target function, and polynomial coefficient perturbation. Under weak regularity conditions, we establish fast rates on utility measured by high-probability uniform approximation. We provide a lower bound on the utility achievable for any functional mechanism that is epsilon-differentially private. The generality of our mechanism is demonstrated by the analysis of a number of example learners, including naive Bayes, non-parametric estimators and regularized empirical risk minimization. Competitive rates are demonstrated for kernel density estimation; and epsilon-differential privacy is achieved for a broader class of support vector machines than known previously.",
        "A1": "address the problem of general function release under differential privacy",
        "A2": "provide a lower bound on the utility achievable for any functional mechanism",
        "A41": "fast rates on utility ",
        "A51": "high-probability uniform approximation",
        "A61": " a broader class of support vector machines",
        "A10": " a broader class of support vector machines",
        "A7": "leveraging the iterated Bernstein operator for polynomial approximation of the target function, and polynomial coefficient perturbation.",
        "A83": "Competitive rates are demonstrated ",
        "A82": "The generality of our mechanism is demonstrated ",
        "A81": "stablish fast rates on utility measured by high-probability uniform approximation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 491750356
    },
    {
        "Abstract": "Security problems can be modeled as two-player partially observable stochastic games with one-sided partial observability and infinite horizon (one-sided POSGs). We seek for optimal strategies of player 1 that correspond to robust strategies against the worst-case opponent (player 2) that is assumed to have a perfect information about the game. We present a novel algorithm for approximately solving one-sided POSGs based on the heuristic search value iteration (HSVI) for POMDPs. Our results include (1) theoretical properties of one-sided POSGs and their value functions, (2) guarantees showing the convergence of our algorithm to optimal strategies, and (3) practical demonstration of applicability and scalability of our algorithm on three different domains: pursuit-evasion, patrolling, and search games.",
        "A1": "seek for optimal strategies of player 1 that correspond to robust strategies against the worst-case opponent (player 2)",
        "A2": "Security problems",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "practical demonstration of applicability and scalability of our algorithm on three different domains: pursuit-evasion, patrolling, and search games",
        "A82": "guarantees showing the convergence of our algorithm to optimal strategies, and",
        "A81": "theoretical properties of one-sided POSGs and their value functions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "the heuristic search value iteration (HSVI) for POMDPs",
        "A43": "a novel algorithm for approximately solving one-sided POSGs",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 324279764
    },
    {
        "Abstract": "Sports broadcasters are continuously seeking to make their live coverages of soccer matches more attractive. A recent innovation is the \u201chighlight channel,\u201d which shows the most interesting events from multiple matches played at the same time. However, switching between matches at the right time is challenging in fast-paced sports like soccer, where interesting situations often evolve as quickly as they disappear again. This paper presents the POGBA algorithm for automatically predicting highlights in soccer matches, which is an important task that has not yet been addressed. POGBA leverages spatio-temporal event streams collected during matches to predict the probability that a particular game state will lead to a goal. An empirical evaluation on a real-world dataset shows that POGBA outperforms the baseline algorithms in terms of both precision and recall.",
        "A1": "predicting highlights in soccer matches",
        "A2": "POGBA leverages spatio-temporal event streams collected during matches to predict the probability that a particular game state will lead to a goal.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "in terms of both precision and recall.",
        "A7": " An empirical evaluation on a real-world dataset ",
        "A83": "",
        "A82": "",
        "A81": "POGBA outperforms the baseline algorithms in terms of both precision and recall",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "precision and recall",
        "A53": "POGBA leverages spatio-temporal event streams collected during matches to predict the probability that a particular game state will lead to a goal",
        "A43": " the POGBA algorithm for automatically predicting highlights in soccer matches",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a real-world dataset ",
        "am_id": 167659529
    },
    {
        "Abstract": "Attributes, or mid-level semantic features, have gained popularity in the past few years in domains ranging from activity recognition to face verification. Improving the accuracy of attribute classifiers is an important first step in any application which uses these attributes. In most works to date, attributes have been considered independent of each other. However, attributes can be strongly related, such as heavy makeup and wearing lipstick as well as male and goatee and many others. We propose a multi-task deep convolutional neural network (MCNN) with an auxiliary network at the top (AUX) which takes advantage of attribute relationships for improved classification. We call our final network MCNN-AUX. MCNN-AUX uses attribute relationships in three ways: by sharing the lowest layers for all attributes, by sharing the higher layers for spatially-related attributes, and by feeding the attribute scores from MCNN into the AUX network to find score-level relationships. Using MCNN-AUX rather than individual attribute classifiers, we are able to reduce the number of parameters in the network from 64 million to fewer than 16 million and reduce the training time by a factor of 16. We demonstrate the effectiveness of our method by producing results on two challenging publicly available datasets achieving state-of-the-art performance on many attributes.",
        "A1": "Improving the accuracy of attribute classifiers",
        "A2": " takes advantage of attribute relationships for improved classification",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we are able to reduce the number of parameters in the network from 64 million to fewer than 16 million and reduce the training time by a factor of 16",
        "A7": "We demonstrate the effectiveness of our method by producing results on two challenging publicly available datasets",
        "A83": "",
        "A82": "",
        "A81": "achieving state-of-the-art performance on many attributes",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " takes advantage of attribute relationships ",
        "A52": "convolutional neural network",
        "A42": "a multi-task deep convolutional neural network (MCNN) with an auxiliary network at the top (AUX)",
        "A45": "",
        "am_id": 482282587
    },
    {
        "Abstract": "Independent Component Analysis (ICA) is the problem of learning a square matrix A, given samples of X = AS, where S is a random vector with independent coordinates. Most existing algorithms are provably efficient only when each Si has finite and moderately valued fourth moment. However, there are practical applications where this assumption need not be true, such as speech and finance. Algorithms have been proposed for heavy-tailed ICA, but they are not practical, using random walks and the full power of the ellipsoid algorithm multiple times. The main contributions of this paper are (1) A practical algorithm for heavy-tailed ICA that we call HTICA. We provide theoretical guarantees and show that it outperforms other algorithms in some heavy-tailed regimes, both on real and synthetic data. Like the current state-of-the-art, the new algorithm is based on the centroid body (a first moment analogue of the covariance matrix). Unlike the state-of-the-art, our algorithm is practically efficient. To achieve this, we use explicit analytic representations of the centroid body, which bypasses the use of the ellipsoid method and random walks. (2) We study how heavy tails affect different ICA algorithms, including HTICA. Somewhat surprisingly, we show that some algorithms that use the covariance matrix or higher moments can successfully solve a range of ICA instances with infinite second moment. We study this theoretically and experimentally, with both synthetic and real-world heavy-tailed data.",
        "A1": " A practical algorithm for heavy-tailed ICA",
        "A2": " A practical algorithm for heavy-tailed ICA",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "it outperforms other algorithms in some heavy-tailed regimes, both on real and synthetic data",
        "A7": "",
        "A83": "",
        "A82": "ome algorithms that use the covariance matrix or higher moments can successfully solve a range of ICA instances with infinite second moment",
        "A81": " A practical algorithm for heavy-tailed ICA that we call HTICA",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " it outperforms other algorithms in some heavy-tailed regimes, both on real and synthetic data",
        "A53": " based on the centroid body",
        "A43": " A practical algorithm for heavy-tailed ICA",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "real and synthetic data",
        "am_id": 180028061
    },
    {
        "Abstract": "Multiple kernel clustering (MKC) algorithms optimally combine a group of pre-specified base kernels to improve clustering performance. However, existing MKC algorithms cannot efficiently address the situation where some rows and columns of base kernels are absent. This paper proposes a simple while effective algorithm to address this issue. Different from existing approaches where incomplete kernels are firstly imputed and a standard MKC algorithm is applied to the imputed kernels, our algorithm integrates imputation and clustering into a unified learning procedure. Specifically, we perform multiple kernel clustering directly with the presence of incomplete kernels, which are treated as auxiliary variables to be jointly optimized. Our algorithm does not require that there be at least one complete base kernel over all the samples. Also, it adaptively imputes incomplete kernels and combines them to best serve clustering. A three-step iterative algorithm with proved convergence is designed to solve the resultant optimization problem. Extensive experiments are conducted on four benchmark data sets to compare the proposed algorithm with existing imputation-based methods. Our algorithm consistently achieves superior performance and the improvement becomes more significant with increasing missing ratio, verifying the effectiveness and advantages of the proposed joint imputation and clustering.",
        "A1": "",
        "A2": " This paper proposes a simple while effective algorithm to address this issue. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we perform multiple kernel clustering directly with the presence of incomplete kernels, which are treated as auxiliary variables to be jointly optimized. Our algorithm does not require that there be at least one complete base kernel over all the samples. Also, it adaptively imputes incomplete kernels and combines them to best serve clustering. A three-step iterative algorithm with proved convergence is designed to solve the resultant optimization problem.",
        "A7": " Extensive experiments are conducted on four benchmark data sets to compare the proposed algorithm with existing imputation-based methods. ",
        "A83": "",
        "A82": "",
        "A81": "Our algorithm consistently achieves superior performance and the improvement becomes more significant with increasing missing ratio, verifying the effectiveness and advantages of the proposed joint imputation and clustering.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Different from existing approaches where incomplete kernels are firstly imputed and a standard MKC algorithm is applied to the imputed kernels, our algorithm integrates imputation and clustering into a unified learning procedure. ",
        "A53": "",
        "A43": "our algorithm integrates imputation and clustering into a unified learning procedure.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 66478907
    },
    {
        "Abstract": "In many applications of classifier learning, training data suffers from label noise. Deep networks are learned using huge training data where the problem of noisy labels is particularly relevant. The current techniques proposed for learning deep networks under label noise focus on modifying the network architecture and on algorithms for estimating true labels from noisy labels. An alternate approach would be to look for loss functions that are inherently noise-tolerant. For binary classification there exist theoretical results on loss functions that are robust to label noise. In this paper, we provide some sufficient conditions on a loss function so that risk minimization under that loss function would be inherently tolerant to label noise for multiclass classification problems. These results generalize the existing results on noise-tolerant loss functions for binary classification. We study some of the widely used loss functions in deep networks and show that the loss function based on mean absolute value of error is inherently robust to label noise. Thus standard back propagation is enough to learn the true classifier even under label noise. Through experiments, we illustrate the robustness of risk minimization with such loss functions for learning neural networks.",
        "A1": " look for loss functions that are inherently noise-tolerant",
        "A2": "training data suffers from label noise",
        "A41": " loss functions in deep networks",
        "A51": "robustness of risk minimization with such loss functions for learning neural networks",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 261802076
    },
    {
        "Abstract": "In classical planning, cost partitioning is a method for admissibly combining a set of heuristic estimators by distributing operator costs among the heuristics. An optimal cost partitioning is often prohibitively expensive to compute. Saturated cost partitioning is an alternative that is much faster to compute and has been shown to offer high-quality heuristic guidance on Cartesian abstractions. However, its greedy nature makes it highly susceptible to the order in which the heuristics are considered. We show that searching in the space of orders leads to significantly better heuristic estimates than with previously considered orders. Moreover, using multiple orders leads to a heuristic that is significantly better informed than any single-order heuristic. In experiments with Cartesian abstractions, the resulting heuristic approximates the optimal cost partitioning very closely.",
        "A1": "",
        "A2": " using multiple orders leads to a heuristic that is significantly better informed than any single-order heuristic",
        "A41": " searching in the space of orders",
        "A51": "",
        "A61": "significantly better heuristic estimates than with previously considered orders",
        "A10": "searching in the space of orders leads to significantly better heuristic estimates than with previously considered orders",
        "A7": "experiments with Cartesian abstractions, ",
        "A83": "",
        "A82": "",
        "A81": "the resulting heuristic approximates the optimal cost partitioning very closely.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 314090403
    },
    {
        "Abstract": "Understanding the nature of dark energy, the mysterious force driving the accelerated expansion of the Universe, is a major challenge of modern cosmology. The next generation of cosmological surveys, specifically designed to address this issue, rely on accurate measurements of the apparent shapes of distant galaxies. However, shape measurement methods suffer from various unavoidable biases and therefore will rely on a precise calibration to meet the accuracy requirements of the science analysis. This calibration process remains an open challenge as it requires large sets of high quality galaxy images. To this end, we study the application of deep conditional generative models in generating realistic galaxy images. In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks. Our results suggest a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys.",
        "A1": "Understanding the nature of dark energy, the mysterious force driving the accelerated expansion of the Universe, is a major challenge of modern cosmology. ",
        "A2": "",
        "A41": " To this end, we study the application of deep conditional generative models in generating realistic galaxy images.",
        "A51": "",
        "A61": ". In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 345999153
    },
    {
        "Abstract": "The formalism of multi-objective influence diagrams has recently been developed for modeling and solving sequential decision problems under uncertainty and multiple objectives. Since utility values representing the decision maker's preferences are only partially ordered (e.g., by the Pareto order) we no longer have a unique maximal value of expected utility, but a set of them. Computing the set of maximal values of expected utility and the corresponding policies can be computationally very challenging. In this paper, we consider alternative notions of optimality, one of the most important one being the notion of possibly optimal, namely optimal in at least one scenario compatible with the inter-objective tradeoffs. We develop a variable elimination algorithm for computing the set of possibly optimal expected utility values, prove formally its correctness, and compare variants of the algorithm experimentally.",
        "A1": "computing the set of possibly optimal expected utility values",
        "A2": "we no longer have a unique maximal value of expected utility, but a set of them. Computing the set of maximal values of expected utility and the corresponding policies can be computationally very challenging",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " consider alternative notions of optimality",
        "A53": " alternative notions of optimality",
        "A43": "computing the set of possibly optimal expected utility values",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 14050315
    },
    {
        "Abstract": "Many natural language understanding (NLU) tasks, such as shallow parsing (i.e., text chunking) and semantic slot filling, require the assignment of representative labels to the meaningful chunks in a sentence. Most of the current deep neural network (DNN) based methods consider these tasks as a sequence labeling problem, in which a word, rather than a chunk, is treated as the basic unit for labeling. These chunks are then inferred by the standard IOB (Inside-Outside- Beginning) labels. In this paper, we propose an alternative approach by investigating the use of DNN for sequence chunking, and propose three neural models so that each chunk can be treated as a complete unit for labeling. Experimental results show that the proposed neural sequence chunking models can achieve start-of-the-art performance on both the text chunking and slot filling tasks.",
        "A1": "each chunk can be treated as a complete unit for labeling",
        "A2": "a word, rather than a chunk, is treated as the basic unit for labeling",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieve start-of-the-art performance on both the text chunking and slot filling tasks.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "neural sequence chunking models can achieve start-of-the-art performance on both the text chunking and slot filling tasks.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " each chunk can be treated as a complete unit for labeling",
        "A52": "the use of DNN for sequence chunking",
        "A42": " three neural models so that each chunk can be treated as a complete unit for labeling",
        "A45": "",
        "am_id": 95056704
    },
    {
        "Abstract": "The key question in transfer learning (TL) research is how to make model induction transferable across different domains. Common methods so far require source and target domains to have a shared/homogeneous feature space, or the projection of features from heterogeneous domains onto a shared space. This paper proposes a novel framework, which does not require a shared feature space but instead uses a parallel corpus to calibrate domain-specific kernels into a unified kernel, to leverage graph-based label propagation in cross-domain settings, and to optimize semi-supervised learning based on labeled and unlabeled data in both source and target domains. Our experiments on benchmark datasets show advantageous performance of the proposed method over that of other state-of-the-art TL methods.",
        "A1": "proposes a novel framework",
        "A2": "how to make model induction transferable across different domains",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " advantageous performance of the proposed method",
        "A7": "experiments on benchmark datasets",
        "A83": "",
        "A82": " advantageous performance of the proposed method",
        "A81": " a novel framework",
        "A64": "does not require a shared feature space",
        "A54": "uses a parallel corpus to calibrate domain-specific kernels into a unified kernel,",
        "A44": "does not require a shared feature space",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 422029396
    },
    {
        "Abstract": "Recent successes in applying Deep Learning techniques on Reinforcement Learning algorithms have led to a wave of breakthrough developments in agent theory and established the field of Deep Reinforcement Learning (DRL). While DRL has shown great results for single task learning, the multi-task case is still underrepresented in the available literature. This D.Sc. research proposal aims at extending DRL to the multi- task case by leveraging the power of Transfer Learning algorithms to improve the training time and results for multi-task learning. Our focus lies on defining a novel framework for scalable DRL agents that detects similarities between tasks and balances various TL techniques, like parameter initialization, policy or skill transfer.",
        "A1": "defining a novel framework for scalable DRL agents ",
        "A2": "extending DRL to the multi- task case ",
        "A41": "defining a novel framework for scalable DRL agents",
        "A51": "the power of Transfer Learning algorithms",
        "A61": "extending DRL to the multi- task case",
        "A10": "improve the training time and results for multi-task learning",
        "A7": "extending DRL to the multi- task case by leveraging the power of Transfer Learning algorithms",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "detects similarities between tasks and balances various TL techniques, like parameter initialization, policy or skill transfer.",
        "A54": "",
        "A44": "detects similarities between tasks and balances various TL techniques, like parameter initialization, policy or skill transfer.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 352631826
    },
    {
        "Abstract": "In the recent years, there has been significant work on the difficulty of heuristic search problems, identifying different problem instance characteristics that can have a significant impact on search effort. Phase transitions in the solubility of random problem instances have proved useful in the study of problem difficulty for other classes of computational problems, notably SAT and CSP, and it has been shown that the hardest problems typically occur during this rapid transition. In this work, we perform the first empirical investigation of the phase transition phenomena for heuristic search. We establish the existence of a rapid transition in the solubility of an abstract model of heuristic search problems and show that, for greedy best first search, the hardest instances are associated with the phase transition region. We then perform a novel investigation of the behavior of heuristics of different strength across the solubility spectrum. Finally, we demonstrate that the behavior of our abstract model carries over to commonly used benchmark problems including the Pancake Problem, Grid Navigation, TopSpin, and the Towers of Hanoi. An interesting deviation is observed and explained in the Sliding Puzzle.",
        "A1": "it has been shown that the hardest problems typically occur during this rapid transition.",
        "A2": " first empirical investigation of the phase transition phenomena for heuristic search",
        "A41": "We establish the existence of a rapid transition in the solubility of an abstract model of heuristic search problems ",
        "A51": "",
        "A61": "the first empirical investigation of the phase transition phenomena for heuristic search",
        "A10": "",
        "A7": "demonstrate that the behavior of our abstract model carries over to commonly used benchmark problems including the Pancake Problem, Grid Navigation, TopSpin, and the Towers of Hanoi.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 209080968
    },
    {
        "Abstract": "Real-Time Strategy (RTS) games involve multiple agents acting simultaneously, and result in enormous state dimensionality. In this paper, we propose an abstracted and simplified model for the famous game StarCraft, and design a dynamic programming algorithm to solve the building order problem, which takes minimal time to achieve a specific target. In addition, Genetic Algorithms (GA) are used to find an optimal target for the opening stage.",
        "A1": "takes minimal time to achieve a specific target",
        "A2": "enormous state dimensionalit",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a dynamic programming algorithm to solve the building order problem",
        "A62": "",
        "A52": "",
        "A42": "an abstracted and simplified model for the famous game StarCraft",
        "A45": "",
        "am_id": 60061233
    },
    {
        "Abstract": "We investigate the task of inferring conversational dependencies between messages in one-on-one online chat, which has become one of the most popular forms of customer service. We propose a novel probabilistic classifier that leverages conversational, lexical and semantic information. The approach is evaluated empirically on a set of customer service chat logs from a Chinese e-commerce website. It outperforms heuristic baselines.",
        "A1": " inferring conversational dependencies between messages in one-on-one online chat",
        "A2": "propose a novel probabilistic classifier that leverages conversational, lexical and semantic information",
        "A41": "a novel probabilistic classifier that leverages conversational, lexical and semantic information",
        "A51": " a novel probabilistic classifier ",
        "A61": "It outperforms heuristic baselines.",
        "A10": " It outperforms heuristic baselines.",
        "A7": " The approach is evaluated empirically on a set of customer service chat logs from a Chinese e-commerce website.",
        "A83": "",
        "A82": "",
        "A81": " It outperforms heuristic baselines.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " a set of customer service chat logs from a Chinese e-commerce website",
        "am_id": 430527853
    },
    {
        "Abstract": "We develop a general framework for agent abstraction based on the situation calculus and the ConGolog agent programming language. We assume that we have a high-level specification and a low-level specification of the agent, both represented as basic action theories. A refinement mapping specifies how each high-level action is implemented by a low-level ConGolog program and how each high-level fluent can be translated into a low-level formula. We define a notion of sound abstraction between such action theories in terms of the existence of a suitable bisimulation between their respective models. Sound abstractions have many useful properties that ensure that we can reason about the agent's actions (e.g., executability, projection, and planning) at the abstract level, and refine and concretely execute them at the low level. We also characterize the notion of complete abstraction where all actions (including exogenous ones) that the high level thinks can happen can in fact occur at the low level.",
        "A1": " develop a general framework for agent abstraction ",
        "A2": " develop a general framework for agent abstraction",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " general framework for agent abstraction ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "the situation calculus and the ConGolog agent programming language",
        "A44": "a general framework for agent abstraction ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 134048874
    },
    {
        "Abstract": "B\u00e4ckstr\u00f6m has previously studied a number of optimization problems for partial-order plans, like finding a minimum deordering (MCD) or reordering (MCR), and finding the minimum parallel execution length (PPL), which are all NP-complete. We revisit these problems, but applying parameterized complexity analysis rather than standard complexity analysis. We consider various parameters, including both the original and desired size of the plan order, as well as its width and height. Our findings include that MCD and MCR are W[2]-hard and in W[P] when parameterized with the desired order size, and MCD is fixed-parameter tractable (fpt) when parameterized with the original order size. Problem PPL is fpt if parameterized with the size of the non-concurrency relation, but para-NP-hard in most other cases. We also consider this problem when the number (k) of agents, or processors, is restricted, finding that this number is a crucial parameter; this problem is fixed-parameter tractable with the order size, the parallel execution length and k as parameter, but para-NP-hard without k as parameter.",
        "A1": "optimization problems for partial-order plans",
        "A2": "applying parameterized complexity analysis rather than standard complexity analysis",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "revisit these problems",
        "A83": " this number is a crucial parameter",
        "A82": "MCD is fixed-parameter tractable (fpt) when parameterized with the original order size",
        "A81": "MCD and MCR are W[2]-hard and in W[P] when parameterized with the desired order size, ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 121614582
    },
    {
        "Abstract": "We present a new perspective on the popular multi-class algorithmic techniques of one-vs-all and error correcting output codes. Rather than studying the behavior of these techniques for supervised learning, we establish a connection between the success of these methods and the existence of label-efficient learning procedures. We show that in both the realizable and agnostic cases, if output codes are successful at learning from labeled data, they implicitly assume structure on how the classes are related. By making that structure explicit, we design learning algorithms to recover the classes with low label complexity. We provide results for the commonly studied cases of one-vs-all learning and when the codewords of the classes are well separated. We additionally consider the more challenging case where the codewords are not well separated, but satisfy a boundary features condition that captures the natural intuition that every bit of the codewords should be significant.",
        "A1": "present a new perspective on the popular multi-class algorithmic techniques of one-vs-all and error correcting output codes",
        "A2": "design learning algorithms to recover the classes with low label complexity",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "results for the commonly studied cases of one-vs-all learning and when the codewords of the classes are well separated",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "learning algorithms to recover the classes with low label complexity",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 498185852
    },
    {
        "Abstract": "An associative memory is a framework of content-addressable memory that stores a collection of message vectors (or a dataset) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version. Designing an associative memory requires addressing two main tasks: 1) learning phase: given a dataset, learn a concise representation of the dataset in the form of a graphical model (or a neural network), 2) recall phase: given a noisy version of a message vector from the dataset, output the correct message vector via a neurally feasible algorithm over the network learnt during the learning phase. This paper studies the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase. Specifically, the associative memories designed in this paper can store dataset containing exp(n) n-length message vectors over a network with O(n) nodes and can tolerate \u03a9(n / polylog) adversarial errors. This paper carries out this memory design by mapping the learning phase and recall phase to the tasks of dictionary learning with a square dictionary and iterative error correction in an expander code, respectively.",
        "A1": "",
        "A2": " the problem of designing a class of neural associative memories which learns a network representation for a large dataset that ensures correction against a large number of adversarial errors during the recall phase",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " mapping the learning phase and recall phase to the tasks of dictionary learning with a square dictionary and iterative error correction in an expander code, respectively.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": " the associative memories designed in this paper can store dataset containing exp(n) n-length message vectors over a network with O(n) nodes and can tolerate \u03a9(n / polylog) adversarial errors",
        "A54": "a framework of content-addressable memory that stores a collection of message vectors (or a dataset) over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version.",
        "A44": "can store dataset containing exp(n) n-length message vectors over a network with O(n) nodes and can tolerate \u03a9(n / polylog) adversarial errors.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 321500578
    },
    {
        "Abstract": "Capstone senior design projects provide students with a collaborative software design and development experience to reinforce learned material while allowing students latitude in developing real-world applications. Our two-semester capstone classes are required for all computer science majors. Students must have completed a software engineering course \u2014 capstone classes are typically taken during their last two semesters. Project proposals come from a variety of sources, including industry, WSU faculty (from our own and other departments), local agencies, and entrepreneurs. We have recently targeted projects in AI \u2014 although students typically have little background, they find the ideas and methods compelling. This paper outlines our instructional approach and reports our experiences with three projects.",
        "A1": "This paper outlines our instructional approach and reports our experiences with three projects.",
        "A2": "Capstone senior design projects provide students with a collaborative software design and development experience to reinforce learned material while allowing students latitude in developing real-world applications. ",
        "A41": "our instructional approach and reports our experiences with three projects.",
        "A51": "",
        "A61": " We have recently targeted projects in AI ",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 427969790
    },
    {
        "Abstract": "While optimal metareasoning is notoriously intractable, humans are nonetheless able to adaptively allocate their computational resources. A possible approximation that humans may use to do this is to only metareason over a finite set of cognitive systems that perform variable amounts of computation. The highly influential \"dual-process\" accounts of human cognition, which postulate the coexistence of a slow accurate system with a fast error-prone system, can be seen as a special case of this approximation. This raises two questions: how many cognitive systems should a bounded optimal agent be equipped with and what characteristics should those systems have? We investigate these questions in two settings: a one-shot decision between two alternatives, and planning under uncertainty in a Markov decision process. We find that the optimal number of systems depends on the variability of the environment and the costliness of metareasoning. Consistent with dual-process theories, we also find that when having two systems is optimal, then the first system is fast but error-prone and the second system is slow but accurate.",
        "A1": "adaptively allocate their computational resources",
        "A2": "optimal metareasoning",
        "A41": "approximation that humans may use to do this is to only metareason over a finite set of cognitive systems that perform variable amounts of computation",
        "A51": "dual-process",
        "A61": "",
        "A10": "",
        "A7": "a one-shot decision between two alternatives, and planning under uncertainty in a Markov decision process",
        "A83": "",
        "A82": "two systems is optimal",
        "A81": "optimal number of systems depends on the variability of the environment and the costliness of metareasoning",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 449276998
    },
    {
        "Abstract": "Multivariate time series (MTS) is useful for detecting abnormity cases in healthcare area. In this paper, we propose an ensemble boosting algorithm to classify abnormality surgery time series based on learning shapelet features. Specifically, we first learn shapelets by logistic regression from multivariate time series. Based on the learnt shapelets, we propose a MTS ensemble boosting approach when the time series arrives as stream fashion. Experimental results on a real-world medical dataset demonstrate the effectiveness of the proposed methods.",
        "A1": "classify abnormality surgery time series based on learning shapelet features",
        "A2": "classify abnormality surgery time series based on learning shapelet features",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the effectiveness of the proposed methods.",
        "A7": " Experimental results on a real-world medical dataset",
        "A83": "",
        "A82": " the effectiveness of the proposed methods.",
        "A81": "propose an ensemble boosting algorithm",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " learn shapelets by logistic regression from multivariate time series",
        "A53": "Based on the learnt shapelets",
        "A43": "an ensemble boosting algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 128030079
    },
    {
        "Abstract": "To facilitate the browsing of long videos, automatic video summarization provides an excerpt that represents its content. In the case of egocentric and consumer videos, due to their personal nature, adapting the summary to specific user's preferences is desirable. Current approaches to customizable video summarization obtain the user's preferences prior to the summarization process. As a result, the user needs to manually modify the summary to further meet the preferences. In this paper, we introduce Active Video Summarization (AVS), an interactive approach to gather the user's preferences while creating the summary. AVS asks questions about the summary to update it on-line until the user is satisfied. To minimize the interaction, the best segment to inquire next is inferred from the previous feedback. We evaluate AVS in the commonly used UTEgo dataset. We also introduce a new dataset for customized video summarization (CSumm) recorded with a Google Glass. The results show that AVS achieves an excellent compromise between usability and quality. In 41% of the videos, AVS is considered the best over all tested baselines, including summaries manually generated. Also, when looking for specific events in the video, AVS provides an average level of satisfaction higher than those of all other baselines after only six questions to the user.",
        "A1": "customizable video summarization",
        "A2": "user needs to manually modify the summary to further meet the preferences",
        "A41": "an interactive approach to gather the user's preferences while creating the summary",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "UTEgo dataset.",
        "A83": "",
        "A82": "",
        "A81": "AVS provides an average level of satisfaction higher than those of all other baselines after only six questions to the use",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "for customized video summarization (CSumm) recorded with a Google Glass",
        "am_id": 152446325
    },
    {
        "Abstract": "Metaheuristics have been developed to provide general purpose approaches for solving hard combinatorial problems. While these frameworks often serve as the starting point for the development of problem-specific search procedures, they very rarely work efficiently in their default state. We combine the ideas of reactive search, which adjusts key parameters during search, and algorithm configuration, which fine-tunes algorithm parameters for a given set of problem instances, for the automatic compilation of a portfolio of highly reactive dialectic search heuristics for MaxSAT. Even though the dialectic search metaheuristic knows nothing more about MaxSAT than how to evaluate the cost of a truth assignment, our automatically generated solver defines a new state of the art for random weighted partial MaxSAT instances. Moreover, when combined with an industrial MaxSAT solver, the self-assembled reactive portfolio was able to win four out of nine gold medals at the recent 2016 MaxSAT Evaluation on random, crafted, and industrial partial and weighted-partial MaxSAT instances.",
        "A1": "combine the ideas of reactive search",
        "A2": " they very rarely work efficiently in their default state",
        "A41": "algorithm configuration, which fine-tunes algorithm parameters for a given set of problem instances",
        "A51": "ideas of reactive search",
        "A61": "generated solver defines a new state of the art for random weighted partial MaxSAT instances",
        "A10": "was able to win four out of nine gold medals",
        "A7": "2016 MaxSAT Evaluation on random, crafted, and industrial partial and weighted-partial MaxSAT instances",
        "A83": "",
        "A82": "",
        "A81": "was able to win four out of nine gold medals",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "automatically generated solver defines a new state of the art for random weighted partial MaxSAT instances",
        "A53": "ideas of reactive search",
        "A43": "algorithm configuration, which fine-tunes algorithm parameters for a given set of problem instances",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 311874462
    },
    {
        "Abstract": "Many machine learning models, such as logistic regression (LR) and support vector machine (SVM), can be formulated as composite optimization problems. Recently, many distributed stochastic optimization (DSO) methods have been proposed to solve the large-scale composite optimization problems, which have shown better performance than traditional batch methods. However, most of these DSO methods might not be scalable enough. In this paper, we propose a novel DSO method, called scalable composite optimization for learning (SCOPE), and implement it on the fault-tolerant distributed platform Spark. SCOPE is both computation-efficient and communication-efficient. Theoretical analysis shows that SCOPE is convergent with linear convergence rate when the objective function is strongly convex. Furthermore, empirical results on real datasets show that SCOPE can outperform other state-of-the-art distributed learning methods on Spark, including both batch learning methods and DSO methods.",
        "A1": "propose a novel DSO method",
        "A2": "DSO methods might not be scalable enough",
        "A41": "scalable composite optimization for learning",
        "A51": "",
        "A61": "outperform other state-of-the-art distributed learning methods",
        "A10": "including both batch learning methods and DSO methods.",
        "A7": "implement it on the fault-tolerant distributed platform Spark",
        "A83": "",
        "A82": " DSO methods.",
        "A81": "batch learning methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 393677836
    },
    {
        "Abstract": "Visual attention plays an important role to understand images and demonstrates its effectiveness in generating natural language descriptions of images. On the other hand, recent studies show that language associated with an image can steer visual attention in the scene during our cognitive process. Inspired by this, we introduce a text-guided attention model for image captioning, which learns to drive visual attention using associated captions. For this model, we propose an exemplar-based learning approach that retrieves from training data associated captions with each image, and use them to learn attention on visual features. Our attention model enables to describe a detailed state of scenes by distinguishing small or confusable objects effectively. We validate our model on MS-COCO Captioning benchmark and achieve the state-of-the-art performance in standard metrics.",
        "A1": "image captioning",
        "A2": "",
        "A41": " retrieves from training data associated captions with each image, and use them to learn attention on visual features",
        "A51": "",
        "A61": "an exemplar-based learning approach ",
        "A10": "",
        "A7": "on MS-COCO Captioning benchmark",
        "A83": "",
        "A82": "",
        "A81": "achieve the state-of-the-art performance in standard metrics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "text-guided attention model for image captioning",
        "A45": "",
        "am_id": 368483465
    },
    {
        "Abstract": "Boundary incompleteness raises great challenges to automatic prostate segmentation in ultrasound images. Shape prior can provide strong guidance in estimating the missing boundary, but traditional shape models often suffer from hand-crafted descriptors and local information loss in the fitting procedure. In this paper, we attempt to address those issues with a novel framework. The proposed framework can seamlessly integrate feature extraction and shape prior exploring, and estimate the complete boundary with a sequential manner. Our framework is composed of three key modules. Firstly, we serialize the static 2D prostate ultrasound images into dynamic sequences and then predict prostate shapes by sequentially exploring shape priors. Intuitively, we propose to learn the shape prior with the biologically plausible Recurrent Neural Networks (RNNs). This module is corroborated to be effective in dealing with the boundary incompleteness. Secondly, to alleviate the bias caused by different serialization manners, we propose a multi-view fusion strategy to merge shape predictions obtained from different perspectives. Thirdly, we further implant the RNN core into a multiscale Auto-Context scheme to successively refine the details of the shape prediction map. With extensive validation on challenging prostate ultrasound images, our framework bridges severe boundary incompleteness and achieves the best performance in prostate boundary delineation when compared with several advanced methods. Additionally, our approach is general and can be extended to other medical image segmentation tasks, where boundary incompleteness is one of the main challenges.",
        "A1": "automatic prostate segmentation in ultrasound images",
        "A2": "Boundary incompleteness",
        "A41": "The proposed framework can seamlessly integrate feature extraction and shape prior exploring, and estimate the complete boundary with a sequential manner",
        "A51": "three key modules.",
        "A61": "hand-crafted descriptors and local information loss",
        "A10": "can be extended to other medical image segmentation tasks",
        "A7": "prostate boundary delineation",
        "A83": "",
        "A82": "",
        "A81": "the best performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 86098217
    },
    {
        "Abstract": "We investigate Pareto stability in Social Distance Games, that are coalition forming games in which agents utilities are proportional to their harmonic centralities in the respective coalitions, i.e., to the average inverse distance from the other agents. Pareto optimal solutions have been already considered in the literature as outcomes arising from the strategic interaction of the agents. In particular, they are stable under the deviation of the grand coalition, as they do not permit a simultaneous deviation by all the agents making all of them weakly better off and some strictly better off. We first show that, while computing a Pareto stable solution maximizing the social welfare is NP-hard in bounded degree graphs, a 2 min{Delta,sqrt n}-approximating one can be determined in polynomial time, where n is the number of agents and Delta the maximum node degree. We then determine asymptotically tight bounds on the Price of Pareto Optimality for several classes of social graphs arising from the following combinations: unbounded and bounded node degree, undirected and directed edges, unweighted and weighted edges.",
        "A1": "Pareto stability in Social Distance Games",
        "A2": "Pareto optimal solutions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "the Price of Pareto Optimality for several classes of social graphs",
        "A83": "",
        "A82": "a 2 min{Delta,sqrt n}-approximating one can be determined in polynomial time",
        "A81": "computing a Pareto stable solution maximizing the social welfare is NP-hard in bounded degree graphs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a Pareto stable solution",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 68544122
    },
    {
        "Abstract": "Motivated by many real world applications such as recommendations in online shopping or entertainment, we consider the problem of selecting sequences of items. In this paper we introduce a novel class of utility functions over sequences of items, strictly generalizing the commonly used class of submodular set functions. We encode the sequential dependencies between items by a directed graph underlying the utility function. Classical algorithms fail to achieve any constant factor approximation guarantees on the problem of selecting sequences of bounded length with maximum utility. We propose an efficient algorithm for this problem that comes with strong theoretical guarantees characterized by the structural properties of the underlying graph. We demonstrate the effectiveness of our algorithm in synthetic and real world experiments on a movie recommendation dataset.",
        "A1": " consider the problem of selecting sequences of items",
        "A2": "Classical algorithms fail to achieve any constant factor approximation guarantees on the problem of selecting sequences of bounded length with maximum utility",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We encode the sequential dependencies between items by a directed graph underlying the utility function. Classical algorithms fail to achieve any constant factor approximation guarantees on the problem of selecting sequences of bounded length with maximum utility",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of our algorithm in synthetic and real world experiments on a movie recommendation dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "an efficient algorithm for this problem that comes with strong theoretical guarantees characterized by the structural properties of the underlying graph",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 456133578
    },
    {
        "Abstract": "We propose a scalable approach to learn video-based question answering (QA): to answer a free-form natural language question about the contents of a video. Our approach automatically harvests a large number of videos and descriptions freely available online. Then, a large number of candidate QA pairs are automatically generated from descriptions rather than manually annotated. Next, we use these candidate QA pairs to train a number of video-based QA methods extended from MN (Sukhbaatar et al. 2015), VQA (Antol et al. 2015), SA (Yao et al. 2015), and SS (Venugopalan et al. 2015). In order to handle non-perfect candidate QA pairs, we propose a self-paced learning procedure to iteratively identify them and mitigate their effects in training. Finally, we evaluate performance on manually generated video-based QA pairs. The results show that our self-paced learning procedure is effective, and the extended SS model outperforms various baselines.",
        "A1": "propose a scalable approach to learn video-based question answering",
        "A2": "answer a free-form natural language question about the contents of a video",
        "A41": "automatically harvests a large number of videos and descriptions freely available online",
        "A51": "video-based QA methods",
        "A61": "",
        "A10": "",
        "A7": "evaluate performance on manually generated video-based QA pairs",
        "A83": "",
        "A82": "the extended SS model outperforms various baselines",
        "A81": "our self-paced learning procedure is effective",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 256007307
    },
    {
        "Abstract": "We present a cognitively plausible novel framework capable of learning the grounding in visual semantics and the grammar of natural language commands given to a robot in a table top environment. The input to the system consists of video clips of a manually controlled robot arm, paired with natural language commands describing the action. No prior knowledge is assumed about the meaning of words, or the structure of the language, except that there are different classes of words (corresponding to observable actions, spatial relations, and objects and their observable properties). The learning process automatically clusters the continuous perceptual spaces into concepts corresponding to linguistic input. A novel relational graph representation is used to build connections between language and vision. As well as the grounding of language to perception, the system also induces a set of probabilistic grammar rules. The knowledge learned is used to parse new commands involving previously unseen objects.",
        "A1": " learning the grounding in visual semantics and the grammar of natural language commands ",
        "A2": "a cognitively plausible novel framework capable ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "learning the grounding in visual semantics and the grammar of natural language commands ",
        "A7": "",
        "A83": "",
        "A82": "A novel relational graph representation",
        "A81": "a cognitively plausible novel framework capable",
        "A64": " learning the grounding in visual semantics and the grammar of natural language commands ",
        "A54": "a set of probabilistic grammar rules",
        "A44": "learning the grounding in visual semantics and the grammar of natural language commands given to a robot in a table top environment",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 97079056
    },
    {
        "Abstract": "The Zero-suppressed Sentential Decision Diagram (ZSDD) is a recentlydiscovered tractable representation of Boolean functions. ZSDD subsumes theZero-suppressed Binary Decision Diagram (ZDD) as a strict subset, andsimilar to ZDD, it can perform several useful operations like model countingand Apply operations. We propose a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures, e.g.,matchings and simple paths of a graph. We experimentally confirm that theproposed algorithm is faster than other construction methods includingbottom-up methods and top-down methods for ZDDs, and the resulting ZSDDsare smaller than ZDDs representing the same graph substructures. We alsoshow that the size constructed ZSDDs can be bounded by the branch-width of thegraph. This bound is tighter than that of ZDDs.",
        "A1": "propose a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures, e.g.,matchings and simple paths of a graph",
        "A2": "propose a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures, e.g.,matchings and simple paths of a graph",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We experimentally confirm that theproposed algorithm is faster than other construction methods",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We experimentally confirm that theproposed algorithm is faster than other construction methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 247077541
    },
    {
        "Abstract": "Automated topic identification is an essential component invarious information retrieval and knowledge representationtasks such as automated summary generation, categorization search and document indexing. In this paper, we present the Wikitop system to automatically generate topic trees from the input text by performing hierarchical classification using the Wikipedia Category Network (WCN). Our preliminary results over a collection of 125 articles are encouraging and show potential of a robust methodology for automated topic tree generation.",
        "A1": "automatically generate topic trees ",
        "A2": "Automated topic identification",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "potential of a robust methodology for automated topic tree generation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Wikipedia Category Network (WCN)",
        "A42": "automatically generate topic trees from the input text by performing hierarchical classification ",
        "A45": "",
        "am_id": 432593733
    },
    {
        "Abstract": "For autonomous robots to collaborate on joint tasks with humans they require a shared understanding of an observed scene. We present a method for unsupervised learning of common human movements and activities on an autonomous mobile robot, which generalises and improves on recent results. Our framework encodes multiple qualitative abstractions of RGBD video from human observations and does not require external temporal segmentation. Analogously to information retrieval in text corpora, each human detection is modelled as a random mixture of latent topics. A generative probabilistic technique is used to recover topic distributions over an auto-generated vocabulary of discrete, qualitative spatio-temporal code words. We show that the emergent categories align well with human activities as interpreted by a human. This is a particularly challenging task on a mobile robot due to the varying camera viewpoints which lead to incomplete, partial and occluded human detections.",
        "A1": "present a method for unsupervised learning of common human movements and activities on an autonomous mobile robot",
        "A2": "human detections",
        "A41": "a method for unsupervised learning of common human movements and activities on an autonomous mobile robot",
        "A51": "recent results",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the emergent categories align well with human activities as interpreted by a human",
        "A64": "",
        "A54": "multiple qualitative abstractions of RGBD video from human observations",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 70642553
    },
    {
        "Abstract": "Personalized ranking is usually considered as an ultimate goal of recommendation systems, but it suffers from efficiency issues when making recommendations. To this end, we propose a learning-based hashing framework called Discrete Personalized Ranking (DPR), to map users and items to a Hamming space, where user-item affinity can be efficiently calculated via Hamming distance. Due to the existence of discrete constraints, it is possible to exploit a two-stage learning procedure for learning binary codes according to most existing methods. This two-stage procedure consists of relaxed optimization by discarding discrete constraints and subsequent binary quantization. However, such a procedure has been shown resulting in a large quantization loss, so that longer binary codes would be required. To this end, DPR directly tackles the discrete optimization problem of personalized ranking. And the balance and un-correlation constraints of binary codes are imposed to derive compact but informatics binary codes. Based on the evaluation on several datasets, the proposed framework shows consistent superiority to the competing baselines even though only using shorter binary code.",
        "A1": "To this end, we propose a learning-based hashing framework called Discrete Personalized Ranking (DPR)",
        "A2": "Personalized ranking is usually considered as an ultimate goal of recommendation systems, but it suffers from efficiency issues when making recommendations.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed framework shows consistent superiority to the competing baselines even though only using shorter binary code.",
        "A7": "Based on the evaluation on several datasets,",
        "A83": "",
        "A82": "",
        "A81": "the proposed framework shows consistent superiority to the competing baselines even though only using shorter binary code.",
        "A64": "user-item affinity can be efficiently calculated via Hamming distance",
        "A54": "learning-based",
        "A44": "a learning-based hashing framework called Discrete Personalized Ranking (DPR), to map users and items to a Hamming space, where user-item affinity can be efficiently calculated via Hamming distance.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 254520632
    },
    {
        "Abstract": "We introduce the domain of preferences that are single-peaked on a circle, which is a generalization of the well-studied single-peaked domain. This preference restriction is useful, e.g., for scheduling decisions, and for one-dimensional decisions in the presence of extremist preferences. We give a fast recognition algorithm of this domain, provide a characterisation by finitely many forbidden subprofiles, and show that many popular single- and multi-winner voting rules are polynomial-time computable on this domain. In contrast, Kemeny's rule remains hard to evaluate, and several impossibility results from social choice theory can be proved using only profiles that are single-peaked on a circle",
        "A1": "",
        "A2": "give a fast recognition algorithm of this domain",
        "A41": "provide a characterisation by finitely many forbidden subprofiles, and show that many popular single- and multi-winner voting rules are polynomial-time computable on this domain.",
        "A51": "a fast recognition algorithm of this domain",
        "A61": " introduce the domain of preferences that are single-peaked on a circle",
        "A10": " useful, e.g., for scheduling decisions, and for one-dimensional decisions in the presence of extremist preferences. ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137679384
    },
    {
        "Abstract": "Heuristics serve as a powerful tool in modern domain-independent planning (DIP) systems by providing critical guidance during the search for high-quality solutions. However, they have not been broadly used with hierarchical planning techniques, which are more expressive and tend to scale better in complex domains by exploiting additional domain-specific knowledge. Complicating matters, we show that for Hierarchical Goal Network (HGN) planning, a goal-based hierarchical planning formalism that we focus on in this paper, any poly-time heuristic that is derived from a delete-relaxation DIP heuristic has to make some relaxation of the hierarchical semantics. To address this, we present a principled framework for incorporating DIP heuristics into HGN planning using a simple relaxation of the HGN semantics we call Hierarchy-Relaxation. This framework allows for computing heuristic estimates of HGN problems using any DIP heuristic in an admissibility-preserving manner. We demonstrate the feasibility of this approach by using the LMCut heuristic to guide an optimal HGN planner. Our empirical results with three benchmark domains demonstrate that simultaneously leveraging hierarchical knowledge and heuristic guidance substantially improves planning performance.",
        "A1": " a goal-based hierarchical planning formalism",
        "A2": "have not been broadly used with hierarchical planning techniques",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "simultaneously leveraging hierarchical knowledge and heuristic guidance substantially improves planning performance",
        "A7": "three benchmark domains ",
        "A83": "",
        "A82": "the feasibility of this approach",
        "A81": "simultaneously leveraging hierarchical knowledge and heuristic guidance substantially improves planning performance",
        "A64": "allows for computing heuristic estimates of HGN problems using any DIP heuristic in an admissibility-preserving manner",
        "A54": "Hierarchical Goal Network (HGN) planning",
        "A44": "a principled framework for incorporating DIP heuristics into HGN planning using a simple relaxation of the HGN semantics",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 266812959
    },
    {
        "Abstract": "State-of-the-art methods for solving SSPs often work by limiting planning to restricted regions of the state space. The resulting problems can then be solved quickly, and the process is repeated during execution when states outside the restricted region are encountered. Typically, these approaches focus on states that are within some distance measure of the start state (e.g., number of actions or probability of being reached). However, these short-sighted approaches make it difficult to propagate information from states that are closer to a goal than to the start state, thus missing opportunities to improve planning. We present an alternative approach in which short-sightedness is used only to determine whether a state should be labeled as solved or not, but otherwise the set of states that can be accounted for during planning is unrestricted. Based on this idea, we propose the FLARES algorithm and show that it performs consistently well on a wide range of benchmark problems.",
        "A1": "solving SSPs",
        "A2": "difficult to propagate information from states that are closer to a goal than to the start state, thus missing opportunities to improve planning",
        "A41": "short-sightedness is used only to determine whether a state should be labeled as solved or not, but otherwise the set of states that can be accounted for during planning is unrestricted",
        "A51": "",
        "A61": "short-sightedness is used only to determine whether a state should be labeled as solved or not",
        "A10": "performs consistently well on a wide range of benchmark problems.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "performs consistently well on a wide range of benchmark problems.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "short-sightedness is used only to determine whether a state should be labeled as solved or not, but otherwise the set of states that can be accounted for during planning is unrestricted",
        "A43": "FLARES algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 260306686
    },
    {
        "Abstract": "Electroencephalography (EEG) is one of the most important noninvasive neuroimaging tools that provides excellent temporal accuracy. As the EEG electrode sensors measure electrical potentials on the scalp instead of direct measuring activities of brain voxels deep inside the head, many approaches are proposed to infer the activated brain regions due to its significance in neuroscience research and clinical application. However, since mostly part of the brain activity is composed of the spontaneous neural activities or non-task related activations, task related activation patterns will be corrupted in strong background signal/noises. In our research, we proposed a sparse learning framework for solving EEG inverse problem which aims to explicitly extract the discriminative sources for different cognitive tasks by fusing the label information into the inverse model. The proposed framework is capable of estimation the discriminative brain sources under given different brain states where traditional inverse methods failed. We introduced two models, one is formulated as supervised sparse dictionary learning and the other one is the graph regularized discriminative source estimation model to promote the consistency within same class. Preliminary experimental results also validated that the proposed sparse learning framework is effective to discover the discriminative task-related brain activation sources, which shows the potential to advance the high resolution EEG source analysis for real-time non-invasive brain imaging research.",
        "A1": "EEG inverse problem",
        "A2": "task related activation patterns will be corrupted in strong background signal/noises",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "which shows the potential to advance the high resolution EEG source analysis for real-time non-invasive brain imaging research",
        "A64": "",
        "A54": "",
        "A44": "is capable of estimation the discriminative brain sources under given different brain states where traditional inverse methods failed",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "one is formulated as supervised sparse dictionary learning and the other one is the graph regularized discriminative source estimation model to promote the consistency within same class.",
        "A42": "",
        "A45": "",
        "am_id": 141691118
    },
    {
        "Abstract": "Circular variables arise in a multitude of data-modelling contexts ranging from robotics to the social sciences, but they have been largely overlooked by the machine learning community. This paper partially redresses this imbalance by extending some standard probabilistic modelling tools to the circular domain. First we introduce a new multivariate distribution over circular variables, called the multivariate Generalised von Mises (mGvM) distribution. This distribution can be constructed by restricting and renormalising a general multivariate Gaussian distribution to the unit hyper-torus. Previously proposed multivariate circular distributions are shown to be special cases of this construction. Second, we introduce a new probabilistic model for circular regression inspired by Gaussian Processes, and a method for probabilistic Principal Component Analysis with circular hidden variables. These models can leverage standard modelling tools (e.g. kernel functions and automatic relevance determination). Third, we show that the posterior distribution in these models is a mGvM distribution which enables development of an efficient variational free-energy scheme for performing approximate inference and approximate maximum-likelihood learning.",
        "A1": "standard probabilistic modelling tools to the circular domain",
        "A2": "approximate inference and approximate maximum-likelihood learning",
        "A41": "a new probabilistic model for circular regression",
        "A51": "Gaussian Processes",
        "A61": "Previously proposed multivariate circular distributions are shown to be special cases of this construction.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 8023684
    },
    {
        "Abstract": "Bounding the partition function is a key inference task in many graphical models. In this paper, we develop an anytime anyspace search algorithm taking advantage of AND/OR tree structure and optimized variational heuristics to tighten deterministic bounds on the partition function. We study how our priority-driven best-first search scheme can improve on state-of-the-art variational bounds in an anytime way within limited memory resources, as well as the effect of the AND/OR framework to exploit conditional independence structure within the search process within the context of summation. We compare our resulting bounds to a number of existing methods, and show that our approach offers a number of advantages on real-world problem instances taken from recent UAI competitions.",
        "A1": "",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our approach offers a number of advantages on real-world problem instances taken from recent UAI competitions.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our approach offers a number of advantages on real-world problem instances taken from recent UAI competitions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "AND/OR framework",
        "A43": "an anytime anyspace search algorithm taking advantage of AND/OR tree structure and optimized variational heuristics to tighten deterministic bounds on the partition function",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 389797526
    },
    {
        "Abstract": "This demonstration showcases the different use cases of Artificial Intelligence (AI) in education by introducing students to applications of the Scribbler robot with the Fluke board in order to cultivate an interest in programming, robotics, and AI. The targeted audience for this is students aged eight through twelve. This demonstration uses three Scribbler robots to introduce students to common tools in AI (OpenCV and Tesseract), and teach them the basics of coding in an interactive, unintimidating way; by physically describing the goals of simple shape-building algorithms and implementing them using cards with both visual and written representations of the instructions.",
        "A1": "cultivate an interest in programming, robotics, and AI",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "uses three Scribbler robots to introduce students to common tools in AI",
        "A83": "",
        "A82": "implementing them using cards with both visual and written representations of the instructions",
        "A81": "by physically describing the goals of simple shape-building algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 314441637
    },
    {
        "Abstract": "In recent years there has been rising interest in the use of programming-by-example techniques to assist users in data manipulation tasks. Such techniques rely on an explicit input-output examples specification from the user to automatically synthesize programs. However, in a wide range of data extraction tasks it is easy for a human observer to predict the desired extraction by just observing the input data itself. Such predictive intelligence has not yet been explored in program synthesis research, and is what we address in this work. We describe a predictive program synthesis algorithm that infers programs in a general form of extraction DSLs (domain specific languages) given input-only examples. We describe concrete instantiations of such DSLs and the synthesis algorithm in the two practical application domains of text extraction and web extraction, and present an evaluation of our technique on a range of extraction tasks encountered in practice.",
        "A1": " predict the desired extraction by just observing the input data itself",
        "A2": " predict the desired extraction by just observing the input data itself",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "describe concrete instantiations of such DSLs and the synthesis algorithm in the two practical application domains of text extraction and web extraction",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Such predictive intelligence has not yet been explored in program synthesis research",
        "A53": "",
        "A43": " a predictive program synthesis algorithm ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 116681560
    },
    {
        "Abstract": "This abstract proposes a time series anomaly detector which 1) makes no assumption about the underlying mechanism of anomaly patterns, 2) refrains from the cumbersome work of threshold setting for good anomaly detection performance under specific scenarios, and 3) keeps evolving with the growth of anomaly detection experience. Essentially, the anomaly detector is powered by the Recurrent Neural Network (RNN) and adopts the Reinforcement Learning (RL) method to achieve the self-learning process. Our initial experiments demonstrate promising results of using the detector in network time series anomaly detection problems.",
        "A1": " time series anomaly detector",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " using the detector in network time series anomaly detection problems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Recurrent Neural Network",
        "A42": "1) makes no assumption about the underlying mechanism of anomaly patterns, 2) refrains from the cumbersome work of threshold setting for good anomaly detection performance under specific scenarios, and 3) keeps evolving with the growth of anomaly detection experience",
        "A45": "",
        "am_id": 31709277
    },
    {
        "Abstract": "Visual recognition from very low-quality images is an extremely challenging task with great practical values. While deep networks have been extensively applied to low-quality image restoration and high-quality image recognition tasks respectively, few works have been done on the important problem of recognition from very low-quality images.This paper presents a degradation-robust pre-training approach on improving deep learning models towards this direction. Extensive experiments on different datasets validate the effectiveness of our proposed method.",
        "A1": "approach on improving deep learning models towards this direction",
        "A2": " few works have been done on the important problem of recognition from very low-quality images",
        "A41": "presents a degradation-robust pre-training approach on improving deep learning models towards this direction",
        "A51": "deep learning models",
        "A61": "on the important problem of recognition from very low-quality images",
        "A10": "validate the effectiveness of our proposed method.",
        "A7": "Extensive experiments on different datasets",
        "A83": "",
        "A82": "",
        "A81": "validate the effectiveness of our proposed method.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 178943065
    },
    {
        "Abstract": "Deep reinforcement learning has emerged as a powerful tool for a variety of learning tasks, however deep nets typically exhibit forgetting when learning multiple tasks in sequence. To mitigate forgetting, we propose an experience replay process that augments the standard FIFO buffer and selectively stores experiences in a long-term memory. We explore four strategies for selecting which experiences will be stored: favoring surprise, favoring reward, matching the global training distribution, and maximizing coverage of the state space. We show that distribution matching successfully prevents catastrophic forgetting, and is consistently the best approach on all domains tested. While distribution matching has better and more consistent performance, we identify one case in which coverage maximization is beneficial---when tasks that receive less trained are more important. Overall, our results show that selective experience replay, when suitable selection algorithms are employed, can prevent catastrophic forgetting.",
        "A1": "Deep reinforcement learning has emerged as a powerful tool for a variety of learning tasks, however deep nets typically exhibit forgetting when learning multiple tasks in sequence. To mitigate forgetting, ",
        "A2": "To mitigate forgetting, we propose an experience replay process that augments the standard FIFO buffer and selectively stores experiences in a long-term memory. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " We show that distribution matching successfully prevents catastrophic forgetting, and is consistently the best approach on all domains tested. While distribution matching has better and more consistent performance, we identify one case in which coverage maximization is beneficial---when tasks that receive less trained are more important. Overall, our results show that selective experience replay, when suitable selection algorithms are employed, can prevent catastrophic forgetting.",
        "A83": " selective experience replay, when suitable selection algorithms are employed, can prevent catastrophic forgetting.",
        "A82": "we identify one case in which coverage maximization is beneficial---when tasks that receive less trained are more important",
        "A81": "that distribution matching successfully prevents catastrophic forgetting, and is consistently the best approach on all domains tested",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": " the standard FIFO buffer ",
        "A43": "favoring surprise, favoring reward, matching the global training distribution, and maximizing coverage of the state space",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 470862246
    },
    {
        "Abstract": "This paper is concerned with how to make efficient use of social information to improve recommendations. Most existing social recommender systems assume people share similar preferences with their social friends. Which, however, may not hold true due to various motivations of making online friends and dynamics of online social networks. Inspired by recent causal process based recommendations that first model user exposures towards items and then use these exposures to guide rating prediction, we utilize social information to capture user exposures rather than user preferences. We assume that people get information of products from their online friends and they do not have to share similar preferences, which is less restrictive and seems closer to reality. Under this new assumption, in this paper, we present a novel recommendation approach (named SERec) to integrate social exposure into collaborative filtering. We propose two methods to implement SERec, namely social regularization and social boosting, each with different ways to construct social exposures. Experiments on four real-world datasets demonstrate that our methods outperform the state-of-the-art methods on top-N recommendations. Further study compares the robustness and scalability of the two proposed methods.",
        "A1": "how to make efficient use of social information to improve recommendations",
        "A2": "how to make efficient use of social information to improve recommendations",
        "A41": " a novel recommendation approach (named SERec) to integrate social exposure into collaborative filtering",
        "A51": "recent causal process based recommendations",
        "A61": " integrate social exposure into collaborative filtering",
        "A10": "demonstrate that our methods outperform the state-of-the-art methods on top-N recommendations",
        "A7": " Experiments on four real-world datasets",
        "A83": "",
        "A82": "",
        "A81": "demonstrate that our methods outperform the state-of-the-art methods on top-N recommendations",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 2834045
    },
    {
        "Abstract": "Taxi demand prediction is an important building block to enabling intelligent transportation systems in a smart city. An accurate prediction model can help the city pre-allocate resources to meet travel demand and to reduce empty taxis on streets which waste energy and worsen the traffic congestion. With the increasing popularity of taxi requesting services such as Uber and Didi Chuxing (in China), we are able to collect large-scale taxi demand data continuously. How to utilize such big data to improve the demand prediction is an interesting and critical real-world problem. Traditional demand prediction methods mostly rely on time series forecasting techniques, which fail to model the complex non-linear spatial and temporal relations. Recent advances in deep learning have shown superior performance on traditionally challenging tasks such as image classification by learning the complex features and correlations from large-scale data. This breakthrough has inspired researchers to explore deep learning techniques on traffic prediction problems. However, existing methods on traffic prediction have only considered spatial relation (e.g., using CNN) or temporal relation (e.g., using LSTM) independently. We propose a Deep Multi-View Spatial-Temporal Network (DMVST-Net) framework to model both spatial and temporal relations. Specifically, our proposed model consists of three views: temporal view (modeling correlations between future demand values with near time points via LSTM), spatial view (modeling local spatial correlation via local CNN), and semantic view (modeling correlations among regions sharing similar temporal patterns). Experiments on large-scale real taxi demand data demonstrate effectiveness of our approach over state-of-the-art methods.",
        "A1": "n interesting an",
        "A2": "nd Didi Chuxing",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "teresting and critical ",
        "A7": "h big data to improv",
        "A83": "el demand and to r",
        "A82": "rsen the traffic congestion",
        "A81": "ravel demand and t",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "ting and cr",
        "A52": "y and worsen th",
        "A42": "h big data to impr",
        "A45": "",
        "am_id": 34265523
    },
    {
        "Abstract": "Multi-task learning (MTL) is a machine learning paradigm that improves the performance of each task by exploiting useful information contained in multiple related tasks. However, the relatedness of tasks can be exploited by attackers to launch data poisoning attacks, which has been demonstrated a big threat to single-task learning. In this paper, we provide the first study on the vulnerability of MTL. Specifically, we focus on multi-task relationship learning (MTRL) models, a popular subclass of MTL models where task relationships are quantized and are learned directly from training data. We formulate the problem of computing optimal poisoning attacks on MTRL as a bilevel program that is adaptive to arbitrary choice of target tasks and attacking tasks. We propose an efficient algorithm called PATOM for computing optimal attack strategies. PATOM leverages the optimality conditions of the subproblem of MTRL to compute the implicit gradients of the upper level objective function. Experimental results on real-world datasets show that MTRL models are very sensitive to poisoning attacks and the attacker can significantly degrade the performance of target tasks, by either directly poisoning the target tasks or indirectly poisoning the related tasks exploiting the task relatedness. We also found that the tasks being attacked are always strongly correlated, which provides a clue for defending against such attacks.",
        "A1": " provide the first study on the vulnerability of MTL",
        "A2": " relatedness of tasks can be exploited by attackers to launch data poisoning attacks, which has been demonstrated a big threat to single-task learning",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on real-world datasets",
        "A83": "",
        "A82": "the tasks being attacked are always strongly correlated, which provides a clue for defending against such attacks",
        "A81": " MTRL models are very sensitive to poisoning attacks and the attacker can significantly degrade the performance of target tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " provide the first study on the vulnerability of MTL",
        "A53": "",
        "A43": "PATOM leverages the optimality conditions of the subproblem of MTRL to compute the implicit gradients of the upper level objective function",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 279302313
    },
    {
        "Abstract": "We present a deep generative model for Zero-Shot Learning (ZSL). Unlike most existing methods for this problem, that represent each class as a point (via a semantic embedding), we represent each seen/unseen class using a class-specific latent-space distribution, conditioned on class attributes. We use these latent-space distributions as a prior for a supervised variational autoencoder (VAE), which also facilitates learning highly discriminative feature representations for the inputs. The entire framework is learned end-to-end using only the seen-class training data. At test time, the label for an unseen-class test input is the class that maximizes the VAE lower bound. We further extend the model to a (i) semi-supervised/transductive setting by leveraging unlabeled unseen-class data via an unsupervised learning module, and (ii) few-shot learning where we also have a small number of labeled inputs from the unseen classes. We compare our model with several state-of-the-art methods through a comprehensive set of experiments on a variety of benchmark data sets.",
        "A1": "Zero-Shot Learning",
        "A2": "Zero-Shot Learning ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a comprehensive set of experiments on a variety of benchmark data sets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "represent each seen/unseen class using a class-specific latent-space distribution",
        "A52": "variational autoencoder (VAE)",
        "A42": "a deep generative model",
        "A45": "",
        "am_id": 429967291
    },
    {
        "Abstract": "We study large-scale machine learning problems in changing environments where a small part of the dataset is modified, and the effect of the data modification must be monitored in order to know how much the modification changes the optimal model. When the entire dataset is large, even if the amount of the data modification is fairly small, the computational cost for re-training the model would be prohibitively large. In this paper, we propose a novel method, called the optimal solution bounding (OSB), for monitoring such a data modification effect on the optimal model by efficiently evaluating (without actually re-training) it. The proposed method provides bounds on the unknown optimal model with the cost proportional only to the size of the data modification.",
        "A1": "",
        "A2": " When the entire dataset is large, even if the amount of the data modification is fairly small, the computational cost for re-training the model would be prohibitively large. ",
        "A41": " optimal solution bounding (OSB), for monitoring such a data modification effect on the optimal model by efficiently evaluating (without actually re-training) it. ",
        "A51": "",
        "A61": "without actually re-training",
        "A10": "The proposed method provides bounds on the unknown optimal model with the cost proportional only to the size of the data modification.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 465083206
    },
    {
        "Abstract": "Heterogeneous face recognition (HFR) refers to matching a probe face image taken from one modality to face images acquired from another modality. It plays an important role in security scenarios. However, HFR is still a challenging problem due to great discrepancies between cross-modality images. This paper proposes an asymmetric joint learning (AJL) approach to handle this issue. The proposed method transforms the cross-modality differences mutually by incorporating the synthesized images into the learning process which provides more discriminative information. Although the aggregated data would augment the scale of intra-classes, it also reduces the diversity (i.e. discriminative information) for inter-classes. Then, we develop the AJL model to balance this dilemma. Finally, we could obtain the similarity score between two heterogeneous face images through the log-likelihood ratio. Extensive experiments on viewed sketch database, forensic sketch database and near infrared image database illustrate that the proposed AJL-HFR method achieve superior performance in comparison to state-of-the-art methods.",
        "A1": "",
        "A2": "HFR is still a challenging problem due to great discrepancies between cross-modality images.",
        "A41": " an asymmetric joint learning (AJL) approach",
        "A51": "",
        "A61": "",
        "A10": "the proposed AJL-HFR method achieve superior performance in comparison to state-of-the-art methods.",
        "A7": " Extensive experiments on viewed sketch database, forensic sketch database and near infrared image database",
        "A83": "",
        "A82": "",
        "A81": "the proposed AJL-HFR method achieve superior performance in comparison to state-of-the-art methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 160391516
    },
    {
        "Abstract": "It is difficult to train a personalized task-oriented dialogue system because the data collected from each individual is often insufficient. Personalized dialogue systems trained on a small dataset is likely to overfit and make it difficult to adapt to different user needs. One way to solve this problem is to consider a collection of multiple users as a source domain and an individual user as a target domain, and to perform transfer learning from the source domain to the target domain. By following this idea, we propose a PErsonalized Task-oriented diALogue (PETAL) system, a transfer reinforcement learning framework based on POMDP, to construct a personalized dialogue system. The PETAL system first learns common dialogue knowledge from the source domain and then adapts this knowledge to the target domain. The proposed PETAL system can avoid the negative transfer problem by considering differences between the source and target users in a personalized Q-function. Experimental results on a real-world coffee-shopping data and simulation data show that the proposed PETAL system can learn optimal policies for different users, and thus effectively improve the dialogue quality under the personalized setting.",
        "A1": "train a personalized task-oriented dialogue system",
        "A2": " Personalized dialogue systems trained on a small dataset is likely to overfit and make it difficult to adapt to different user needs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "effectively improve the dialogue quality under the personalized setting",
        "A7": "Experimental results on a real-world coffee-shopping data and simulation data ",
        "A83": "",
        "A82": "effectively improve the dialogue quality under the personalized setting",
        "A81": "earn optimal policies for different users",
        "A64": "consider a collection of multiple users as a source domain and an individual user as a target domain",
        "A54": "POMDP",
        "A44": " a PErsonalized Task-oriented diALogue (PETAL) system, a transfer reinforcement learning framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 358119291
    },
    {
        "Abstract": "Existing action detection algorithms usually generate action proposals through an extensive search over the video at multiple temporal scales, which brings about huge computational overhead and deviates from the human perception procedure. We argue that the process of detecting actions should be naturally one of observation and refinement: observe the current window and refine the span of attended window to cover true action regions. In this paper, we propose a Self-Adaptive Proposal (SAP) model that learns to find actions through continuously adjusting the temporal bounds in a self-adaptive way. The whole process can be deemed as an agent, which is firstly placed at the beginning of the video and traverse the whole video by adopting a sequence of transformations on the current attended region to discover actions according to a learned policy. We utilize reinforcement learning, especially the Deep Q-learning algorithm to learn the agent\u2019s decision policy. In addition, we use temporal pooling operation to extract more effective feature representation for the long temporal window, and design a regression network to adjust the position offsets between predicted results and the ground truth. Experiment results on THUMOS\u201914 validate the effectiveness of SAP, which can achieve competitive performance with current action detection algorithms via much fewer proposals.",
        "A1": "We argue that the process of detecting actions should be naturally one of observation and refinement: observe the current window and refine the span of attended window to cover true action regions.",
        "A2": "Existing action detection algorithms usually generate action proposals through an extensive search over the video at multiple temporal scales, which brings about huge computational overhead and deviates from the human perception procedure. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of SAP, which can achieve competitive performance with current action detection algorithms via much fewer proposals.",
        "A7": " Experiment results on THUMOS\u201914 ",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of SAP, which can achieve competitive performance with current action detection algorithms via much fewer proposals.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " the process of detecting actions should be naturally one of observation and refinement",
        "A52": "We utilize reinforcement learning, especially the Deep Q-learning algorithm to learn the agent\u2019s decision policy. In addition, we use temporal pooling operation to extract more effective feature representation for the long temporal window, and design a regression network to adjust the position offsets between predicted results and the ground truth.",
        "A42": "a Self-Adaptive Proposal (SAP) model that learns to find actions through continuously adjusting the temporal bounds in a self-adaptive way",
        "A45": "",
        "am_id": 430650483
    },
    {
        "Abstract": "The minimum weighted vertex cover (MWVC) problem is a well known combinatorial optimization problem with important applications. This paper introduces a novel local search algorithm called NuMWVC for MWVC based on three ideas. First, four reduction rules are introduced during the initial construction phase. Second, the configuration checking with aspiration is proposed to reduce cycling problem. Moreover, a self-adaptive vertex removing strategy is proposed to save time.",
        "A1": "introduces a novel local search algorithm",
        "A2": "The minimum weighted vertex cover (MWVC) problem",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "First, four reduction rules are introduced during the initial construction phase. Second, the configuration checking with aspiration is proposed to reduce cycling problem. Moreover, a self-adaptive vertex removing strategy is proposed to save time.",
        "A43": " This paper introduces a novel local search algorithm called NuMWVC for MWVC based on three ideas",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 265955495
    },
    {
        "Abstract": "We study response generation for open domain conversation in chatbots. Existing methods assume that words in responses are generated from an identical vocabulary regardless of their inputs, which not only makes them vulnerable to generic patterns and irrelevant noise, but also causes a high cost in decoding. We propose a dynamic vocabulary sequence-to-sequence (DVS2S) model which allows each input to possess their own vocabulary in decoding. In training, vocabulary construction and response generation are jointly learned by maximizing a lower bound of the true objective with a Monte Carlo sampling method. In inference, the model dynamically allocates a small vocabulary for an input with the word prediction model, and conducts decoding only with the small vocabulary. Because of the dynamic vocabulary mechanism, DVS2S eludes many generic patterns and irrelevant words in generation, and enjoys efficient decoding at the same time. Experimental results on both automatic metrics and human annotations show that DVS2S can significantly outperform state-of-the-art methods in terms of response quality, but only requires 60% decoding time compared to the most efficient baseline.",
        "A1": "study response generation for open domain conversation in chatbots",
        "A2": "response generation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significantly outperform",
        "A7": "automatic metrics and human annotations",
        "A83": "",
        "A82": "only requires 60% decoding time compared to the most efficient baseline",
        "A81": "significantly outperform state-of-the-art methods in terms of response quality",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "allows each input to possess their own vocabulary in decoding",
        "A52": "",
        "A42": "a dynamic vocabulary sequence-to-sequence (DVS2S) model",
        "A45": "",
        "am_id": 378092141
    },
    {
        "Abstract": "This paper introduces a novel methodology for 3D template matching that is scalable to higher-dimensional spaces and larger kernel sizes. It uses the Hilbert Maps framework to model raw pointcloud information as a continuous occupancy function, and we derive a closed-form solution to the convolution operation that takes place directly in the Reproducing Kernel Hilbert Space defining these functions. The result is a third function modeling activation values, that can be queried at arbitrary resolutions with logarithmic complexity, and by iteratively searching for high similarity areas we can determine matching candidates. Experimental results show substantial speed gains over standard discrete convolution techniques, such as sliding window and fast Fourier transform, along with a significant decrease in memory requirements, without accuracy loss. This efficiency allows the proposed methodology to be used in areas where discrete convolution is currently infeasible. As a practical example we explore the key problem in robotics of global localization, in which a vehicle must be positioned on a map using only its current sensor information, and provide comparisons with other state-of-the-art techniques in terms of computational speed and accuracy.",
        "A1": "This paper introduces a novel methodology for 3D template matching that is scalable to higher-dimensional spaces and larger kernel sizes.",
        "A2": "convolution operation that takes place directly in the Reproducing Kernel Hilbert Space defining these functions.",
        "A41": "a novel methodology for 3D template matching that is scalable to higher-dimensional spaces and larger kernel sizes",
        "A51": "Hilbert Maps framework",
        "A61": "substantial speed gains over standard discrete convolution techniques, such as sliding window and fast Fourier transform, along with a significant decrease in memory requirements, without accuracy loss",
        "A10": "substantial speed gains over standard discrete convolution techniques, such as sliding window and fast Fourier transform, along with a significant decrease in memory requirements, without accuracy loss.",
        "A7": " we explore the key problem in robotics of global localization, in which a vehicle must be positioned on a map using only its current sensor information",
        "A83": "",
        "A82": "This efficiency allows the proposed methodology to be used in areas where discrete convolution is currently infeasible.",
        "A81": " Experimental results show substantial speed gains over standard discrete convolution techniques, such as sliding window and fast Fourier transform, along with a significant decrease in memory requirements, without accuracy loss. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 318115110
    },
    {
        "Abstract": "The aim of this paper is to propose a new overarching challenge for AI: the design of imagination machines. Imagination has been defined as the capacity to mentally transcend time, place, and/or circumstance. Much of the success of AI currently comes from a revolution in data science, specifically the use of deep learning neural networks to extract structure from data. This paper argues for the development of a new field called imagination science, which extends data science beyond its current realm of learning probability distributions from samples. Numerous examples are given in the paper to illustrate that human achievements in the arts, literature, poetry, and science may lie beyond the realm of data science, because they require abilities that go beyond finding correlations: for example, generating samples from a novel probability distribution different from the one given during training; causal reasoning to uncover interpretable explanations; or analogical reasoning to generalize to novel situations (e.g., imagination in art, representing alien life in a distant galaxy, understanding a story about talking animals, or inventing representations to model the large-scale structure of the universe). We describe the key challenges in automating imagination, discuss connections between ongoing research and imagination, and outline why automation of imagination provides a powerful launching pad for transforming AI.",
        "A1": "propose a new overarching challenge for AI: the design of imagination machines",
        "A2": "the development of a new field called imagination science",
        "A41": "This paper argues for the development of a new field called imagination science,",
        "A51": "AI",
        "A61": "a new field called imagination science",
        "A10": "We describe the key challenges in automating imagination, discuss connections between ongoing research and imagination, and outline why automation of imagination provides a powerful launching pad for transforming AI.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 174943559
    },
    {
        "Abstract": "We propose a novel approach for constructing effective treatment policies when the observed data is biased and lacks counterfactual information. Learning in settings where the observed data does not contain all possible outcomes for all treatments is difficult since the observed data is typically biased due to existing clinical guidelines. This is an important problem in the medical domain as collecting unbiased data is expensive and so learning from the wealth of existing biased data is a worthwhile task. Our approach separates the problem into two stages: first we reduce the bias by learning a representation map using a novel auto-encoder network---this allows us to control the trade-off between the bias-reduction and the information loss---and then we construct effective treatment policies on the transformed data using a novel feedforward network. Separation of the problem into these two stages creates an algorithm that can be adapted to the problem at hand---the bias-reduction step can be performed as a preprocessing step for other algorithms. We compare our algorithm against state-of-art algorithms on two semi-synthetic datasets and demonstrate that our algorithm achieves a significant improvement in performance.",
        "A1": " learning from the wealth of existing biased data",
        "A2": "We propose a novel approach for constructing effective treatment policies when the observed data is biased and lacks counterfactual information. ",
        "A41": "We propose a novel approach for constructing effective treatment policies when the observed data is biased and lacks counterfactual information. ",
        "A51": "feedforward network",
        "A61": "",
        "A10": " We compare our algorithm against state-of-art algorithms on two semi-synthetic datasets and demonstrate that our algorithm achieves a significant improvement in performance.",
        "A7": " We compare our algorithm against state-of-art algorithms on two semi-synthetic datasets and demonstrate that our algorithm achieves a significant improvement in performance.",
        "A83": "",
        "A82": "",
        "A81": "our algorithm achieves a significant improvement in performance.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 398815840
    },
    {
        "Abstract": "Estimating the future event sequence conditioned on current observations is a long-standing and challenging task in temporal analysis. On one hand for many real-world problems the underlying dynamics can be very complex and often unknown. This renders the traditional parametric point process models often fail to fit the data for their limited capacity. On the other hand, long-term prediction suffers from the problem of bias exposure where the error accumulates and propagates to future prediction. Our new model builds upon the sequence to sequence (seq2seq) prediction network. Compared with parametric point process models, its modeling capacity is higher and has better flexibility for fitting real-world data. The main novelty of the paper is to mitigate the second challenge by introducing the likelihood-free loss based on Wasserstein distance between point processes, besides negative maximum likelihood loss used in the traditional seq2seq model. Wasserstein distance, unlike KL divergence i.e. MLE loss, is sensitive to the underlying geometry between samples and can robustly enforce close geometry structure between them. This technique is proven able to improve the vanilla seq2seq model by a notable margin on various tasks.",
        "A1": "Estimating the future event sequence conditioned on current observations is a long-standing and challenging task in temporal analysis. ",
        "A2": "Estimating the future event sequence conditioned on current observations is a long-standing and challenging task in temporal analysis.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "This technique is proven able to improve the vanilla seq2seq model by a notable margin on various tasks.",
        "A7": "The main novelty of the paper is to mitigate the second challenge by introducing the likelihood-free loss based on Wasserstein distance between point processes, ",
        "A83": "",
        "A82": "",
        "A81": "sensitive to the underlying geometry between samples and can robustly enforce close geometry structure between them. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " Compared with parametric point process models, its modeling capacity is higher and has better flexibility for fitting real-world data. ",
        "A52": "sequence to sequence (seq2seq) prediction network",
        "A42": "Our new model builds upon the sequence to sequence (seq2seq) prediction network. ",
        "A45": "",
        "am_id": 114928031
    },
    {
        "Abstract": "Generating music medleys is about finding an optimal permutation of a given set of music clips. Toward this goal, we propose a self-supervised learning task, called the music puzzle game, to train neural network models to learn the sequential patterns in music. In essence, such a game requires machines to correctly sort a few multisecond music fragments. In the training stage, we learn the model by sampling multiple non-overlapping fragment pairs from the same songs and seeking to predict whether a given pair is consecutive and is in the correct chronological order. For testing, we design a number of puzzle games with different difficulty levels, the most difficult one being music medley, which requiring sorting fragments from different songs. On the basis of state-of-the-art Siamese convolutional network, we propose an improved architecture that learns to embed frame-level similarity scores computed from the input fragment pairs to a common space, where fragment pairs in the correct order can be more easily identified. Our result shows that the resulting model, dubbed as the similarity embedding network (SEN), performs better than competing models across different games, including music jigsaw puzzle, music sequencing, and music medley. Example results can be found at our project website, https://remyhuang.github.io/DJnet.",
        "A1": "Generating music medleys",
        "A2": "orrectly sort a few multisecond music fragments",
        "A41": "In the training stage, we learn the model by sampling multiple non-overlapping fragment pairs from the same songs and seeking to predict whether a given pair is consecutive and is in the correct chronological order. For testing, we design a number of puzzle games with different difficulty levels, the most difficult one being music medley",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the resulting model, dubbed as the similarity embedding network (SEN), performs better than competing models across different games",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "state-of-the-art Siamese convolutional network",
        "A42": " learns to embed frame-level similarity scores computed from the input fragment pairs to a common space",
        "A45": "",
        "am_id": 311867735
    },
    {
        "Abstract": "Search task success rate is a crucial metric based on the search experience of users to measure the performance of search systems. Modeling search action sequence would help to capture the latent search patterns of users in successful and unsuccessful search tasks. Existing approaches use aggregated features to describe the user behavior in search action sequences, which depend on heuristic hand-crafted feature design and ignore a lot of information inherent in the user behavior. In this paper, we employ Long Short-Term Memory (LSTM) that performs end-to-end fine-tuning during the training to learn search action sequence representation for search task success evaluation. Concretely, we normalize the search action sequences by introducing a dummy idle action, which guarantees that the time intervals between contiguous actions are fixed. Simultaneously, we propose a novel data augmentation strategy to increase the pattern variations on search action sequence data to improve the generalization ability of LSTM. We evaluate the proposed approach on open datasets with two different definitions of search task success. The experimental results show that the proposed approach achieves significant performance improvement compared with several excellent search task success evaluation approaches.",
        "A1": " learn search action sequence representation for search task success evaluation",
        "A2": "normalize the search action sequences ",
        "A41": "Long Short-Term Memory",
        "A51": "introducing a dummy idle action",
        "A61": "he time intervals between contiguous actions are fixed",
        "A10": " the proposed approach achieves significant performance improvement",
        "A7": "two different definitions of search task success",
        "A83": "",
        "A82": "",
        "A81": " the proposed approach achieves significant performance improvement compared with several excellent search task success evaluation approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 128762959
    },
    {
        "Abstract": "We revisit the problem of robust principal component analysis with features acting as prior side information. To this aim, a novel, elegant, non-convex optimization approach is proposed to decompose a given observation matrix into a low-rank core and the corresponding sparse residual. Rigorous theoretical analysis of the proposed algorithm results in exact recovery guarantees with low computational complexity. Aptly designed synthetic experiments demonstrate that our method is the first to wholly harness the power of non-convexity over convexity in terms of both recoverability and speed. That is, the proposed non-convex approach is more accurate and faster compared to the best available algorithms for the problem under study. Two real-world applications, namely image classification and face denoising further exemplify the practical superiority of the proposed method.",
        "A1": "We revisit the problem of robust principal component analysis with features acting as prior side information. ",
        "A2": "",
        "A41": "a novel, elegant, non-convex optimization approach is proposed to decompose a given observation matrix into a low-rank core and the corresponding sparse residual",
        "A51": "",
        "A61": "",
        "A10": "That is, the proposed non-convex approach is more accurate and faster compared to the best available algorithms for the problem under study.",
        "A7": " Aptly designed synthetic experiments",
        "A83": "",
        "A82": "Two real-world applications, namely image classification and face denoising further exemplify the practical superiority of the proposed method.",
        "A81": "our method is the first to wholly harness the power of non-convexity over convexity in terms of both recoverability and speed",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 123296497
    },
    {
        "Abstract": "Robots assisting the disabled or elderly must perform complex manipulation tasks and must adapt to the home environment and preferences of their user. Learning from demonstration is a promising choice, that would allow the non-technical user to teach the robot different tasks. However, collecting demonstrations in the home environment of a disabled user is time consuming, disruptive to the comfort of the user, and presents safety challenges. It would be desirable to perform the demonstrations in a virtual environment. In this paper we describe a solution to the challenging problem of behavior transfer from virtual demonstration to a physical robot. The virtual demonstrations are used to train a deep neural network based controller, which is using a Long Short Term Memory (LSTM) recurrent neural network to generate trajectories. The training process uses a Mixture Density Network (MDN) to calculate an error signal suitable for the multimodal nature of demonstrations. The controller learned in the virtual environment is transferred to a physical robot (a Rethink Robotics Baxter). An off-the-shelf vision component is used to substitute for geometric knowledge available in the simulation and an inverse kinematics module is used to allow the Baxter to enact the trajectory. Our experimental studies validate the three contributions of the paper: (1) the controller learned from virtual demonstrations can be used to successfully perform the manipulation tasks on a physical robot, (2) the LSTM+MDN architectural choice outperforms other choices, such as the use of feedforward networks and mean-squared error based training signals and (3) allowing imperfect demonstrations in the training set also allows the controller to learn how to correct its manipulation mistakes.",
        "A1": "describe a solution to the challenging problem of behavior transfer from virtual demonstration to a physical robot",
        "A2": "behavior transfer from virtual demonstration to a physical robot",
        "A41": "The virtual demonstrations",
        "A51": "",
        "A61": "",
        "A10": "describe a solution to the challenging problem of behavior transfer from virtual demonstration to a physical robot",
        "A7": "",
        "A83": " allowing imperfect demonstrations in the training set also allows the controller to learn how to correct its manipulation mistakes",
        "A82": "the LSTM+MDN architectural choice outperforms other choices, such as the use of feedforward networks and mean-squared error based training signals",
        "A81": " the controller learned from virtual demonstrations can be used to successfully perform the manipulation tasks on a physical robot",
        "A64": "An off-the-shelf vision component is used to substitute for geometric knowledge available in the simulation and an inverse kinematics module is used to allow the Baxter to enact the trajectory",
        "A54": " a Long Short Term Memory (LSTM) recurrent neural network",
        "A44": "a deep neural network based controller",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 26545630
    },
    {
        "Abstract": "Employee scheduling is one of the most difficult challenges facing any small business owner. The problem becomes more complex when employees with different levels of seniority indicate preferences for specific roles in certain shifts and request flexible work hours outside of the standard eight-hour block. Many business owners and managers, who cannot afford (or choose not to use) commercially-available timetabling apps, spend numerous hours creating sub-optimal schedules by hand, leading to low staff morale. In this paper, we explain how two undergraduate students generalized the Nurse Scheduling Problem to take into account multiple roles and flexible work hours, and implemented a user-friendly automated timetabler based on a four-dimensional integer linear program. This system has been successfully deployed at two businesses in our community, each with 20+ employees: a coffee shop and a health clinic.",
        "A1": " In this paper, we explain how two undergraduate students generalized the Nurse Scheduling Problem to take into account multiple roles and flexible work hours, and implemented a user-friendly automated timetabler based on a four-dimensional integer linear program.",
        "A2": "Employee scheduling is one of the most difficult challenges facing any small business owner",
        "A41": " In this paper, we explain how two undergraduate students generalized the Nurse Scheduling Problem to take into account multiple roles and flexible work hours, and implemented a user-friendly automated timetabler based on a four-dimensional integer linear program.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " This system has been successfully deployed at two businesses in our community, each with 20+ employees: a coffee shop and a health clinic.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 485825519
    },
    {
        "Abstract": "A user can be represented as what he/she does along the history. A common way to deal with the user modeling problem is to manually extract all kinds of aggregated features over the heterogeneous behaviors, which may fail to fully represent the data itself due to limited human instinct. Recent works usually use RNN-based methods to give an overall embedding of a behavior sequence, which then could be exploited by the downstream applications. However, this can only preserve very limited information, or aggregated memories of a person. When a downstream application requires to facilitate the modeled user features, it may lose the integrity of the specific highly correlated behavior of the user, and introduce noises derived from unrelated behaviors. This paper proposes an attention based user behavior modeling framework called ATRank, which we mainly use for recommendation tasks. Heterogeneous user behaviors are considered in our model that we project all types of behaviors into multiple latent semantic spaces, where influence can be made among the behaviors via self-attention. Downstream applications then can use the user behavior vectors via vanilla attention. Experiments show that ATRank can achieve better performance and faster training process. We further explore ATRank to use one unified model to predict different types of user behaviors at the same time, showing a comparable performance with the highly optimized individual models.",
        "A1": " This paper proposes an attention based user behavior modeling framework called ATRank, which we mainly use for recommendation tasks. ",
        "A2": "A user can be represented as what he/she does along the history",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " better performance and faster training process",
        "A7": "explore ATRank to use one unified model to predict different types of user behaviors at the same time",
        "A83": "",
        "A82": " ATRank can achieve better performance and faster training process",
        "A81": "a comparable performance with the highly optimized individual models.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Heterogeneous user behaviors are considered in our model that we project all types of behaviors into multiple latent semantic spaces,",
        "A52": "attention ",
        "A42": "an attention based user behavior modeling framework called ATRank",
        "A45": "",
        "am_id": 489287630
    },
    {
        "Abstract": "Event extraction plays an important role in natural language processing (NLP) applications including question answering and information retrieval. Traditional event extraction relies heavily on lexical and syntactic features, which require intensive human engineering and may not generalize to different datasets. Deep neural networks, on the other hand, are able to automatically learn underlying features, but existing networks do not make full use of syntactic relations. In this paper, we propose a novel dependency bridge recurrent neural network (dbRNN) for event extraction. We build our model upon a recurrent neural network, but enhance it with dependency bridges, which carry syntactically related information when modeling each word.We illustrates that simultaneously applying tree structure and sequence structure in RNN brings much better performance than only uses sequential RNN. In addition, we use a tensor layer to simultaneously capture the various types of latent interaction between candidate arguments as well as identify/classify all arguments of an event. Experiments show that our approach achieves competitive results compared with previous work.",
        "A1": "Event extraction plays",
        "A2": "Traditional event extraction relies heavily on lexical and syntactic features, which require intensive human engineering and may not generalize to different datasets. Deep neural networks, on the other hand, are able to automatically learn underlying features, but existing networks do not make full use of syntactic relations.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our approach achieves competitive results compared with previous work",
        "A7": "",
        "A83": "",
        "A82": "simultaneously applying tree structure and sequence structure in RNN brings much better performance than only uses sequential RNN",
        "A81": "our approach achieves competitive results compared with previous work",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "enhance it with dependency bridges, which carry syntactically related information when modeling each word.",
        "A52": " a recurrent neural network",
        "A42": "a novel dependency bridge recurrent neural network (dbRNN) ",
        "A45": "",
        "am_id": 313061881
    },
    {
        "Abstract": "Answer Set Programming (ASP) is a well-established formalism for nonmonotonic reasoning.While incoherence, the non-existence of answer sets for some programs, is an important feature of ASP, it has frequently been criticised and indeed has some disadvantages, especially for query answering.Paracoherent semantics have been suggested as a remedy, which extend the classical notion of answer sets to draw meaningful conclusions also from incoherent programs. In this paper we present an alternative characterization of the two major paracoherent semantics in terms of (extended) externally supported models. This definition uses a transformation of ASP programs that is more parsimonious than the classic epistemic transformation used in recent implementations.A performance comparison carried out on benchmarks from ASP competitions shows that the usage of the new transformation brings about performance improvements that are independent of the underlying algorithms.",
        "A1": "Answer Set Programming (ASP)",
        "A2": " the non-existence of answer sets for some programs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "A performance comparison carried out on benchmarks from ASP competitions",
        "A83": "",
        "A82": "",
        "A81": "the usage of the new transformation brings about performance improvements that are independent of the underlying algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "uses a transformation of ASP programs that is more parsimonious than the classic epistemic transformation used in recent implementations",
        "A52": "(extended) externally supported models",
        "A42": " an alternative characterization of the two major paracoherent semantics",
        "A45": "",
        "am_id": 416900355
    },
    {
        "Abstract": "Considering the diversity of the views, assigning the multiviews with different weights is important to multi-view clustering. Several multi-view clustering algorithms have been proposed to assign different weights to the views. However, the existing weighting schemes do not simultaneously consider the characteristic of multi-view clustering and the characteristic of related single-view clustering. In this paper, based on the spectral perturbation theory of spectral clustering, we propose a weighted multi-view spectral clustering algorithm which employs the spectral perturbation to model the weights of the views. The proposed weighting scheme follows the two basic principles: 1) the clustering results on each view should be close to the consensus clustering result, and 2) views with similar clustering results should be assigned similar weights. According to spectral perturbation theory, the largest canonical angle is used to measure the difference between spectral clustering results. In this way, the weighting scheme can be formulated into a standard quadratic programming problem. Experimental results demonstrate the superiority of the proposed algorithm.",
        "A1": "",
        "A2": "do not simultaneously consider the characteristic of multi-view clustering and the characteristic of related single-view clustering",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "the largest canonical angle is used to measure the difference between spectral clustering results",
        "A81": "the weighting scheme can be formulated into a standard quadratic programming problem",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "the clustering results on each view should be close to the consensus clustering result, and 2) views with similar clustering results should be assigned similar weights",
        "A53": "the spectral perturbation theory of spectral clustering",
        "A43": " a weighted multi-view spectral clustering algorithm which employs the spectral perturbation to model the weights of the views",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 172072176
    },
    {
        "Abstract": "Shortest path planning is a fundamental building block in many applications. Hence developing efficient methods for computing shortest paths in e.g. road or grid networks is an important challenge. The most successful techniques for fast query answering rely on preprocessing. But for many of these techniques it is not fully understood why they perform so remarkably well and theoretical justification for the empirical results is missing. An attempt to explain the excellent practical performance of preprocessing based techniques on road networks (as transit nodes, hub labels, or contraction hierarchies) in a sound theoretical way are parametrized analyses, e.g., considering the highway dimension or skeleton dimension of a graph. But these parameters tend to be large (order of \u0398(\u221an)) when the network contains grid-like substructures \u2014 which inarguably is the case for real-world road networks around the globe. In this paper, we use the very intuitive notion of bounded growth graphs to describe road networks and also grid graphs. We show that this model suffices to prove sublinear search spaces for the three above mentioned state-of-the-art shortest path planning techniques. For graphs with a large highway or skeleton dimension, our results turn out to be superior. Furthermore, our preprocessing methods are close to the ones used in practice and only require randomized polynomial time.",
        "A1": " computing shortest paths",
        "A2": "many of these techniques it is not fully understood why they perform so remarkably well and theoretical justification for the empirical results is missing. An attempt to explain the excellent practical performance of preprocessing based techniques on road networks (as transit nodes, hub labels, or contraction hierarchies) in a sound theoretical way are parametrized analyses, e.g., considering the highway dimension or skeleton dimension of a graph. But these parameters tend to be large (order of \u0398(\u221an)) when the network contains grid-like substructures \u2014 which inarguably is the case for real-world road networks around the globe",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our results turn out to be superior. Furthermore, our preprocessing methods are close to the ones used in practice and only require randomized polynomial time.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our results turn out to be superior",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " sublinear search spaces for the three above mentioned state-of-the-art shortest path planning techniques",
        "A52": "",
        "A42": "use the very intuitive notion of bounded growth graphs to describe road networks and also grid graphs",
        "A45": "",
        "am_id": 474108737
    },
    {
        "Abstract": "The lack of interpretability remains a key barrier to the adoption of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Specifically, we train deep time-series models so their class-probability predictions have high accuracy while being closely modeled by decision trees with few nodes. Using intuitive toy examples as well as medical tasks for treating sepsis and HIV, we demonstrate that this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacrificing predictive power.",
        "A1": "The lack of interpretability",
        "A2": "The lack of interpretability",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacrificing predictive power",
        "A7": "Using intuitive toy examples as well as medical tasks for treating sepsis and HIV",
        "A83": "",
        "A82": "",
        "A81": " this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacrificing predictive power",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "The lack of interpretability remains a key barrier to the adoption of deep models in many applications.",
        "A52": "",
        "A42": "we explicitly regularize deep models",
        "A45": "",
        "am_id": 268548324
    },
    {
        "Abstract": "Feature selection is effective in preparing high-dimensional data for a variety of learning tasks such as classification, clustering and anomaly detection. A vast majority of existing feature selection methods assume that all instances share some common patterns manifested in a subset of shared features. However, this assumption is not necessarily true in many domains where data instances could show high individuality. For example, in the medical domain, we need to capture the heterogeneous nature of patients for personalized predictive modeling, which could be characterized by a subset of instance-specific features. Motivated by this, we propose to study a novel problem of personalized feature selection. In particular, we investigate the problem in an unsupervised scenario as label information is usually hard to obtain in practice. To be specific, we present a novel unsupervised personalized feature selection framework UPFS to find some shared features by all instances and instance-specific features tailored to each instance. We formulate the problem into a principled optimization framework and provide an effective algorithm to solve it. Experimental results on real-world datasets verify the effectiveness of the proposed UPFS framework.",
        "A1": "we propose to study a novel problem of personalized feature selection",
        "A2": "this assumption is not necessarily true in many domains where data instances could show high individuality",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on real-world datasets",
        "A83": "",
        "A82": "",
        "A81": "verify the effectiveness of the proposed UPFS framework.",
        "A64": "We formulate the problem into a principled optimization framework",
        "A54": "",
        "A44": "a novel unsupervised personalized feature selection framework UPFS to find some shared features by all instances and instance-specific features tailored to each instance",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 383391493
    },
    {
        "Abstract": "Sensor-based activity recognition aims to predict users' activities from multi-dimensional streams of various sensor readings received from ubiquitous sensors. To use machine learning techniques for sensor-based activity recognition, previous approaches focused on composing a feature vector to represent sensor-reading streams received within a period of various lengths. With the constructed feature vectors, e.g., using predefined orders of moments in statistics, and their corresponding labels of activities, standard classification algorithms can be applied to train a predictive model, which will be used to make predictions online. However, we argue that in this way some important information, e.g., statistical information captured by higher-order moments, may be discarded when constructing features. Therefore, in this paper, we propose a new method, denoted by SMMAR, based on learning from distributions for sensor-based activity recognition. Specifically, we consider sensor readings received within a period as a sample, which can be represented by a feature vector of infinite dimensions in a Reproducing Kernel Hilbert Space (RKHS) using kernel embedding techniques. We then train a classifier in the RKHS. To scale-up the proposed method, we further offer an accelerated version by utilizing an explicit feature map instead of using a kernel function. We conduct experiments on four benchmark datasets to verify the effectiveness and scalability of our proposed method.",
        "A1": "Sensor-based activity recognition",
        "A2": "Sensor-based activity recognition",
        "A41": "SMMAR",
        "A51": "learning from distributions for sensor-based activity recognition",
        "A61": "statistical information captured by higher-order moments",
        "A10": "",
        "A7": "four benchmark datasets ",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness and scalability of our proposed method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 155628426
    },
    {
        "Abstract": "Previous models for video captioning often use the output from a specific layer of a Convolutional Neural Network (CNN) as video features. However, the variable context-dependent semantics in the video may make it more appropriate to adaptively select features from the multiple CNN layers. We propose a new approach for generating adaptive spatiotemporal representations of videos for the captioning task. A novel attention mechanism is developed, that adaptively and sequentially focuses on different layers of CNN features (levels of feature \"abstraction\"), as well as local spatiotemporal regions of the feature maps at each layer. The proposed approach is evaluated on three benchmark datasets: YouTube2Text, M-VAD and MSR-VTT. Along with visualizing the results and how the model works, these experiments quantitatively demonstrate the effectiveness of the proposed adaptive spatiotemporal feature abstraction for translating videos to sentences with rich semantics.",
        "A1": "video captioning",
        "A2": "generating adaptive spatiotemporal representations of videos for the captioning task",
        "A41": "A novel attention mechanism is developed, that adaptively and sequentially focuses on different layers of CNN features (levels of feature \"abstraction\"), as well as local spatiotemporal regions of the feature maps at each layer",
        "A51": "",
        "A61": "adaptively and sequentially focuses on different layers of CNN features (levels of feature \"abstraction\"), as well as local spatiotemporal regions of the feature maps at each layer.",
        "A10": "the effectiveness of the proposed adaptive spatiotemporal feature abstraction for translating videos to sentences with rich semantics",
        "A7": "evaluated on three benchmark datasets: YouTube2Text, M-VAD and MSR-VTT",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of the proposed adaptive spatiotemporal feature abstraction for translating videos to sentences with rich semantics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 430477135
    },
    {
        "Abstract": "In network analysis, community detection and network embedding are two important topics. Community detection tends to obtain the most noticeable partition, while network embedding aims at seeking node representations which contains as many diverse properties as possible. We observe that the current community detection and network embedding problems are being resolved by a general solution, i.e., \"maximizing the consistency between similar nodes while maximizing the distance between the dissimilar nodes.\" This general solution only exploits the most noticeable structure (facet) of the network, which effectively satisfies the demands of the community detection. Unfortunately, most of the specific embedding algorithms, which are developed from the general solution, cannot achieve the goal of network embedding by exploring only one facet of the network. To improve the general solution for better modeling the real network, we propose a novel network embedding method, Multi-facet Network Embedding (MNE), to capture the multiple facets of the network. MNE learns multiple embeddings simultaneously, with the Hilbert Schmidt Independence Criterion (HSIC) being the a diversity constraint. To efficiently solve the optimization problem, we propose a Binary HSIC with linear complexity and solve the MNE objective function by adopting the Augmented Lagrange Multiplier (ALM) method. The overall complexity is linear with the scale of the network. Extensive results demonstrate that MNE gives efficient performances and outperforms the state-of-the-art network embedding methods.",
        "A1": "To improve the general solution for better modeling the real network",
        "A2": "most of the specific embedding algorithms, which are developed from the general solution, cannot achieve the goal of network embedding by exploring only one facet of the network.",
        "A41": "we propose a novel network embedding method, Multi-facet Network Embedding (MNE)",
        "A51": "learns multiple embeddings simultaneously",
        "A61": "learns multiple embeddings simultaneously",
        "A10": "The overall complexity is linear with the scale of the network. Extensive results demonstrate that MNE gives efficient performances and outperforms the state-of-the-art network embedding methods.",
        "A7": "Extensive results ",
        "A83": "",
        "A82": "outperforms the state-of-the-art network embedding methods.",
        "A81": "MNE gives efficient performances ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 456527708
    },
    {
        "Abstract": "In this paper, we present a Character-Aware Neural Network (Char-Net) for recognizing distorted scene text. Our Char-Net is composed of a word-level encoder, a character-level encoder, and a LSTM-based decoder. Unlike previous work which employed a global spatial transformer network to rectify the entire distorted text image, we take an approach of detecting and rectifying individual characters. To this end, we introduce a novel hierarchical attention mechanism (HAM) which consists of a recurrent RoIWarp layer and a character-level attention layer. The recurrent RoIWarp layer sequentially extracts a feature region corresponding to a character from the feature map produced by the word-level encoder, and feeds it to the character-level encoder which removes the distortion of the character through a simple spatial transformer and further encodes the character region. The character-level attention layer then attends to the most relevant features of the feature map produced by the character-level encoder and composes a context vector, which is finally fed to the LSTM-based decoder for decoding. This approach of adopting a simple local transformation to model the distortion of individual characters not only results in an improved efficiency, but can also handle different types of distortion that are hard, if not impossible, to be modelled by a single global transformation. Experiments have been conducted on six public benchmark datasets. Our results show that Char-Net can achieve state-of-the-art performance on all the benchmarks, especially on the IC-IST which contains scene text with large distortion. Code will be made available.",
        "A1": "a Character-Aware Neural Network (Char-Net) for recognizing distorted scene text",
        "A2": "recognizing distorted scene text",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "conducted on six public benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "Char-Net can achieve state-of-the-art performance on all the benchmarks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "take an approach of detecting and rectifying individual characters",
        "A52": "LSTM",
        "A42": "composed of a word-level encoder, a character-level encoder, and a LSTM-based decoder",
        "A45": "",
        "am_id": 342436412
    },
    {
        "Abstract": "Recently, hashing methods have been widely used in large-scale image retrieval. However, most existing supervised hashing methods do not consider the hierarchical relation of labels,which means that they ignored the rich semantic information stored in the hierarchy. Moreover, most of previous works treat each bit in a hash code equally, which does not meet the scenario of hierarchical labeled data. To tackle the aforementioned problems, in this paper, we propose a novel deep hashing method, called supervised hierarchical deep hashing (SHDH), to perform hash code learning for hierarchical labeled data. Speci\ufb01cally, we de\ufb01ne a novel similarity formula for hierarchical labeled data by weighting each level, and design a deep neural network to obtain a hash code for each data point. Extensive experiments on two real-world public datasets show that the proposed method outperforms the state-of-the-art baselines in the image retrieval task.",
        "A1": "perform hash code learning for hierarchical labeled data",
        "A2": "most existing supervised hashing methods do not consider the hierarchical relation of labels,which means that they ignored the rich semantic information stored in the hierarchy",
        "A41": "a novel deep hashing method, called supervised hierarchical deep hashing (SHDH)",
        "A51": "de\ufb01ne a novel similarity formula for hierarchical labeled data by weighting each level",
        "A61": "design a deep neural network to obtain a hash code for each data point",
        "A10": "the proposed method outperforms the state-of-the-art baselines in the image retrieval task",
        "A7": "Extensive experiments on two real-world public datasets",
        "A83": "",
        "A82": "",
        "A81": "the proposed method outperforms the state-of-the-art baselines in the image retrieval task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "two real-world public datasets",
        "am_id": 100906508
    },
    {
        "Abstract": "We introduce a novel perception-action-learning system for mobile social-service robots. The state-of-the-art deep learning techniques were incorporated into each module which significantly improves the performance in solving social service tasks. The system not only demonstrated fast and robust performance in a homelike environment but also achieved the highest score in the RoboCup2017@Home Social Standard Platform League (SSPL) held in Nagoya, Japan.",
        "A1": " improves the performance in solving social service tasks",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The state-of-the-art deep learning techniques were incorporated into each module which significantly improves the performance in solving social service tasks. ",
        "A7": "The system not only demonstrated fast and robust performance in a homelike environment but also achieved the highest score in the RoboCup2017@Home Social Standard Platform League (SSPL) held in Nagoya, Japan.",
        "A83": "",
        "A82": "achieved the highest score",
        "A81": "fast and robust performance in a homelike environment",
        "A64": "",
        "A54": "",
        "A44": "The state-of-the-art deep learning techniques were incorporated into each module",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 50938799
    },
    {
        "Abstract": "In this paper, we are interested in designing small CNNs by decoupling the convolution along the spatial and channel domains. Most existing decoupling techniques focus on approximating the filter matrix through decomposition. In contrast, we provide a two-step interpretation of the standard convolution from the filter at a single location to all locations, which is exactly equivalent to the standard convolution. Motivated by the observations in our decoupling view, we propose an effective approach to relax the sparsity of the filter in spatial aggregation by learning a spatial configuration, and reduce the redundancy by reducing the number of intermediate channels. Our approach achieves comparable classification performance with the standard uncoupled convolution, but with a smaller model size over CIFAR-100, CIFAR-10 and ImageNet.",
        "A1": "designing small CNNs by decoupling the convolution along the spatial and channel domains",
        "A2": "we provide a two-step interpretation of the standard convolution from the filter at a single location to all locations, which is exactly equivalent to the standard convolution",
        "A41": " an effective approach to relax the sparsity of the filter in spatial aggregation by learning a spatial configuration, and reduce the redundancy by reducing the number of intermediate channels",
        "A51": "the observations in our decoupling view",
        "A61": "Most existing decoupling techniques focus on approximating the filter matrix through decomposition. In contrast, we provide a two-step interpretation of the standard convolution from the filter at a single location to all locations, which is exactly equivalent to the standard convolution. ",
        "A10": "achieves comparable classification performance with the standard uncoupled convolution, but with a smaller model size over CIFAR-100, CIFAR-10 and ImageNet.",
        "A7": "Our approach achieves comparable classification performance with the standard uncoupled convolution, but with a smaller model size over CIFAR-100, CIFAR-10 and ImageNet.",
        "A83": "",
        "A82": "with a smaller model size over CIFAR-100, CIFAR-10 and ImageNet",
        "A81": "achieves comparable classification performance with the standard uncoupled convolution",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 25744704
    },
    {
        "Abstract": "We present a novel approach for learning to predict sets using deep learning. In recent years, deep neural networks have shown remarkable results in computer vision, natural language processing and other related problems. Despite their success,traditional architectures suffer from a serious limitation in that they are built to deal with structured input and output data,i.e. vectors or matrices. Many real-world problems, however, are naturally described as sets, rather than vectors. Existing techniques that allow for sequential data, such as recurrent neural networks, typically heavily depend on the input and output order and do not guarantee a valid solution. Here, we derive in a principled way, a mathematical formulation for set prediction where the output is permutation invariant. In particular, our approach jointly learns both the cardinality and the state distribution of the target set. We demonstrate the validity of our method on the task of multi-label image classification and achieve a new state of the art on the PASCAL VOC and MS COCO datasets.",
        "A1": "present a novel approach for learning to predict sets using deep learning",
        "A2": "we derive in a principled way, a mathematical formulation for set prediction where the output is permutation invariant",
        "A41": "set prediction",
        "A51": "deep learning",
        "A61": "the output is permutation invarian",
        "A10": "the output is permutation invariant",
        "A7": "achieve a new state of the art on the PASCAL VOC and MS COCO datasets",
        "A83": "",
        "A82": "a mathematical formulation for set prediction",
        "A81": " the validity of our method on the task of multi-label image classification",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "output is permutation invariant",
        "A53": "deep learning",
        "A43": "set prediction ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 128274635
    },
    {
        "Abstract": "Movies provide us with a mass of visual content as well as attracting stories. Existing methods have illustrated that understanding movie stories through only visual content is still a hard problem. In this paper, for answering questions about movies, we put forward a Layered Memory Network (LMN) that represents frame-level and clip-level movie content by the Static Word Memory module and the Dynamic Subtitle Memory module, respectively. Particularly, we firstly extract words and sentences from the training movie subtitles. Then the hierarchically formed movie representations, which are learned from LMN, not only encode the correspondence between words and visual content inside frames, but also encode the temporal alignment between sentences and frames inside movie clips. We also extend our LMN model into three variant frameworks to illustrate the good extendable capabilities. We conduct extensive experiments on the MovieQA dataset. With only visual content as inputs, LMN with frame-level representation obtains a large performance improvement. When incorporating subtitles into LMN to form the clip-level representation, we achieve the state-of-the-art performance on the online evaluation task of 'Video+Subtitles'. The good performance successfully demonstrates that the proposed framework of LMN is effective and the hierarchically formed movie representations have good potential for the applications of movie question answering.",
        "A1": "understanding movie stories through only visual content",
        "A2": "understanding movie stories through only visual content",
        "A41": "a Layered Memory Network (LMN) that represents frame-level and clip-level movie content",
        "A51": "Layered Memory Network",
        "A61": "",
        "A10": "understanding movie stories through only visual content",
        "A7": "extensive experiments on the MovieQA dataset",
        "A83": "",
        "A82": "",
        "A81": "the hierarchically formed movie representations have good potential for the applications of movie question answering",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 420743152
    },
    {
        "Abstract": "We study the problem of robust attributed graph clustering. In real data, the clustering structure is often obfuscated due to anomalies or corruptions. While robust methods have been recently introduced that handle anomalies as part of the clustering process, they all fail to account for one core aspect: Since attributed graphs consist of two views (network structure and attributes) anomalies might materialize only partially, i.e. instances might be corrupted in one view but perfectly fit in the other. In this case, we can still derive meaningful cluster assignments. Existing works only consider complete anomalies. In this paper, we present a novel probabilistic generative model (PAICAN) that explicitly models partial anomalies by generalizing ideas of Degree Corrected Stochastic Block Models and Bernoulli Mixture Models. We provide a highly scalable variational inference approach with runtime complexity linear in the number of edges. The robustness of our model w.r.t. anomalies is demonstrated by our experimental study, outperforming state-of-the-art competitors.",
        "A1": "we present a novel probabilistic generative model (PAICAN) that explicitly models partial anomalies by generalizing ideas of Degree Corrected Stochastic Block Models and Bernoulli Mixture Models.",
        "A2": "problem of robust attributed graph clustering.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "The robustness of our model w.r.t. anomalies is demonstrated by our experimental study, outperforming state-of-the-art competitors.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "provide a highly scalable variational inference approach with runtime complexity linear in the number of edges. ",
        "A52": "",
        "A42": " a novel probabilistic generative model (PAICAN) that explicitly models partial anomalies by generalizing ideas of Degree Corrected Stochastic Block Models and Bernoulli Mixture Models",
        "A45": "",
        "am_id": 232003280
    },
    {
        "Abstract": "Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Combining such an embedding model with logic rules has recently attracted increasing attention. Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate. In this paper, we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. RUGE enables an embedding model to learn simultaneously from 1) labeled triples that have been directly observed in a given KG, 2) unlabeled triples whose labels are going to be predicted iteratively, and 3) soft rules with various confidence levels extracted automatically from the KG. In the learning process, RUGE iteratively queries rules to obtain soft labels for unlabeled triples, and integrates such newly labeled triples to update the embedding model. Through this iterative procedure, knowledge embodied in logic rules may be better transferred into the learned embeddings. We evaluate RUGE in link prediction on Freebase and YAGO. Experimental results show that: 1) with rule knowledge injected iteratively, RUGE achieves significant and consistent improvements over state-of-the-art baselines; and 2) despite their uncertainties, automatically extracted soft rules are highly beneficial to KG embedding, even those with moderate confidence levels. The code and data used for this paper can be obtained from https://github.com/iieir-km/RUGE.",
        "A1": "we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. ",
        "A2": "Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate.",
        "A41": "a novel paradigm of KG embedding with iterative guidance from soft rules.",
        "A51": "we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. ",
        "A61": "Through this iterative procedure, knowledge embodied in logic rules may be better transferred into the learned embeddings. ",
        "A10": "Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate.",
        "A7": " We evaluate RUGE in link prediction on Freebase and YAGO. ",
        "A83": "",
        "A82": "despite their uncertainties, automatically extracted soft rules are highly beneficial to KG embedding, even those with moderate confidence levels",
        "A81": "ith rule knowledge injected iteratively, RUGE achieves significant and consistent improvements over state-of-the-art baselines;",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 474120069
    },
    {
        "Abstract": "Consider a policymaker who wants to decide which intervention to perform in order to change a currently undesirable situation. The policymaker has at her disposal a team of experts, each with their own understanding of the causal dependencies between different factors contributing to the outcome. The policymaker has varying degrees of confidence in the experts\u2019 opinions. She wants to combine their opinions in order to decide on the most effective intervention. We formally define the notion of an effective intervention, and then consider how experts\u2019 causal judgments can be combined in order to determine the most effective intervention. We define a notion of two causal models being compatible, and show how compatible causal models can be combined. We then use it as the basis for combining experts causal judgments. We illustrate our approach on a number of real-life examples.",
        "A1": " consider how experts\u2019 causal judgments can be combined in order to determine the most effective intervention",
        "A2": "The policymaker has varying degrees of confidence in the experts\u2019 opinions. She wants to combine their opinions in order to decide on the most effective intervention. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We illustrate our approach on a number of real-life examples",
        "A83": "",
        "A82": "",
        "A81": "We then use it as the basis for combining experts causal judgments. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " two causal models",
        "A42": "We formally define the notion of an effective intervention, and then consider how experts\u2019 causal judgments can be combined in order to determine the most effective intervention. ",
        "A45": "",
        "am_id": 292193628
    },
    {
        "Abstract": "We present an interactive guided activity to introduce supervised learning by training a deep neural network (treated as a black box) to recognize \"rock paper scissors\" hand gestures from unconstrained images. The audience is actively involved in acquiring a varied and representative dataset, on which the rest of the activity is based. Covered concepts include the training/evaluation split, classifier evaluation, baseline accuracy, overfitting, generalization, data augmentation.",
        "A1": "present an interactive guided activity to introduce supervised learning",
        "A2": "training a deep neural network (treated as a black box) to recognize \"rock paper scissors\" hand gestures from unconstrained images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "resent an interactive guided activity to introduce supervised learning",
        "A7": "The audience is actively involved in acquiring a varied and representative dataset",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "recognize \"rock paper scissors\" hand gestures from unconstrained images",
        "A53": " a varied and representative dataset, on which the rest of the activity is based.",
        "A43": "supervised learning by training a deep neural network",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 275816146
    },
    {
        "Abstract": "In Reinforcement Learning, an intelligent agent has to make a sequence of decisions to accomplish a goal. If this sequence is long, then the agent has to plan over a long horizon. While learning the optimal policy and its value function is a well studied problem in Reinforcement Learning, this paper focuses on the structure of the optimal value function and how hard it is to represent the optimal value function. We show that the generalized Rademacher complexity of the hypothesis space of all optimal value functions is dependent on the planning horizon and independent of the state and action space size. Further, we present bounds on the action-gaps of action value functions and show that they can collapse if a long planning horizon is used. The theoretical results are verified empirically on randomly generated MDPs and on a grid-world fruit collection task using deep value function approximation. Our theoretical results highlight a connection between value function approximation and the Options framework and suggest that value functions should be decomposed along bottlenecks of the MDP's transition dynamics.",
        "A1": "focuses on the structure of the optimal value function and how hard it is to represent the optimal value function",
        "A2": "If this sequence is long, then the agent has to plan over a long horizon",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our theoretical results highlight a connection between value function approximation and the Options framework and suggest that value functions should be decomposed along bottlenecks of the MDP's transition dynamics.",
        "A7": "Our theoretical results highlight a connection between value function approximation and the Options framework and suggest that value functions should be decomposed along bottlenecks of the MDP's transition dynamics.",
        "A83": "",
        "A82": "",
        "A81": "Our theoretical results highlight a connection between value function approximation and the Options framework and suggest that value functions should be decomposed along bottlenecks of the MDP's transition dynamics.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 456980947
    },
    {
        "Abstract": "TD(0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such results. Existing convergence rates for Temporal Difference (TD) methods apply only to somewhat modified versions, e.g., projected variants or ones where stepsizes depend on unknown problem parameters. Our analyses obviate these artificial alterations by exploiting strong properties of TD(0). We provide convergence rates both in expectation and with high-probability. The two are obtained via different approaches that use relatively unknown, recently developed stochastic approximation techniques.",
        "A1": "finite sample analysis for TD(0) with function approximation",
        "A2": "Despite this, there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such results.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "there is no existing finite sample analysis for TD(0) with function approximation, even for the linear case. Our work is the first to provide such results.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We provide convergence rates both in expectation and with high-probability",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "We provide convergence rates both in expectation and with high-probability",
        "A53": "reinforcement learning",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 291865530
    },
    {
        "Abstract": "The current state-of-the-art in feature learning relies on the supervised learning of large-scale datasets consisting of target content items and their respective category labels. However, constructing such large-scale fully-labeled datasets generally requires painstaking manual effort. One possible solution to this problem is to employ community contributed text tags as weak labels, however, the concepts underlying a single text tag strongly depends on the users. We instead present a new paradigm for learning discriminative features by making full use of the human curation process on social networking services (SNSs). During the process of content curation, SNS users collect content items manually from various sources and group them by context, all for their own benefit. Due to the nature of this process, we can assume that (1) content items in the same group share the same semantic concept and (2) groups sharing the same images might have related semantic concepts. Through these insights, we can define human curated groups as weak labels from which our proposed framework can learn discriminative features as a representation in the space of semantic concepts the users intended when creating the groups. We show that this feature learning can be formulated as a problem of link prediction for a bipartite graph whose nodes corresponds to content items and human curated groups, and propose a novel method for feature learning based on sparse coding or network fine-tuning.",
        "A1": "present a new paradigm for learning discriminative features by making full use of the human curation process on social networking services (SNSs)",
        "A2": "learn discriminative features as a representation in the space of semantic concepts",
        "A41": "a new paradigm for learning discriminative features by making full use of the human curation process on social networking services (SNSs)",
        "A51": "making full use of the human curation process",
        "A61": "One possible solution to this problem is to employ community contributed text tags as weak labels, however, the concepts underlying a single text tag strongly depends on the users.",
        "A10": "",
        "A7": "",
        "A83": "propose a novel method for feature learning based on sparse coding or network fine-tuning",
        "A82": "We show that this feature learning can be formulated as a problem of link prediction for a bipartite graph whose nodes corresponds to content items and human curated groups,",
        "A81": "we can define human curated groups as weak labels from which our proposed framework can learn discriminative features as a representation in the space of semantic concepts the users intended when creating the groups.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 243736328
    },
    {
        "Abstract": "Variational encoder-decoders (VEDs) have shown promising results in dialogue generation. However, the latent variable distributions are usually approximated by a much simpler model than the powerful RNN structure used for encoding and decoding, yielding the KL-vanishing problem and inconsistent training objective. In this paper, we separate the training step into two phases: The first phase learns to autoencode discrete texts into continuous embeddings, from which the second phase learns to generalize latent representations by reconstructing the encoded embedding.xa0 In this case, latent variables are sampled by transforming Gaussian noise through multi-layer perceptrons and are trained with a separate VED model, which has the potential of realizing a much more flexible distribution. We compare our model with current popular models and the experiment demonstrates substantial improvement in both metric-based and human evaluations.",
        "A1": " we separate the training step into two phases:",
        "A2": "However, the latent variable distributions are usually approximated by a much simpler model than the powerful RNN structure used for encoding and decoding, yielding the KL-vanishing problem and inconsistent training objective.",
        "A41": "we separate the training step into two phases:",
        "A51": "",
        "A61": "The first phase learns to autoencode discrete texts into continuous embeddings, from which the second phase learns to generalize latent representations by reconstructing the encoded embedding.xa0",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We compare our model with current popular models and the experiment demonstrates substantial improvement in both metric-based and human evaluations.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 140903249
    },
    {
        "Abstract": "Deep neural networks are used in many state-of-the-art systems for machine perception. Once a network is trained to do a specific task, e.g., bird classification, it cannot easily be trained to do new tasks, e.g., incrementally learning to recognize additional bird species or learning an entirely different task such as flower recognition. When new tasks are added, typical deep neural networks are prone to catastrophically forgetting previous tasks. Networks that are capable of assimilating new information incrementally, much like how humans form new memories over time, will be more efficient than re-training the model from scratch each time a new task needs to be learned. There have been multiple attempts to develop schemes that mitigate catastrophic forgetting, but these methods have not been directly compared, the tests used to evaluate them vary considerably, and these methods have only been evaluated on small-scale problems (e.g., MNIST). In this paper, we introduce new metrics and benchmarks for directly comparing five different mechanisms designed to mitigate catastrophic forgetting in neural networks: regularization, ensembling, rehearsal, dual-memory, and sparse-coding. Our experiments on real-world images and sounds show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used, but they all demonstrate that the catastrophic forgetting problem is not yet solved.",
        "A1": "mitigate catastrophic forgetting in neural networks",
        "A2": " introduce new metrics and benchmarks for directly comparing five different mechanisms",
        "A41": "regularization, ensembling, rehearsal, dual-memory, and sparse-coding",
        "A51": "",
        "A61": "mitigate catastrophic forgetting in neural networks",
        "A10": "",
        "A7": "experiments on real-world images and sounds",
        "A83": "",
        "A82": "all demonstrate that the catastrophic forgetting problem is not yet solved",
        "A81": "show that the mechanism(s) that are critical for optimal performance vary based on the incremental training paradigm and type of data being used",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 395861805
    },
    {
        "Abstract": "Word embedding has been widely used in many natural language processing tasks. In this paper, we focus on learning word embeddings through selective higher-order relationships in sentences to improve the embeddings to be less sensitive to local context and more accurate in capturing semantic compositionality. We present a novel multi-order dependency-based strategy to composite and represent the context under several essential constraints. In order to realize selective learning from the word contexts, we automatically assign the strengths of different dependencies between co-occurred words in the stochastic gradient descent process. We evaluate and analyze our proposed approach using several direct and indirect tasks for word embeddings. Experimental results demonstrate that our embeddings are competitive to or better than state-of-the-art methods and significantly outperform other methods in terms of context stability. The output weights and representations of dependencies obtained in our embedding model conform to most of the linguistic characteristics and are valuable for many downstream tasks.",
        "A1": "learning word embeddings through selective higher-order relationships in sentences to improve the embeddings to be less sensitive to local context and more accurate in capturing semantic compositionality",
        "A2": "",
        "A41": "a novel multi-order dependency-based strategy to composite and represent the context under several essential constraints. ",
        "A51": "multi-order dependency-based",
        "A61": "",
        "A10": "The output weights and representations of dependencies obtained in our embedding model conform to most of the linguistic characteristics and are valuable for many downstream tasks.",
        "A7": "We evaluate and analyze our proposed approach using several direct and indirect tasks for word embeddings.",
        "A83": "",
        "A82": "",
        "A81": " our embeddings are competitive to or better than state-of-the-art methods and significantly outperform other methods in terms of context stability",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 54758447
    },
    {
        "Abstract": "Representation-based classification methods such as sparse representation-based classification (SRC) and linear regression classification (LRC) have attracted a lot of attentions. In order to obtain the better representation, a novel method called projection representation-based classification (PRC) is proposed for image recognition in this paper. PRC is based on a new mathematical model. This model denotes that the \"ideal projection\" of a sample point x on the hyper-space H may be gained by iteratively computing the projection of x on a line of hyper-space H with the proper strategy. Therefore, PRC is able to iteratively approximate the \"ideal representation\" of each subject for classification. Moreover, the discriminant PRC (DPRC) is further proposed, which obtains the discriminant information by maximizing the ratio of the between-class reconstruction error over the within-class reconstruction error. Experimental results on five typical databases show that the proposed PRC and DPRC are effective and outperform other state-of-the-art methods on several vision recognition tasks.",
        "A1": "obtain the better representation",
        "A2": "",
        "A41": "projection representation-based classification (PRC)",
        "A51": "a new mathematical model",
        "A61": "PRC is able to iteratively approximate the \"ideal representation\" of each subject for classification. ",
        "A10": "the proposed PRC and DPRC are effective and outperform other state-of-the-art methods on several vision recognition tasks",
        "A7": "on five typical databases ",
        "A83": "",
        "A82": "",
        "A81": "the proposed PRC and DPRC are effective and outperform other state-of-the-art methods on several vision recognition tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "the discriminant PRC (DPRC)",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 497506757
    },
    {
        "Abstract": "Link prediction is of fundamental importance in network science and machine learning. Early methods consider only simple topological features, while subsequent supervised approaches typically rely on human-labeled data and feature engineering. In this work, we present a new representation learning-based approach called SEMAC that jointly exploits fine-grained node features as well as the overall graph topology. In contrast to the SGNS or SVD methods espoused in previous representation-based studies, our model represents nodes in terms of subgraph embeddings acquired via a form of convex matrix completion to iteratively reduce the rank, and thereby, more effectively eliminate noise in the representation. Thus, subgraph embeddings and convex matrix completion are elegantly integrated into a novel link prediction framework. Experimental results on several datasets show the effectiveness of our method compared to previous work.",
        "A1": "subsequent supervised approaches typically rely on human-labeled data and feature engineering",
        "A2": "Link prediction",
        "A41": "a new representation learning-based approach called SEMAC",
        "A51": "fine-grained node features as well as the overall graph topology",
        "A61": "represents nodes in terms of subgraph embeddings acquired via a form of convex matrix completion to iteratively reduce the rank, and thereby, more effectively eliminate noise in the representation",
        "A10": "",
        "A7": "Experimental results on several datasets",
        "A83": "",
        "A82": "",
        "A81": "show the effectiveness of our method compared to previous work",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "several datasets",
        "am_id": 436816915
    },
    {
        "Abstract": "Autoencoders (AE) are essential in learning representation of large data (like images) for dimensionality reduction. Images are converted to sparse domain using transforms like Fast Fourier Transform (FFT) or Discrete Cosine Transform (DCT) where information that requires encoding is minimal. By optimally selecting the feature-rich frequencies, we are able to learn the latent vectors more robustly. We successfully show enhanced performance of autoencoders in sparse domain for images.",
        "A1": "enhanced performance of autoencoders",
        "A2": "Autoencoders",
        "A41": " learn the latent vectors more robustly",
        "A51": " Fast Fourier Transform (FFT) or Discrete Cosine Transform (DCT) ",
        "A61": "optimally selecting the feature-rich frequencies",
        "A10": "",
        "A7": "autoencoders in sparse domain for images",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 384528942
    },
    {
        "Abstract": "In multi-label learning, each training example is represented by a single instance (feature vector) while associated with multiple class labels simultaneously. The task is to learn a predictive model from the training examples which can assign a set of proper labels for the unseen instance. Most existing approaches make use of multi-label training examples by exploiting their labeling information in a crisp manner, i.e. one class label is either fully relevant or irrelevant to the instance. In this paper, a novel multi-label learning approach is proposed which aims to enrich the labeling information by leveraging the structural information in feature space. Firstly, the underlying structure of feature space is characterized by conducting sparse reconstruction among the training examples. Secondly, the reconstruction information is conveyed from feature space to label space so as to enrich the original categorical labels into numerical ones. Thirdly, the multi-label predictive model is induced by learning from training examples with enriched labeling information. Extensive experiments on fifteen benchmark data sets clearly validate the effectiveness of the proposed feature-induced strategy for enhancing labeling information of multi-label examples.",
        "A1": "aims to enrich the labeling information by leveraging the structural information in feature space",
        "A2": "Most existing approaches make use of multi-label training examples by exploiting their labeling information in a crisp manner",
        "A41": "enrich the labeling information by leveraging the structural information in feature space.",
        "A51": "the structural information in feature space",
        "A61": "Most existing approaches make use of multi-label training examples by exploiting their labeling information in a crisp manner",
        "A10": "",
        "A7": "Extensive experiments on fifteen benchmark data sets",
        "A83": "",
        "A82": "",
        "A81": "validate the effectiveness of the proposed feature-induced strategy for enhancing labeling information of multi-label examples.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 78419205
    },
    {
        "Abstract": "We introduce MAgent, a platform to support research and development of many-agent reinforcement learning. Unlike previous research platforms on single or multi-agent reinforcement learning, MAgent focuses on supporting the tasks and the applications that require hundreds to millions of agents. Within the interactions among a population of agents, it enables not only the study of learning algorithms for agents' optimal polices, but more importantly, the observation and understanding of individual agent's behaviors and social phenomena emerging from the AI society, including communication languages, leaderships, altruism. MAgent is highly scalable and can host up to one million agents on a single GPU server. MAgent also provides flexible configurations for AI researchers to design their customized environments and agents. In this demo, we present three environments designed on MAgent and show emerged collective intelligence by learning from scratch.",
        "A1": "introduce MAgent",
        "A2": "supporting the tasks and the applications that require hundreds to millions of agents",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "MAgent focuses on supporting the tasks and the applications that require hundreds to millions of agents",
        "A7": "present three environments designed on MAgent ",
        "A83": "highly scalable",
        "A82": "observation and understanding of individual agent's behaviors and social phenomena emerging from the AI society",
        "A81": "study of learning algorithms for agents' optimal polices",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 228921151
    },
    {
        "Abstract": "The existing image captioning approaches typically train a one-stage sentence decoder, which is difficult to generate rich fine-grained descriptions. On the other hand, multi-stage image caption model is hard to train due to the vanishing gradient problem. In this paper, we propose a coarse-to-fine multi-stage prediction framework for image captioning, composed of multiple decoders each of which operates on the output of the previous stage, producing increasingly refined image descriptions. Our proposed learning approach addresses the difficulty of vanishing gradients during training by providing a learning objective function that enforces intermediate supervisions. Particularly, we optimize our model with a reinforcement learning approach which utilizes the output of each intermediate decoder's test-time inference algorithm as well as the output of its preceding decoder to normalize the rewards, which simultaneously solves the well-known exposure bias problem and the loss-evaluation mismatch problem. We extensively evaluate the proposed approach on MSCOCO and show that our approach can achieve the state-of-the-art performance.",
        "A1": "propose a coarse-to-fine multi-stage prediction framework for image captioning, composed of multiple decoders each of which operates on the output of the previous stage, producing increasingly refined image descriptions",
        "A2": "solves the well-known exposure bias problem and the loss-evaluation mismatch problem",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "producing increasingly refined image descriptions",
        "A7": "We extensively evaluate the proposed approach on MSCOCO",
        "A83": "",
        "A82": "",
        "A81": "our approach can achieve the state-of-the-art performance",
        "A64": "producing increasingly refined image descriptions",
        "A54": "composed of multiple decoders each of which operates on the output of the previous stage",
        "A44": "a coarse-to-fine multi-stage prediction framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 3446623
    },
    {
        "Abstract": "Approximate nearest neighbor (ANN) search is a fundamental problem in computer vision, machine learning and information retrieval. Recently, quantization-based methods have drawn a lot of attention due to their superior accuracy and comparable efficiency compared with traditional hashing techniques. However, despite the prosperity of quantization techniques, they are all designed for the centralized setting, i.e., quantization is performed on the data on a single machine. This makes it difficult to scale these techniques to large-scale datasets. Built upon the Composite Quantization, we propose a novel quantization algorithm for data dis- tributed across different nodes of an arbitrary network. The proposed Distributed Composite Quantization (DCQ) decom-poses Composite Quantization into a set of decentralized sub-problems such that each node solves its own sub-problem on its local data, meanwhile is still able to attain consistent quantizers thanks to the consensus constraint. Since there is no exchange of training data across the nodes in the learning process, the communication cost of our method is low. Ex- tensive experiments on ANN search and image retrieval tasks validate that the proposed DCQ significantly improves Composite Quantization in both efficiency and scale, while still maintaining competitive accuracy.",
        "A1": " propose a novel quantization algorithm for data dis- tributed across different nodes of an arbitrary network. ",
        "A2": "quantization is performed on the data on a single machine. This makes it difficult to scale these techniques to large-scale datasets. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed DCQ significantly improves Composite Quantization in both efficiency and scale, while still maintaining competitive accuracy.",
        "A7": " Ex- tensive experiments on ANN search and image retrieval tasks",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "The proposed Distributed Composite Quantization (DCQ) decom-poses Composite Quantization into a set of decentralized sub-problems such that each node solves its own sub-problem on its local data, meanwhile is still able to attain consistent quantizers thanks to the consensus constraint.",
        "A53": "",
        "A43": " a novel quantization algorithm for data dis- tributed across different nodes of an arbitrary network.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 115274611
    },
    {
        "Abstract": "We propose a novel fully-automated approach towards inducing multilingual taxonomies from Wikipedia. Given an English taxonomy, our approach first leverages the interlanguage links of Wikipedia to automatically construct training datasets for the isa relation in the target language. Character-level classifiers are trained on the constructed datasets, and used in an optimal path discovery framework to induce high-precision, high-coverage taxonomies in other languages. Through experiments, we demonstrate that our approach significantly outperforms the state-of-the-art, heuristics-heavy approaches for six languages. As a consequence of our work, we release presumably the largest and the most accurate multilingual taxonomic resource spanning over 280 languages.",
        "A1": "multilingual taxonomies",
        "A2": "multilingual taxonomies",
        "A41": "a novel fully-automated approach towards inducing multilingual taxonomies from Wikipedia",
        "A51": "interlanguage links of Wikipedia",
        "A61": "",
        "A10": "Through experiments, we demonstrate that our approach significantly outperforms the state-of-the-art, heuristics-heavy approaches for six languages",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "the largest and the most accurate multilingual taxonomic resource spanning over 280 languages",
        "am_id": 252922668
    },
    {
        "Abstract": "The ability of machine-based agents to play games in human-like fashion is considered a benchmark of progress in AI. In this paper, we introduce the first computational model aimed at Pictionary, the popular word-guessing social game. We first introduce Sketch-QA, an elementary version of Visual Question Answering task. Styled after Pictionary, Sketch-QA uses incrementally accumulated sketch stroke sequences as visual data. Notably, Sketch-QA involves asking a fixed question (\"What object is being drawn?\") and gathering open-ended guess-words from human guessers. To mimic Pictionary-style guessing, we propose a deep neural model which generates guess-words in response to temporally evolving human-drawn sketches. Our model even makes human-like mistakes while guessing, thus amplifying the human mimicry factor. We evaluate our model on the large-scale guess-word dataset generated via Sketch-QA task and compare with various baselines. We also conduct a Visual Turing Test to obtain human impressions of the guess-words generated by humans and our model. Experimental results demonstrate the promise of our approach for Pictionary and similarly themed games.",
        "A1": "mimic Pictionary-style guessing",
        "A2": "mimic Pictionary-style guessing",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a Visual Turing Test to obtain human impressions of the guess-words generated by humans and our model",
        "A83": "",
        "A82": "",
        "A81": "Experimental results demonstrate the promise of our approach for Pictionary and similarly themed games",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a deep neural model which generates guess-words in response to temporally evolving human-drawn sketches",
        "A45": "",
        "am_id": 345395211
    },
    {
        "Abstract": "Research has shown that a person's financial success is more dependent on the ability to deal with people than on professional knowledge. Sage advice, such as \"if you can't say something nice, don't say anything at all\" and principles articulated in Carnegie's classic \"How to Win Friends and Influence People,\" offer trusted rules-of-thumb for how people can successfully deal with each other. However, alternative philosophies for dealing with people have also emerged. The success of an AI system is likewise contingent on its ability to win friends and influence people. In this paper, we study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs). We create several algorithms for playing RGCTs by combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies. Via user study, we evaluate these algorithms in four RGCTs. Our results suggest sufficient properties for AIs to win friends and influence people in RGCTs.",
        "A1": "study how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs)",
        "A2": "how AI systems should be designed to win friends and influence people in repeated games with cheap talk (RGCTs).",
        "A41": "playing RGCTs ",
        "A51": "y combining existing behavioral strategies (what the AI does) with signaling strategies (what the AI says) derived from several competing philosophies",
        "A61": "",
        "A10": "",
        "A7": "Via user study, we evaluate these algorithms in four RGCTs",
        "A83": "",
        "A82": "",
        "A81": "AIs to win friends and influence people in RGCTs.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 393878901
    },
    {
        "Abstract": "Linear Dynamical Systems are widely used to study the underlying patterns of multivariate time series. A basic assumption of these models is that high-dimensional time series can be characterized by some underlying, low-dimensional and time-varying latent states. However, existing approaches to LDS modeling mostly learn the latent space with a prescribed dimensionality. When dealing with short-length high- dimensional time series data, such models would be easily overfitted. We propose Reduced-Rank Linear Dynamical Systems (RRLDS), to automatically retrieve the intrinsic dimensionality of the latent space during model learning. Our key observation is that the rank of the dynamics matrix of LDS captures the intrinsic dimensionality, and the variational inference with a reduced-rank regularization finally leads to a concise, structured, and interpretable latent space. To enable our method to handle count-valued data, we introduce the dispersion-adaptive distribution to accommodate over-/ equal-/ and under-dispersion nature of such data. Results on both simulated and experimental data demonstrate our model can robustly learn latent space from short-length, noisy, count-valued data and significantly improve the prediction performance over the state-of-the-art methods.",
        "A1": " propose Reduced-Rank Linear Dynamical Systems (RRLDS)",
        "A2": "automatically retrieve the intrinsic dimensionality of the latent space during model learning",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " significantly improve",
        "A7": "",
        "A83": "",
        "A82": "significantly improve the prediction performance ",
        "A81": "learn latent space from short-length, noisy, count-valued data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "dispersion-adaptive distribution",
        "A42": "Reduced-Rank Linear Dynamical Systems (RRLDS)",
        "A45": "",
        "am_id": 85927949
    },
    {
        "Abstract": "This paper presents a Generative Adversarial Network (GAN) to model multiturn dialogue generation, which trains a latent hierarchical recurrent encoder-decoder simultaneously with a discriminative classifier that make the prior approximate to the posterior. Experiments show that our model achieves better results.",
        "A1": " presents a Generative Adversarial Network (GAN) to model multiturn dialogue generation",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " our model achieves better results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "our model achieves better results",
        "A52": "GAN",
        "A42": "model multiturn dialogue generation",
        "A45": "",
        "am_id": 155341555
    },
    {
        "Abstract": "Due to the limited natural water resources and the increase in population, managing water consumption is becoming an increasingly important subject worldwide. In this paper, we present and compare different machine learning models that are able to predict water demand for Central Indiana. The models are developed for two different time scales: daily and monthly. The input features for the proposed model include weather conditions (temperature, rainfall, snow), social features (holiday, median income), date (day of the year, month), and operational features (number of customers, previous water demand levels). The importance of these input features as accurate predictors is investigated. The results show that daily and monthly models based on recurrent neural networks produced the best results with an average error in prediction of 1.69% and 2.29%, respectively for 2016. These models achieve a high accuracy with a limited set of input features.",
        "A1": "managing water consumption",
        "A2": "present and compare different machine learning models that are able to predict water demand for Central Indiana",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " The models are developed for two different time scales: daily and monthly. The input features for the proposed model include weather conditions (temperature, rainfall, snow), social features (holiday, median income), date (day of the year, month), and operational features (number of customers, previous water demand levels). The importance of these input features as accurate predictors is investigated.",
        "A83": "",
        "A82": "These models achieve a high accuracy with a limited set of input features.",
        "A81": "daily and monthly models based on recurrent neural networks produced the best results with an average error",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "recurrent neural networks",
        "A42": "daily and monthly models",
        "A45": "",
        "am_id": 413774599
    },
    {
        "Abstract": "A major goal of grounded language learning research is to enable robots to connect language predicates to a robot's physical interactive perception of the world. Coupling object exploratory behaviors such as grasping, lifting, and looking with multiple sensory modalities (e.g., audio, haptics, and vision) enables a robot to ground non-visual words like ``heavy'' as well as visual words like ``red''. A major limitation of existing approaches to multi-modal language grounding is that a robot has to exhaustively explore training objects with a variety of actions when learning a new such language predicate. This paper proposes a method for guiding a robot's behavioral exploration policy when learning a novel predicate based on known grounded predicates and the novel predicate's linguistic relationship to them. We demonstrate our approach on two datasets in which a robot explored large sets of objects and was tasked with learning to recognize whether novel words applied to those objects.",
        "A1": "proposes a method for guiding a robot's behavioral exploration policy",
        "A2": " a robot has to exhaustively explore training objects with a variety of actions when learning a new such language predicate",
        "A41": "guiding a robot's behavioral exploration policy when learning a novel predicat",
        "A51": "known grounded predicates and the novel predicate's linguistic relationship to them. ",
        "A61": "based on known grounded predicates and the novel predicate's linguistic relationship to them.",
        "A10": "based on known grounded predicates and the novel predicate's linguistic relationship to them",
        "A7": "two datasets in which a robot explored large sets of objects and was tasked with learning to recognize",
        "A83": "",
        "A82": "",
        "A81": "a method for guiding a robot's behavioral exploration policy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 297917241
    },
    {
        "Abstract": "We would like to learn a representation of the data that reflects the semantics behind a specific grouping of the data, where within a group the samples share a common factor of variation. For example, consider a set of face images grouped by identity. We wish to anchor the semantics of the grouping into a disentangled representation that we can exploit. However, existing deep probabilistic models often assume that the samples are independent and identically distributed, thereby disregard the grouping information. We present the Multi-Level Variational Autoencoder (ML-VAE), a new deep probabilistic model for learning a disentangled representation of grouped data. The ML-VAE separates the latent representation into semantically relevant parts by working both at the group level and the observation level, while retaining efficient test-time inference. We experimentally show that our model (i) learns a semantically meaningful disentanglement, (ii) enables control over the latent representation, and (iii) generalises to unseen groups.",
        "A1": "learn a representation of the data that reflects the semantics behind a specific grouping of the data,",
        "A2": "separates the latent representation into semantically relevant parts by working both at the group level and the observation level, while retaining efficient test-time inference. ",
        "A41": "Multi-Level Variational Autoencoder (ML-VAE), a new deep probabilistic model for learning a disentangled representation of grouped data",
        "A51": "",
        "A61": "at the group level and the observation level",
        "A10": "(i) learns a semantically meaningful disentanglement, (ii) enables control over the latent representation, and (iii) generalises to unseen groups",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "group level and the observation level",
        "A52": "deep probabilistic model for learning a disentangled representation of grouped data",
        "A42": "Multi-Level Variational Autoencoder (ML-VAE)",
        "A45": "",
        "am_id": 384718748
    },
    {
        "Abstract": "Neural language models do not scale well when the vocabulary is large. Noise contrastive estimation (NCE) is a sampling-based method that allows for fast learning with large vocabularies. Although NCE has shown promising performance in neural machine translation, its full potential has not been demonstrated in the language modelling literature. A sufficient investigation of the hyperparameters in the NCE-based neural language models was clearly missing. In this paper, we showed that NCE can be a very successful approach in neural language modelling when the hyperparameters of a neural network are tuned appropriately. We introduced the `search-then-converge' learning rate schedule for NCE and designed a heuristic that specifies how to use this schedule. The impact of the other important hyperparameters, such as the dropout rate and the weight initialisation range, was also demonstrated. Using a popular benchmark, we showed that appropriate tuning of NCE in neural language models outperforms the state-of-the-art single-model methods based on standard dropout and the standard LSTM recurrent neural networks.",
        "A1": "Using a popular benchmark, we showed that appropriate tuning of NCE in neural language models outperforms the state-of-the-art single-model methods based on standard dropout and the standard LSTM recurrent neural networks.",
        "A2": "A sufficient investigation of the hyperparameters in the NCE-based neural language models was clearly missing.",
        "A41": "Noise contrastive estimation",
        "A51": "sampling-based",
        "A61": "",
        "A10": "appropriate tuning",
        "A7": "a popular benchmark",
        "A83": "appropriate tuning of NCE in neural language models outperforms the state-of-the-art single-model methods based on standard dropout and the standard LSTM recurrent neural networks",
        "A82": "The impact of the other important hyperparameters",
        "A81": "We introduced the `search-then-converge' learning rate schedule for NCE and designed a heuristic that specifies how to use this schedule",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 282911732
    },
    {
        "Abstract": "With widespread use of machine learning methods in numerous domains involving humans, several studies have raised questions about the potential for unfairness towards certain individuals or groups. A number of recent works have proposed methods to measure and eliminate unfairness from machine learning models. However, most of this work has focused on only one dimension of fair decision making: distributive fairness, i.e., the fairness of the decision outcomes. In this work, we leverage the rich literature on organizational justice and focus on another dimension of fair decision making: procedural fairness, i.e., the fairness of the decision making process. We propose measures for procedural fairness that consider the input features used in the decision process, and evaluate the moral judgments of humans regarding the use of these features. We operationalize these measures on two real world datasets using human surveys on the Amazon Mechanical Turk (AMT) platform, demonstrating that our measures capture important properties of procedurally fair decision making. We provide fast submodular mechanisms to optimize the tradeoff between procedural fairness and prediction accuracy. On our datasets, we observe empirically that procedural fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.",
        "A1": "procedural fairness",
        "A2": "propose measures for procedural fairness",
        "A41": "measures for procedural fairness",
        "A51": "",
        "A61": "focus on another dimension of fair decision making: procedural fairness",
        "A10": "procedural fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.",
        "A7": "operationalize these measures on two real world datasets using human surveys on the Amazon Mechanical Turk (AMT) platform",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 436071105
    },
    {
        "Abstract": "With the rapidly increasing popularity of deep neural networks for image recognition tasks, a parallel interest in generating adversarial examples to attack the trained models has arisen. To date, these approaches have involved either directly computing gradients with respect to the image pixels or directly solving an optimization on the image pixels. We generalize this pursuit in a novel direction: can a separate network be trained to efficiently attack another fully trained network? We demonstrate that it is possible, and that the generated attacks yield startling insights into the weaknesses of the target network. We call such a network an Adversarial Transformation Network (ATN). ATNs transform any input into an adversarial attack on the target network, while being minimally perturbing to the original inputs and the target network's outputs. Further, we show that ATNs are capable of not only causing the target network to make an error, but can be constructed to explicitly control the type of misclassification made. We demonstrate ATNs on both simple MNIST-digit classifiers and state-of-the-art ImageNet classifiers deployed by Google, Inc.: Inception ResNet-v2.",
        "A1": "",
        "A2": "generating adversarial examples to attack the trained models has arisen",
        "A41": "a separate network be trained to efficiently attack another fully trained network",
        "A51": "",
        "A61": "ATNs transform any input into an adversarial attack on the target network, while being minimally perturbing to the original inputs and the target network's outputs. ",
        "A10": "",
        "A7": "on both simple MNIST-digit classifiers and state-of-the-art ImageNet classifiers deployed by Google",
        "A83": "",
        "A82": "can be constructed to explicitly control the type of misclassification made",
        "A81": "capable of not only causing the target network to make an error,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 97925717
    },
    {
        "Abstract": "Conventional methods of 3D object generative modeling learn volumetric predictions using deep networks with 3D convolutional operations, which are direct analogies to classical 2D ones. However, these methods are computationally wasteful in attempt to predict 3D shapes, where information is rich only on the surfaces. In this paper, we propose a novel 3D generative modeling framework to efficiently generate object shapes in the form of dense point clouds. We use 2D convolutional operations to predict the 3D structure from multiple viewpoints and jointly apply geometric reasoning with 2D projection optimization. We introduce the pseudo-renderer, a differentiable module to approximate the true rendering operation, to synthesize novel depth maps for optimization. Experimental results for single-image 3D object reconstruction tasks show that we outperforms state-of-the-art methods in terms of shape similarity and prediction density.",
        "A1": "However, these methods are computationally wasteful in attempt to predict 3D shapes, where information is rich only on the surfaces.",
        "A2": " In this paper, we propose a novel 3D generative modeling framework to efficiently generate object shapes in the form of dense point clouds.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperforms state-of-the-art methods in terms of shape similarity and prediction density.",
        "A7": "Experimental results for single-image 3D object reconstruction tasks",
        "A83": "",
        "A82": "",
        "A81": "outperforms state-of-the-art methods in terms of shape similarity and prediction density.",
        "A64": "",
        "A54": "",
        "A44": "we propose a novel 3D generative modeling framework to efficiently generate object shapes in the form of dense point clouds.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 198147717
    },
    {
        "Abstract": "News diffusion prediction aims to predict a sequence of news sites which will quote a particular piece of news. Most of previous propagation models make efforts to estimate propagation probabilities along observed links and ignore the characteristics of news diffusion processes, and they fail to capture the implicit relationships between news sites. In this paper, we propose an algorithm to model the news diffusion processes in a continuous space and take the attributes of news into account. Experiments performed on a real-world news dataset show that our model can take advantage of news\u2019 attributes and predict news diffusion accurately.",
        "A1": "News diffusion prediction",
        "A2": "News diffusion prediction",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "real-world news dataset",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "take the attributes of news",
        "A53": "",
        "A43": "predict news diffusion",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 294886636
    },
    {
        "Abstract": "Analyzing people\u2019s opinions and sentiments towards certain aspects is an important task of natural language understanding. In this paper, we propose a novel solution to targeted aspect-based sentiment analysis, which tackles the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by exploiting commonsense knowledge. We augment the long short-term memory (LSTM) network with a hierarchical attention mechanism consisting of a target-level attention and a sentence-level attention. Commonsense knowledge of sentiment-related concepts is incorporated into the end-to-end training of a deep neural network for sentiment classification. In order to tightly integrate the commonsense knowledge into the recurrent encoder, we propose an extension of LSTM, termed Sentic LSTM. We conduct experiments on two publicly released datasets, which show that the combination of the proposed attention architecture and Sentic LSTM can outperform state-of-the-art methods in targeted aspect sentiment tasks.",
        "A1": "Analyzing people\u2019s opinions and sentiments towards certain aspects ",
        "A2": "In this paper, we propose a novel solution to targeted aspect-based sentiment analysis, which tackles the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by exploiting commonsense knowledge",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the combination of the proposed attention architecture and Sentic LSTM can outperform state-of-the-art methods in targeted aspect sentiment tasks.",
        "A7": "We conduct experiments on two publicly released datasets, which show that the combination of the proposed attention architecture and Sentic LSTM can outperform state-of-the-art methods in targeted aspect sentiment tasks.",
        "A83": "",
        "A82": "",
        "A81": " the combination of the proposed attention architecture and Sentic LSTM can outperform state-of-the-art methods in targeted aspect sentiment tasks.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " the long short-term memory (LSTM) network with a hierarchical attention mechanism consisting of a target-level attention and a sentence-level attention. ",
        "A42": " We augment the long short-term memory (LSTM) network with a hierarchical attention mechanism consisting of a target-level attention and a sentence-level attention. ",
        "A45": "",
        "am_id": 172788030
    },
    {
        "Abstract": "Aspect-based sentiment analysis (ABSA) tries to predict the polarity of a given document with respect to a given aspect entity. While neural network architectures have been successful in predicting the overall polarity of sentences, aspect-specific sentiment analysis still remains as an open problem. In this paper, we propose a novel method for integrating aspect information into the neural model. More specifically, we incorporate aspect information into the neural model by modeling word-aspect relationships. Our novel model, Aspect Fusion LSTM (AF-LSTM) learns to attend based on associative relationships between sentence words and aspect which allows our model to adaptively focus on the correct words given an aspect term. This ameliorates the flaws of other state-of-the-art models that utilize naive concatenations to model word-aspect similarity. Instead, our model adopts circular convolution and circular correlation to model the similarity between aspect and words and elegantly incorporates this within a differentiable neural attention framework. Finally, our model is end-to-end differentiable and highly related to convolution-correlation (holographic like) memories. Our proposed neural model achieves state-of-the-art performance on benchmark datasets, outperforming ATAE-LSTM by 4%-5% on average across multiple datasets.",
        "A1": "propose a novel method for integrating aspect information into the neural model",
        "A2": "aspect-specific sentiment analysis",
        "A41": "ncorporate aspect information into the neural model by modeling word-aspect relationships",
        "A51": "",
        "A61": " adopts circular convolution and circular correlation to model the similarity between aspect and words and elegantly incorporates this within a differentiable neural attention framework",
        "A10": "outperforming ATAE-LSTM by 4%-5% on average across multiple datasets",
        "A7": "benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "outperforming ATAE-LSTM by 4%-5% on average across multiple datasets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 99247420
    },
    {
        "Abstract": "Domain generalization aims to apply knowledge gained from multiple labeled source domains to unseen target domains. The main difficulty comes from the dataset bias: training data and test data have different distributions, and the training set contains heterogeneous samples from different distributions. Let X denote the features, and Y be the class labels. Existing domain generalization methods address the dataset bias problem by learning a domain-invariant representation h(X) that has the same marginal distribution P(h(X)) across multiple source domains. The functional relationship encoded in P(Y|X) is usually assumed to be stable across domains such that P(Y|h(X)) is also invariant. However, it is unclear whether this assumption holds in practical problems. In this paper, we consider the general situation where both P(X) and P(Y|X) can change across all domains. We propose to learn a feature representation which has domain-invariant class conditional distributions P(h(X)|Y). With the conditional invariant representation, the invariance of the joint distribution P(h(X),Y) can be guaranteed if the class prior P(Y) does not change across training and test domains. Extensive experiments on both synthetic and real data demonstrate the effectiveness of the proposed method.",
        "A1": "apply knowledge gained from multiple labeled source domains to unseen target domains",
        "A2": " the dataset bias",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on both synthetic and real data",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "the conditional invariant representation",
        "A43": " change across all domains",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 447407240
    },
    {
        "Abstract": "This paper addresses two obstacles hindering advances in accurate gesture recognition on mobile devices. First, gesture recognition performance is highly dependent on feature selection, but optimal features typically vary from gesture to gesture. Second, diverse user behaviors and mobile environments result in extremely large intra-class variations. We tackle these issues by introducing a new network layer, called an adaptive hidden layer (AHL), to generalize a hidden layer in deep neural networks and dynamically generate an activation map conditioned on the input. To this end, an AHL is composed of multiple neuron groups and an extra selector. The former compiles multi-modal features captured by mobile sensors, while the latter adaptively picks a plausible group for each input sample. The AHL is end-to-end trainable and can generalize an arbitrary subset of hidden layers. Through a series of AHLs, the great expressive power from exponentially many forward paths allows us to choose proper multi-modal features in a sample-specific fashion and resolve the problems caused by the unfavorable variations in mobile gesture recognition. The proposed approach is evaluated on a benchmark for gesture recognition and a newly collected dataset. Superior performance demonstrates its effectiveness.",
        "A1": "We tackle these issues by introducing a new network layer, called an adaptive hidden layer (AHL), to generalize a hidden layer in deep neural networks and dynamically generate an activation map conditioned on the input.",
        "A2": "First, gesture recognition performance is highly dependent on feature selection, but optimal features typically vary from gesture to gesture. Second, diverse user behaviors and mobile environments result in extremely large intra-class variations.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Superior performance demonstrates its effectiveness.",
        "A7": "The proposed approach is evaluated on a benchmark for gesture recognition and a newly collected dataset.",
        "A83": "",
        "A82": "",
        "A81": "Superior performance demonstrates its effectiveness.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Through a series of AHLs, the great expressive power from exponentially many forward paths allows us to choose proper multi-modal features in a sample-specific fashion and resolve the problems caused by the unfavorable variations in mobile gesture recognition. ",
        "A52": "an AHL is composed of multiple neuron groups and an extra selector. ",
        "A42": " an adaptive hidden layer (AHL)",
        "A45": "",
        "am_id": 280113618
    },
    {
        "Abstract": "Loop closure detection is a critical component of large-scale simultaneous localization and mapping (SLAM) in loopy environments. This capability is challenging to achieve in long-term SLAM, when the environment appearance exhibits significant long-term variations across various time of the day, months, and even seasons. In this paper, we introduce a novel formulation to learn an integrated long-term representation based upon both holistic and landmark information, which integrates two previous insights under a unified framework: (1) holistic representations outperform keypoint-based representations, and (2) landmarks as an intermediate representation provide informative cues to detect challenging locations. Our new approach learns the representation by projecting input visual data into a low-dimensional space, which preserves both the global consistency (to minimize representation error) and the local consistency (to preserve landmarks\u2019 pairwise relationship) of the input data. To solve the formulated optimization problem, a new algorithm is developed with theoretically guaranteed convergence. Extensive experiments have been conducted using two large-scale public benchmark data sets, in which the promising performances have demonstrated the effectiveness of the proposed approach.",
        "A1": "learn an integrated long-term representation based upon both holistic and landmark information",
        "A2": " introduce a novel formulation to learn an integrated long-term representation based upon both holistic and landmark information, which integrates two previous insights under a unified framework",
        "A41": " learns the representation by projecting input visual data into a low-dimensional space, which preserves both the global consistency (to minimize representation error) and the local consistency (to preserve landmarks\u2019 pairwise relationship) of the input data.",
        "A51": "a unified framework",
        "A61": "(1) holistic representations outperform keypoint-based representations, and (2) landmarks as an intermediate representation provide informative cues to detect challenging locations. ",
        "A10": "(1) holistic representations outperform keypoint-based representations, and (2) landmarks as an intermediate representation provide informative cues to detect challenging locations. ",
        "A7": "Extensive experiments have been conducted using two large-scale public benchmark data sets,",
        "A83": "",
        "A82": "",
        "A81": "the promising performances have demonstrated the effectiveness of the proposed approach.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " two large-scale public benchmark data sets",
        "am_id": 116932156
    },
    {
        "Abstract": "Energy disaggregation (a.k.a nonintrusive load monitoring, NILM), a single-channel blind source separation problem, aims to decompose the mains which records the whole house electricity consumption into appliance-wise readings. This problem is difficult because it is inherently unidentifiable. Recent approaches have shown that the identifiability problem could be reduced by introducing domain knowledge into the model. Deep neural networks have been shown to be a promising approach for these problems, but sliding windows are necessary to handle the long sequences which arise in signal processing problems, which raises issues about how to combine predictions from different sliding windows. In this paper, we propose sequence-to-point learning, where the input is a window of the mains and the output is a single point of the target appliance. We use convolutional neural networks to train the model. Interestingly, we systematically show that the convolutional neural networks can inherently learn the signatures of the target appliances, which are automatically added into the model to reduce the identifiability problem. We applied the proposed neural network approaches to real-world household energy data, and show that the methods achieve state-of-the-art performance, improving two standard error measures by 84% and 92%.",
        "A1": "",
        "A2": "Energy disaggregation (a.k.a nonintrusive load monitoring, NILM), a single-channel blind source separation problem, aims to decompose the mains which records the whole house electricity consumption into appliance-wise readings",
        "A41": "sequence-to-point learning, where the input is a window of the mains and the output is a single point of the target appliance.",
        "A51": "convolutional neural networks",
        "A61": "the input is a window of the mains and the output is a single point of the target appliance",
        "A10": "the methods achieve state-of-the-art performance, improving two standard error measures by 84% and 92%.",
        "A7": " real-world household energy data",
        "A83": "",
        "A82": "",
        "A81": "the methods achieve state-of-the-art performance, improving two standard error measures by 84% and 92%.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 245557292
    },
    {
        "Abstract": "Nonparametric classification models, such as K-Nearest Neighbor (KNN), have become particularly powerful tools in machine learning and data mining, due to their simplicity and flexibility. However, the testing time of the KNN classifier becomes unacceptable and the KNN's performance deteriorates significantly when applied to data sets with millions of dimensions. We observe that state-of-the-art approximate nearest neighbor (ANN) methods aim to either reduce the number of distance comparisons based on tree structure or decrease the cost of distance computation by dimension reduction methods. In this paper, we propose a doubly approximate nearest neighbor classification strategy, which marries the two branches which compress the dimensions for decreasing distance computation cost as well as reduce the number of distance comparison instead of full scan. Under this strategy, we build a compressed dimensional tree (CD-Tree) to avoid unnecessary distance calculations. In each decision node, we propose a novel feature selection paradigm by optimizing the feature selection vector as well as the separator (indicator variables for splitting instances) with the maximum margin. An efficient algorithm is then developed to find the globally optimal solution with convergence guarantee. Furthermore, we also provide a data-dependent generalization error bound for our model, which reveals a new insight for the design of ANN classification algorithms. Our empirical studies show that our algorithm consistently obtains competitive or better classification results on all data sets, yet we can also achieve three orders of magnitude faster than state-of-the-art libraries on very high dimensions.",
        "A1": " propose a doubly approximate nearest neighbor classification strategy",
        "A2": " marries the two branches which compress the dimensions for decreasing distance computation cost as well as reduce the number of distance comparison instead of full scan.",
        "A41": " a doubly approximate nearest neighbor classification strategy",
        "A51": "",
        "A61": " a doubly approximate nearest neighbor classification strategy, which marries the two branches which compress the dimensions for decreasing distance computation cost as well as reduce the number of distance comparison instead of full scan.",
        "A10": "our algorithm consistently obtains competitive or better classification results on all data sets, yet we can also achieve three orders of magnitude faster than state-of-the-art libraries on very high dimensions.",
        "A7": " empirical studies ",
        "A83": "",
        "A82": "",
        "A81": "our algorithm consistently obtains competitive or better classification results on all data sets, yet we can also achieve three orders of magnitude faster than state-of-the-art libraries on very high dimensions.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "our algorithm consistently obtains competitive or better classification results on all data sets, yet we can also achieve three orders of magnitude faster than state-of-the-art libraries on very high dimensions.",
        "A53": " a novel feature selection paradigm ",
        "A43": " An efficient algorithm is then developed to find the globally optimal solution with convergence guarantee. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 142108559
    },
    {
        "Abstract": "Machine comprehension of text is the problem to answer a query based on a given context. Many existing systems use RNN-based units for contextual modeling linked with some attention mechanisms. In this paper, however, we propose StackReader, an end-to-end neural network model, to solve this problem, without recurrent neural network (RNN) units and its variants. This simple model is based solely on attention mechanism and gated convolutional neural network. Experiments on SQuAD have shown to have relatively high accuracy with a significant decrease in training time.",
        "A1": "to solve this problem, without recurrent neural network (RNN) units and its variants",
        "A2": "Machine comprehension of text",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "have shown to have relatively high accuracy with a significant decrease in training time.",
        "A7": "Experiments on SQuAD",
        "A83": "",
        "A82": "",
        "A81": "have shown to have relatively high accuracy with a significant decrease in training time.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "without recurrent neural network (RNN) units and its variants",
        "A52": " based solely on attention mechanism and gated convolutional neural network",
        "A42": "StackReader, an end-to-end neural network model, to solve this problem, without recurrent neural network (RNN) units and its variants",
        "A45": "",
        "am_id": 279669427
    },
    {
        "Abstract": "Link prediction is a fundamental problem with a wide range of applications in various domains, which predicts the links that are not yet observed or the links that may appear in the future. Most existing works in this field only focus on modeling a single network, while real-world networks are actually aligned with each other. Network alignments contain valuable additional information for understanding the networks, and provide a new direction for addressing data insufficiency and alleviating cold start problem. However, there are rare works leveraging network alignments for better link prediction. Besides, neural network is widely employed in various domains while its capability of capturing high-level patterns and correlations for link prediction problem has not been adequately researched yet. Hence, in this paper we target atlink prediction over aligned networks using neural networks. The major challenge is the heterogeneousness of the considered networks, as the networks may have different characteristics, link purposes, etc. To overcome this, we propose a novel multi-neural-network framework MNN, where we have one individual neural network for each heterogeneous target or feature while the vertex representations are shared. We further discuss training methods for the multi-neural-network framework. Extensive experiments demonstrate that MNN outperforms the state-of-the-art methods and achieves 3% to 5% relative improvement of AUC score across different settings, particularly over 8% for cold start scenarios.",
        "A1": "we target atlink prediction over aligned networks using neural networks.",
        "A2": "its capability of capturing high-level patterns and correlations for link prediction problem has not been adequately researched yet",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "MNN outperforms the state-of-the-art methods and achieves 3% to 5% relative improvement of AUC score across different settings, particularly over 8% for cold start scenarios.",
        "A7": "Extensive experiments ",
        "A83": "",
        "A82": "",
        "A81": "MNN outperforms the state-of-the-art methods and achieves 3% to 5% relative improvement of AUC score across different settings, particularly over 8% for cold start scenarios.",
        "A64": " we target atlink prediction over aligned networks using neural networks",
        "A54": "",
        "A44": "a novel multi-neural-network framework MNN, where we have one individual neural network for each heterogeneous target or feature while the vertex representations are shared.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 364416780
    },
    {
        "Abstract": "In order to assist scriptwriters during the process of story-writing, we have developed a system that can extract information from natural language stories, and allow for story-centric as well as character-centric reasoning. These inferencing capabilities are exposed to the user through intuitive querying systems, allowing the scriptwriter to ask the system questions about story and character information. We introduce knowledge bytes as atoms of information and demonstrate that the system can parse text into a stream of knowledge bytes and use these mentioned reasoning capabilities through logical reasoning.",
        "A1": "assist scriptwriters during the process of story-writing",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We introduce knowledge bytes as atoms of information and demonstrate that the system can parse text into a stream of knowledge bytes and use these mentioned reasoning capabilities through logical reasoning.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": " extract information from natural language stories",
        "A44": "a system that can extract information from natural language stories, and allow for story-centric as well as character-centric reasoning",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 298954867
    },
    {
        "Abstract": "Label distribution learning (LDL) is a novel multi-label learning paradigm proposed in recent years for solving label ambiguity. Existing approaches typically exploit label correlations globally to improve the effectiveness of label distribution learning, by assuming that the label correlations are shared by all instances. However, different instances may share different label correlations, and few correlations are globally applicable in real-world applications. In this paper, we propose a new label distribution learning algorithm by exploiting sample correlations locally (LDL-SCL). To encode the influence of local samples, we design a local correlation vector for each instance based on the clustered local samples. Then we predict the label distribution for an unseen instance based on the original features and the local correlation vector simultaneously. Experimental results demonstrate that LDL-SCL can effectively deal with the label distribution problems and perform remarkably better than the state-of-the-art LDL methods.",
        "A1": "In this paper, we propose a new label distribution learning algorithm by exploiting sample correlations locally (LDL-SCL).",
        "A2": "However, different instances may share different label correlations, and few correlations are globally applicable in real-world applications. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " Experimental results demonstrate that LDL-SCL can effectively deal with the label distribution problems and perform remarkably better than the state-of-the-art LDL methods.",
        "A7": " Experimental results demonstrate that LDL-SCL can effectively deal with the label distribution problems and perform remarkably better than the state-of-the-art LDL methods.",
        "A83": "",
        "A82": "",
        "A81": "Experimental results demonstrate that LDL-SCL can effectively deal with the label distribution problems and perform remarkably better than the state-of-the-art LDL methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "Label distribution learning (LDL) is a novel multi-label learning paradigm proposed in recent years for solving label ambiguity.",
        "A43": "In this paper, we propose a new label distribution learning algorithm by exploiting sample correlations locally (LDL-SCL).",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 438574613
    },
    {
        "Abstract": "Existential rules, a family of expressive ontology languages, inherit desired expressive and reasoning properties from both description logics and logic programming. On the other hand, forgetting is a well studied operation for ontology reuse, obfuscation and analysis. Yet it is challenging to establish a theory of forgetting for existential rules. In this paper, we lay the foundation for a theory of forgetting for existential rules by developing a novel notion of unfolding. In particular, we introduce a definition of forgetting for existential rules in terms of query answering and provide a characterisation of forgetting by the unfolding. A result of forgetting may not be expressible in existential rules, and we then capture the expressibility of forgetting by a variant of boundedness. While the expressibility is undecidable in general, we identify a decidable fragment. Finally, we provide an algorithm for forgetting in this fragment.",
        "A1": "lay the foundation for a theory of forgetting for existential rules by developing a novel notion of unfolding.",
        "A2": "introduce a definition of forgetting for existential rules in terms of query answering and provide a characterisation of forgetting by the unfolding",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "identify a decidable fragment.",
        "A7": "",
        "A83": "",
        "A82": "lay the foundation for a theory of forgetting for existential rules by developing a novel notion of unfolding",
        "A81": "introduce a definition of forgetting for existential rules in terms of query answering and provide a characterisation of forgetting by the unfolding",
        "A64": "",
        "A54": " foundation for a theory of forgetting for existential rules by developing a novel notion of unfolding",
        "A44": "introduce a definition of forgetting for existential rules in terms of query answering and provide a characterisation of forgetting by the unfolding",
        "A63": "",
        "A53": "",
        "A43": "forgetting in this fragment.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 306437188
    },
    {
        "Abstract": "We propose the first privacy-preserving approach to address the privacy issues that arise in multi-agent planning problems modeled as a Dec-POMDP. Our solution is a distributed message-passing algorithm based on trials, where the agents' policies are optimized using the cross-entropy method. In our algorithm, the agents' private information is protected using a public-key homomorphic cryptosystem. We prove the correctness of our algorithm and analyze its complexity in terms of message passing and encryption/decryption operations. Furthermore, we analyze several privacy aspects of our algorithm and show that it can preserve the agent privacy of non-neighbors, model privacy, and decision privacy. Our experimental results on several common Dec-POMDP benchmark problems confirm the effectiveness of our approach.",
        "A1": "",
        "A2": "address the privacy issues that arise in multi-agent planning problems modeled as a Dec-POMDP",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "experimental results on several common Dec-POMDP benchmark problems",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of our approach",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "it can preserve the agent privacy of non-neighbors, model privacy, and decision privacy",
        "A53": " trials, where the agents' policies are optimized using the cross-entropy method",
        "A43": "distributed message-passing algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 12139608
    },
    {
        "Abstract": "We study minimal single-task peer prediction mechanisms that have limited knowledge about agents' beliefs. Without knowing what agents' beliefs are or eliciting additional information, it is not possible to design a truthful mechanism in a Bayesian-Nash sense. We go beyond truthfulness and explore equilibrium strategy profiles that are only partially truthful. Using the results from the multi-armed bandit literature, we give a characterization of how inefficient these equilibria are comparing to truthful reporting. We measure the inefficiency of such strategies by counting the number of dishonest reports that any minimal knowledge-bounded mechanism must have. We show that the order of this number is \u03b8(log n), where n is the number of agents, and we provide a peer prediction mechanism that achieves this bound in expectation.",
        "A1": "We go beyond truthfulness and explore equilibrium strategy profiles that are only partially truthful.",
        "A2": "minimal single-task peer prediction mechanisms",
        "A41": "We go beyond truthfulness and explore equilibrium strategy profiles that are only partially truthful.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": " the order of this number is \u03b8(log n)",
        "A82": " measure the inefficiency of such strategies",
        "A81": " give a characterization of how inefficient these equilibria are comparing to truthful reporting",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 31334609
    },
    {
        "Abstract": "For years, recursive neural networks (RvNNs) have been shown to be suitable for representing text into fixed-length vectors and achieved good performance on several natural language processing tasks. However, the main drawback of RvNNs is that they require structured input, which makes data preparation and model implementation hard. In this paper, we propose Gumbel Tree-LSTM, a novel tree-structured long short-term memory architecture that learns how to compose task-specific tree structures only from plain text data efficiently. Our model uses Straight-Through Gumbel-Softmax estimator to decide the parent node among candidates dynamically and to calculate gradients of the discrete decision. We evaluate the proposed model on natural language inference and sentiment analysis,xa0 and show that our model outperforms or is at least comparable to previous models. We also find that our model converges significantly faster than other models.",
        "A1": "propose Gumbel Tree-LSTM",
        "A2": "the main drawback of RvNNs is that they require structured input, which makes data preparation and model implementation hard",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " our model converges significantly faster than other models",
        "A52": "Straight-Through Gumbel-Softmax estimator ",
        "A42": "Gumbel Tree-LSTM, a novel tree-structured long short-term memory architecture that learns how to compose task-specific tree structures only from plain text data efficiently",
        "A45": "",
        "am_id": 364823766
    },
    {
        "Abstract": "We propose a general joint representation learning framework for knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text. In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space. To achieve better fusion, we propose an effective mutual attention between KGs and text. The reciprocal attention mechanism enables us to highlight important features and perform better KGC and RE. Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models. Experiments on relation extraction and entity link prediction show that models trained under our joint framework are significantly improved in comparison with other baselines. Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures. The source code of this paper can be obtained from https://github.com/thunlp/JointNRE.",
        "A1": "learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space",
        "A2": "knowledge acquisition (KA) on two tasks, knowledge graph completion (KGC) and relation extraction (RE) from text",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significantly improved",
        "A7": "Experiments on relation extraction and entity link prediction",
        "A83": "",
        "A82": "Most existing methods for KGC and RE can be easily integrated into our framework due to its flexible architectures",
        "A81": "models trained under our joint framework are significantly improved in comparison with other baselines",
        "A64": "Different from conventional joint models, no complicated linguistic analysis or strict alignments between KGs and text are required to train our models",
        "A54": "",
        "A44": "In this framework, we learn representations of knowledge graphs (KGs) and text within a unified parameter sharing semantic space.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 130703674
    },
    {
        "Abstract": "As most recently proposed methods for human detection have achieved a sufficiently high recall rate within a reasonable number of proposals, in this paper, we mainly focus on how to improve the precision rate of human detectors. In order to address the two main challenges in precision improvement, i.e., i) hard background instances and ii) redundant partial proposals, we propose the novel PoseHD framework, a top-down pose-based approach on the basis of an arbitrary state-of-the-art human detector. In our proposed PoseHD framework, we first make use of human pose estimation (in a batch manner) and present pose heatmap classification (by a convolutional neural network) to eliminate hard negatives by extracting the more detailed structural information; then, we utilize pose-based proposal clustering and reranking modules, filtering redundant partial proposals by comprehensively considering both holistic and part information. The experimental results on multiple pedestrian benchmark datasets validate that our proposed PoseHD framework can generally improve the overall performance of recent state-of-the-art human detectors (by 2-4% in both mAP and MR metrics). Moreover, our PoseHD framework can be easily extended to object detection with large-scale object part annotations. Finally, in this paper, we present extensive ablative analysis to compare our approach with these traditional bottom-up pose-based models and highlight the importance of our framework design decisions.",
        "A1": "propose the novel PoseHD framework",
        "A2": "how to improve the precision rate of human detectors.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "improve the overall performance of recent state-of-the-art human detectors (by 2-4% in both mAP and MR metrics)",
        "A7": "multiple pedestrian benchmark datasets",
        "A83": "extensive ablative analysis to compare our approach with these traditional bottom-up pose-based models and highlight the importance of our framework design decisions.",
        "A82": " can be easily extended to object detection with large-scale object part annotations. ",
        "A81": "our proposed PoseHD framework can generally improve the overall performance of recent state-of-the-art human detectors (by 2-4% in both mAP and MR metrics). ",
        "A64": "these traditional bottom-up pose-based models",
        "A54": "an arbitrary state-of-the-art human detector.",
        "A44": "a top-down pose-based approach on the basis of an arbitrary state-of-the-art human detector. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 338967235
    },
    {
        "Abstract": "Link prediction in signed social networks is challenging because of the existence and imbalance of the three kinds of social status (positive, negative and no-relation). Furthermore, there are a variety types of no-relation status in reality, e.g., strangers and frenemies, which cannot be well distinguished from the other linked status by existing approaches. In this paper, we propose a novel Framework of Integrating both Latent and Explicit features (FILE), to better deal with the no-relation status and improve the overall link prediction performance in signed networks. In particular, we design two latent features from latent space and two explicit features by extending social theories, and learn these features for each user via matrix factorization with a specially designed ranking-oriented loss function. Experimental results demonstrate the superior of our approach over state-of-the-art methods.",
        "A1": "better deal with the no-relation status and improve the overall link prediction performance in signed networks",
        "A2": "better deal with the no-relation status and improve the overall link prediction performance in signed networks",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the superior of our approach over state-of-the-art methods",
        "A7": "learn these features for each user via matrix factorization with a specially designed ranking-oriented loss function",
        "A83": "",
        "A82": "",
        "A81": "the superior of our approach over state-of-the-art methods",
        "A64": "design two latent features from latent space and two explicit features by extending social theories",
        "A54": "",
        "A44": "a novel Framework of Integrating both Latent and Explicit features",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 394711125
    },
    {
        "Abstract": "We present assertion based question answering (ABQA), an open domain question answering task that takes a question and a passage as inputs, and outputs a semi-structured assertion consisting of a subject, a predicate and a list of arguments. An assertion conveys more evidences than a short answer span in reading comprehension, and it is more concise than a tedious passage in passage-based QA. These advantages make ABQA more suitable for human-computer interaction scenarios such as voice-controlled speakers. Further progress towards improving ABQA requires richer supervised dataset and powerful models of text understanding. To remedy this, we introduce a new dataset called WebAssertions, which includes hand-annotated QA labels for 358,427 assertions in 55,960 web passages. To address ABQA, we develop both generative and extractive approaches. The backbone of our generative approach is sequence to sequence learning. In order to capture the structure of the output assertion, we introduce a hierarchical decoder that first generates the structure of the assertion and then generates the words of each field. The extractive approach is based on learning to rank. Features at different levels of granularity are designed to measure the semantic relevance between a question and an assertion. Experimental results show that our approaches have the ability to infer question-aware assertions from a passage. We further evaluate our approaches by incorporating the ABQA results as additional features in passage-based QA. Results on two datasets show that ABQA features significantly improve the accuracy on passage-based QA.",
        "A1": "an open domain question answering task",
        "A2": "takes a question and a passage as inputs, and outputs a semi-structured assertion consisting of a subject, a predicate and a list of arguments",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ABQA features significantly improve the accuracy on passage-based QA",
        "A7": "incorporating the ABQA results as additional features in passage-based QA",
        "A83": "",
        "A82": "",
        "A81": "ABQA features significantly improve the accuracy on passage-based QA",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " ABQA features significantly improve the accuracy on passage-based QA",
        "A52": "sequence learning",
        "A42": "hierarchical decoder that first generates the structure of the assertion and then generates the words of each field",
        "A45": "WebAssertions, which includes hand-annotated QA labels for 358,427 assertions in 55,960 web passages",
        "am_id": 235638255
    },
    {
        "Abstract": "Fine-grained Entity Recognition (FgER) is the task of detecting and classifying entity mentions into more than 100 types. The type set can span various domains including biomedical (e.g., disease, gene), sport (e.g., sports event, sports player), religion and mythology (e.g., religion, god) and entertainment (e.g., movies, music). Most of the existing literature for Entity Recognition (ER) focuses on coarse-grained entity recognition (CgER), i.e., recognition of entities belonging to few types such as person, location and organization. In the past two decades, several manually annotated datasets spanning different genre of texts were created to facilitate the development and evaluation of CgER systems (Nadeau and Sekine 2007). The state-of-the-art CgER systems use supervised statistical learning models trained on manually annotated datasets (Ma and Hovy 2016). In contrast, FgER systems are yet to match the performance level of CgER systems. There are two major challenges associated with failure of FgER systems. First, manually annotating a large-scale multi-genre training data for FgER task is expensive, time-consuming and error-prone. Note that, a human-annotator will have to choose a subset of types from a large set of types and types for the same entity might differ in sentences based on the contextual information. Second, supervised statistical learning models when trained on automatically generated noisy training data fits to noise, impacting the model\u2019s performance. The objective of my thesis is to create a FgER system by exploring an off the beaten path which can eliminate the need for manually annotating large-scale multi-genre training dataset. The path includes: (1) automatically generating a large-scale single-genre training dataset, (2) noise-aware learning models that learn better in noisy datasets, and (3) use of knowledge transfer approaches to adapt FgER system to different genres of text.",
        "A1": "create a FgER system",
        "A2": " First, manually annotating a large-scale multi-genre training data for FgER task is expensive, time-consuming and error-prone. Note that, a human-annotator will have to choose a subset of types from a large set of types and types for the same entity might differ in sentences based on the contextual information. Second, supervised statistical learning models when trained on automatically generated noisy training data fits to noise, impacting the model\u2019s performance.",
        "A41": "exploring an off the beaten path which can eliminate the need for manually annotating large-scale multi-genre training dataset",
        "A51": "",
        "A61": "eliminate the need for manually annotating large-scale multi-genre training dataset",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 439522393
    },
    {
        "Abstract": "Counting people in dense crowds is a demanding task even for humans. This is primarily due to the large variability in appearance of people. Often people are only seen as a bunch of blobs. Occlusions, pose variations and background clutter further compound the difficulty. In this scenario, identifying a person requires larger spatial context and semantics of the scene. But the current state-of-the-art CNN regressors for crowd counting are feedforward and use only limited spatial context to detect people. They look for local crowd patterns to regress the crowd density map, resulting in false predictions. Hence, we propose top-down feedback to correct the initial prediction of the CNN. Our architecture consists of a bottom-up CNN along with a separate top-down CNN to generate feedback. The bottom-up network, which regresses the crowd density map, has two columns of CNN with different receptive fields. Features from various layers of the bottom-up CNN are fed to the top-down network. The feedback, thus generated, is applied on the lower layers of the bottom-up network in the form of multiplicative gating. This masking weighs activations of the bottom-up network at spatial as well as feature levels to correct the density prediction. We evaluate the performance of our model on all major crowd datasets and show the effectiveness of top-down feedback.",
        "A1": " correct the initial prediction of the CNN.",
        "A2": " top-down feedback to correct the initial prediction of the CNN",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "show the effectiveness of top-down feedback.",
        "A7": "evaluate the performance of our model on all major crowd datasets ",
        "A83": "",
        "A82": "",
        "A81": " the effectiveness of top-down feedback.",
        "A64": " show the effectiveness of top-down feedback.",
        "A54": " CNN ",
        "A44": " consists of a bottom-up CNN along with a separate top-down CNN to generate feedback. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " all major crowd datasets ",
        "am_id": 344519295
    },
    {
        "Abstract": "This paper focuses on the task of RGB-D indoor scene classification. It is a very challenging task due to two folds. 1) Learning robust representation for indoor scene is difficult because of various objects and layouts. 2) Fusing the complementary cues in RGB and Depth is nontrivial since there are large semantic gaps between the two modalities. Most existing works learn representation for classification by training a deep network with softmax loss and fuse the two modalities by simply concatenating the features of them. However, these pipelines do not explicitly consider intra-class and inter-class similarity as well as inter-modal intrinsic relationships. To address these problems, this paper proposes a Discriminative Feature Learning and Fusion Network (DF2Net) with two-stage training. In the first stage, to better represent scene in each modality, a deep multi-task network is constructed to simultaneously minimize the structured loss and the softmax loss. In the second stage, we design a novel discriminative fusion network which is able to learn correlative features of multiple modalities and distinctive features of each modality. Extensive analysis and experiments on SUN RGB-D Dataset and NYU Depth Dataset V2 show the superiority of DF2Net over other state-of-the-art methods in RGB-D indoor scene classification task.",
        "A1": "",
        "A2": " RGB-D indoor scene classification",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the superiority of DF2Net over other state-of-the-art methods in RGB-D indoor scene classification task",
        "A7": "SUN RGB-D Dataset and NYU Depth Dataset V2",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "consider intra-class and inter-class similarity as well as inter-modal intrinsic relationships",
        "A52": "a deep multi-task network",
        "A42": "Discriminative Feature Learning and Fusion Network (DF2Net) with two-stage training.",
        "A45": "",
        "am_id": null
    },
    {
        "Abstract": "Makeup is widely used to improve facial attractiveness and is well accepted by the public. However, different makeup styles will result in significant facial appearance changes. It remains a challenging problem to match makeup and non-makeup face images. This paper proposes a learning from generation approach for makeup-invariant face verification by introducing a bi-level adversarial network (BLAN). To alleviate the negative effects from makeup, we first generate non-makeup images from makeup ones, and then use the synthesized non-makeup images for further verification. Two adversarial networks in BLAN are integrated in an end-to-end deep network, with the one on pixel level for reconstructing appealing facial images and the other on feature level for preserving identity information. These two networks jointly reduce the sensing gap between makeup and non-makeup images. Moreover, we make the generator well constrained by incorporating multiple perceptual losses. Experimental results on three benchmark makeup face datasets demonstrate that our method achieves state-of-the-art verification accuracy across makeup status and can produce photo-realistic non-makeup face images.",
        "A1": "This paper proposes a learning from generation approach for makeup-invariant face verification by introducing a bi-level adversarial network (BLAN). ",
        "A2": "to match makeup and non-makeup face images.",
        "A41": "To alleviate the negative effects from makeup, we first generate non-makeup images from makeup ones, and then use the synthesized non-makeup images for further verification. ",
        "A51": "bi-level adversarial network (BLAN)",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on three benchmark makeup face datasets",
        "A83": "",
        "A82": "",
        "A81": "our method achieves state-of-the-art verification accuracy across makeup status and can produce photo-realistic non-makeup face images.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "three benchmark makeup face datasets",
        "am_id": 127088990
    },
    {
        "Abstract": "Despite the vast amount of research related to Chinese typo detection, we still lack a publicly available benchmark dataset for evaluation. Furthermore, no precise evaluation schema for Chinese typo detection has been defined. In response to these problems: (1) we release a benchmark dataset to assist research on Chinese typo correction; (2) we present an evaluation schema which was adopted in our NLPTEA 2017 Shared Task on Chinese Spelling Check; and (3) we report new improvements to our Chinese typo detection system ACT.",
        "A1": "Chinese typo detection",
        "A2": "lack a publicly available benchmark dataset for evaluation",
        "A41": "an evaluation schema",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "new improvements to our Chinese typo detection system ACT",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a benchmark dataset",
        "am_id": 253207418
    },
    {
        "Abstract": "Community Question Answering (cQA) forums are very popular nowadays, as they represent effective means for communities around particular topics to share information. Unfortunately, this information is not always factual. Thus, here we explore a new dimension in the context of cQA, which has been ignored so far: checking the veracity of answers to particular questions in cQA forums. As this is a new problem, we create a specialized dataset for it. We further propose a novel multi-faceted model, which captures information from the answer content (what is said and how), from the author profile (who says it), from the rest of the community forum (where it is said), and from external authoritative sources of information (external support). Evaluation results show a MAP value of 86.54, which is 21 points absolute above the baseline.",
        "A1": "Thus, here we explore a new dimension in the context of cQA, which has been ignored so far: checking the veracity of answers to particular questions in cQA forums. ",
        "A2": "Community Question Answering (cQA) forums are very popular nowadays, as they represent effective means for communities around particular topics to share information. Unfortunately, this information is not always factual.",
        "A41": "hus, here we explore a new dimension in the context of cQA, which has been ignored so far: checking the veracity of answers to particular questions in cQA forums.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We further propose a novel multi-faceted model, which captures information from the answer content (what is said and how), from the author profile (who says it), from the rest of the community forum (where it is said), and from external authoritative sources of information (external support).",
        "A83": "",
        "A82": "",
        "A81": "Evaluation results show a MAP value of 86.54, which is 21 points absolute above the baseline.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 201445676
    },
    {
        "Abstract": "It is challenging to directly apply text classification models without much feature engineering on domain-specific use cases, and expect the state of art performance. Much more so when the number of classes is large. Convolutional Neural Network (CNN or Con-vNet) has attracted much in text mining due to its effectiveness in automatic feature extraction from text. In this paper, we compare traditional and deep learning approaches for automatic categorization of IT tickets in a real-world production ticketing system. Experimental results demonstrate the good potential of CNN models in our task.",
        "A1": "ompare traditional and deep learning approaches",
        "A2": "",
        "A41": "Convolutional Neural Network",
        "A51": "Convolutional Neural Network",
        "A61": "attracted much",
        "A10": "good potential",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " the good potential of CNN models in our task.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 387863090
    },
    {
        "Abstract": "Partially inspired by successful applications of variational recurrent neural networks, we propose a novel variational recurrent neural machine translation (VRNMT) model in this paper. Different from the variational NMT, VRNMT introduces a series of latent random variables to model the translation procedure of a sentence in a generative way, instead of a single latent variable. Specifically, the latent random variables are included into the hidden states of the NMT decoder with elements from the variational autoencoder. In this way, these variables are recurrently generated, which enables them to further capture strong and complex dependencies among the output translations at different timesteps. In order to deal with the challenges in performing efficient posterior inference and large-scale training during the incorporation of latent variables, we build a neural posterior approximator, and equip it with a reparameterization technique to estimate the variational lower bound. Experiments on Chinese-English and English-German translation tasks demonstrate that the proposed model achieves significant improvements over both the conventional and variational NMT models.",
        "A1": "machine translation ",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on Chinese-English and English-German translation tasks",
        "A83": "",
        "A82": "",
        "A81": "the proposed model achieves significant improvements over both the conventional and variational NMT models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "VRNMT introduces a series of latent random variables to model the translation procedure of a sentence in a generative way, instead of a single latent variable",
        "A52": "latent random variables",
        "A42": "VRNMT introduces a series of latent random variables to model the translation procedure of a sentence in a generative way",
        "A45": "",
        "am_id": 410157772
    },
    {
        "Abstract": "Transfer learning significantly accelerates the reinforcement learning process by exploiting relevant knowledge from previous experiences. The problem of optimally selecting source policies during the learning process is of great importance yet challenging. There has been little theoretical analysis of this problem. In this paper, we develop an optimal online method to select source policies for reinforcement learning. This method formulates online source policy selection as a multi-armed bandit problem and augments Q-learning with policy reuse. We provide theoretical guarantees of the optimal selection process and convergence to the optimal policy. In addition, we conduct experiments on a grid-based robot navigation domain to demonstrate its efficiency and robustness by comparing to the state-of-the-art transfer learning method.",
        "A1": " select source policies for reinforcement learning",
        "A2": "The problem of optimally selecting source policies during the learning process",
        "A41": "n optimal online method to select source policies for reinforcement learning.",
        "A51": "This method formulates online source policy selection as a multi-armed bandit problem and augments Q-learning with policy reuse.",
        "A61": "",
        "A10": "",
        "A7": " we conduct experiments on a grid-based robot navigation domain",
        "A83": "",
        "A82": "",
        "A81": "demonstrate its efficiency and robustness by comparing to the state-of-the-art transfer learning method.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 163965776
    },
    {
        "Abstract": "MaxSAT reasoning is an effective technology used in modern branch-and-bound (BnB) algorithms for the Maximum Weight Clique problem (MWC) to reduce the search space. However, the current MaxSAT reasoning approach for MWC is carried out in a blind manner and is not guided by any relevant strategy. In this paper, we describe a new BnB algorithm for MWC that incorporates a novel two-stage MaxSAT reasoning approach. In each stage, the MaxSAT reasoning is specialised and guided for different tasks. Experiments on an extensive set of graphs show that the new algorithm implementing this approach significantly outperforms relevant exact and heuristic MWC algorithms in both small/medium and massive real-world graphs.",
        "A1": "describe a new BnB algorithm for MWC",
        "A2": "the current MaxSAT reasoning approach for MWC is carried out in a blind manner and is not guided by any relevant strategy",
        "A41": "a novel two-stage MaxSAT reasoning approach",
        "A51": "",
        "A61": "",
        "A10": "this approach significantly outperforms relevant exact and heuristic MWC algorithms in both small/medium and massive real-world graphs",
        "A7": "Experiments on an extensive set of graphs",
        "A83": "",
        "A82": "",
        "A81": "the new algorithm implementing this approach significantly outperforms relevant exact and heuristic MWC algorithms in both small/medium and massive real-world graphs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "incorporates a novel two-stage MaxSAT reasoning approach",
        "A43": " a new BnB algorithm for MWC",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 420354570
    },
    {
        "Abstract": "A number of proposals have been made to define inconsistency measures. Each has its rationale. But to date, it is not clear how to delineate the space of options for measures, nor is it clear how we can classify measures systematically. In this paper, we introduce a general framework for comparing syntactic inconsistency measures. It uses the construction of an inconsistency graph for each knowledgebase. We then introduce abstractions of the inconsistency graph and use the hierarchy of the abstractions to classify a range of inconsistency measures.",
        "A1": "for comparing syntactic inconsistency measures",
        "A2": "classify a range of inconsistency measures",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "classify a range of inconsistency measures",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "introduce a general framework for comparing syntactic inconsistency measures",
        "A64": " classify a range of inconsistency measures",
        "A54": "It uses the construction of an inconsistency graph for each knowledgebase",
        "A44": "a general framework for comparing syntactic inconsistency measures",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 212072429
    },
    {
        "Abstract": "Recently, domain adaptation based on deep models has been a promising way to deal with the domains with scarce labeled data, which is a critical problem for deep learning models. Domain adaptation propagates the knowledge from a source domain with rich information to the target domain. In reality, the source and target domains are mostly unbalanced in that the source domain is more resource-rich and thus has more reliable knowledge than the target domain. However, existing deep domain adaptation approaches often pre-assume the source and target domains balanced and equally, leading to a medium solution between the source and target domains, which is not optimal for the unbalanced domain adaptation. In this paper, we propose a novel Deep Asymmetric Transfer Network (DATN) to address the problem of unbalanced domain adaptation. Specifically, our model will learn a transfer function from the target domain to the source domain and meanwhile adapting the source domain classifier with more discriminative power to the target domain. By doing this, the deep model is able to adaptively put more emphasis on the resource-rich source domain. To alleviate the scarcity problem of supervised data, we further propose an unsupervised transfer method to propagate the knowledge from a lot of unsupervised data by minimizing the distribution discrepancy over the unlabeled data of two domains. The experiments on two real-world datasets demonstrate that DATN attains a substantial gain over state-of-the-art methods.",
        "A1": "we propose a novel Deep Asymmetric Transfer Network (DATN) to address the problem of unbalanced domain adaptation. Specifically, our model will learn a transfer function from the target domain to the source domain and meanwhile adapting the source domain classifier with more discriminative power to the target domain",
        "A2": "unbalanced domain adaptation",
        "A41": "an unsupervised transfer method to propagate the knowledge from a lot of unsupervised data",
        "A51": "",
        "A61": "minimizing the distribution discrepancy over the unlabeled data of two domains.",
        "A10": "DATN attains a substantial gain over state-of-the-art methods.",
        "A7": "The experiments on two real-world datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "By doing this, the deep model is able to adaptively put more emphasis on the resource-rich source domain. ",
        "A52": "",
        "A42": " Deep Asymmetric Transfer Network (DATN)",
        "A45": "",
        "am_id": 92596188
    },
    {
        "Abstract": "Robust reinforcement learning aims to produce policies that have strong guarantees even in the face of environments/transition models whose parameters have strong uncertainty. Existing work uses value-based methods and the usual primitive action setting. In this paper, we propose robust methods for learning temporally abstract actions, in the framework of options. We present a Robust Options Policy Iteration (ROPI) algorithm with convergence guarantees, which learns options that are robust to model uncertainty. We utilize ROPI to learn robust options with the Robust Options Deep Q Network (RO-DQN) that solves multiple tasks and mitigates model misspecification due to model uncertainty. We present experimental results which suggest that policy iteration with linear features may have an inherent form of robustness when using coarse feature representations. In addition, we present experimental results which demonstrate that robustness helps policy iteration implemented on top of deep neural networks to generalize over a much broader range of dynamics than non-robust policy iteration.",
        "A1": " In this paper, we propose robust methods for learning temporally abstract actions",
        "A2": "Robust reinforcement learning aims to produce policies that have strong guarantees even in the face of environments/transition models whose parameters have strong uncertainty.",
        "A41": "In this paper, we propose robust methods for learning temporally abstract actions, in the framework of options.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "we present experimental results which demonstrate that robustness helps policy iteration implemented on top of deep neural networks to generalize over a much broader range of dynamics than non-robust policy iteration",
        "A81": "We present experimental results which suggest that policy iteration with linear features may have an inherent form of robustness when using coarse feature representations.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "We present a Robust Options Policy Iteration (ROPI) algorithm with convergence guarantees, which learns options that are robust to model uncertainty.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 307508882
    },
    {
        "Abstract": "The winner determination problems of many attractive multi-winner voting rules are NP-complete. However, they often admit polynomial-time algorithms when restricting inputs to be single-peaked. Commonly, such algorithms employ dynamic programming along the underlying axis. We introduce a new technique: carefully chosen integer linear programming (IP) formulations for certain voting problems admit an LP relaxation which is totally unimodular if preferences are single-peaked, and which thus admits an integral optimal solution. This technique gives efficient algorithms for finding optimal committees under Proportional Approval Voting (PAV) and the Chamberlin-Courant rule with single-peaked preferences, as well as for certain OWA-based rules. For PAV, this is the first technique able to efficiently find an optimal committee when preferences are single-peaked. An advantage of our approach is that no special-purpose algorithm needs to be used to exploit structure in the input preferences: any standard IP solver will terminate in the first iteration if the input is single-peaked, and will continue to work otherwise.",
        "A1": "admits an integral optimal solution",
        "A2": "they often admit polynomial-time algorithms when restricting inputs to be single-peaked.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " An advantage of our approach is that no special-purpose algorithm needs to be used to exploit structure in the input preferences: any standard IP solver will terminate in the first iteration if the input is single-peaked, and will continue to work otherwise.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "is totally unimodular if preferences are single-peaked, and which thus admits an integral optimal solution",
        "A53": "",
        "A43": " carefully chosen integer linear programming (IP) formulations for certain voting problems admit an LP relaxation",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 464945697
    },
    {
        "Abstract": "We provide, to the best of our knowledge, the first computational study of extensive-form adversarial team games. These games are sequential, zero-sum games in which a team of players, sharing the same utility function, faces an adversary. We define three different scenarios according to the communication capabilities of the team. In the first, the teammates can communicate and correlate their actions both before and during the play. In the second, they can only communicate before the play. In the third, no communication is possible at all. We define the most suitable solution concepts, and we study the inefficiency caused by partial or null communication, showing that the inefficiency can be arbitrarily large in the size of the game tree. Furthermore, we study the computational complexity of the equilibrium-finding problem in the three scenarios mentioned above, and we provide, for each of the three scenarios, an exact algorithm. Finally, we empirically evaluate the scalability of the algorithms in random games and the inefficiency caused by partial or null communication.",
        "A1": "",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "evaluate the scalability of the algorithms in random games and the inefficiency caused by partial or null communication.",
        "A81": "showing that the inefficiency can be arbitrarily large in the size of the game tree",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "the computational complexity of the equilibrium-finding problem in the three scenarios",
        "A43": "for each of the three scenarios, an exact algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 382475051
    },
    {
        "Abstract": "Learning representations on Grassmann manifolds is popular in quite a few visual recognition tasks. In order to enable deep learning on Grassmann manifolds, this paper proposes a deep network architecture by generalizing the Euclidean network paradigm to Grassmann manifolds. In particular, we design full rank mapping layers to transform input Grassmannian data to more desirable ones, exploit re-orthonormalization layers to normalize the resulting matrices, study projection pooling layers to reduce the model complexity in the Grassmannian context, and devise projection mapping layers to respect Grassmannian geometry and meanwhile achieve Euclidean forms for regular output layers. To train the Grassmann networks, we exploit a stochastic gradient descent setting on manifolds of the connection weights, and study a matrix generalization of backpropagation to update the structured data. The evaluations on three visual recognition tasks show that our Grassmann networks have clear advantages over existing Grassmann learning methods, and achieve results comparable with state-of-the-art approaches.",
        "A1": "enable deep learning on Grassmann manifolds",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "The evaluations on three visual recognition tasks",
        "A83": "",
        "A82": "and achieve results comparable with state-of-the-art approaches.",
        "A81": "The evaluations on three visual recognition tasks show that our Grassmann networks have clear advantages over existing Grassmann learning methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " a deep network architecture by generalizing the Euclidean network paradigm to Grassmann manifolds",
        "A45": "",
        "am_id": 432562993
    },
    {
        "Abstract": "Multi-view based shape descriptors have achieved impressive performance for 3D shape retrieval. The core of view-based methods is to interpret 3D structures through 2D observations. However, most existing methods pay more attention to discriminative models and none of them necessarily incorporate the 3D properties of the objects. To resolve this problem, we propose an encoder-decoder recurrent feature aggregation network (ERFA-Net) to emphasize the 3D properties of 3D shapes in multi-view features aggregation. In our network, a view sequence of the shape is trained to encode a discriminative shape embedding and estimate unseen rendered views of any viewpoints. This generation task gives an effective supervision which makes the network exploit 3D properties of shapes through various 2D images. During feature aggregation, a discriminative feature representation across multiple views is effectively exploited based on LSTM network. The proposed 3D representation has following advantages against other state-of-the-art: 1) it performs robust discrimination under the existence of noise such as view missing and occlusion, because of the improvement brought by 3D properties. 2) it has strong generative capabilities, which is useful for various 3D shape tasks. We evaluate ERFA-Net on two popular 3D shape datasets, ModelNet and ShapeNetCore55, and ERFA-Net outperforms the state-of-the-art methods significantly. Extensive experiments show the effectiveness and robustness of the proposed 3D representation.",
        "A1": "most existing methods pay more attention to discriminative models and none of them necessarily incorporate the 3D properties of the objects. To resolve this problem, ",
        "A2": "we propose an encoder-decoder recurrent feature aggregation network (ERFA-Net) to emphasize the 3D properties of 3D shapes in multi-view features aggregation.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ERFA-Net outperforms the state-of-the-art methods significantly. ",
        "A7": "We evaluate ERFA-Net on two popular 3D shape datasets, ModelNet and ShapeNetCore55",
        "A83": " ERFA-Net outperforms the state-of-the-art methods significantly. Extensive experiments show the effectiveness and robustness of the proposed 3D representation.",
        "A82": " it has strong generative capabilities, which is useful for various 3D shape tasks.",
        "A81": "it performs robust discrimination under the existence of noise such as view missing and occlusion, because of the improvement brought by 3D properties.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "LSTM network",
        "A42": "we propose an encoder-decoder recurrent feature aggregation network (ERFA-Net) to emphasize the 3D properties of 3D shapes in multi-view features aggregation.",
        "A45": "",
        "am_id": 126330599
    },
    {
        "Abstract": "Recent studies have highlighted the vulnerability of deep neural networks (DNNs) to adversarial examples \u2014 a visually indistinguishable adversarial image can easily be crafted to cause a well-trained model to misclassify. Existing methods for crafting adversarial examples are based on L2 and L\u221e distortion metrics. However, despite the fact that L1 distortion accounts for the total variation and encourages sparsity in the perturbation, little has been developed for crafting L1-based adversarial examples. In this paper, we formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem. Our elastic-net attacks to DNNs (EAD) feature L1-oriented adversarial examples and include the state-of-the-artxa0L2 attack as a special case. Experimental results on MNIST, CIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial examples with smallxa0L1 distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios. More importantly, EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveragingxa0L1 distortion in adversarial machine learning and security implications of DNNs.",
        "A1": "formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem",
        "A2": "the vulnerability of deep neural networks (DNNs) to adversarial examples",
        "A41": "formulate the process of attacking DNNs via adversarial examples as an elastic-net regularized optimization problem",
        "A51": "Existing methods for crafting adversarial examples are based on L2 and L\u221e distortion metrics",
        "A61": " Our elastic-net attacks to DNNs (EAD) feature L1-oriented adversarial examples and include the state-of-the-artxa0L2 attack as a special case",
        "A10": "improved attack transferability and complements adversarial training for DNNs",
        "A7": "Experimental results on MNIST, CIFAR10 and ImageNet",
        "A83": "",
        "A82": "EAD leads to improved attack transferability and complements adversarial training for DNNs, suggesting novel insights on leveragingxa0L1 distortion in adversarial machine learning and security implications of DNNs",
        "A81": "EAD can yield a distinct set of adversarial examples with smallxa0L1 distortion and attains similar attack performance to the state-of-the-art methods in different attack scenarios",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 465786185
    },
    {
        "Abstract": "We propose a simple approach to visual alignment, focusing on the illustrative task of facial landmark estimation. While most prior work treats this as a regression problem, we instead formulate it as a discrete K-way classification task, where a classifier is trained to return one of K discrete alignments. One crucial benefit of a classifier is the ability to report back a (softmax) distribution over putative alignments. We demonstrate that this distribution is a rich representation that can be marginalized (to generate uncertainty estimates over groups of landmarks) and conditioned on (to incorporate top-down context, provided by temporal constraints in a video stream or an interactive human user). Such capabilities are difficult to integrate into classic regression-based approaches. We study performance as a function of the number of classes K, including the extreme \"exemplar class\" setting where K is equal to the number of training examples (140K in our setting). Perhaps surprisingly, we show that classifiers can still be learned in this setting. When compared to prior work in classification, our K is unprecedentedly large, including many \"fine-grained\" classes that are very similar. We address these issues by using a multi-label loss function that allows for training examples to be non-uniformly shared across discrete classes. We perform a comprehensive experimental analysis of our method on standard benchmarks, demonstrating state-of-the-art results for facial alignment in videos.",
        "A1": "propose a simple approach to visual alignment",
        "A2": "focusing on the illustrative task of facial landmark estimation",
        "A41": "a simple approach to visual alignment",
        "A51": "facial landmark ",
        "A61": "While most prior work treats this as a regression problem, we instead formulate it as a discrete K-way classification task",
        "A10": "",
        "A7": "We perform a comprehensive experimental analysis of our method on standard benchmarks",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 378644898
    },
    {
        "Abstract": "Generating plausible and fluent sentence with desired properties has long been a challenge. Most of the recent works use recurrent neural networks (RNNs) and their variants to predict following words given previous sequence and target label. In this paper, we propose a novel framework to generate constrained sentences via Gibbs Sampling. The candidate sentences are revised and updated iteratively, with sampled new words replacing old ones. Our experiments show the effectiveness of the proposed method to generate plausible and diverse sentences.",
        "A1": "generate constrained sentences",
        "A2": "Generating plausible and fluent sentence with desired properties",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Our experiments show the effectiveness of the proposed method to generate plausible and diverse sentences",
        "A64": "Gibbs Sampling",
        "A54": "Gibbs Sampling",
        "A44": "a novel framework to generate constrained sentences via Gibbs Sampling",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 443466838
    },
    {
        "Abstract": "We propose a scheme for training a computerized agent to perform complex human tasks such as highway steering. The scheme is designed to follow a natural learning process whereby a human instructor teaches a computerized trainee. It enables leveraging the weak supervision abilities of a (human) instructor, who, while unable to perform well herself at the required task, can provide coherent and learnable instantaneous reward signals to the computerized trainee. The learning process consists of three supervised elements followed by reinforcement learning. The supervised learning stages are: (i) supervised imitation learning; (ii) supervised reward induction; and (iii) supervised safety module construction. We implemented this scheme using deep convolutional networks and applied it to successfully create a computerized agent capable of autonomous highway steering over the well-known racing game Assetto Corsa. We demonstrate that the use of all components is essential to effectively carry out reinforcement learning of the steering task using vision alone, without access to a driving simulator internals, and operating in wall-clock time.",
        "A1": "propose a scheme for training a computerized agent",
        "A2": "training a computerized agent to perform complex human tasks such as highway steering",
        "A41": "a scheme for training a computerized agent to perform complex human tasks",
        "A51": "(i) supervised imitation learning; (ii) supervised reward induction; and (iii) supervised safety module construction",
        "A61": "It enables leveraging the weak supervision abilities of a (human) instructor, who, while unable to perform well herself at the required task, can provide coherent and learnable instantaneous reward signals to the computerized trainee",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the use of all components is essential to effectively carry out reinforcement learning of the steering task using vision alone, without access to a driving simulator internals, and operating in wall-clock time",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 110518220
    },
    {
        "Abstract": "The multi-armed bandit problem has been extensively studied under the stationary assumption. However in reality, this assumption often does not hold because the distributions of rewards themselves may change over time. In this paper, we propose a change-detection (CD) based framework for multi-armed bandit problems under the piecewise-stationary setting, and study a class of change-detection based UCB (Upper Confidence Bound) policies, CD-UCB, that actively detects change points and restarts the UCB indices. We then develop CUSUM-UCB and PHT-UCB, that belong to the CD-UCB class and use cumulative sum (CUSUM) and Page-Hinkley Test (PHT) to detect changes. We show that CUSUM-UCB obtains the best known regret upper bound under mild assumptions. We also demonstrate the regret reduction of the CD-UCB policies over arbitrary Bernoulli rewards and Yahoo! datasets of webpage click-through rates.",
        "A1": "",
        "A2": " in reality, this assumption often does not hold because the distributions of rewards themselves may change over time",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " CUSUM-UCB obtains the best known regret upper bound under mild assumptions",
        "A7": "arbitrary Bernoulli rewards and Yahoo! datasets of webpage click-through rates.",
        "A83": "",
        "A82": " CUSUM-UCB obtains the best known regret upper bound under mild assumptions",
        "A81": "the regret reduction of the CD-UCB policies over",
        "A64": "",
        "A54": "change-detection (CD) ",
        "A44": "a change-detection (CD) based framework for multi-armed bandit problems under the piecewise-stationary setting, and study a class of change-detection based UCB (Upper Confidence Bound) policies, CD-UCB, that actively detects change points and restarts the UCB indices",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 387218589
    },
    {
        "Abstract": "Scene recognition remains one of the most challenging problems in image understanding. With the help of fully connected layers (FCL) and rectified linear units (ReLu), deep networks can extract the moderately sparse and discriminative feature representation required for scene recognition. However, few methods consider exploiting a sparsity model for learning the feature representation in order to provide enhanced discriminative capability. In this paper, we replace the conventional FCL and ReLu with a new dictionary learning layer, that is composed of a finite number of recurrent units to simultaneously enhance the sparse representation and discriminative abilities of features via the determination of optimal dictionaries. In addition, with the help of the structure of the dictionary, we propose a new label discriminative regressor to boost the discrimination ability. We also propose new constraints to prevent overfitting by incorporating the advantage of the Mahalanobis and Euclidean distances to balance the recognition accuracy and generalization performance. Our proposed approach is evaluated using various scene datasets and shows superior performance to many state-of-the-art approaches.",
        "A1": "a sparsity model for learning the feature representation in order to provide enhanced discriminative capability",
        "A2": " enhanced discriminative capability",
        "A41": "a new dictionary learning layer",
        "A51": "finite number of recurrent units",
        "A61": "eplace the conventional FCL and ReLu ",
        "A10": "ur proposed approach is evaluated using various scene datasets and shows superior performance to many state-of-the-art approaches",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "consider exploiting a sparsity model for learning the feature representation",
        "A52": "the structure of the dictionary",
        "A42": " a new label discriminative regressor",
        "A45": "",
        "am_id": 303468580
    },
    {
        "Abstract": "Data are often labeled by many different experts with each expert only labeling a small fraction of the data and each data point being labeled by several experts. This reduces the workload on individual experts and also gives a better estimate of the unobserved ground truth. When experts disagree, the standard approaches are to treat the majority opinion as the correct label or to model the correct label as a distribution. These approaches, however, do not make any use of potentially valuable information about which expert produced which label. To make use of this extra information, we propose modeling the experts individually and then learning averaging weights for combining them, possibly in sample-specific ways. This allows us to give more weight to more reliable experts and take advantage of the unique strengths of individual experts at classifying certain types of data. Here we show that our approach leads to improvements in computer-aided diagnosis of diabetic retinopathy. We also show that our method performs better than competing algorithms by Welinder and Perona (2010); Mnih and Hinton (2012). Our work offers an innovative approach for dealing with the myriad real-world settings that use expert opinions to define labels for training.",
        "A1": "make use of this extra information",
        "A2": "Data are often labeled by many different experts with each expert only labeling a small fraction of the data and each data point being labeled by several experts. This reduces the workload on individual experts and also gives a better estimate of the unobserved ground truth. When experts disagree, the standard approaches are to treat the majority opinion as the correct label or to model the correct label as a distribution. These approaches, however, do not make any use of potentially valuable information about which expert produced which label",
        "A41": "modeling the experts individually and then learning averaging weights for combining them, possibly in sample-specific ways",
        "A51": "",
        "A61": "make use of this extra information",
        "A10": "our approach leads to improvements in computer-aided diagnosis of diabetic retinopathy. We also show that our method performs better than competing algorithms by Welinder and Perona (2010); Mnih and Hinton (2012)",
        "A7": "computer-aided diagnosis of diabetic retinopathy",
        "A83": "",
        "A82": " our method performs better than competing algorithms by Welinder and Perona (2010); Mnih and Hinton (2012)",
        "A81": "leads to improvements in computer-aided diagnosis of diabetic retinopathy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 297629629
    },
    {
        "Abstract": "We propose Clopen Knowledge Bases (CKBs) as a new formalism combining Answer Set Programming (ASP) with ontology languages based on first-order logic. CKBs generalize the prominent r-hybrid and DL+LOG languages of Rosati, and are more flexible for specification of problems that combine open-world and closed-world reasoning. We argue that the guarded negation fragment of first-order logic(GNFO)\u2014a very expressive fragment that subsumes many prominent ontology languages like Description Logics (DLs) and the guarded fragment\u2014is an ontology language that can be used in CKBs while enjoying decidability for basic reasoning problems. We further show how CKBs can be used with expressive DLs of the ALC family, and obtain worst-case optimal complexity results in this setting. For DL-based CKBs, we define a fragment called separable CKBs (which still strictly subsumes r-hybrid and DL+LOG knowledge bases), and show that they can be rather efficiently translated into standard ASP programs. This approach allows us to perform basic inference from separable CKBs by reusing existing efficient ASP solvers. We have implemented the approach for separable CKBs containing ontologies in the DL ALCH, and present in this paper some promising empirical results for real-life data. They show that our approach provides a dramatic improvement over a naive implementation based on a translation of such CKBs into dl-programs.",
        "A1": "propose Clopen Knowledge Bases (CKBs) as a new formalism combining Answer Set Programming (ASP) with ontology languages based on first-order logic",
        "A2": " generalize the prominent r-hybrid and DL+LOG languages of Rosati,",
        "A41": "We propose Clopen Knowledge Bases (CKBs) as a new formalism combining Answer Set Programming (ASP) with ontology languages based on first-order logic. ",
        "A51": "combining Answer Set Programming (ASP) with ontology languages based on first-order logic.",
        "A61": "",
        "A10": "",
        "A7": "We have implemented the approach for separable CKBs containing ontologies in the DL ALCH, and present in this paper some promising empirical results for real-life data.",
        "A83": "",
        "A82": "",
        "A81": "They show that our approach provides a dramatic improvement over a naive implementation based on a translation of such CKBs into dl-programs.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 406544433
    },
    {
        "Abstract": "We study an important yet under-addressed problem of quickly and safely improving policies in online reinforcement learning domains. As its solution, we propose a novel exploration strategy - diverse exploration (DE), which learns and deploys a diverse set of safe policies to explore the environment. We provide DE theory explaining why diversity in behavior policies enables effective exploration without sacrificing exploitation. Our empirical study shows that an online policy improvement algorithm framework implementing the DE strategy can achieve both fast policy improvement and safe online performance.",
        "A1": "study an important yet under-addressed problem",
        "A2": "quickly and safely improving policies in online reinforcement learning domains",
        "A41": "a novel exploration strategy - diverse exploration (DE)",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "empirical study",
        "A83": "",
        "A82": "",
        "A81": "an online policy improvement algorithm framework implementing the DE strategy can achieve both fast policy improvement and safe online performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 66609511
    },
    {
        "Abstract": "Recent studies reveal that social advertising is more effective than conventional online advertising. This is mainly because conventional advertising targets at individual's interest while social advertising is able to produce a large cascade of further exposures to other users via social influence. This motivates us to study the optimal social advertising problem from platform's perspective, and our objective is to find the best ad sequence for each user in order to maximize the expected revenue. Although there is rich body of work that has been devoted to ad sequencing, the network value of each customer is largely ignored in existing algorithm design. To fill this gap, we propose to integrate viral marketing into existing ad sequencing model, and develop both non-adaptive and adaptive ad sequencing policies that can maximize the viral marketing efficiency.",
        "A1": "find the best ad sequence for each user in order to maximize the expected revenue",
        "A2": "the network value of each customer is largely ignored in existing algorithm design",
        "A41": "develop both non-adaptive and adaptive ad sequencing policies",
        "A51": "",
        "A61": "maximize the viral marketing efficiency",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " integrate viral marketing into existing ad sequencing model",
        "A45": "",
        "am_id": 12072145
    },
    {
        "Abstract": "Co-clustering computes clusters of data items and the related features concurrently, and it has been used in many applications such as community detection, product recommendation, computer vision, and pricing optimization. In this paper, we propose a new co-clustering method, called CoDiNMF, which improves the clustering quality and finds directional patterns among co-clusters by using multiple directed and undirected graphs. We design the objective function of co-clustering by using min-cut criterion combined with an additional term which controls the sum of net directional flow between different co-clusters. In addition, we show that a variant of Nonnegative Matrix Factorization (NMF) can solve the proposed objective function effectively. We run experiments on the US patents and BlogCatalog data sets whose ground truth have been known, and show that CoDiNMF improves clustering results compared to other co-clustering methods in terms of average F1 score, Rand index, and adjusted Rand index (ARI). Finally, we compare CoDiNMF and other co-clustering methods on the Wikipedia data set of philosophers, and we can find meaningful directional flow of influence among co-clusters of philosophers.",
        "A1": "Co-clustering",
        "A2": "Co-clustering",
        "A41": "propose a new co-clustering method, called CoDiNMF",
        "A51": "multiple directed and undirected graphs",
        "A61": "",
        "A10": "find meaningful directional flow of influence among co-clusters of philosophers",
        "A7": "compare CoDiNMF and other co-clustering methods on the Wikipedia data set of philosophers",
        "A83": "",
        "A82": "",
        "A81": " find meaningful directional flow of influence among co-clusters of philosophers",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 447988459
    },
    {
        "Abstract": "Probabilistic topic models are popular unsupervised learning methods, including probabilistic latent semantic indexing (pLSI) and latent Dirichlet allocation (LDA). By now, their training is implemented on general purpose computers (GPCs), which are flexible in programming but energy-consuming. Towards low-energy implementations, this paper investigates their training on an emerging hardware technology called the neuromorphic multi-chip systems (NMSs). NMSs are very effective for a family of algorithms called spiking neural networks (SNNs). We present three SNNs to train topic models.The first SNN is a batch algorithm combining the conventional collapsed Gibbs sampling (CGS) algorithm and an inference SNN to train LDA. The other two SNNs are online algorithms targeting at both energy- and storage-limited environments. The two online algorithms are equivalent with training LDA by using maximum-a-posterior estimation and maximizing the semi-collapsed likelihood, respectively.They use novel, tailored ordinary differential equations for stochastic optimization. We simulate the new algorithms and show that they are comparable with the GPC algorithms, while being suitable for NMS implementation. We also propose an extension to train pLSI and a method to prune the network to obey the limited fan-in of some NMSs.",
        "A1": "Towards low-energy implementations, this paper investigates their training on an emerging hardware technology called the neuromorphic multi-chip systems (NMSs)",
        "A2": " We simulate the new algorithms and show that they are comparable with the GPC algorithms, while being suitable for NMS implementation. We also propose an extension to train pLSI and a method to prune the network to obey the limited fan-in of some NMSs.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "being suitable for NMS implementation",
        "A7": " We simulate the new algorithms and show that they are comparable with the GPC algorithms",
        "A83": "",
        "A82": "being suitable for NMS implementation",
        "A81": "re comparable with the GPC algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "emerging hardware technology called the neuromorphic multi-chip systems ",
        "A53": "We present three SNNs to train topic models",
        "A43": "spiking neural networks (SNNs)",
        "A62": "low-energy implementations, this paper investigates their training on an emerging hardware technology called the neuromorphic multi-chip systems (NMSs)",
        "A52": "We present three SNNs to train topic models",
        "A42": "NMSs are very effective for a family of algorithms called spiking neural networks (SNNs)",
        "A45": "",
        "am_id": 56915194
    },
    {
        "Abstract": "We consider sequential decision making problems under uncertainty, in which a user has a general idea of the task to achieve, and gives advice to an agent in charge of computing an optimal policy. Many different notions of advice have been proposed in somewhat different settings, especially in the field of inverse reinforcement learning and for resolution of Markov Decision Problems with Imprecise Rewards. Two key questions are whether the advice required by a specific method is natural for the user to give, and how much advice is needed for the agent to compute a good policy, as evaluated by the user. We give a unified view of a number of proposals made in the literature, and propose a new notion of advice, which corresponds to a user telling why she would take a given action in a given state. For all these notions, we discuss their naturalness for a user and the integration of advice. We then report on an experimental study of the amount of advice needed for the agent to compute a good policy. Our study shows in particular that continual interaction between the user and the agent is worthwhile, and sheds light on the pros and cons of each type of advice.",
        "A1": "sequential decision making problems under uncertainty",
        "A2": "sequential decision making problems under uncertainty",
        "A41": "a unified view of a number of proposals made in the literature, and propose a new notion of advice",
        "A51": "Markov Decision Problems",
        "A61": "",
        "A10": "",
        "A7": "an experimental study of the amount of advice needed for the agent",
        "A83": "",
        "A82": "sheds light on the pros and cons of each type of advice",
        "A81": "continual interaction between the user and the agent is worthwhile",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 243523677
    },
    {
        "Abstract": "Qualitative Decentralized Partially Observable Markov Decision Problems (QDec-POMDPs) constitute a very general class of decision problems. They involve multiple agents, decentralized execution, sequential decision, partial observability, and uncertainty. Typically, joint policies, which prescribe to each agent an action to take depending on its full history of (local) actions and observations, are huge, which makes it difficult to store them onboard, at execution time, and also hampers the computation of joint plans. We propose and investigate a new representation for joint policies in QDec-POMDPs, which we call Multi-Agent Knowledge-Based Programs (MAKBPs), and which uses epistemic logic for compactly representing conditions on histories. Contrary to standard representations, executing an MAKBP requires reasoning at execution time, but we show that MAKBPs can be exponentially more succinct than any reactive representation.",
        "A1": "",
        "A2": "Qualitative Decentralized Partially Observable Markov Decision Problems (QDec-POMDPs) constitute a very general class of decision problems. ",
        "A41": "a new representation for joint policies in QDec-POMDPs, which we call Multi-Agent Knowledge-Based Programs (MAKBPs)",
        "A51": "uses epistemic logic for compactly representing conditions on histories",
        "A61": "Contrary to standard representations, executing an MAKBP requires reasoning at execution time",
        "A10": "we show that MAKBPs can be exponentially more succinct than any reactive representation.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 160978285
    },
    {
        "Abstract": "The clustering methods have absorbed even-increasing attention in machine learning and computer vision communities in recent years. Exploring manifold information in multi-way graph cut clustering, such as ratio cut clustering, has shown its promising performance. However, traditional multi-way ratio cut clustering method is NP-hard and thus the spectral solution may deviate from the optimal one. In this paper, we propose a new relaxed multi-way graph cut clustering method, where l2,1-norm distance instead of squared distance is utilized to preserve the solution having much more clearer cluster structures. Furthermore, the resulting solution is constrained with normalization to obtain more sparse representation, which can encourage the solution to contain more discrete values with many zeros. For the objective function, it is very difficult to optimize due to minimizing the ratio of two non-smooth items. To address this problem, we transform the objective function into a quadratic problem on the Stiefel manifold (QPSM), and introduce a novel yet efficient iterative algorithm to solve it. Experimental results on several benchmark datasets show that our method significantly outperforms several state-of-the-art clustering approaches.",
        "A1": "we propose a new relaxed multi-way graph cut clustering method, where l2,1-norm distance instead of squared distance is utilized to preserve the solution having much more clearer cluster structures",
        "A2": "traditional multi-way ratio cut clustering method is NP-hard and thus the spectral solution may deviate from the optimal one.",
        "A41": " a new relaxed multi-way graph cut clustering method, where l2,1-norm distance instead of squared distance is utilized to preserve the solution having much more clearer cluster structures.",
        "A51": " we transform the objective function into a quadratic problem on the Stiefel manifold (QPSM), and introduce a novel yet efficient iterative algorithm to solve it.",
        "A61": "l2,1-norm distance instead of squared distance",
        "A10": "our method significantly outperforms several state-of-the-art clustering approaches.",
        "A7": "Experimental results on several benchmark datasets",
        "A83": "",
        "A82": "l2,1-norm distance instead of squared distance is utilized to preserve the solution having much more clearer cluster structures.",
        "A81": "our method significantly outperforms several state-of-the-art clustering approaches.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": null
    },
    {
        "Abstract": "Single image dehazing is a challenging under-constrained problem because of the ambiguities of unknown scene radiance and transmission. Previous methods solve this problem using various hand-designed priors or by supervised training on synthetic hazy image pairs. In practice, however, the predefined priors are easily violated and the paired image data is unavailable for supervised training. In this work, we propose Disentangled Dehazing Network, an end-to-end model that generates realistic haze-free images using only unpaired supervision. Our approach alleviates the paired training constraint by introducing a physical-model based disentanglement and reconstruction mechanism. A multi-scale adversarial training is employed to generate perceptually haze-free images. Experimental results on synthetic datasets demonstrate our superior performance compared with the state-of-the-art methods in terms of PSNR, SSIM and CIEDE2000. Through training on purely natural haze-free and hazy images from our collected HazyCity dataset, our model can generate more perceptually appealing dehazing results.",
        "A1": "Single image dehazing",
        "A2": " the predefined priors are easily violated and the paired image data is unavailable for supervised training.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "hrough training on purely natural haze-free and hazy images from our collected HazyCity dataset, our model can generate more perceptually appealing dehazing results.",
        "A7": " Experimental results on synthetic datasets demonstrate our superior performance compared with the state-of-the-art methods in terms of PSNR, SSIM and CIEDE2000. ",
        "A83": "",
        "A82": "",
        "A81": "our superior performance compared with the state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Our approach alleviates the paired training constraint by introducing a physical-model based disentanglement and reconstruction mechanism.",
        "A42": "we propose Disentangled Dehazing Network, an end-to-end model that generates realistic haze-free images using only unpaired supervision.",
        "A45": "",
        "am_id": 129245387
    },
    {
        "Abstract": "Causal discovery without intervention is well recognized as a challenging yet powerful data analysis tool, boosting the development of other scientific areas, such as biology, astronomy, and social science. The major technical difficulty behind the observation-based causal discovery is to effectively and efficiently identify causes and effects from correlated variables given the existence of significant noises. Previous studies mostly employ two very different methodologies under Bayesian network framework, namely global likelihood maximization and locally complexity analysis over marginal distributions. While these approaches are effective in their respective problem domains, in this paper, we show that they can be combined to formulate a new global optimization model with local statistical significance, called structural equational likelihood framework (or SELF in short). We provide thorough analysis on the soundness of the model under mild conditions and present efficient heuristic-based algorithms for scalable model training. Empirical evaluations using XGBoost validate the superiority of our proposal over state-of-the-art solutions, on both synthetic and real world causal structures.",
        "A1": "Causal discovery without intervention",
        "A2": "we show that they can be combined to formulate a new global optimization model with local statistical significance, called structural equational likelihood framework",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Empirical evaluations using XGBoost validate the superiority of our proposal over state-of-the-art solutions, on both synthetic and real world causal structures",
        "A7": "Empirical evaluations using XGBoost",
        "A83": "",
        "A82": "",
        "A81": "validate the superiority of our proposal over state-of-the-art solutions, on both synthetic and real world causal structures",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "we show that they can be combined",
        "A52": "global likelihood maximization and locally complexity analysis over marginal distributions",
        "A42": "structural equational likelihood framework",
        "A45": "",
        "am_id": 338364348
    },
    {
        "Abstract": "The problem of video classification is inherently sequential and multimodal, and deep neural models hence need to capture and aggregate the most pertinent signals for a given input video. We propose Keyless Attention as an elegant and efficient means to more effectively account for the sequential nature of the data. Moreover, comparing a variety of multimodal fusion methods, we find that Multimodal Keyless Attention Fusion is the most successful at discerning interactions between modalities. We experiment on four highly heterogeneous datasets, UCF101, ActivityNet, Kinetics, and YouTube-8M to validate our conclusion, and show that our approach achieves highly competitive results. Especially on large-scale data, our method has great advantages in efficiency and performance. Most remarkably, our best single model can achieve 77.0% in terms of the top-1 accuracy and 93.2% in terms of the top-5 accuracy on the Kinetics validation set, and achieve 82.2% in terms of GAP@20 on the official YouTube-8M test set.",
        "A1": "more effectively account for the sequential nature of the data",
        "A2": "deep neural models hence need to capture and aggregate the most pertinent signals for a given input video",
        "A41": "Keyless Attention as an elegant and efficient means",
        "A51": "",
        "A61": "",
        "A10": "our best single model can achieve 77.0% in terms of the top-1 accuracy and 93.2% in terms of the top-5 accuracy on the Kinetics validation set, and achieve 82.2% in terms of GAP@20 on the official YouTube-8M test set.",
        "A7": "We experiment on four highly heterogeneous datasets, UCF101, ActivityNet, Kinetics, and YouTube-8M to validate our conclusion",
        "A83": "that Multimodal Keyless Attention Fusion is the most successful at discerning interactions between modalities.",
        "A82": "Especially on large-scale data, our method has great advantages in efficiency and performance",
        "A81": " our approach achieves highly competitive results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 63499352
    },
    {
        "Abstract": "Automatic facial expression analysis in inter-personal communication is challenging. Not only because conversation partners' facial expressions mutually influence each other, but also because no correct interpretation of facial expressions is possible without taking social context into account. In this paper, we propose a probabilistic framework to model interactional synchronization between conversation partners based on their facial expressions. Interactional synchronization manifests temporal dynamics of conversation partners' mutual influence. In particular, the model allows us to discover a set of common and unique facial synchronization templates directly from natural interpersonal interaction without recourse to any predefined labeling schemes. The facial synchronization templates represent periodical facial event coordinations shared by multiple conversation pairs in a specific social context. We test our model on two different dyadic conversations of negotiation and job-interview. Based on the discovered facial event coordination, we are able to predict their conversation outcomes with higher accuracy than HMMs and GMMs.",
        "A1": "",
        "A2": "Automatic facial expression analysis in inter-personal communication",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "predict their conversation outcomes with higher accuracy than HMMs and GMMs",
        "A7": " We test our model on two different dyadic conversations of negotiation and job-interview",
        "A83": "",
        "A82": "",
        "A81": " predict their conversation outcomes with higher accuracy than HMMs and GMMs",
        "A64": "the model allows us to discover a set of common and unique facial synchronization templates directly from natural interpersonal interaction without recourse to any predefined labeling schemes",
        "A54": "",
        "A44": "a probabilistic framework to model interactional synchronization between conversation partners based on their facial expressions",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 330676872
    },
    {
        "Abstract": "In recent years, research interest in object retrieval has shifted from 2D towards 3D data. Despite many well-designed approaches, we point out that limitations still exist and there is tremendous room for improvement, including the heavy reliance on hand-crafted features, the separated optimization of feature extraction and object retrieval, and the lack of sufficient training samples. In this work, we address the above limitations for 3D object retrieval by developing a novel end-to-end solution named Group Pair Convolutional Neural Network (GPCNN). It can jointly learn the visual features from multiple views of a 3D model and optimize towards the object retrieval task. To tackle the insufficient training data issue, we innovatively employ a pair-wise learning scheme, which learns model parameters from the similarity of each sample pair, rather than the traditional way of learning from sparse label\u2013sample matching. Extensive experiments on three public benchmarks show that our GPCNN solution significantly outperforms the state-of-the-art methods with 3% to 42% improvement in retrieval accuracy.",
        "A1": "In recent years, research interest in object retrieval has shifted from 2D towards 3D data. Despite many well-designed approaches, we point out that limitations still exist and there is tremendous room for improvement",
        "A2": "address the above limitations for 3D object retrieval by developing a novel end-to-end solution named Group Pair Convolutional Neural Network (GPCNN)",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our GPCNN solution significantly outperforms the state-of-the-art methods with 3% to 42% improvement in retrieval accuracy",
        "A7": " Extensive experiments on three public benchmarks",
        "A83": "",
        "A82": "",
        "A81": "our GPCNN solution significantly outperforms the state-of-the-art methods with 3% to 42% improvement in retrieval accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "To tackle the insufficient training data issue, we innovatively employ a pair-wise learning scheme, which learns model parameters from the similarity of each sample pair, rather than the traditional way of learning from sparse label\u2013sample matching",
        "A52": " Convolutional Neural Network",
        "A42": " It can jointly learn the visual features from multiple views of a 3D model and optimize towards the object retrieval task",
        "A45": "",
        "am_id": 89365058
    },
    {
        "Abstract": "I present the outline of my dissertation work, Identifying Private Content for Online Image Sharing. Particularly, in my dissertation, I explore learning models to predict appropriate binary privacy settings (i.e., private, public) for images, before they are shared online. Specifically, I investigate textual features (user-annotated tags and automatically derived tags), and visual semantic features that are transferred from various layers of deep Convolutional Neural Network (CNN). Experimental results show that the learning models based on the proposed features outperform strong baseline models for this task on the Flickr dataset of thousands of images.",
        "A1": " Identifying Private Content for Online Image Sharing",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the learning models based on the proposed features outperform strong baseline models for this task on the Flickr dataset of thousands of images",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "he learning models based on the proposed features outperform strong baseline models for this task on the Flickr dataset of thousands of images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "deep Convolutional Neural Network (CNN)",
        "A42": "learning models to predict appropriate binary privacy settings (i.e., private, public) for images, before they are shared online",
        "A45": "",
        "am_id": 63290349
    },
    {
        "Abstract": "Recent advances in deep domain adaptation reveal that adversarial learning can be embedded into deep networks to learn transferable features that reduce distribution discrepancy between the source and target domains. Existing domain adversarial adaptation methods based on single domain discriminator only align the source and target data distributions without exploiting the complex multimode structures. In this paper, we present a multi-adversarial domain adaptation (MADA) approach, which captures multimode structures to enable fine-grained alignment of different data distributions based on multiple domain discriminators. The adaptation can be achieved by stochastic gradient descent with the gradients computed by back-propagation in linear-time. Empirical evidence demonstrates that the proposed model outperforms state of the art methods on standard domain adaptation datasets.",
        "A1": "adversarial learning can be embedded into deep networks to learn transferable features that reduce distribution discrepancy between the source and target domains",
        "A2": "Existing domain adversarial adaptation methods based on single domain discriminator only align the source and target data distributions without exploiting the complex multimode structures",
        "A41": "captures multimode structures to enable fine-grained alignment of different data distributions",
        "A51": "multiple domain discriminators",
        "A61": " captures multimode structures ",
        "A10": "Empirical evidence demonstrates that the proposed model outperforms state of the art methods on standard domain adaptation datasets.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 441259773
    },
    {
        "Abstract": "Expanding the domain that deep neural network has already learned without accessing old domain data is a challenging task because deep neural networks forget previously learned information when learning new data from a new domain. In this paper, we propose a less-forgetful learning method for the domain expansion scenario. While existing domain adaptation techniques solely focused on adapting to new domains, the proposed technique focuses on working well with both old and new domains without needing to know whether the input is from the old or new domain. First, we present two naive approaches which will be problematic, then we provide a new method using two proposed properties for less-forgetful learning. Finally, we prove the effectiveness of our method through experiments on image classification tasks. All datasets used in the paper, will be released on our website for someone's follow-up study.",
        "A1": "Expanding the domain that deep neural network has already learned without accessing old domain data",
        "A2": "deep neural networks forget previously learned information when learning new data from a new domain",
        "A41": "a less-forgetful learning method for the domain expansion scenario",
        "A51": "",
        "A61": "working well with both old and new domains without needing to know whether the input is from the old or new domain",
        "A10": "",
        "A7": " experiments on image classification tasks",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of our method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " image classification tasks",
        "am_id": 397942418
    },
    {
        "Abstract": "With super-resolution optical microscopy, it is now possible to observe molecular interactions in living cells. The obtained images have a very high spatial precision but their overall quality can vary a lot depending on the structure of interest and the imaging parameters. Moreover, evaluating this quality is often difficult for non-expert users. In this work, we tackle the problem of learning the quality function of super-resolution images from scores provided by experts. More specifically, we are proposing a system based on a deep neural network that can provide a quantitative quality measure of a STED image of neuronal structures given as input. We conduct a user study in order to evaluate the quality of the predictions of the neural network against those of a human expert. Results show the potential while highlighting some of the limits of the proposed approach.",
        "A1": "provide a quantitative quality measure of a STED image of neuronal structures given as input",
        "A2": "tackle the problem of learning the quality function of super-resolution images from scores provided by experts",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "conduct a user study",
        "A83": "",
        "A82": "evaluate the quality of the predictions of the neural network against those of a human expert",
        "A81": "the potential while highlighting some of the limits of the proposed approach",
        "A64": "",
        "A54": "deep neural network",
        "A44": "a system based on a deep neural network that can provide a quantitative quality measure of a STED image of neuronal structures given as input",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 118284141
    },
    {
        "Abstract": "Cell nuclei detection and fine-grained classification have been fundamental yet challenging problems in histopathology image analysis. Due to the nuclei tiny size, significant inter-/intra-class variances, as well as the inferior image quality, previous automated methods would easily suffer from limited accuracy and robustness. In the meanwhile, existing approaches usually deal with these two tasks independently, which would neglect the close relatedness of them. In this paper, we present a novel method of sibling fully convolutional network with prior objectness interaction (called SFCN-OPI) to tackle the two tasks simultaneously and interactively using a unified end-to-end framework. Specifically, the sibling FCN branches share features in earlier layers while holding respective higher layers for specific tasks. More importantly, the detection branch outputs the objectness prior which dynamically interacts with the fine-grained classification sibling branch during the training and testing processes. With this mechanism, the fine-grained classification successfully focuses on regions with high confidence of nuclei existence and outputs the conditional probability, which in turn benefits the detection through back propagation. Extensive experiments on colon cancer histology images have validated the effectiveness of our proposed SFCN-OPI and our method has outperformed the state-of-the-art methods by a large margin.",
        "A1": "present a novel method of sibling fully convolutional network with prior objectness interaction (called SFCN-OPI) to tackle the two tasks simultaneously and interactively using a unified end-to-end framework",
        "A2": "Cell nuclei detection and fine-grained classification",
        "A41": "a novel method of sibling fully convolutional network with prior objectness interaction (called SFCN-OPI) to tackle the two tasks simultaneously and interactively using a unified end-to-end framework",
        "A51": "",
        "A61": "focuses on regions with high confidence of nuclei existence and outputs the conditional probability",
        "A10": "our method has outperformed the state-of-the-art methods by a large margin",
        "A7": " Extensive experiments on colon cancer histology images",
        "A83": "",
        "A82": "",
        "A81": "our method has outperformed the state-of-the-art methods by a large margin",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 31569142
    },
    {
        "Abstract": "We introduce an architecture, the Tensor Product RecurrentNetwork (TPRN). In our application of TPRN, internal representations\u2014learned by end-to-end optimization in a deep neural network performing a textual question-answering(QA) task\u2014can be interpreted using basic concepts from linguistic theory. No performance penalty need be paid for this increased interpretability: the proposed model performs comparably to a state-of-the-art system on the SQuAD QA task.The internal representation which is interpreted is a Tensor Product Representation: for each input word, the model selects a symbol to encode the word, and a role in which to place the symbol, and binds the two together. The selection is via soft attention. The overall interpretation is built from interpretations of the symbols, as recruited by the trained model, and interpretations of the roles as used by the model. We find support for our initial hypothesis that symbols can be interpreted as lexical-semantic word meanings, while roles can be interpreted as approximations of grammatical roles (or categories)such as subject, wh-word, determiner, etc. Fine-grained analysis reveals specific correspondences between the learned roles and parts of speech as assigned by a standard tagger(Toutanova et al. 2003), and finds several discrepancies in the model\u2019s favor. In this sense, the model learns significant aspectsof grammar, after having been exposed solely to linguistically unannotated text, questions, and answers: no prior linguistic knowledge is given to the model. What is given is the means to build representations using symbols and roles, with an inductive bias favoring use of these in an approximately discrete manner.",
        "A1": "introduce an architecture, the Tensor Product RecurrentNetwork ",
        "A2": "performing a textual question-answering(QA) task\u2014can be interpreted using basic concepts from linguistic theory.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "end-to-end optimization in a deep neural network ",
        "A44": "performing a textual question-answering(QA) task\u2014can be interpreted using basic concepts from linguistic theory.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 16440353
    },
    {
        "Abstract": "Observing that many real-world sequential decision problems are not purely cooperative or purely competitive, we propose a new model\u2014cooperative-competitive process (CCP)\u2014that can simultaneously encapsulate both cooperation and competition. First, we discuss how the CCP model bridges the gap between cooperative and competitive models. Next, we investigate a specific class of group-dominant CCPs, in which agents cooperate to achieve a common goal as their primary objective, while also pursuing individual goals as a secondary objective. We provide an approximate solution for this class of problems that leverages stochastic finite-state controllers. The model is grounded in two multi-robot meeting and box-pushing domains that are implemented in simulation and demonstrated on two real robots.",
        "A1": "simultaneously encapsulate both cooperation and competition",
        "A2": "real-world sequential decision problems",
        "A41": "cooperative-competitive process",
        "A51": "",
        "A61": "simultaneously encapsulate both cooperation and competition",
        "A10": "bridges the gap between cooperative and competitive models",
        "A7": "two multi-robot meeting and box-pushing domains",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "bridges the gap between cooperative and competitive models",
        "A52": "cooperative and competitive models",
        "A42": "CCP model",
        "A45": "",
        "am_id": 360770268
    },
    {
        "Abstract": "The recurrent neural networks (RNNs) have shown good performance for sentence similarity modeling in recent years. Most RNNs focus on modeling the hidden states based on the current sentence, while the context information from the other sentence is not well investigated during the hidden state generation. In this paper, we propose a context-aligned RNN (CA-RNN) model, which incorporates the contextual information of the aligned words in a sentence pair for the inner hidden state generation. Specifically, we first perform word alignment detection to identify the aligned words in the two sentences. Then, we present a context alignment gating mechanism and embed it into our model to automatically absorb the aligned words' context for the hidden state update. Experiments on three benchmark datasets, namely TREC-QA and WikiQA for answer selection and MSRP for paraphrase identification, show the great advantages of our proposed model. In particular, we achieve the new state-of-the-art performance on TREC-QA and WikiQA. Furthermore, our model is comparable to if not better than the recent neural network based approaches on MSRP.",
        "A1": "the inner hidden state generation",
        "A2": "the context information from the other sentence is not well investigated during the hidden state generation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on three benchmark datasets, namely TREC-QA and WikiQA for answer selection and MSRP for paraphrase identification",
        "A83": "",
        "A82": "comparable to if not better than the recent neural network based approaches on MSRP",
        "A81": "achieve the new state-of-the-art performance on TREC-QA and WikiQA",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "incorporates the contextual information of the aligned words in a sentence pair ",
        "A52": "",
        "A42": " a context-aligned RNN (CA-RNN) model",
        "A45": "",
        "am_id": 421624518
    },
    {
        "Abstract": "Typically, neural conversation systems generate replies based on the sequence-to-sequence (seq2seq) model. seq2seq tends to produce safe and universal replies, which suffers from the lack of diversity and information. Determinantal Point Processes (DPPs) is a probabilistic model defined on item sets, which can select the items with good diversity and quality. In this paper, we investigate the diversity issue in two different aspects, namely query-level and system-level diversity. We propose a novel framework which organically combines seq2seq model with Determinantal Point Processes (DPPs). The new framework achieves high quality in generated reply and significantly improves the diversity among them. Experiments show that our model achieves the best performance among various baselines in terms of both quality and diversity.",
        "A1": "combines seq2seq model with Determinantal Point Processes (DPPs)",
        "A2": "seq2seq tends to produce safe and universal replies, which suffers from the lack of diversity and information",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "show that our model achieves the best performance among various baselines in terms of both quality and diversity",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "show that our model achieves the best performance among various baselines in terms of both quality and diversity",
        "A64": "The new framework achieves high quality in generated reply and significantly improves the diversity among them",
        "A54": "neural conversation systems",
        "A44": "a novel framework which organically combines seq2seq model with Determinantal Point Processes (DPPs)",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 761239
    },
    {
        "Abstract": "Electricity disaggregation identifies individual appliances from one or more aggregate data streams and has immense potential to reduce residential and commercial electrical waste. Since supervised learning methods rely on meticulously labeled training samples that are expensive to obtain, unsupervised methods show the most promise for wide-spread application. However, unsupervised learning methods previously applied to electricity disaggregation suffer from critical limitations. This paper introduces the concept of iterative appliance discovery, a novel unsupervised disaggregation method that progressively identifies the \"easiest to find\" or \"most likely\" appliances first. Once these simpler appliances have been identified, the computational complexity of the search space can be significantly reduced, enabling iterative discovery to identify more complex appliances. We test iterative appliance discovery against an existing competitive unsupervised method using two publicly available datasets. Results using different sampling rates show iterative discovery has faster runtimes and produces better accuracy. Furthermore, iterative discovery does not require prior knowledge of appliance characteristics and demonstrates unprecedented scalability to identify long, overlapped sequences that other unsupervised learning algorithms cannot.",
        "A1": "This paper introduces the concept of iterative appliance discovery, a novel unsupervised disaggregation method that progressively identifies the \"easiest to find\" or \"most likely\" appliances first",
        "A2": "unsupervised learning methods previously applied to electricity disaggregation suffer from critical limitations.",
        "A41": "a novel unsupervised disaggregation method that progressively identifies the \"easiest to find\" or \"most likely\" appliances first",
        "A51": "unsupervised learning methods",
        "A61": "",
        "A10": "iterative discovery does not require prior knowledge of appliance characteristics and demonstrates unprecedented scalability to identify long, overlapped sequences that other unsupervised learning algorithms cannot.",
        "A7": "test iterative appliance discovery against an existing competitive unsupervised method using two publicly available datasets",
        "A83": "",
        "A82": "iterative discovery does not require prior knowledge of appliance characteristics and demonstrates unprecedented scalability to identify long, overlapped sequences that other unsupervised learning algorithms cannot.",
        "A81": "show iterative discovery has faster runtimes and produces better accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 73930718
    },
    {
        "Abstract": "Online symptom checkers have been deployed by sites such as WebMD and Mayo Clinic to identify possible causes and treatments for diseases based on a patient\u2019s symptoms. Symptom checking first assesses a patient by asking a series of questions about their symptoms, then attempts to predict potential diseases. The two design goals of a symptom checker are to achieve high accuracy and intuitive interactions. In this paper we present our context-aware hierarchical reinforcement learning scheme, which significantly improves accuracy of symptom checking over traditional systems while also making a limited number of inquiries.",
        "A1": "Symptom checking",
        "A2": "achieve high accuracy and intuitive interactions",
        "A41": "context-aware hierarchical reinforcement learning",
        "A51": "reinforcement learning",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "making a limited number of inquiries",
        "A81": "accuracy of symptom checking",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 403677656
    },
    {
        "Abstract": "Dynamics of human body skeletons convey significant information for human action recognition. Conventional approaches for modeling skeletons usually rely on hand-crafted parts or traversal rules, thus resulting in limited expressive power and difficulties of generalization. In this work, we propose a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN), which moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data. This formulation not only leads to greater expressive power but also stronger generalization capability. On two large datasets, Kinetics and NTU-RGBD, it achieves substantial improvements over mainstream methods.",
        "A1": "human action recognition",
        "A2": " limited expressive power and difficulties of generalization",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves substantial improvements over mainstream methods",
        "A7": " On two large datasets, Kinetics and NTU-RGBD",
        "A83": " stronger generalization capability",
        "A82": "greater expressive power",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "moves beyond the limitations of previous methods by automatically learning both the spatial and temporal patterns from data",
        "A52": "",
        "A42": "a novel model of dynamic skeletons called Spatial-Temporal Graph Convolutional Networks (ST-GCN)",
        "A45": "",
        "am_id": 334015384
    },
    {
        "Abstract": "Affective image understanding has been extensively studied in the last decade since more and more users express emotion via visual contents. While current algorithms based on convolutional neural networks aim to distinguish emotional categories in a discrete label space, the task is inherently ambiguous. This is mainly because emotional labels with the same polarity (i.e., positive or negative) are highly related, which is different from concrete object concepts such as cat, dog and bird. To the best of our knowledge, few methods focus on leveraging such characteristic of emotions for affective image understanding. In this work, we address the problem of understanding affective images via deep metric learning and propose a multi-task deep framework to optimize both retrieval and classification goals. We propose the sentiment constraints adapted from the triplet constraints, which are able to explore the hierarchical relation of emotion labels. We further exploit the sentiment vector as an effective representation to distinguish affective images utilizing the texture representation derived from convolutional layers. Extensive evaluations on four widely-used affective datasets, i.e., Flickr and Instagram, IAPSa, Art Photo, and Abstract Paintings, demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods on both affective image retrieval and classification tasks.",
        "A1": "propose a multi-task deep framework to optimize both retrieval and classification goals",
        "A2": "the problem of understanding affective images via deep metric learning",
        "A41": " the sentiment constraints",
        "A51": " the triplet constraints",
        "A61": "explore the hierarchical relation of emotion labels",
        "A10": "",
        "A7": "Extensive evaluations on four widely-used affective datasets",
        "A83": "",
        "A82": "",
        "A81": " the proposed algorithm performs favorably against the state-of-the-art methods on both affective image retrieval and classification tasks",
        "A64": "",
        "A54": "",
        "A44": "a multi-task deep framework",
        "A63": "explore the hierarchical relation of emotion labels",
        "A53": "triplet constraints",
        "A43": "sentiment constraints",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 160988878
    },
    {
        "Abstract": "Neural networks are typically designed to deal with data in tensor forms. In this paper, we propose a novel neural network architecture accepting graphs of arbitrary structure. Given a dataset containing graphs in the form of (G,y) where G is a graph and y is its class, we aim to develop neural networks that read the graphs directly and learn a classification function. There are two main challenges: 1) how to extract useful features characterizing the rich information encoded in a graph for classification purpose, and 2) how to sequentially read a graph in a meaningful and consistent order. To address the first challenge, we design a localized graph convolution model and show its connection with two graph kernels. To address the second challenge, we design a novel SortPooling layer which sorts graph vertices in a consistent order so that traditional neural networks can be trained on the graphs. Experiments on benchmark graph classification datasets demonstrate that the proposed architecture achieves highly competitive performance with state-of-the-art graph kernels and other graph neural network methods. Moreover, the architecture allows end-to-end gradient-based training with original graphs, without the need to first transform graphs into vectors.",
        "A1": "",
        "A2": " 1) how to extract useful features characterizing the rich information encoded in a graph for classification purpose, and 2) how to sequentially read a graph in a meaningful and consistent order. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "highly competitive performance with state-of-the-art graph kernels and other graph neural network methods. Moreover, the architecture allows end-to-end gradient-based training with original graphs, without the need to first transform graphs into vectors.",
        "A7": " benchmark graph classification datasets ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "a localized graph convolution model",
        "A42": " accepting graphs of arbitrary structure. ",
        "A45": "",
        "am_id": 494487296
    },
    {
        "Abstract": "We have witnessed rapid evolution of deep neural network architecture design in the past years. These latest progresses greatly facilitate the developments in various areas such as computer vision and natural language processing. However, along with the extraordinary performance, these state-of-the-art models also bring in expensive computational cost. Directly deploying these models into applications with real-time requirement is still infeasible. Recently, Hinton et al. have shown that the dark knowledge within a powerful teacher model can significantly help the training of a smaller and faster student network. These knowledge are vastly beneficial to improve the generalization ability of the student model. Inspired by their work, we introduce a new type of knowledge---cross sample similarities for model compression and acceleration. This knowledge can be naturally derived from deep metric learning model. To transfer them, we bring the \"learning to rank\" technique into deep metric learning formulation. We test our proposed DarkRank method on various metric learning tasks including pedestrian re-identification, image retrieval and image clustering. The results are quite encouraging. Our method can improve over the baseline method by a large margin. Moreover, it is fully compatible with other existing methods. When combined, the performance can be further boosted.",
        "A1": "introduce a new type of knowledge---cross sample similarities for model compression and acceleration.",
        "A2": "model compression and acceleration",
        "A41": " DarkRank method",
        "A51": "Hinton et al. have shown that the dark knowledge within a powerful teacher model can significantly help the training of a smaller and faster student network.",
        "A61": "it is fully compatible with other existing methods. When combined, the performance can be further boosted.",
        "A10": "When combined, the performance can be further boosted.",
        "A7": " test our proposed DarkRank method on various metric learning tasks",
        "A83": "",
        "A82": "",
        "A81": "Our method can improve over the baseline method by a large margin.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 307379192
    },
    {
        "Abstract": "Existing relation classification methods that rely on distant supervision assume that a bag of sentences mentioning an entity pair are all describing a relation for the entity pair. Such methods, performing classification at the bag level, cannot identify the mapping between a relation and a sentence, and largely suffers from the noisy labeling problem. In this paper, we propose a novel model for relation classification at the sentence level from noisy data. The model has two modules: an instance selector and a relation classifier. The instance selector chooses high-quality sentences with reinforcement learning and feeds the selected sentences into the relation classifier, and the relation classifier makes sentence-level prediction and provides rewards to the instance selector. The two modules are trained jointly to optimize the instance selection and relation classification processes.Experiment results show that our model can deal with the noise of data effectively and obtains better performance for relation classification at the sentence level.",
        "A1": "",
        "A2": "Existing relation classification methods that rely on distant supervision assume that a bag of sentences mentioning an entity pair are all describing a relation for the entity pair. Such methods, performing classification at the bag level, cannot identify the mapping between a relation and a sentence, and largely suffers from the noisy labeling problem.",
        "A41": "we propose a novel model for relation classification at the sentence level from noisy data",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our model can deal with the noise of data effectively and obtains better performance for relation classification at the sentence level.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "The model has two modules: an instance selector and a relation classifier. The instance selector chooses high-quality sentences with reinforcement learning and feeds the selected sentences into the relation classifier, and the relation classifier makes sentence-level prediction and provides rewards to the instance selector. The two modules are trained jointly to optimize the instance selection and relation classification processes.",
        "A42": "we propose a novel model for relation classification at the sentence level from noisy data. ",
        "A45": "",
        "am_id": 90747418
    },
    {
        "Abstract": "Instance Search (INS) is a fundamental problem for many applications, while it is more challenging comparing to traditional image search since the relevancy is defined at the instance level. Existing works have demonstrated the success of many complex ensemble systems that are typically conducted by firstly generating object proposals, and then extracting handcrafted and/or CNN features of each proposal for matching. However, object bounding box proposals and feature extraction are often conducted in two separated steps, thus the effectiveness of these methods collapses. Also, due to the large amount of generated proposals, matching speed becomes the bottleneck that limits its application to large-scale datasets. To tackle these issues, in this paper we propose an effective and efficient Deep Region Hashing (DRH) approach for large-scale INS using an image patch as the query. Specifically, DRH is an end-to-end deep neural network which consists of object proposal, feature extraction, and hash code generation. DRH shares full-image convolutional feature map with the region proposal network, thus enabling nearly cost-free region proposals. Also, each high-dimensional, real-valued region features are mapped onto a low-dimensional, compact binary codes for the efficient object region level matching on large-scale dataset. Experimental results on four datasets show that our DRH can achieve even better performance than the state-of-the-arts in terms of mAP, while the efficiency is improved by nearly 100 times.",
        "A1": "tackle these issues",
        "A2": "propose an effective and efficient Deep Region Hashing (DRH) approach for large-scale INS",
        "A41": "(DRH) approach for large-scale INS ",
        "A51": "an image patch ",
        "A61": "effective and efficient Deep Region Hashing",
        "A10": " achieve even better performance ",
        "A7": "Experimental results on four datasets ",
        "A83": "",
        "A82": " the efficiency is improved by nearly 100 times.",
        "A81": " DRH can achieve even better performance than the state-of-the-arts in terms of mAP",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " four datasets ",
        "am_id": 10091768
    },
    {
        "Abstract": "To have a more meaningful impact, educational applications need to significantly improve the way feedback is offered to teachers and students. We propose two methods for determining propositional-level entailment relations between a reference answer and a student's response. Both methods, one using hand-crafted features and an SVM and the other using word embeddings and deep neural networks, achieve significant improvements over a state-of-the-art system and two alternative approaches.",
        "A1": "propose two methods",
        "A2": "determining propositional-level entailment relations between a reference answer and a student's response",
        "A41": "one using hand-crafted features and an SVM and the other using word embeddings and deep neural networks",
        "A51": "an SVM and the other using word embeddings and deep neural networks",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "achieve significant improvements over a state-of-the-art system and two alternative approaches.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 295165986
    },
    {
        "Abstract": "Generative adversarial networks (GANs) while being very versatile in realistic image synthesis, still are sensitive to the input distribution. Given a set of data that has an imbalance in the distribution, the networks are susceptible to missing modes and not capturing the data distribution. While various methods have been tried to improve training of GANs, these have not addressed the challenges of covering the full data distribution. Specifically, a generator is not penalized for missing a mode. We show that these are therefore still susceptible to not capturing the full data distribution. In this paper, we propose a simple approach that combines an encoder based objective with novel loss functions for generator and discriminator that improves the solution in terms of capturing missing modes. We validate that the proposed method results in substantial improvements through its detailed analysis on toy and real datasets. The quantitative and qualitative results demonstrate that the proposed method improves the solution for the problem of missing modes and improves training of GANs.",
        "A1": "propose a simple approach that combines an encoder based objective with novel loss functions for generator and discriminator that improves the solution in terms of capturing missing modes.",
        "A2": "capturing missing modes.",
        "A41": " combines an encoder based objective with novel loss functions for generator and discriminator",
        "A51": "novel loss functions for generator and discriminator",
        "A61": "improves the solution for the problem of missing modes and improves training of GANs.",
        "A10": "improves the solution for the problem of missing modes and improves training of GANs.",
        "A7": "through its detailed analysis on toy and real datasets. ",
        "A83": "",
        "A82": " improves training of GANs.",
        "A81": "proposed method improves the solution for the problem of missing modes",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 131103937
    },
    {
        "Abstract": "While conversing with chatbots, humans typically tend to ask many questions, a significant portion of which can be answered by referring to large-scale knowledge graphs (KG). While Question Answering (QA) and dialog systems have been studied independently, there is a need to study them closely to evaluate such real-world scenarios faced by bots involving both these tasks. Towards this end, we introduce the task of Complex Sequential QA which combines the two tasks of (i) answering factual questions through complex inferencing over a realistic-sized KG of millions of entities, and (ii) learning to converse through a series of coherently linked QA pairs. Through a labor intensive semi-automatic process, involving in-house and crowdsourced workers, we created a dataset containing around 200K dialogs with a total of 1.6M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in our dialogs require a larger subgraph of the KG. Specifically, our dataset has questions which require logical, quantitative, and comparative reasoning as well as their combinations. This calls for models which can: (i) parse complex natural language questions, (ii) use conversation context to resolve coreferences and ellipsis in utterances, (iii) ask for clarifications for ambiguous queries, and finally (iv) retrieve relevant subgraphs of the KG to answer such questions. However, our experiments with a combination of state of the art dialog and QA models show that they clearly do not achieve the above objectives and are inadequate for dealing with such complex real world settings. We believe that this new dataset coupled with the limitations of existing models as reported in this paper should encourage further research in Complex Sequential QA.",
        "A1": "Complex Sequential QA ",
        "A2": "Complex Sequential QA ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "inadequate for dealing with such complex real world settings",
        "A82": "do not achieve the above objectives",
        "A81": "require a larger subgraph of the KG",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "200K dialogs with a total of 1.6M turns",
        "am_id": 450996734
    },
    {
        "Abstract": "Effective solving of constraint problems often requires choosing good or specific search heuristics. However, choosing or designing a good search heuristic is non-trivial and is often a manual process. In this paper, rather than manually choosing/designing search heuristics, we propose the use of bandit-based learning techniques to automatically select search heuristics. Our approach is online where the solver learns and selects from a set of heuristics during search. The goal is to obtain automatic search heuristics which give robust performance. Preliminary experiments show that our adaptive technique is more robust than the original search heuristics. It can also outperform the original heuristics.",
        "A1": "propose the use of bandit-based learning techniques to automatically select search heuristics",
        "A2": "Effective solving of constraint problems",
        "A41": "automatically select search heuristics",
        "A51": "bandit-based learning techniques",
        "A61": "online ",
        "A10": "",
        "A7": "Preliminary experiments",
        "A83": "",
        "A82": "outperform the original heuristics",
        "A81": "more robust than the original search heuristics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 340069605
    },
    {
        "Abstract": "In this paper, we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. By mimicking the relational structure of planning problems, ASNets are able to adopt a weight sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain. Further, we propose a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems. In experiments, we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.",
        "A1": "we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. ",
        "A2": "adopt a weight sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain.",
        "A41": "a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems.",
        "A51": "",
        "A61": "",
        "A10": "we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "By mimicking the relational structure of planning problems, ASNets are able to adopt a weight sharing scheme which allows the network to be applied to any problem from a given planning domain",
        "A52": "",
        "A42": "the Action Schema Network (ASNet)",
        "A45": "",
        "am_id": 324116732
    },
    {
        "Abstract": "To capture the inherent geometric features of many community detection problems, we propose to use a new random graph model of communities that we call a Geometric Block Model. The geometric block model generalizes the random geometric graphs in the same way that the well-studied stochastic block model generalizes the Erd\u00f6s-Renyi random graphs. It is also a natural extension of random community models inspired by the recent theoretical and practical advancement in community detection. While being a topic of fundamental theoretical interest, our main contribution is to show that many practical community structures are better explained by the geometric block model. We also show that a simple triangle-counting algorithm to detect communities in the geometric block model is near-optimal. Indeed, even in the regime where the average degree of the graph grows only logarithmically with the number of vertices (sparse-graph), we show that this algorithm performs extremely well, both theoretically and practically. In contrast, the triangle-counting algorithm is far from being optimum for the stochastic block model. We simulate our results on both real and synthetic datasets to show superior performance of both the new model as well as our algorithm.",
        "A1": "To capture the inherent geometric features of many community detection problems",
        "A2": ". The geometric block model generalizes the random geometric graphs in the same way that the well-studied stochastic block model generalizes the Erd\u00f6s-Renyi random graphs. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " show superior performance of both the new model as well as our algorithm.",
        "A7": "We simulate our results on both real and synthetic datasets",
        "A83": "",
        "A82": "",
        "A81": " show superior performance of both the new model as well as our algorithm.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "The geometric block model generalizes the random geometric graphs in the same way that the well-studied stochastic block model generalizes the Erd\u00f6s-Renyi random graphs. It is also a natural extension of random community models inspired by the recent theoretical and practical advancement in community detection.",
        "A52": "a new random graph model of communities",
        "A42": "use a new random graph model of communities that we call a Geometric Block Model. ",
        "A45": "",
        "am_id": 234404309
    },
    {
        "Abstract": "The Leiter International Performance Scale-Revised (Leiter-R) is a standardized cognitive test that seeks to \"provide a nonverbal measure of general intelligence by sampling a wide variety of functions from memory to nonverbal reasoning.\" Understanding the computational building blocks of nonverbal cognition, as measured by the Leiter-R, is an important step towards understanding human nonverbal cognition, especially with respect to typical and atypical trajectories of child development. One subtest of the Leiter-R, Form Completion, involves synthesizing and localizing a visual figure from its constituent slices. Form Completion poses an interesting nonverbal problem that seems to combine several aspects of visual memory, mental rotation, and visual search. We describe a new computational cognitive model that addresses Form Completion using a novel, mental-rotation-friendly image representation that we call the Polar Augmented Resolution (PolAR) Picture, which enables high-fidelity mental rotation operations. We present preliminary results using actual Leiter-R test items and discuss directions for future work.",
        "A1": " Understanding the computational building blocks of nonverbal cognition, as measured by the Leiter-R",
        "A2": "Form Completion ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "using actual Leiter-R test items ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "enables high-fidelity mental rotation operations.",
        "A52": " Polar Augmented Resolution (PolAR) Picture, which enables high-fidelity mental rotation operations",
        "A42": " a new computational cognitive model",
        "A45": "",
        "am_id": 237462201
    },
    {
        "Abstract": "Two key aspects of problem solving are representation and search heuristics. Both theoretical and experimental studies have shown that there is no one best problem representation nor one best search heuristic. Therefore, some recent methods, e.g., portfolios, learn a good combination of problem solvers to be used in a given domain or set of domains. There are even dynamic portfolios that select a particular combination of problem solvers specific to a problem. These approaches: (1) need to perform a learning step; (2) do not usually focus on changing the representation of the input domain/problem; and (3) frequently do not adapt the portfolio to the specific problem. This paper describes a meta-reasoning system that searches through the space of combinations of representations and heuristics to find one suitable for optimally solving the specific problem. We show that this approach can be better than selecting a combination to use for all problems within a domain and is competitive with state of the art optimal planners.",
        "A1": " representation and search heuristics",
        "A2": " These approaches: (1) need to perform a learning step; (2) do not usually focus on changing the representation of the input domain/problem; and (3) frequently do not adapt the portfolio to the specific problem",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "this approach can be better than selecting a combination to use for all problems within a domain and is competitive with state of the art optimal planners",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "a meta-reasoning system that searches through the space of combinations of representations and heuristics to find one suitable for optimally solving the specific problem",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 347761016
    },
    {
        "Abstract": "Scan statistics is one of the most popular approaches for anomaly detection in spatial and network data. In practice, there are numerous sources of uncertainty in the observed data. However, most prior works have overlooked such uncertainty, which can affect the accuracy and inferences of such methods. In this paper, we develop the first systematic approach to incorporating uncertainty in scan statistics. We study two formulations for robust scan statistics, one based on the sample average approximation and the other using a max-min objective. We show that uncertainty significantly increases the computational complexity of these problems. Rigorous algorithms and efficient heuristics for both formulations are developed with justification of theoretical bounds. We evaluate our proposed methods on synthetic and real datasets, and we observe that our methods give significant improvement in the detection power as well as optimization objective, relative to a baseline.",
        "A1": "anomaly detection in spatial and network data",
        "A2": "numerous sources of uncertainty in the observed data",
        "A41": "the first systematic approach",
        "A51": "one based on the sample average approximation and the other using a max-min objective",
        "A61": "incorporating uncertainty in scan statistics",
        "A10": " give significant improvement in the detection power as well as optimization objective, relative to a baseline",
        "A7": "on synthetic and real datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 332334977
    },
    {
        "Abstract": "Driven by the wave of urbanization in recent decades, the research topic about migrant behavior analysis draws great attention from both academia and the government. Nevertheless, subject to the cost of data collection and the lack of modeling methods, most of existing studies use only questionnaire surveys with sparse samples and non-individual level statistical data to achieve coarse-grained studies of migrant behaviors. In this paper, a partially supervised cross-domain deep learning model named CD-CNN is proposed for migrant/native recognition using mobile phone signaling data as behavioral features and questionnaire survey data as incomplete labels. Specifically, CD-CNN features in decomposing the mobile data into location domain and communication domain, and adopts a joint learning framework that combines two convolutional neural networks with a feature balancing scheme. Moreover, CD-CNN employs a three-step algorithm for training, in which the co-training step is of great value to partially supervised cross-domain learning. Comparative experiments on the city Wuxi demonstrate the high predictive power of CD-CNN. Two interesting applications further highlight the ability of CD-CNN for in-depth migrant behavioral analysis.",
        "A1": "",
        "A2": " Nevertheless, subject to the cost of data collection and the lack of modeling methods, most of existing studies use only questionnaire surveys with sparse samples and non-individual level statistical data to achieve coarse-grained studies of migrant behaviors.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Comparative experiments on the city Wuxi ",
        "A83": "",
        "A82": "Two interesting applications further highlight the ability of CD-CNN for in-depth migrant behavioral analysis.",
        "A81": "he high predictive power of CD-CNN",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "using mobile phone signaling data as behavioral features and questionnaire survey data as incomplete labels.",
        "A52": "",
        "A42": " partially supervised cross-domain deep learning model named CD-CNN is proposed for migrant/native recognition ",
        "A45": "",
        "am_id": 283015090
    },
    {
        "Abstract": "In machine learning research, the proximal gradient methods are popular for solving various optimization problems with non-smooth regularization. Inexact proximal gradient methods are extremely important when exactly solving the proximal operator is time-consuming, or the proximal operator does not have an analytic solution. However, existing inexact proximal gradient methods only consider convex problems. The knowledge of inexact proximal gradient methods in the non-convex setting is very limited. To address this challenge, in this paper, we first propose three inexact proximal gradient algorithms, including the basic version and Nesterov\u2019s accelerated version. After that, we provide the theoretical analysis to the basic and Nesterov\u2019s accelerated versions. The theoretical results show that our inexact proximal gradient algorithms can have the same convergence rates as the ones of exact proximal gradient algorithms in the non-convex setting. Finally, we show the applications of our inexact proximal gradient algorithms on three representative non-convex learning problems. Empirical results confirm the superiority of our new inexact proximal gradient algorithms.",
        "A1": "propose three inexact proximal gradient algorithms",
        "A2": "The knowledge of inexact proximal gradient methods in the non-convex setting is very limited.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "show the applications of our inexact proximal gradient algorithms on three representative non-convex learning problems",
        "A83": "",
        "A82": "",
        "A81": "confirm the superiority of our new inexact proximal gradient algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "inexact proximal gradient algorithms can have the same convergence rates as the ones of exact proximal gradient algorithms in the non-convex setting",
        "A53": "",
        "A43": "three inexact proximal gradient algorithms, including the basic version and Nesterov\u2019s accelerated version",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 45382225
    },
    {
        "Abstract": "Hashing is widely applied to large-scale image retrieval due to the storage and retrieval efficiency. Existing work on deep hashing assumes that the database in the target domain is identically distributed with the training set in the source domain. This paper relaxes this assumption to a transfer retrieval setting, which allows the database and the training set to come from different but relevant domains. However, the transfer retrieval setting will introduce two technical difficulties: first, the hash model trained on the source domain cannot work well on the target domain due to the large distribution gap; second, the domain gap makes it difficult to concentrate the database points to be within a small Hamming ball. As a consequence, transfer retrieval performance within Hamming Radius 2 degrades significantly in existing hashing methods. This paper presents Transfer Adversarial Hashing (TAH), a new hybrid deep architecture that incorporates a pairwise t-distribution cross-entropy loss to learn concentrated hash codes and an adversarial network to align the data distributions between the source and target domains. TAH can generate compact transfer hash codes for efficient image retrieval on both source and target domains. Comprehensive experiments validate that TAH yields state of the art Hamming space retrieval performance on standard datasets.",
        "A1": "This paper relaxes this assumption to a transfer retrieval setting, which allows the database and the training set to come from different but relevant domains",
        "A2": " first, the hash model trained on the source domain cannot work well on the target domain due to the large distribution gap; second, the domain gap makes it difficult to concentrate the database points to be within a small Hamming ball.",
        "A41": "Transfer Adversarial Hashing (TAH)",
        "A51": "a new hybrid deep architecture that incorporates a pairwise t-distribution cross-entropy loss to learn concentrated hash codes and an adversarial network to align the data distributions between the source and target domains",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 366729145
    },
    {
        "Abstract": "We present a new segmentation method that leverages latent photographic information available at the moment of taking pictures. Photography on a portable device is often done by tapping to focus before shooting the picture. This tap-and-shoot interaction for photography not only specifies the region of interest but also yields useful focus/defocus cues for image segmentation. However, most of the previous interactive segmentation methods address the problem of image segmentation in a post-processing scenario without considering the action of taking pictures. We propose a learning-based approach to this new tap-and-shoot scenario of interactive segmentation. The experimental results on various datasets show that, by training a deep convolutional network to integrate the selection and focus/defocus cues, our method can achieve higher segmentation accuracy in comparison with existing interactive segmentation methods.",
        "A1": "present a new segmentation method",
        "A2": "most of the previous interactive segmentation methods address the problem of image segmentation in a post-processing scenario without considering the action of taking pictures.",
        "A41": "a learning-based approach to this new tap-and-shoot scenario of interactive segmentation",
        "A51": "tap-and-shoot interaction for photography not only specifies the region of interest but also yields useful focus/defocus cues for image segmentation",
        "A61": " most of the previous interactive segmentation methods address the problem of image segmentation in a post-processing scenario without considering the action of taking pictures. ",
        "A10": "",
        "A7": "experimental results on various datasets",
        "A83": "",
        "A82": "",
        "A81": "achieve higher segmentation accuracy in comparison with existing interactive segmentation methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 66440717
    },
    {
        "Abstract": "Can student behavior be anticipated in real-time so that an intelligent tutor system can adapt its content to keep the student engaged? Current methods detect affective states of students during learning session to determine their engagement levels but apply the learning in next session in the form of intervention policies and tutor responses. However, if students' imminent behavioral action could be anticipated from their affective states in real-time, this could lead to much more responsive intervention policies by the tutor and assist in keeping the student engaged in an activity, thereby increasing tutor efficacy as well as student engagement levels. In this paper we explore if there exist any links between a student's affective states and his/her imminent behavior action in RoboTutor, an intelligent tutor system for children to learn math, reading and writing. We then exploit our findings to develop a real-time student behavior prediction module.",
        "A1": "explore if there exist any links between a student's affective states and his/her imminent behavior action",
        "A2": "increasing tutor efficacy as well as student engagement levels",
        "A41": "students' imminent behavioral action could be anticipated from their affective states in real-time",
        "A51": "Current methods",
        "A61": "increasing tutor efficacy as well as student engagement levels",
        "A10": "a real-time student behavior prediction module",
        "A7": "explore if there exist any links between a student's affective states and his/her imminent behavior action in RoboTutor",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": " students' imminent behavioral action could be anticipated from their affective states in real-time",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "real-time",
        "A52": " students' imminent behavioral action could be anticipated from their affective states in real-time",
        "A42": " students' imminent behavioral action could be anticipated from their affective states in real-time",
        "A45": "",
        "am_id": 433201555
    },
    {
        "Abstract": "Product compatibility and functionality are of utmost importance to customers when they purchase products, and to sellers and manufacturers when they sell products. Due to the huge number of products available online, it is infeasible to enumerate and test the compatibility and functionality of every product. In this paper, we address two closely related problems: product compatibility analysis and function satisfiability analysis, where the second problem is a generalization of the first problem (e.g., whether a product works with another product can be considered as a special function). We first identify a novel question and answering corpus that is up-to-date regarding product compatibility and functionality information. To allow automatic discovery product compatibility and functionality, we then propose a deep learning model called Dual Attention Network (DAN). Given a QA pair for a to-be-purchased product, DAN learns to 1) discover complementary products (or functions), and 2) accurately predict the actual compatibility (or satisfiability) of the discovered products (or functions). The challenges addressed by the model include the briefness of QAs, linguistic patterns indicating compatibility, and the appropriate fusion of questions and answers. We conduct experiments to quantitatively and qualitatively show that the identified products and functions have both high coverage and accuracy, compared with a wide spectrum of baselines.",
        "A1": "",
        "A2": "we address two closely related problems: product compatibility analysis and function satisfiability analysis, where the second problem is a generalization of the first problem ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the identified products and functions have both high coverage and accuracy",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "he identified products and functions have both high coverage and accuracy, compared with a wide spectrum of baselines.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Given a QA pair for a to-be-purchased product",
        "A42": "To allow automatic discovery product compatibility and functionality",
        "A45": "We first identify a novel question and answering corpus that is up-to-date regarding product compatibility and functionality information",
        "am_id": 7706772
    },
    {
        "Abstract": "Hashing has been widely used for large-scale approximate nearest neighbor search because of its storage and search efficiency. Recent work has found that deep supervised hashing can significantly outperform non-deep supervised hashing in many applications. However, most existing deep supervised hashing methods adopt a symmetric strategy to learn one deep hash function for both query points and database (retrieval) points. The training of these symmetric deep supervised hashing methods is typically time-consuming, which makes them hard to effectively utilize the supervised information for cases with large-scale database. In this paper, we propose a novel deep supervised hashing method, called asymmetric deep supervised hashing (ADSH), for large-scale nearest neighbor search. ADSH treats the query points and database points in an asymmetric way. More specifically, ADSH learns a deep hash function only for query points, while the hash codes for database points are directly learned. The training of ADSH is much more efficient than that of traditional symmetric deep supervised hashing methods. Experiments show that ADSH can achieve state-of-the-art performance in real applications.",
        "A1": "propose a novel deep supervised hashing method, called asymmetric deep supervised hashing (ADSH), for large-scale nearest neighbor search.",
        "A2": "The training of these symmetric deep supervised hashing methods is typically time-consuming",
        "A41": "a novel deep supervised hashing method, called asymmetric deep supervised hashing (ADSH)",
        "A51": "",
        "A61": "ADSH learns a deep hash function only for query points, while the hash codes for database points are directly learned",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " The training of ADSH is much more efficient than that of traditional symmetric deep supervised hashing methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137533692
    },
    {
        "Abstract": "The technique called splitting sets has been proven useful in simplifying the investigation of Answer Set Programming (ASP). In this paper, we investigate the splitting set theorem for LPMLN that is a new extension of ASP created by combining the ideas of ASP and Markov Logic Networks (MLN). Firstly, we extend the notion of splitting sets to LPMLN programs and present the splitting set theorem for LPMLN. Then, the use of the theorem for simplifying several LPMLN inference tasks is illustrated. After that, we give two parallel approaches for solving LPMLN programs via using the theorem. The preliminary experimental results show that these approaches are alternative ways to promote an LPMLN solver.",
        "A1": "investigate the splitting set theorem for LPMLN",
        "A2": "promote an LPMLN solver",
        "A41": "the splitting set theorem for LPMLN ",
        "A51": "ASP and Markov Logic Networks (MLN)",
        "A61": "simplifying several LPMLN inference tasks",
        "A10": "simplifying several LPMLN inference tasks",
        "A7": "The preliminary experimental ",
        "A83": "extend the notion of splitting sets to LPMLN programs and present the splitting set theorem for LPMLN",
        "A82": "solving LPMLN programs via using the theorem.",
        "A81": "The technique called splitting sets has been proven useful in simplifying the investigation of Answer Set Programming (ASP). ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 241620590
    },
    {
        "Abstract": "Aspect-level sentiment classification aims at detecting the sentiment expressed towards a particular target in a sentence. Based on the observation that the sentiment polarity is often related to specific spans in the given sentence, it is possible to make use of such information for better classification. On the other hand, such information can also serve as justifications associated with the predictions.We propose a segmentation attention based LSTM model which can effectively capture the structural dependencies between the target and the sentiment expressions with a linear-chain conditional random field (CRF) layer.xa0The model simulates human's process of inferring sentiment information when reading: when given a target, humans tend to search for surrounding relevant text spans in the sentence before making an informed decision on the underlying sentiment information.We perform sentiment classification tasks on publicly available datasets on online reviews across different languages from SemEval tasks and social comments from Twitter. Extensive experiments show that our model achieves the state-of-the-art performance while extracting interpretable sentiment expressions.",
        "A1": "detecting the sentiment expressed towards a particular target in a sentence",
        "A2": "Aspect-level sentiment classification",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our model achieves the state-of-the-art performance while extracting interpretable sentiment expressions",
        "A7": "sentiment classification tasks on publicly available datasets on online reviews across different languages from SemEval tasks and social comments from Twitter",
        "A83": "",
        "A82": "",
        "A81": "our model achieves the state-of-the-art performance while extracting interpretable sentiment expressions.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "with a linear-chain conditional random field (CRF) layer",
        "A52": "LSTM model",
        "A42": "a segmentation attention based LSTM model which can effectively capture the structural dependencies between the target and the sentiment expressions",
        "A45": "",
        "am_id": 440746000
    },
    {
        "Abstract": "The potential for agents, whether embodied or software, to learn by observing other agents performing procedures involving objects and actions is rich. Current research on automatic procedure learning heavily relies on action labels or video subtitles, even during the evaluation phase, which makes them infeasible in real-world scenarios. This leads to our question: can the human-consensus structure of a procedure be learned from a large set of long, unconstrained videos (e.g., instructional videos from YouTube) with only visual evidence? To answer this question, we introduce the problem of procedure segmentation---to segment a video procedure into category-independent procedure segments. Given that no large-scale dataset is available for this problem, we collect a large-scale procedure segmentation dataset with procedure segments temporally localized and described; we use cooking videos and name the dataset YouCook2. We propose a segment-level recurrent network for generating procedure segments by modeling the dependencies across segments. The generated segments can be used as pre-processing for other tasks, such as dense video captioning and event parsing. We show in our experiments that the proposed model outperforms competitive baselines in procedure segmentation.",
        "A1": "can the human-consensus structure of a procedure be learned from a large set of long, unconstrained videos (e.g., instructional videos from YouTube) with only visual evidence?",
        "A2": "to segment a video procedure into category-independent procedure segments",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed model outperforms competitive baselines in procedure segmentation.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the proposed model outperforms competitive baselines in procedure segmentation.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "he proposed model outperforms competitive baselines in procedure segmentation.",
        "A52": "",
        "A42": "a segment-level recurrent network for generating procedure segments by modeling the dependencies across segments",
        "A45": "a large-scale procedure segmentation dataset with procedure segments temporally localized and described",
        "am_id": 172643182
    },
    {
        "Abstract": "Action abstractions restrict the number of legal actions available during search in multi-unit real-time adversarial games, thus allowing algorithms to focus their search on a set of promising actions. Optimal strategies derived from un-abstracted spaces are guaranteed to be no worse than optimal strategies derived from action-abstracted spaces. In practice, however, due to real-time constraints and the state space size, one is only able to derive good strategies in un-abstracted spaces in small-scale games. In this paper we introduce search algorithms that use an action  abstraction scheme we call asymmetric abstraction. Asymmetric abstractions retain the un-abstracted spaces' theoretical advantage over regularly abstracted spaces while still allowing the search algorithms to derive effective strategies, even in large-scale games. Empirical results on combat scenarios that arise in a real-time strategy game show that our search algorithms are able to substantially outperform state-of-the-art approaches.",
        "A1": "introduce search algorithms that use an action  abstraction scheme",
        "A2": " retain the un-abstracted spaces' theoretical advantage over regularly abstracted spaces ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "substantially outperform state-of-the-art approaches.",
        "A7": "Empirical results on combat scenarios that arise in a real-time strategy game",
        "A83": "",
        "A82": "search algorithms that use an action  abstraction scheme",
        "A81": "substantially outperform state-of-the-art approaches.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "an action  abstraction scheme",
        "A53": "an action  abstraction scheme",
        "A43": "asymmetric abstraction",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 208136440
    },
    {
        "Abstract": "Policy optimization methods have shown great promise in solving complex reinforcement and imitation learning tasks. While model-free methods are broadly applicable, they often require many samples to optimize complex policies. Model-based methods greatly improve sample-efficiency but at the cost of poor generalization, requiring a carefully handcrafted model of the system dynamics for each task. Recently, hybrid methods have been successful in trading off applicability for improved sample-complexity. However, these have been limited to continuous action spaces. In this work, we present a new hybrid method based on an approximation of the dynamics as an expectation over the next state under the current policy. This relaxation allows us to derive a novel hybrid policy gradient estimator, combining score function and pathwise derivative estimators, that is applicable to discrete action spaces. We show significant gains in sample complexity, ranging between 1.7 and 25 times, when learning parameterized policies on Cart Pole, Acrobot, Mountain Car and Hand Mass. Our method is applicable to both discrete and continuous action spaces, when competing pathwise methods are limited to the latter.",
        "A1": "Policy optimization methods",
        "A2": "solving complex reinforcement and imitation learning tasks",
        "A41": "a new hybrid method based on an approximation of the dynamics as an expectation over the next state under the current policy",
        "A51": "an approximation of the dynamics",
        "A61": "derive a novel hybrid policy gradient estimator, combining score function and pathwise derivative estimators",
        "A10": "applicable to both discrete and continuous action spaces",
        "A7": "Cart Pole, Acrobot, Mountain Car and Hand Mass",
        "A83": "",
        "A82": "",
        "A81": "significant gains in sample complexity",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 254980866
    },
    {
        "Abstract": "Automatic generation of 3D visual content is a fundamental problem that sits at the intersection of visual computing and artificial intelligence. So far, most existing works have focused on geometry synthesis. In contrast, advances in automatic synthesis of color information, which conveys rich semantic information of 3D geometry, remain rather limited. In this paper, we propose to learn a generative model that maps a latent color parameter space to a space of colorizations across a shape collection. The colorizations are diverse on each shape and consistent across the shape collection. We introduce an unsupervised approach for training this generative model and demonstrate its effectiveness across a wide range of categories. The key feature of our approach is that it only requires one colorization per shape in the training data, and utilizes a neural network to propagate the color information of other shapes to train the generative model for each particular shape. This characteristics makes our approach applicable to standard internet shape repositories.",
        "A1": " learn a generative model",
        "A2": "Automatic generation of 3D visual content",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "applicable to standard internet shape repositories",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " advances in automatic synthesis of color information",
        "A52": "",
        "A42": "maps a latent color parameter space to a space of colorizations across a shape collection",
        "A45": "",
        "am_id": 457999886
    },
    {
        "Abstract": "Recently there has been significant activity in developing algorithms with provable guarantees for topic modeling. In this work we consider a broad generalization of the traditional topic modeling framework, where we no longer assume that words are drawn i.i.d. and instead view a topic as a complex distribution over sequences of paragraphs. Since one could not hope to even represent such a distribution in general (even if paragraphs are given using some natural feature representation), we aim instead to directly learn a predictor that given a new document, accurately predicts its topic mixture, without learning the distributions explicitly. We present several natural conditions under which one can do this from unlabeled data only, and give efficient algorithms to do so, also discussing issues such as noise tolerance and sample complexity. More generally, our model can be viewed as a generalization of the multi-view or co-training setting in machine learning.",
        "A1": "developing algorithms with provable guarantees for topic modeling",
        "A2": "",
        "A41": "a broad generalization of the traditional topic modeling framework",
        "A51": "traditional topic modeling framework",
        "A61": " no longer assume that words are drawn i.i.d. and instead view a topic as a complex distribution over sequences of paragraphs",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 413067584
    },
    {
        "Abstract": "We propose a novel method for exploiting the semantic structure of text to answer multiple-choice questions. The approach is especially suitable for domains that require reasoning over a diverse set of linguistic constructs but have limited training data. To address these challenges, we present the first system, to the best of our knowledge, that reasons over a wide range of semantic abstractions of the text, which are derived using off-the-shelf, general-purpose, pre-trained natural language modules such as semantic role labelers, coreference resolvers, and dependency parsers. Representing multiple abstractions as a family of graphs, we translate question answering (QA) into a search for an optimal subgraph that satisfies certain global and local properties. This formulation generalizes several prior structured QA systems. Our system, SEMANTICILP, demonstrates strong performance on two domains simultaneously. In particular, on a collection of challenging science QA datasets, it outperforms various state-of-the-art approaches, including neural models, broad coverage information retrieval, and specialized techniques using structured knowledge bases, by 2%-6%.",
        "A1": "to answer multiple-choice questions",
        "A2": "The approach is especially suitable for domains that require reasoning over a diverse set of linguistic constructs but have limited training data.",
        "A41": "a novel method for exploiting the semantic structure of tex",
        "A51": "",
        "A61": "",
        "A10": "on a collection of challenging science QA datasets, it outperforms various state-of-the-art approaches",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "on a collection of challenging science QA datasets, it outperforms various state-of-the-art approaches, including neural models, broad coverage information retrieval, and specialized techniques using structured knowledge bases, by 2%-6%.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 355365839
    },
    {
        "Abstract": "To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.",
        "A1": "task-oriented language grounding in 3D environments",
        "A2": " task-oriented language grounding.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.",
        "A7": "on unseen instructions as well as unseen maps, both quantitatively and qualitatively.",
        "A83": "",
        "A82": "",
        "A81": "We show the effectiveness of the proposed model ",
        "A64": "",
        "A54": "",
        "A44": "an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods",
        "A42": " an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments",
        "A45": "",
        "am_id": 10765667
    },
    {
        "Abstract": "Context-aware features have been widely recognized as important factors in recommender systems. However, as a major technique in recommender systems, traditional Collaborative Filtering (CF) does not provide a straight-forward way of integrating the context-aware information into personal recommendation. We propose a Coupled Collaborative Filtering (CCF) model to measure the contextual information and use it to improve recommendations. In the proposed approach, coupled similarity computation is designed to be calculated by interitem, intra-context and inter-context interactions among item, user and context-ware factors. Experiments based on different types of CF models demonstrate the effectiveness of our design.",
        "A1": " propose a Coupled Collaborative Filtering (CCF) model to measure the contextual information and use it to improve recommendations",
        "A2": "as a major technique in recommender systems, traditional Collaborative Filtering (CF) does not provide a straight-forward way of integrating the context-aware information into personal recommendation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experiments based on different types of CF models demonstrate the effectiveness of our design.",
        "A7": "Experiments based on different types of CF models demonstrate the effectiveness of our design.",
        "A83": "",
        "A82": "",
        "A81": "Experiments based on different types of CF models demonstrate the effectiveness of our design.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " Coupled Collaborative Filtering (CCF)",
        "A52": " Coupled Collaborative Filtering (CCF)",
        "A42": " propose a Coupled Collaborative Filtering (CCF) model to measure the contextual information and use it to improve recommendations",
        "A45": "",
        "am_id": 406598108
    },
    {
        "Abstract": "While probabilistic planning models have been extensively used by AI and Decision Theoretic communities for planning under uncertainty, the objective to minimize the expected cumulative cost is inappropriate for high-stake planning problems. With this motivation in mind, we revisit the Risk-Sensitive criterion (RS-criterion), where the objective is to find a policy that maximizes the probability that the cumulative cost is within some user-defined cost threshold. The overall scope of this research is to develop efficient and scalable algorithms to optimize the RS-criterion in probabilistic planning problems. In our recent paper (Hou, Yeoh, and Varakantham 2014), we formally defined Risk-Sensitive MDPs (RS-MDPs) and introduced new algorithms for RS-MDPs with non-negative costs. Next, my plan is to develop algorithm for RS-MDPs with negative cost cycles and for Risk-Sensitive POMDPs (RS-POMDPs).",
        "A1": "develop efficient and scalable algorithms to optimize the RS-criterion in probabilistic planning problems",
        "A2": "objective to minimize the expected cumulative cost is inappropriate for high-stake planning problems",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "with negative cost cycles and for Risk-Sensitive POMDPs (RS-POMDPs)",
        "A53": "Risk-Sensitive MDPs (RS-MDPs) and introduced new algorithms for RS-MDPs with non-negative costs",
        "A43": "algorithm for RS-MDPs with negative cost cycles and for Risk-Sensitive POMDPs (RS-POMDPs)",
        "A62": "",
        "A52": "",
        "A42": "Risk-Sensitive MDPs",
        "A45": "",
        "am_id": 157828848
    },
    {
        "Abstract": "Effective tutoring requires personalization of the interaction to each student.Continuous and efficient assessment of the student's skills are a prerequisite for such personalization.We developed a Bayesian active-learning algorithm that continuously and efficiently assesses a child's word-reading skills and implemented it in a social robot.We then developed an integrated experimental paradigm in which a child plays a novel story-creation tablet game with the robot.The robot is portrayed as a younger peer who wishes to learn to read, framing the assessment of the child's word-reading skills as well as empowering the child.We show that our algorithm results in an accurate representation of the child's word-reading skills for a large age range, 4-8 year old children, and large initial reading skill range.We also show that employing child-specific assessment-based tutoring results in an age- and initial reading skill-independent learning, compared to random tutoring.Finally, our integrated system enables us to show that implementing the same learning algorithm on the robot's reading skills results in knowledge that is comparable to what the child thinks the robot has learned.The child's perception of the robot's knowledge is age-dependent and may facilitate an indirect assessment of the development of theory-of-mind.",
        "A1": "developed a Bayesian active-learning algorithm that continuously and efficiently assesses a child's word-reading skills and implemented it in a social robot",
        "A2": "Continuous and efficient assessment of the student's skills ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "developed an integrated experimental paradigm in which a child plays a novel story-creation tablet game with the robot",
        "A83": "implementing the same learning algorithm on the robot's reading skills results in knowledge that is comparable to what the child thinks the robot has learned",
        "A82": "employing child-specific assessment-based tutoring results in an age- and initial reading skill-independent learning, compared to random tutoring",
        "A81": "our algorithm results in an accurate representation of the child's word-reading skills for a large age range, 4-8 year old children, and large initial reading skill range",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": " algorithm that continuously and efficiently assesses a child's word-reading skills and implemented it in a social robot",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 431052009
    },
    {
        "Abstract": "Entity Resolution (ER) concerns identifying logically equivalent pairs of entities that may be syntactically disparate. Although ER is a long-standing problem in the artificial intelligence community, the growth of Linked Open Data, a collection of semi-structured datasets published and inter-connected on the Web, mandates a new approach. The thesis is that building a viable Entity Resolution solution for serving Big Data needs requires simultaneously resolving challenges of automation, heterogeneity, scalability and domain independence. The dissertation aims to build such a system and evaluate it on real-world datasets published already as Linked Open Data.",
        "A1": "building a viable Entity Resolution solution for serving Big Data needs requires simultaneously resolving challenges of automation, heterogeneity, scalability and domain independence.",
        "A2": "ER is a long-standing problem in the artificial intelligence community",
        "A41": "building a viable Entity Resolution solution for serving Big Data needs requires simultaneously resolving challenges of automation, heterogeneity, scalability and domain independence.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " evaluate it on real-world datasets published already as Linked Open Data.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 14796837
    },
    {
        "Abstract": "Collaborative filtering suffers from the problems of data sparsity and cold start, which dramatically degrade recommendation performance. To help resolve these issues, we propose TrustSVD, a trust-based matrix factorization technique. By analyzing the social trust data from four real-world data sets, we conclude that not only the explicit but also the implicit influence of both ratings and trust should be taken into consideration in a recommendation model. Hence, we build on top of a state-of-the-art recommendation algorithm SVD++ which inherently involves the explicit and implicit influence of rated items, by further incorporating both the explicit and implicit influence of trusted users on the prediction of items for an active user. To our knowledge, the work reported is the first to extend SVD++ with social trust information. Experimental results on the four data sets demonstrate that our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.",
        "A1": "propose TrustSVD, a trust-based matrix factorization technique",
        "A2": "Collaborative filtering suffers from the problems of data sparsity and cold start, which dramatically degrade recommendation performance",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experimental results on the four data sets demonstrate that our approach TrustSVD achieves better accuracy than other ten counterparts, and can better handle the concerned issues.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "further incorporating both the explicit and implicit influence of trusted users on the prediction of items for an active user",
        "A52": "a state-of-the-art recommendation algorithm SVD++",
        "A42": "a trust-based matrix factorization technique",
        "A45": "",
        "am_id": 381172925
    },
    {
        "Abstract": "In this paper, we formulate a new problem related to the well-known influence maximization in the context of computational advertising. Our new problem considers allocating marketing channels (e.g., TV, newspaper, and websites) to advertisers from the view point of a match maker, which was not taken into account in previous studies on the influence maximization. The objective of the problem is to find an allocation such that each advertiser can influence some given number of customers while the slots of marketing channels are limited. We propose an algorithm based on the Lagrangian decomposition. We empirically show that our algorithm computes better quality solutions than existing algorithms, scales up to graphs of 10M vertices, and performs well particularly in a parallel environment.",
        "A1": "to find an allocation such that each advertiser can influence some given number of customers while the slots of marketing channels are limited",
        "A2": "a new problem related to the well-known influence maximization in the context of computational advertising",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We empirically show that our algorithm computes better quality solutions than existing algorithms, scales up to graphs of 10M vertices, and performs well particularly in a parallel environment.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "the Lagrangian decomposition",
        "A43": "an algorithm based on the Lagrangian decomposition",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 251307036
    },
    {
        "Abstract": "Multi-label image classification is of significant interest due to its major role in real-world web image analysis applications such as large-scale image retrieval and browsing. Recently, matrix completion (MC) has been developed to deal with multi-label classification tasks. MC has distinct advantages, such as robustness to missing entries in the feature and label spaces and a natural ability to handle multi-label problems. However, current MC-based multi-label image classification methods only consider data represented by a single-view feature, therefore, do not precisely characterize images that contain several semantic concepts. An intuitive way to utilize multiple features taken from different views is to concatenate the different features into a long vector; however, this concatenation is prone to over-fitting and leads to high time complexity in MC-based image classification. Therefore, we present a novel multi-view learning model for MC-based image classification, called low-rank multi-view matrix completion (lrMMC), which first seeks a low-dimensional common representation of all views by utilizing the proposed low-rank multi-view learning (lrMVL) algorithm. In lrMVL, the common subspace is constrained to be low rank so that it is suitable for MC. In addition, combination weights are learned to explore complementarity between different views. An efficient solver based on fixed-point continuation (FPC) is developed for optimization, and the learned low-rank representation is then incorporated into MC-based image classification. Extensive experimentation on the challenging PASCAL VOC' 07 dataset demonstrates the superiority of lrMMC compared to other multi-label image classification approaches.",
        "A1": "matrix completion (MC) has been developed to deal with multi-label classification tasks.",
        "A2": "MC has distinct advantages,",
        "A41": "deal with multi-label classification tasks.",
        "A51": "Multi-label image classification is of significant interest due to its major role in real-world web image analysis applications such as large-scale image retrieval and browsing.",
        "A61": "matrix completion (MC) has been developed",
        "A10": "demonstrates the superiority of lrMMC compared to other multi-label image classification approaches.",
        "A7": "concatenate the different features into a long vector",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 362576792
    },
    {
        "Abstract": "The problem of computing optimal strategy to commit to in various games has attracted intense research interests and has important real-world applications such as security (attacker-defender) games. In this paper, we consider the problem of computing optimal leader\u2019s machine to commit to in two-person repeated game, where the follower also plays a machine strategy. Machine strategy is the generalized notion of automaton strategy, where the number of states in the automaton can be possibly infinite. We begin with the simple case where both players are confined to automata strategies, and then extend to general (possibly randomized) machine strategies. We first give a concise linear program to compute the optimal leader\u2019s strategy and give two efficient implementations of the linear program: one via enumeration of a convex hull and the other via randomization. We then investigate the case where two machines have different levels of intelligence in the sense that one machine is able to record more history information than the other. We show that an intellectually superior leader, sometimes considered being exploited by the follower, can figure out the follower\u2019s machine by brute-force and exploit the follower in return.",
        "A1": "we consider the problem of computing optimal leader\u2019s machine to commit to in two-person repeated game, where the follower also plays a machine strategy",
        "A2": "The problem of computing optimal strategy to commit to in various games",
        "A41": "We first give a concise linear program to compute the optimal leader\u2019s strategy and give two efficient implementations of the linear program: one via enumeration of a convex hull and the other via randomization. We then investigate the case where two machines have different levels of intelligence in the sense that one machine is able to record more history information than the other",
        "A51": "",
        "A61": "can figure out the follower\u2019s machine by brute-force and exploit the follower in return",
        "A10": "can figure out the follower\u2019s machine by brute-force and exploit the follower in return",
        "A7": "begin with the simple case where both players are confined to automata strategies, and then extend to general (possibly randomized) machine strategies",
        "A83": "",
        "A82": "",
        "A81": "We show that an intellectually superior leader, sometimes considered being exploited by the follower, can figure out the follower\u2019s machine by brute-force and exploit the follower in return",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 6464485
    },
    {
        "Abstract": "Existing multi-view clustering algorithms require thatthe data is completely or partially mapped betweeneach pair of views. However, this requirement couldnot be satisfied in most practical settings. In this paper,we tackle the problem of multi-view clustering for unmappeddata in the framework of NMF based clustering.With the help of inter-view constraints, we definethe disagreement between each pair of views by the factthat the indicator vectors of two instances from two differentviews should be similar if they belong to the samecluster and dissimilar otherwise. The overall objectiveof our algorithm is to minimize the loss function of NMFin each view as well as the disagreement betweeneach pair of views. Experimental results show that, witha small number of constraints, the proposed algorithmgets good performance on unmapped data, and outperformsexisting algorithms on partially mapped data andcompletely mapped data.",
        "A1": "to minimize the loss function of NMFin each view as well as the disagreement betweeneach pair of views",
        "A2": "the problem of multi-view clustering for unmappeddata in the framework of NMF based clustering",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperformsexisting algorithms on partially mapped data andcompletely mapped data",
        "A7": "",
        "A83": "",
        "A82": "outperformsexisting algorithms on partially mapped data andcompletely mapped data",
        "A81": "witha small number of constraints, the proposed algorithmgets good performance on unmapped data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 239751564
    },
    {
        "Abstract": "Applications in sustainability domains such as in energy, transportation, and natural resource and environment monitoring, increasingly use sensors for collecting data and sending it back to centrally located processing nodes. While data can usually be collected by the sensors at a very high speed, in many cases, it can not be sent back to central nodes at a frequency that is required for fast and real-time modeling and decision-making. This may be due to physical limitations of the transmission networks, or due to consumers limiting frequent transmission of data from sensors located at their premises for security and privacy concerns. We propose a novel solution to the problem of making short term predictions in absence of real-time data from sensors. A key implication of our work is that by using real-time data from only a small subset of influential sensors, we are able to make predictions for all sen- sors. We evaluated our approach with a large real-world electricity consumption data collected from smart meters in Los Angeles and the results show that between prediction horizons of 2 to 8 hours, despite lack of real time data, our influence model outperforms the baseline model that uses real-time data. Also, when using partial real-time data from only \u2248 7% influential smart meters, we witness prediction error increase by only \u2248 0.5% over the baseline, thus demonstrating the usefulness of our method for practical scenarios.",
        "A1": "We propose a novel solution to the problem of making short term predictions in absence of real-time data from sensors. ",
        "A2": " While data can usually be collected by the sensors at a very high speed, in many cases, it can not be sent back to central nodes at a frequency that is required for fast and real-time modeling and decision-making.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Also, when using partial real-time data from only \u2248 7% influential smart meters, we witness prediction error increase by only \u2248 0.5% over the baseline, thus demonstrating the usefulness of our method for practical scenarios.",
        "A7": "We evaluated our approach with a large real-world electricity consumption data collected from smart meters in Los Angeles",
        "A83": "",
        "A82": "Also, when using partial real-time data from only \u2248 7% influential smart meters, we witness prediction error increase by only \u2248 0.5% over the baseline, thus demonstrating the usefulness of our method for practical scenarios.",
        "A81": "results show that between prediction horizons of 2 to 8 hours, despite lack of real time data, our influence model outperforms the baseline model that uses real-time data.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 467801067
    },
    {
        "Abstract": "Documents from the same domain usually discuss similar topics in a similar order. However, the number of topics and the exact topics discussed in each individual document can vary. In this paper we present a simple topic model that uses generalised Mallows models and incomplete topic orderings to incorporate this ordering regularity into the probabilistic generative process of the new model. We show how to reparameterise the new model so that a point-wise sampling algorithm from the Bayesian word segmentation literature can be used for inference. This algorithm jointly samples not only the topic orders and the topic assignments but also topic segmentations of documents. Experimental results show that our model performs significantly better than the other ordering-based topic models on nearly all the corpora that we used, and competitively with other state-of-the-art topic segmentation models on corpora that have a strong ordering regularity.",
        "A1": "incorporate this ordering regularity into the probabilistic generative process of the new mode",
        "A2": "the number of topics and the exact topics discussed in each individual document can vary",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " reparameterise the new model so that a point-wise sampling algorithm from the Bayesian word segmentation literature can be used for inference",
        "A7": "",
        "A83": "",
        "A82": "competitively with other state-of-the-art topic segmentation models on corpora that have a strong ordering regularity",
        "A81": " our model performs significantly better than the other ordering-based topic models on nearly all the corpora that we used",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "not only the topic orders and the topic assignments but also topic segmentations of documents",
        "A52": "generalised Mallows models and incomplete topic orderings",
        "A42": "a simple topic model",
        "A45": "",
        "am_id": 168437853
    },
    {
        "Abstract": "Identifying aspect-based opinions has been studied extensively in recent years. However, existing work primarily focused on adjective, adverb, and noun expressions. Clearly, verb expressions can imply opinions too. We found that in many domains verb expressions can be even more important to applications because they often describe major issues of products or services. These issues enable brands and businesses to directly improve their products or services. To the best of our knowledge, this problem has not received much attention in the literature. In this paper, we make an attempt to solve this problem. Our proposed method first extracts verb expressions from reviews and then employs Markov Networks to model rich linguistic features and long distance relationships to identify negative issue expressions. Since our training data is obtained from titles of reviews whose labels are automatically inferred from review ratings, our approach is applicable to any domain without manual involvement. Experimental results using real-life review datasets show that our approach outperforms strong baselines.",
        "A1": "verb expressions can imply opinions too",
        "A2": "verb expressions can imply opinions too",
        "A41": "first extracts verb expressions from reviews and then employs Markov Networks to model rich linguistic features and long distance relationships to identify negative issue expressions",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Experimental results using real-life review datasets",
        "A83": "",
        "A82": "",
        "A81": "our approach outperforms strong baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 227515799
    },
    {
        "Abstract": "Broad application of answer set programming (ASP) for declarative problem solving requires the development of tools supporting the coding process. Program debugging is one of the crucial activities within this process. Modern ASP debugging approaches allow efficient computation of possible explanations of a fault. However, even for a small program a debugger might return a large number of possible explanations and selection of the correct one must be done manually. In this paper we present an interactive query-based ASP debugging method which extends previous approaches and finds the preferred explanation by means of observations. The system automatically generates a sequence of queries to a programmer asking whether a set of ground atoms must be true in all (cautiously) or some (bravely) answer sets of the program. Since some queries can be more informative than the others, we discuss query selection strategies which - given user's preferences for an explanation - can find the most informative query reducing the overall number of queries required for the identification of a preferred explanation.",
        "A1": "we present an interactive query-based ASP debugging method which extends previous approaches and finds the preferred explanation by means of observations",
        "A2": "even for a small program a debugger might return a large number of possible explanations and selection of the correct one must be done manually",
        "A41": "an interactive query-based ASP debugging method",
        "A51": "query-based",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "we discuss query selection strategies which - given user's preferences for an explanation - can find the most informative query reducing the overall number of queries required for the identification of a preferred explanation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 403226700
    },
    {
        "Abstract": "Spectral clustering, a graph partitioning technique, has gained immense popularity in machine learning in the context of unsupervised learning. This is due to convincing empirical studies, elegant approaches involved and the theoretical guarantees provided in the literature. To tackle some challenging problems that arose in computer vision etc., recently, a need to develop spectral methods that incorporate multi-way similarity measures surfaced. This, in turn, leads to a hypergraph partitioning problem. In this paper, we formulate a criterion for partitioning uniform hypergraphs, and show that a relaxation of this problem is related to the multilinear singular value decomposition (SVD) of symmetric tensors. Using this, we provide a spectral technique for clustering based on higher order affinities, and derive a theoretical bound on the error incurred by this method. We also study the complexity of the algorithm and use Nystr \u0308om\u2019s method and column sampling techniques to develop approximate methods with significantly reduced complexity. Experiments on geometric grouping and motion segmentation demonstrate the practical significance of the proposed methods.",
        "A1": "we formulate a criterion for partitioning uniform hypergraphs, and show that a relaxation of this problem is related to the multilinear singular value decomposition (SVD) of symmetric tensors",
        "A2": "a need to develop spectral methods that incorporate multi-way similarity measures surfaced. This, in turn, leads to a hypergraph partitioning problem",
        "A41": "multilinear singular value decomposition (SVD) of symmetric tensors",
        "A51": "higher order affinities",
        "A61": "",
        "A10": "",
        "A7": "Experiments on geometric grouping and motion segmentation",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the practical significance of the proposed methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 346261132
    },
    {
        "Abstract": "Merton's portfolio optimization problem in the presence of transaction costs for multiple assets has been an important and challenging problem in both theory and practice. Most existing work suffers from curse of dimensionality and encounters with the difficulty of generalization. In this paper, we develop an approximate dynamic programing method of synergistically combining the Lowner-John ellipsoid approximation with conventional value function iteration to quantify the associated optimal trading policy. Through constructing Lowner-John ellipsoids to parameterize the optimal policy and taking Euclidean projections onto the constructed ellipsoids to implement the trading policy, the proposed algorithm has cut computational costs up to a factor of five hundred and meanwhile achieved near-optimal risk-adjusted returns across both synthetic and real-world market datasets.",
        "A1": "an approximate dynamic programing method of synergistically combining the Lowner-John ellipsoid approximation with conventional value function iteration to quantify the associated optimal trading policy. ",
        "A2": " Most existing work suffers from curse of dimensionality and encounters with the difficulty of generalization",
        "A41": "an approximate dynamic programing method of synergistically combining the Lowner-John ellipsoid approximation with conventional value function iteration to quantify the associated optimal trading policy. ",
        "A51": "approximate dynamic programing",
        "A61": " the proposed algorithm has cut computational costs up to a factor of five hundred",
        "A10": "",
        "A7": "synthetic and real-world market datasets.",
        "A83": "",
        "A82": "",
        "A81": " achieved near-optimal risk-adjusted returns across both synthetic and real-world market datasets.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 240145452
    },
    {
        "Abstract": "The frequency and intensity of natural disasters has significantly increased over the past decades and this trend is predicted to continue. Facing these possible and unexpected disasters, understanding and simulating of human emergency mobility following disasters will becomethe critical issue for planning effective humanitarian relief, disaster management, and long-term societal reconstruction. However, due to the uniquenessof various disasters and the unavailability of reliable and large scale human mobility data, such kind of research is very difficult to be performed. Hence, in this paper,we collect big and heterogeneous data (e.g. 1.6 million users' GPS records in three years, 17520 times of Japan earthquake data in four years, news reporting data, transportation network data and etc.) to capture and analyze human emergency mobility following different disasters. By mining these big data, we aim to understand what basic laws govern human mobility following disasters, and develop a general model of human emergency mobility for generating and simulating large amount of human emergency movements. The experimental results and validations demonstrate the efficiency of our simulation model, and suggest that human mobility following disasters may be significantly morepredictable and can be easier simulated than previously thought.",
        "A1": "develop a general model of human emergency mobility for generating and simulating large amount of human emergency movements",
        "A2": "understanding and simulating of human emergency mobility following disasters",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "can be easier simulated than previously thought.",
        "A7": "",
        "A83": "can be easier simulated than previously thought.",
        "A82": "suggest that human mobility following disasters may be significantly morepredictable",
        "A81": "demonstrate the efficiency of our simulation model",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "can be easier simulated than previously thought.",
        "A52": "big and heterogeneous data",
        "A42": "a general model of human emergency mobility for generating and simulating large amount of human emergency movements",
        "A45": "",
        "am_id": 303245447
    },
    {
        "Abstract": "In multi-data learning, it is usually assumed that common latent factors exist among multi-datasets, but it may lead to deteriorated performance when datasets are heterogeneous and unbalanced. In this paper, we propose a novel common structure for multi-data learning. Instead of common latent factors, we assume that datasets share Common Adjacency Graph (CAG) structure, which is more robust to heterogeneity and unbalance of datasets. Furthermore, we utilize CAG structure to develop a new method for multi-tensor completion, which exploits the common structure in datasets to improve the completion performance. Numerical results demostrate that the proposed method not only outperforms state-of-the-art methods for video in-painting, but also can recover missing data well even in cases that conventional methods are not applicable.",
        "A1": "",
        "A2": "In multi-data learning, it is usually assumed that common latent factors exist among multi-datasets, but it may lead to deteriorated performance when datasets are heterogeneous and unbalanced.",
        "A41": "a new method for multi-tensor completion, which exploits the common structure in datasets to improve the completion performance",
        "A51": "CAG structure",
        "A61": "",
        "A10": "outperforms state-of-the-art methods for video in-painting,",
        "A7": " Numerical results",
        "A83": "",
        "A82": "can recover missing data well even in cases that conventional methods are not applicable.",
        "A81": "the proposed method not only outperforms state-of-the-art methods for video in-painting",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "more robust to heterogeneity and unbalance of datasets",
        "A52": "",
        "A42": "Common Adjacency Graph (CAG) structure",
        "A45": "",
        "am_id": 276969796
    },
    {
        "Abstract": "Notions of identity and of the self have long been studied in social psychology and sociology as key guiding elements of social interaction and coordination. In the AI of the future, these notions will also play a role in producing natural, socially appropriate artificially intelligent agents that encompass subtle and complex human social and affective skills. We propose here a Bayesian generalization of the sociological affect control theory of self as a theoretical foundation for socio-affectively skilled artificial agents. This theory posits that each human maintains an internal model of his or her deep sense of \"self\" that captures their emotional, psychological, and socio-cultural sense of being in the world. The \"self\" is then externalised as an identity within any given interpersonal and institutional situation, and this situational identity is the person's local (in space and time) representation of the self. Situational identities govern the actions of humans according to affect control theory. Humans will seek situations that allow them to enact identities consistent with their sense of self. This consistency is cumulative over time: if some parts of a person's self are not actualized regularly, the person will have a growing feeling of inauthenticity that they will seek to resolve. In our present generalisation, the self is represented as a probability distribution, allowing it to be multi-modal (a person can maintain multiple different identities), uncertain (a person can be unsure about who they really are), and learnable (agents can learn the identities and selves of other agents). We show how the Bayesian affect control theory of self can underpin artificial agents that are socially intelligent.",
        "A1": " We propose here a Bayesian generalization of the sociological affect control theory of self as a theoretical foundation for socio-affectively skilled artificial agents",
        "A2": "We show how the Bayesian affect control theory of self can underpin artificial agents that are socially intelligent.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " as a theoretical foundation for socio-affectively skilled artificial agents",
        "A7": "In our present generalisation",
        "A83": " learnable",
        "A82": "uncertain",
        "A81": "the self is represented as a probability distribution, allowing it to be multi-modal ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Bayesian generalization",
        "A52": "ocial psychology and sociology ",
        "A42": "a Bayesian generalization of the sociological affect control theory of self as a theoretical foundation for socio-affectively skilled artificial agents",
        "A45": "",
        "am_id": 270869575
    },
    {
        "Abstract": "We consider partially observable Markov decision processes (POMDPs) with a set of target states and every transition is associated with an integer cost. The optimization objective we study asks to minimize the expected total cost till the target set is reached, while ensuring that the target set is reached almost-surely (with probability 1). We show that for integer costs approximating the optimal cost is undecidable. For positive costs, our results are as follows: (i) we establish matching lower and upper bounds for the optimal cost and the bound is double exponential; (ii) we show that the problem of approximating the optimal cost is decidable and present approximation algorithms developing on the existing algorithms for POMDPs with finite-horizon objectives. While the worst-case running time of our algorithm is double exponential, we present efficient stopping criteria for the algorithm and show experimentally that it performs well in many examples of interest.",
        "A1": " minimize the expected total cost",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "the problem of approximating the optimal cost is decidable ",
        "A82": "establish matching lower and upper bounds for the optimal cost",
        "A81": "it performs well in many examples of interest",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": " efficient stopping criteria for the algorithm ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 485001249
    },
    {
        "Abstract": "We study the problem of learning sparse structure changes between two Markov networks P and Q. Rather than fitting two Markov networks separately to two sets of data and figuring out their differences, a recent work proposed to learn changes directly via estimating the ratio between two Markov network models. xa0Such a direct approach was demonstrated to perform excellently in experiments, although its theoretical properties remained unexplored. xa0In this paper, we give sufficient conditions for successful change detection with respect to the sample size np, nq, the dimension of data m, and the number of changed edges d.",
        "A1": "",
        "A2": "learning sparse structure changes between two Markov networks P and Q",
        "A41": " learn changes directly via estimating the ratio between two Markov network models",
        "A51": "two Markov networks",
        "A61": "Rather than fitting two Markov networks separately to two sets of data and figuring out their differences, a recent work proposed to learn changes directly via estimating the ratio between two Markov network models",
        "A10": "Rather than fitting two Markov networks separately to two sets of data and figuring out their differences, a recent work proposed to learn changes directly via estimating the ratio between two Markov network models",
        "A7": "we give sufficient conditions for successful change detection with respect to the sample size np, nq, the dimension of data m, and the number of changed edges d",
        "A83": "",
        "A82": "",
        "A81": "perform excellently in experiments",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 88317752
    },
    {
        "Abstract": "We address the problem of planning collision-free paths for multiple agents using optimization methods known as proximal algorithms. Recently this approach was explored in Bento et al. (2013), which demonstrated its ease of parallelization and decentralization, the speed with which the algorithms generate good quality solutions, and its ability to incorporate different proximal operators, each ensuring that paths satisfy a desired property. Unfortunately, the operators derived only apply to paths in 2D and require that any intermediate waypoints we might want agents to follow be preassigned to specific agents, limiting their range of applicability. In this paper we resolve these limitations. We introduce new operators to deal with agents moving in arbitrary dimensions that are faster to compute than their 2D predecessors and we introduce landmarks, space-time positions that are automatically assigned to the set of agents under different optimality criteria. Finally, we report the performance of the new operators in several numerical experiments.",
        "A1": "",
        "A2": "planning collision-free paths for multiple agents",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "faster to compute than their 2D predecessors",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "deal with agents moving in arbitrary dimensions",
        "A53": "",
        "A43": "deal with agents moving in arbitrary dimensions",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 165124085
    },
    {
        "Abstract": "Sequential decision problems that involve multiple objectives are prevalent. Consider for example a driver of a semi-autonomous car who may want to optimize competing objectives such as travel time and the effort associated with manual driving. We introduce a rich model called Lexicographic MDP (LMDP) and a corresponding planning algorithm called LVI that generalize previous work by allowing for conditional lexicographic preferences with slack. We analyze the convergence characteristics of LVI and establish its game theoretic properties. The performance of LVI in practice is tested within a realistic benchmark problem in the domain of semi-autonomous driving. Finally, we demonstrate how GPU-based optimization can improve the scalability of LVI and other value iteration algorithms for MDPs.",
        "A1": "Sequential decision problems that involve multiple objectives",
        "A2": "Sequential decision problems that involve multiple objectives",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "The performance of LVI in practice is tested within a realistic benchmark problem in the domain of semi-autonomous driving.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "generalize previous work by allowing for conditional lexicographic preferences with slack.",
        "A53": "",
        "A43": " a corresponding planning algorithm called LVI",
        "A62": " generalize previous work by allowing for conditional lexicographic preferences with slack.",
        "A52": "",
        "A42": " Lexicographic MDP (LMDP",
        "A45": "",
        "am_id": 24430522
    },
    {
        "Abstract": "We investigate a problem at the intersection of machine learning and security: training-set attacks on machine learners. In such attacks an attacker contaminates the training data so that a specific learning algorithm would produce a model profitable to the attacker. Understanding training-set attacks is important as more intelligent agents (e.g. spam filters and robots) are equipped with learning capability and can potentially be hacked via data they receive from the environment. This paper identifies the optimal training-set attack on a broad family of machine learners. First we show that optimal training-set attack can be formulated as a bilevel optimization problem. Then we show that for machine learners with certain Karush-Kuhn-Tucker conditions we can solve the bilevel problem efficiently using gradient methods on an implicit function. As examples, we demonstrate optimal training-set attacks on Support VectorMachines, logistic regression, and linear regression with extensive experiments. Finally, we discuss potential defenses against such attacks.",
        "A1": " identifies the optimal training-set attack on a broad family of machine learners",
        "A2": "a problem at the intersection of machine learning and security",
        "A41": "optimal training-set attack can be formulated as a bilevel optimization problem",
        "A51": "a bilevel optimization problem",
        "A61": "machine learners with certain Karush-Kuhn-Tucker conditions we can solve the bilevel problem efficiently using gradient methods on an implicit function",
        "A10": "",
        "A7": "optimal training-set attacks on Support VectorMachines, logistic regression, and linear regression with extensive experiments",
        "A83": "",
        "A82": "",
        "A81": "discuss potential defenses against such attacks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 212968731
    },
    {
        "Abstract": "Support Vector Machine (SVM) is a fundamental technique in machine learning. A long time challenge facing SVM is how to deal with outliers (caused by mislabeling), as they could make the classes in SVM nonseparable. Existing techniques, such as soft margin SVM, \u03bd-SVM, and Core-SVM, can alleviate the problem to certain extent, but cannot completely resolve the issue. Recently, there are also techniques available for explicit outlier removal. But they suffer from high time complexity and cannot guarantee quality of solution. In this paper, we present a new combinatorial approach, called Random Gradient Descent Tree (or RGD-tree), to explicitly deal with outliers; this results in a new algorithm called RGD-SVM. Our technique yields provably good solution and can be efficiently implemented for practical purpose. The time and space complexities of our approach only linearly depend on the input size and the dimensionality of the space, which are significantly better than existing ones. Experiments on benchmark datasets suggest that our technique considerably outperforms several popular techniques in most of the cases.",
        "A1": "deal with outliers (caused by mislabeling)",
        "A2": "outliers (caused by mislabeling)",
        "A41": "a new combinatorial approach, called Random Gradient Descent Tree (or RGD-tree)",
        "A51": "",
        "A61": "",
        "A10": "our technique considerably outperforms several popular techniques in most of the cases",
        "A7": "Experiments on benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a new algorithm called RGD-SVM",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137329249
    },
    {
        "Abstract": "In this paper, we propose an interpretation of active learning from a pure algebraic view and combine it with semi-supervised manifold learning. The proposed active manifold learning algorithm aims to learn the low-dimensional parameter space of the manifold with high accuracy from smartly labeled samples. We demonstrate that this problem is equivalent to a condition number minimization problem of the alignment matrix. Focusing on this problem, we first give a theoretical upper bound for the solution. Then we develop a heuristic but effective sample selection algorithm with the help of the Gershgorin circle theorem. We investigate the rationality, the feasibility, the universality and the complexity of the proposed method and demonstrate that our method yields encouraging active learning results.",
        "A1": "propose an interpretation of active learning",
        "A2": "learn the low-dimensional parameter space of the manifold with high accuracy from smartly labeled samples",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " first give a theoretical upper bound for the solution. Then we develop a heuristic but effective sample selection algorithm with the help of the Gershgorin circle theorem",
        "A83": "",
        "A82": "",
        "A81": "our method yields encouraging active learning results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "pure algebraic view and combine it with semi-supervised manifold learning",
        "A43": "algorithm aims to learn the low-dimensional parameter space of the manifold with high accuracy from smartly labeled samples.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 498413155
    },
    {
        "Abstract": "With the current upward trend in semantically annotated data, ontology-based data access (OBDA) was formulated to tackle the problem of data integration and query answering, where an ontology is formalized as a description logic TBox. In order to meet usability requirements set by users, efforts have been made to equip OBDA system with explanation facilities. One important explanation tool for DL ontologies, referred to as query abduction, can be formalised as abductive reasoning. In particular, given an ontology and an observation (i.e., a query with an answer), an explanation to the observation is a set of facts that together with the ontology can entail the observation. In this paper, we develop a sound and complete algorithm of query abduction for general conjunctive queries in ELH ontologies. This is achieved through ontology approximation and query rewriting. We implemented a prototypical system using the highly optimized Prolog engine XSB. We evaluated our algorithm over university benchmark ontology and our experimental results show that the system is capable of handling query abduction problems for ontology that has approximately 10 millions ABox assertions.",
        "A1": "In order to meet usability requirements set by users, efforts have been made to equip OBDA system with explanation facilities.",
        "A2": "With the current upward trend in semantically annotated data, ontology-based data access (OBDA) was formulated to tackle the problem of data integration and query answering, where an ontology is formalized as a description logic TBox.",
        "A41": " One important explanation tool for DL ontologies, referred to as query abduction, can be formalised as abductive reasoning. In particular, given an ontology and an observation (i.e., a query with an answer), an explanation to the observation is a set of facts that together with the ontology can entail the observation.",
        "A51": "",
        "A61": "",
        "A10": "the system is capable of handling query abduction problems for ontology that has approximately 10 millions ABox assertions.",
        "A7": "We evaluated our algorithm over university benchmark ontology and our experimental results show that the system is capable of handling query abduction problems for ontology that has approximately 10 millions ABox assertions.",
        "A83": "",
        "A82": "an explanation to the observation is a set of facts that together with the ontology can entail the observation.",
        "A81": "the system is capable of handling query abduction problems for ontology that has approximately 10 millions ABox assertions.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "This is achieved through ontology approximation and query rewriting.",
        "A43": "a sound and complete algorithm of query abduction for general conjunctive queries in ELH ontologies",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 419684354
    },
    {
        "Abstract": "The expressive power of a Gaussian process (GP) model comes at a cost of poor scalability in the data size. To improve its scalability, this paper presents a low-rank-cum-Markov approximation (LMA) of the GP model that is novel in leveraging the dual computational advantages stemming from complementing a low-rank approximate representation of the full-rank GP based on a support set of inputs with a Markov approximation of the resulting residual process; the latter approximation is guaranteed to be closest in the Kullback-Leibler distance criterion subject to some constraint and is considerably more refined than that of existing sparse GP models utilizing low-rank representations due to its more relaxed conditional independence assumption (especially with larger data). As a result, our LMA method can trade off between the size of the support set and the order of the Markov property to (a) incur lower computational cost than such sparse GP models while achieving predictive performance comparable to them and (b) accurately represent features/patterns of any scale. Interestingly, varying the Markov order produces a spectrum of LMAs with PIC approximation and full-rank GP at the two extremes. An advantage of our LMA method is that it is amenable to parallelization on multiple machines/cores, thereby gaining greater scalability. Empirical evaluation on three real-world datasets in clusters of up to 32 computing nodes shows that our centralized and parallel LMA methods are significantly more time-efficient and scalable than state-of-the-art sparse and full-rank GP regression methods while achieving comparable predictive performances.",
        "A1": "The expressive power of a Gaussian process (GP) model comes at a cost of poor scalability in the data size. To improve its scalability, ",
        "A2": "The expressive power of a Gaussian process (GP) model comes at a cost of poor scalability in the data size. ",
        "A41": "a low-rank-cum-Markov approximation (LMA) of the GP model that is novel in leveraging the dual computational advantages stemming from complementing a low-rank approximate representation of the full-rank GP",
        "A51": "based on a support set of inputs with a Markov approximation of the resulting residual process;",
        "A61": " An advantage of our LMA method is that it is amenable to parallelization on multiple machines/cores, thereby gaining greater scalability. Empirical evaluation on three real-world datasets in clusters of up to 32 computing nodes shows that our centralized and parallel LMA methods are significantly more time-efficient and scalable than state-of-the-art sparse and full-rank GP regression methods while achieving comparable predictive performances.",
        "A10": "our centralized and parallel LMA methods are significantly more time-efficient and scalable than state-of-the-art sparse and full-rank GP regression methods while achieving comparable predictive performances.",
        "A7": "Empirical evaluation on three real-world datasets in clusters of up to 32 computing nodes",
        "A83": "(b) accurately represent features/patterns of any scale. Interestingly, varying the Markov order produces a spectrum of LMAs with PIC approximation and full-rank GP at the two extremes.",
        "A82": "(a) incur lower computational cost than such sparse GP models while achieving predictive performance comparable to them",
        "A81": "our centralized and parallel LMA methods are significantly more time-efficient and scalable than state-of-the-art sparse and full-rank GP regression methods while achieving comparable predictive performances.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 431738986
    },
    {
        "Abstract": "Learning for maximizing AUC performance is an important research problem in machine learning. Unlike traditional batch learning methods for maximizing AUC which often suffer from poor scalability, recent years have witnessed some emerging studies that attempt to maximize AUC by single-pass online learning approaches. Despite their encouraging results reported, the existing online AUC maximization algorithms often adopt simple stochastic gradient descent approaches, which fail to exploit the geometry knowledge of the data observed in the online learning process, and thus could suffer from relatively slow convergence. To overcome the limitation of the existing studies, in this paper, we propose a novel algorithm of Adaptive Online AUC Maximization (AdaOAM), by applying an adaptive gradient method for exploiting the knowledge of historical gradients to perform more informative online learning. The new adaptive updating strategy by AdaOAM is less sensitive to parameter settings due to its natural effect of tuning the learning rate. In addition, the time complexity of the new algorithm remains the same as the previous non-adaptive algorithms. To demonstrate the effectiveness of the proposed algorithm, we analyze its theoretical bound, and further evaluate its empirical performance on both public benchmark datasets and anomaly detection datasets. The encouraging empirical results clearly show the effectiveness and efficiency of the proposed algorithm.",
        "A1": "Learning for maximizing AUC performance",
        "A2": "overcome the limitation of the existing studies",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "is less sensitive to parameter settings",
        "A53": "applying an adaptive gradient method for exploiting the knowledge of historical gradients to perform more informative online learning",
        "A43": "Adaptive Online AUC Maximization",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 450509386
    },
    {
        "Abstract": "Commenting is a popular facility provided by news sites. Analyzing such user-generated content has recently attracted research interest. However, in multilingual societies such as India, analyzing such user-generated content is hard due to several reasons: (1) There are more than 20 official languages but linguistic resources are available mainly for Hindi. It is observed that people frequently use romanized text as it is easy and quick using an English keyboard, resulting in multi-glyphic comments, where the texts are in the same language but in different scripts. Such romanized texts are almost unexplored in machine learning so far. (2) In many cases, comments are made on a specific part of the article rather than the topic of the entire article. Off-the-shelf methods such as correspondence LDA are insufficient to model such relationships between articles and comments. In this paper, we extend the notion of correspondence to model multi-lingual, multi-script, and inter-lingual topics in a unified probabilistic model called the Multi-glyphic Correspondence Topic Model (MCTM). Using several metrics, we verify our approach and show that it improves over the state-of-the-art.",
        "A1": " we extend the notion of correspondence to model multi-lingual, multi-script, and inter-lingual topics in a unified probabilistic model called the Multi-glyphic Correspondence Topic Model ",
        "A2": " analyzing such user-generated content is hard",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " it improves over the state-of-the-art.",
        "A7": "Using several metrics,",
        "A83": "",
        "A82": "",
        "A81": "it improves over the state-of-the-art.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " in a unified probabilistic model",
        "A52": "the notion of correspondence",
        "A42": "unified probabilistic model called the Multi-glyphic Correspondence Topic Model (MCTM)",
        "A45": "",
        "am_id": 178132413
    },
    {
        "Abstract": "Subspace recovery from noisy or even corrupted data is critical for various applications in machine learning and data analysis. To detect outliers, Robust PCA (R PCA) via Outlier Pursuit was proposed and had found many successful applications. However, the current theoretical analysis on Outlier Pursuit only shows that it succeeds when the sparsity of the corruption matrix is of O(n/r), where n is the number of the samples and r is the rank of the intrinsic matrix which may be comparable to n. Moreover, the regularization parameter is suggested as 3/(7 squareroot gamma n}, where gamma is a parameter that is not known a priori. In this paper, with incoherence condition and proposed ambiguity condition we prove that Outlier Pursuit succeeds when the rank of the intrinsic matrix is of O(n log n) and the sparsity of the corruption matrix is of O(n). We further show that the orders of both bounds are tight. Thus R-PCA via Outlier Pursuit is able to recover intrinsic matrix of higher rank and identify much denser corruptions than what the existing results could predict. Moreover, we suggest that the regularization parameter be chosen as 1 squareroot{log n}, which is definite. Our analysis waives the necessity of tuning the regularization parameter and also significantly extends the working range of the Outlier Pursuit. Experiments on synthetic and real data verify our theories.",
        "A1": "",
        "A2": "Subspace recovery from noisy or even corrupted data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our analysis waives the necessity of tuning the regularization parameter and also significantly extends the working range of the Outlier Pursuit. ",
        "A7": " Experiments on synthetic and real data",
        "A83": "",
        "A82": "",
        "A81": "verify our theories",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 195161034
    },
    {
        "Abstract": "We present a novel semantics for extracting bounded-level modules from RDF ontologies and databases augmented with safe inference rules, a la Datalog. Dealing with a recursive rule language poses challenging issues for defining the module semantics, and also makes module extraction algorithmically unsolvable in some cases. Our results include a set of module extraction algorithms compliant with the novel semantics. Experimental results show that the resulting framework is effective in extracting expressive modules from RDF datasets with formal guarantees, whilst controlling their succinctness.",
        "A1": " present a novel semantics",
        "A2": "extracting bounded-level modules from RDF ontologies and databases",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "controlling their succinctness.",
        "A81": " extracting expressive modules from RDF datasets with formal guarantees",
        "A64": "Dealing with a recursive rule language",
        "A54": "a set of module extraction algorithms",
        "A44": "is effective in extracting expressive modules from RDF datasets with formal guarantees, whilst controlling their succinctness.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 395420691
    },
    {
        "Abstract": "Analogies are a fundamental human reasoning pattern that relies on relational similarity. Understanding how analogies are formed facilitates the transfer of knowledge between contexts. The approach presented in this work focuses on obtaining precise interpretations of analogies. We leverage noisy semantic networks to answer and explain a wide spectrum of analogy questions. The core of our contribution, the Semantic Similarity Engine, consists of methods for extracting and comparing graph-contexts that reveal the relational parallelism that analogies are based on, while mitigating uncertainty in the semantic network.We demonstrate these methods in two tasks: answering multiple choice analogy questions and generating human readable analogy explanations. We evaluate our approach on two datasets totaling 600 analogy questions. Our results show reliable performance and low false-positive rate in question answering; human evaluators agreed with 96% of our analogy explanations.",
        "A1": "The approach presented in this work focuses on obtaining precise interpretations of analogies. ",
        "A2": "We leverage noisy semantic networks to answer and explain a wide spectrum of analogy questions. ",
        "A41": "methods for extracting and comparing graph-contexts that reveal the relational parallelism that analogies are based on, while mitigating uncertainty in the semantic network.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We evaluate our approach on two datasets totaling 600 analogy questions.",
        "A83": "",
        "A82": " human evaluators agreed with 96% of our analogy explanations.",
        "A81": " reliable performance and low false-positive rate in question answering",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 421509641
    },
    {
        "Abstract": "NetworkRepository (NR) is the first interactive data repository with a web-based platform for visual interactive analytics. Unlike other data repositories (e.g., UCI ML Data Repository, and SNAP), the network data repository (networkrepository.com) allows users to not only download, but to interactively analyze and visualize such data using our web-based interactive graph analytics platform. Users can in real-time analyze, visualize, compare, and explore data along many different dimensions. The aim of NR is to make it easy to discover key insights into the data extremely fast with little effort while also providing a medium for users to share data, visualizations, and insights. Other key factors that differentiate NR from the current data repositories is the number of graph datasets, their size, and variety. While other data repositories are static, they also lack a means for users to collaboratively discuss a particular dataset, corrections, or challenges with using the data for certain applications. In contrast, NR incorporates many social and collaborative aspects that facilitate scientific research, e.g., users can discuss each graph, post observations, and visualizations.",
        "A1": "NetworkRepository",
        "A2": "visual interactive analytics",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "in real-time analyze, visualize, compare, and explore data along many different dimensions",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "easy to discover key insights into the data extremely fast with little effort while also providing a medium for users to share data, visualizations, and insights",
        "A52": "",
        "A42": "with a web-based platform for visual interactive analytics",
        "A45": "",
        "am_id": 46403243
    },
    {
        "Abstract": "With the pervasion of social media, topic identification in short texts attracts increasing attention inxa0 recent years. However, in nature the texts of social media are short and noisy, and the structures are sparse and dynamic, resulting in difficulty to identify topic categories exactly from online social media. Inspired by social science findings that preference consistency and social contagion are observed in social media, we investigate topic identification in short and noisy texts by exploring social context from the perspective of social sciences. In particular, we present a mathematical optimization formulation that incorporates the preference consistency and social contagion theories into a supervised learning method, and conduct feature selection to tackle short and noisy texts in social media, which result in a Sociological framework for Topic Identification (STI). Experimental results on real-world datasets from Twitter and Citation Network demonstrate the effectiveness of the proposed framework. Further experiments are conducted to understand the importance of social context in topic identification.",
        "A1": "present a mathematical optimization formulation that incorporates the preference consistency and social contagion theories into a supervised learning method, and conduct feature selection to tackle short and noisy texts in social media, which result in a Sociological framework for Topic Identification (STI)",
        "A2": "in nature the texts of social media are short and noisy, and the structures are sparse and dynamic, resulting in difficulty to identify topic categories exactly from online social media",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on real-world datasets from Twitter and Citation Network ",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the effectiveness of the proposed framework",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "investigate topic identification in short and noisy texts by exploring social context from the perspective of social sciences",
        "A53": "social science findings that preference consistency and social contagion are observed in social media",
        "A43": "a mathematical optimization formulation that incorporates the preference consistency and social contagion theories into a supervised learning method, and conduct feature selection to tackle short and noisy texts in social media",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 40224610
    },
    {
        "Abstract": "We study a game with strategic vendors (the agents) who own multiple items and a single buyer with a submodular valuation function. The goal of the vendors is to maximize their revenue via pricing of the items, given that the buyer will buy the set of items that maximizes his net payoff.% (valuation minus the prices). We show this game may not always have a pure Nash equilibrium, in contrast to previous results for the special case where each vendor owns a single item. We do so by relating our game to an intermediate, discrete game in which the vendors only choose the available items, and their prices are set exogenously afterwards. We further make use of the intermediate game to provide tight bounds on the price of anarchy for the subset games that have pure Nash equilibria; we find that the optimal PoA reached in the previous special cases does not hold, but only a logarithmic one. Finally, we show that for a special case of submodular functions, efficient pure Nash equilibria always exist.",
        "A1": "",
        "A2": "study a game with strategic vendors (the agents) who own multiple items and a single buyer with a submodular valuation function",
        "A41": "relating our game to an intermediate, discrete game in which the vendors only choose the available items, and their prices are set exogenously afterwards",
        "A51": "",
        "A61": "this game may not always have a pure Nash equilibrium, in contrast to previous results for the special case where each vendor owns a single item",
        "A10": "",
        "A7": "study a game with strategic vendors (the agents) who own multiple items and a single buyer with a submodular valuation function",
        "A83": "for a special case of submodular functions, efficient pure Nash equilibria always exist",
        "A82": "the optimal PoA reached in the previous special cases does not hold, but only a logarithmic one",
        "A81": "this game may not always have a pure Nash equilibrium",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 382247908
    },
    {
        "Abstract": "Stack Overflow and MedHelp are examples of domain-specific community-based question answering (CQA) systems. Different from CQA systems for general topics (e.g., Yahoo! Answers, Baidu Knows), questions and answers in domain-specific CQA systems are mostly in the same topical domain, enabling more comprehensive interaction between users on fine-grained topics. In such systems, users are more likely to ask questions on unfamiliar topics and to answer questions matching their expertise. Users can also vote answers based on their judgements. In this paper, we propose a Tri-Role Topic Model (TRTM) to model the tri-roles of users (i.e., as askers, answerers, and voters, respectively) and the activities of each role including composing question, selecting question to answer, contributing and voting answers. The proposed model can be used to enhance CQA systems from many perspectives. As a case study, we conducted experiments on ranking answers for questions on Stack Overflow, a CQA system for professional and enthusiast programmers. Experimental results show that TRTM is effective in facilitating users getting ideal rankings of answers, particularly for new and less popular questions. Evaluated on nDCG, TRTM outperforms state-of-the-art methods.",
        "A1": "model the tri-roles of users (i.e., as askers, answerers, and voters, respectively) and the activities of each role",
        "A2": "users are more likely to ask questions on unfamiliar topics and to answer questions matching their expertise",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperforms state-of-the-art methods",
        "A7": "conducted experiments on ranking answers for questions on Stack Overflow, a CQA system for professional and enthusiast programmers",
        "A83": "",
        "A82": "particularly for new and less popular questions",
        "A81": "TRTM is effective in facilitating users getting ideal rankings of answers",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Topic Model",
        "A42": "a Tri-Role Topic Model (TRTM) to model the tri-roles of users (i.e., as askers, answerers, and voters, respectively) and the activities of each role",
        "A45": "",
        "am_id": 270579457
    },
    {
        "Abstract": "This paper introduces a new structured model for learning anaphoricity detection and coreference resolution in a joint fashion. Specifically,we use a latent tree to represent the full coreference and anaphoric structure of a document at a global level, and we jointly learn the parameters of the two models using a version of the structured perceptron algorithm. Our joint structured model is further refined by the use of pairwise constraints which help the model to capture accurately certain patterns of coreference. Our experiments on the CoNLL-2012 English datasets show large improvements in both coreference resolution and anaphoricity detection, compared to various competing architectures. Our best coreference system obtains a CoNLL score of 81.97 on gold mentions, which is to date the best score reported on this setting.",
        "A1": "learning anaphoricity detection and coreference resolution in a joint fashion",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the best score reported on this setting",
        "A7": "experiments on the CoNLL-2012 English datasets",
        "A83": "",
        "A82": "best coreference system obtains a CoNLL score of 81.97",
        "A81": " large improvements in both coreference resolution and anaphoricity detection",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "a version of the structured perceptron algorithm",
        "A42": "a new structured model for learning anaphoricity detection and coreference resolution in a joint fashion",
        "A45": "",
        "am_id": 244571176
    },
    {
        "Abstract": "A* search is a fundamental topic in artificial intelligence. Recently, the general purpose computation on graphics processing units (GPGPU) has been widely used to accelerate numerous computational tasks. In this paper, we propose the first parallel variant of the A* search algorithm such that the search process of an agent can be accelerated by a single GPU processor in a massively parallel fashion. Our experiments have demonstrated that the GPU-accelerated A* search is efficient in solving multiple real-world search tasks, including combinatorial optimization problems, pathfinding and game solving. Compared to the traditional sequential CPU-based A* implementation, our GPU-based A* algorithm can achieve a significant speedup by up to 45x on large-scale search problems.",
        "A1": "A* search is a fundamental topic in artificial intelligence",
        "A2": "the search process of an agent can be accelerated by a single GPU processor in a massively parallel fashion.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieve a significant speedup by up to 45x on large-scale search problems.",
        "A7": " Our experiments have demonstrated that the GPU-accelerated A* search is efficient in solving multiple real-world search tasks",
        "A83": "",
        "A82": "achieve a significant speedup by up to 45x on large-scale search problems.",
        "A81": "GPU-accelerated A* search is efficient in solving multiple real-world search tasks, including combinatorial optimization problems, pathfinding and game solving",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "search process of an agent can be accelerated by a single GPU processor in a massively parallel fashion",
        "A53": " GPU",
        "A43": " GPU-based A* algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 126562126
    },
    {
        "Abstract": "Many scenarios require that robots work together as a team in order to effectively accomplish their tasks. However, pre-coordinating these teams may not always be possible given the growing number of companies and research labs creating these robots. Therefore, it is desirable for robots to be able to reason about ad hoc teamwork and adapt to new teammates on the fly. Past research on ad hoc teamwork has focused on relatively simple domains, but this paper demonstrates that agents can reason about ad hoc teamwork in complex scenarios. To handle these complex scenarios, we introduce a new algorithm, PLASTIC\u2013Policy, that builds on an existing ad hoc teamwork approach. Specifically, PLASTIC\u2013 Policy learns policies to cooperate with past teammates and reuses these policies to quickly adapt to new teammates. This approach is tested in the 2D simulation soccer league of RoboCup using the half field offense task.",
        "A1": "agents can reason about ad hoc teamwork in complex scenarios",
        "A2": "pre-coordinating these teams may not always be possible given the growing number of companies and research labs creating these robots",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "2D simulation soccer league of RoboCup using the half field offense task",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": " existing ad hoc teamwork approach",
        "A43": "PLASTIC\u2013Policy, that builds on an existing ad hoc teamwork approach",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 458417238
    },
    {
        "Abstract": "We introduce Extended Property Paths (EPPs), a significant enhancement of SPARQL property paths. EPPs allow to capture in a succinct way a larger class of navigational queries than property paths. We present the syntax and formal semantics of EPPs and introduce two different evaluation strategies. The first is based on an algorithm implemented in a custom query processor. The second strategy leverages a translation algorithm of EPPs into SPARQL queries that can be executed on existing SPARQL processors. We compare the two evaluation strategies on real data to highlight their pros and cons.",
        "A1": " Extended Property Paths (EPPs)",
        "A2": " a significant enhancement of SPARQL property paths",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "a significant enhancement of SPARQL property paths",
        "A7": "The first is based on an algorithm implemented in a custom query processor. The second strategy leverages a translation algorithm of EPPs into SPARQL queries that can be executed on existing SPARQL processors. ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "EPPs allow to capture in a succinct way a larger class of navigational queries than property paths. ",
        "A53": "the syntax and formal semantics of EPPs",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 197161159
    },
    {
        "Abstract": "Many various types of sensors coming from different complex devices collect data from a city. Their underlying data representation follows specific manufacturer specifications that have possibly incomplete descriptions (in ontology) alignments. This paper addresses the problem of determining accurate and complete matching of ontologies given some common descriptions and their pre-determined high level alignments. In this context the problem of ontology matching consists of automatically determining all matching given the latter alignments, and manually verifying the matching results. Especially for applications where it is crucial that ontologies are matched correctly the latter can turn into a very time-consuming task for the user. This paper tackles this challenge and addresses the problem of computing the minimum number of user inputs needed to verify all matchings. We show how to represent this problem as a reasoning problem over a bipartite graph and how to encode it over pseudo Boolean constraints. Experiments show that our approach can be successfully applied to real-world data sets.",
        "A1": "This paper addresses the problem",
        "A2": "the problem of determining accurate and complete matching of ontologies given some common descriptions and their pre-determined high level alignments",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "addresses the problem of computing the minimum number of user inputs needed to verify all matchings",
        "A7": "Experiments show that our approach can be successfully applied to real-world data sets",
        "A83": "",
        "A82": "",
        "A81": "We show how to represent this problem as a reasoning problem over a bipartite graph and how to encode it over pseudo Boolean constraints",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 79117546
    },
    {
        "Abstract": "Link prediction and multi-label learning on graphs are two important but challenging machine learning problems that have broad applications in diverse fields. Not only are the two problems inherently correlated and often appear concurrently, they are also exacerbated by incomplete data. We develop a novel algorithm to solve these two problems jointly under a unified framework, which helps reduce the impact of graph noise and benefits both tasks individually. We reduce multi-label learning problem into an additional link prediction task and solve both problems with marginalized denoising, which we co-regularize with Laplacian smoothing. This approach combines both learning tasks into a single convex objective function, which we optimize efficiently with iterative closed-form updates. The resulting approach performs significantly better than prior work on several important real-world applications with great consistency.",
        "A1": "",
        "A2": "Link prediction and multi-label learning on graphs",
        "A41": ". This approach combines both learning tasks into a single convex objective function, which we optimize efficiently with iterative closed-form updates",
        "A51": "",
        "A61": "educe multi-label learning problem into an additional link prediction task",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "unified",
        "A54": "",
        "A44": "",
        "A63": "solve these two problems jointly under a unified framework,",
        "A53": "a unified framework",
        "A43": " jointly under a unified framework, which helps reduce the impact of graph noise and benefits both tasks individually. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137021658
    },
    {
        "Abstract": "Linear Dynamical System (LDS) is an elegant mathematical framework for modeling and learning Multivariate Time Series (MTS). However, in general, it is difficult to set the dimension of an LDS's hidden state space. A small number of hidden states may not be able to model the complexities of a MTS, while a large number of hidden states can lead to overfitting. In this paper, we study learning methods that impose various regularization penalties on the transition matrix of the LDS model and propose a regularized LDS learning framework (rLDS) which aims to (1) automatically shut down LDSs' spurious and unnecessary dimensions, and consequently, address the problem of choosing the optimal number of hidden states; (2) prevent the overfitting problem given a small amount of MTS data; and (3) support accurate MTS forecasting. To learn the regularized LDS from data we incorporate a second order cone program and a generalized gradient descent method into the Maximum a Posteriori framework and use Expectation Maximization to obtain a low-rank transition matrix of the LDS model. We propose two priors for modeling the matrix which lead to two instances of our rLDS. We show that our rLDS is able to recover well the intrinsic dimensionality of the time series dynamics and it improves the predictive performance when compared to baselines on both synthetic and real-world MTS datasets.",
        "A1": " propose a regularized LDS learning framework (rLDS)",
        "A2": " set the dimension of an LDS's hidden state space",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "baselines on both synthetic and real-world MTS datasets",
        "A83": "",
        "A82": "t improves the predictive performance",
        "A81": "rLDS is able to recover well the intrinsic dimensionality of the time series dynamics",
        "A64": "rLDS is able to recover well the intrinsic dimensionality of the time series dynamics and it improves the predictive performance",
        "A54": "",
        "A44": "Linear Dynamical System (LDS)",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 235365458
    },
    {
        "Abstract": "The paper concisely proposes a distinguishing paradigm to study a very large, collective group of agents that is called Network Organization. We will formally define and substantially evaluate this paradigm for self-governing agents, in which the state value function changes dynamically, and describe its salient properties.",
        "A1": "proposes a distinguishing paradigm",
        "A2": "study a very large, collective group of agents",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " evaluate this paradigm for self-governing agents",
        "A83": "",
        "A82": "",
        "A81": "the state value function changes dynamically, and describe its salient properties.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 380265910
    },
    {
        "Abstract": "We introduce a novel method for the continuous online prediction of particulate matter in the air (more specifically, PM10 and PM2.5) given sparse sensor information. A nonparametric model is developed using Gaussian Processes, which eschews the need for an explicit formulation of internal -- and usually very complex -- dependencies between meteorological variables. Instead, it uses historical data to extrapolate pollutant values both spatially (in areas with no sensor information) and temporally (the near future). Each prediction also contains a respective variance, indicating its uncertainty level and thus allowing a probabilistic treatment of results. A novel training methodology (Structural Cross-Validation) is presented, which preserves the spatio-temporal structure of available data during the hyperparameter optimization process. Tests were conducted using a real-time feed from a sensor network in an area of roughly 50x80 km, alongside comparisons with other techniques for air pollution prediction. The promising results motivated the development of a smartphone applicative and a website, currently in use to increase the efficiency of air quality monitoring and control in the area.",
        "A1": " introduce a novel method for the continuous online prediction of particulate matter in the air",
        "A2": " continuous online prediction of particulate matter in the air (more specifically, PM10 and PM2.5) given sparse sensor information",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "continuous online prediction of particulate matter in the air (more specifically, PM10 and PM2.5) given sparse sensor information",
        "A7": "comparisons with other techniques for air pollution prediction",
        "A83": "",
        "A82": "The promising results",
        "A81": " increase the efficiency of air quality monitoring and control in the area",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "eschews the need for an explicit formulation of internal",
        "A52": "Gaussian Processes",
        "A42": " a novel method for the continuous online prediction of particulate matter in the air",
        "A45": " a real-time feed from a sensor network in an area of roughly 50x80 km",
        "am_id": 293763115
    },
    {
        "Abstract": "We develop a new approach for a pre-disaster planning problem which consists in computing an optimal investment plan to strengthen a transportation network, given that a future disaster probabilistically destroys links in the network. We show how the problem can be formulated as a non-linear integer program and devise an AI algorithm to solve it. In particular, we introduce a new type of extreme resource constraint and develop a practically efficient propagation algorithm for it. Experiments show several orders of magnitude improvements over existing approaches, allowing us to close an existing real-world benchmark and to solve to optimality other, more challenging benchmarks.",
        "A1": "develop a new approach for a pre-disaster planning problem which consists in computing an optimal investment plan to strengthen a transportation network, given that a future disaster probabilistically destroys links in the network. ",
        "A2": "a pre-disaster planning problem",
        "A41": " a new approach for a pre-disaster planning problem which consists in computing an optimal investment plan to strengthen a transportation network, given that a future disaster probabilistically destroys links in the network.",
        "A51": "",
        "A61": "",
        "A10": "a new type of extreme resource constraint and develop a practically efficient propagation algorithm for it",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "several orders of magnitude improvements over existing approaches, allowing us to close an existing real-world benchmark and to solve to optimality other, more challenging benchmark",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 362427889
    },
    {
        "Abstract": "Spectral clustering is a fundamental technique in the field of data mining and information processing. Most existing spectral clustering algorithms integrate dimensionality reduction into the clustering process assisted by manifold learning in the original space. However, the manifold in reduced-dimensional subspace is likely to exhibit altered properties in contrast with the original space. Thus, applying manifold information obtained from the original space to the clustering process in a low-dimensional subspace is prone to inferior performance. Aiming to address this issue, we propose a novel convex algorithm that mines the manifold structure in the low-dimensional subspace. In addition, our unified learning process makes the manifold learning particularly tailored for the clustering. Compared with other related methods, the proposed algorithm results in more structured clustering result. To validate the efficacy of the proposed algorithm, we perform extensive experiments on several benchmark datasets in comparison with some state-of-the-art clustering approaches. The experimental results demonstrate that the proposed algorithm has quite promising clustering performance.",
        "A1": " propose a novel convex algorithm ",
        "A2": "applying manifold information obtained from the original space to the clustering process in a low-dimensional subspace is prone to inferior performance. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on several benchmark datasets in comparison with some state-of-the-art clustering approaches",
        "A83": "",
        "A82": "",
        "A81": "quite promising clustering performance.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "mines the manifold structure in the low-dimensional subspac",
        "A53": "",
        "A43": "mines the manifold structure in the low-dimensional subspace.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 152896887
    },
    {
        "Abstract": "Image clustering and visual codebook learning are two fundamental problems in computer vision and they are tightly related. On one hand, a good codebook can generate effective feature representations which largely affect clustering performance. On the other hand, class labels obtained from image clustering can serve as supervised information to guide codebook learning. Traditionally, these two processes are conducted separately and their correlation is generally ignored.In this paper, we propose a Double Layer Gaussian Mixture Model (DLGMM) to simultaneously perform image clustering and codebook learning. In DLGMM, two tasks are seamlessly coupled and can mutually promote each other. Cluster labels and codebook are jointly estimated to achieve the overall best performance. To incorporate the spatial coherence between neighboring visual patches, we propose a Spatially Coherent DLGMM which uses a Markov Random Field to encourage neighboring patches to share the same visual word label.We use variational inference to approximate the posterior of latent variables and learn model parameters.Experiments on two datasets demonstrate the effectiveness of two models.",
        "A1": "we propose a Double Layer Gaussian Mixture Model (DLGMM) to simultaneously perform image clustering and codebook learning.",
        "A2": " In DLGMM, two tasks are seamlessly coupled and can mutually promote each other. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Cluster labels and codebook are jointly estimated to achieve the overall best performance. ",
        "A7": ".Experiments on two datasets ",
        "A83": "",
        "A82": "",
        "A81": "Experiments on two datasets demonstrate the effectiveness of two models.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Experiments on two datasets demonstrate the effectiveness of two models.",
        "A52": "uses a Markov Random Field to encourage neighboring patches to share the same visual word label.",
        "A42": "we propose a Double Layer Gaussian Mixture Model (DLGMM) to simultaneously perform image clustering and codebook learning. ",
        "A45": "",
        "am_id": 419729476
    },
    {
        "Abstract": "The related problems of transfer learning and multitask learning have attracted significant attention, generating a rich literature of models and algorithms. Yet most existing approaches are studied in an offline fashion, implicitly assuming that data from different domains are given as a batch. Such an assumption is not valid in many real-world applications where data samples arrive sequentially, and one wants a good learner even from few examples. The goal of our work is to provide sound extensions to existing transfer and multitask learning algorithms such that they can be used in an anytime setting. More specifically, we propose two novel online boosting algorithms, one for transfer learning and one for multitask learning, both designed to leverage the knowledge of instances in other domains. The experimental results show state-of-the-art empirical performance on standard benchmarks, and we present results of using our methods for effectively detecting new seizures in patients with epilepsy from very few previous samples.",
        "A1": "we propose two novel online boosting algorithms, one for transfer learning and one for multitask learning",
        "A2": "we present results of using our methods for effectively detecting new seizures in patients with epilepsy from very few previous samples.",
        "A41": "transfer learning and multitask learning ",
        "A51": "most existing approaches are studied in an offline fashion, implicitly assuming that data from different domains are given as a batch",
        "A61": " they can be used in an anytime setting",
        "A10": "our methods for effectively detecting new seizures in patients with epilepsy from very few previous samples.",
        "A7": "effectively detecting new seizures in patients with epilepsy ",
        "A83": "",
        "A82": "effectively detecting new seizures in patients with epilepsy from very few previous samples.",
        "A81": " state-of-the-art empirical performance on standard benchmarks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " state-of-the-art empirical performance on standard benchmarks",
        "A53": "leverage the knowledge of instances in other domains",
        "A43": "two novel online boosting algorithms, one for transfer learning and one for multitask learning",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "new seizures in patients with epilepsy ",
        "am_id": 36192163
    },
    {
        "Abstract": "In many situations, it is desirable to optimize a sequence of decisions by maximizing a primary objective while respecting some constraints with respect to secondary objectives. Such problems can be naturally modeled as constrained partially observable Markov decision processes (CPOMDPs) when the environment is partially observable. In this work, we describe a technique based on approximate linear programming to optimize policies in CPOMDPs. The optimization is performed offline and produces a finite state controller with desirable performance guarantees. The approach outperforms a constrained version of point-based value iteration on a suite of benchmark problems.",
        "A1": "we describe a technique based on approximate linear programming to optimize policies in CPOMDPs. ",
        "A2": "The approach outperforms a constrained version of point-based value iteration on a suite of benchmark problems.",
        "A41": "a technique based on approximate linear programming to optimize policies in CPOMDPs. ",
        "A51": "The optimization is performed offline and produces a finite state controller with desirable performance guarantees. ",
        "A61": "The approach outperforms a constrained version of point-based value iteration on a suite of benchmark problems.",
        "A10": " The approach outperforms a constrained version of point-based value iteration on a suite of benchmark problems.",
        "A7": "The approach outperforms a constrained version of point-based value iteration on a suite of benchmark problems.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 99639639
    },
    {
        "Abstract": "Text classification is a foundational task in many NLP applications. Traditional text classifiers often rely on many human-designed features, such as dictionaries, knowledge bases and special tree kernels. In contrast to traditional methods, we introduce a recurrent convolutional neural network for text classification without human-designed features. In our model, we apply a recurrent structure to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks. We also employ a max-pooling layer that automatically judges which words play key roles in text classification to capture the key components in texts. We conduct experiments on four commonly used datasets. The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets.",
        "A1": "we introduce a recurrent convolutional neural network for text classification without human-designed features.",
        "A2": "we apply a recurrent structure to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks.",
        "A41": "a max-pooling layer that automatically judges which words play key roles",
        "A51": "a max-pooling layer that automatically judges which words play key roles in text classification to capture the key components in texts.",
        "A61": "The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets.",
        "A10": "The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets.",
        "A7": "We conduct experiments on four commonly used datasets. ",
        "A83": "",
        "A82": "The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets.",
        "A81": "which may introduce considerably less noise compared to traditional window-based neural networks. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "which may introduce considerably less noise compared to traditional window-based neural networks",
        "A52": "we apply a recurrent structure to capture contextual information as far as possible when learning word representations",
        "A42": " a recurrent convolutional neural network for text classification without human-designed features. ",
        "A45": "",
        "am_id": 78043724
    },
    {
        "Abstract": "Social media platforms are often used by people to express their needs and desires. Such data offer great opportunities to identify users\u2019 consumption intention from user-generated contents, so that better tailored products or services can be recommended. However, there have been few efforts on mining commercial intents from social media contents. In this paper, we investigate the use of social media data to identify consumption intentions for individuals. We develop a Consumption Intention Mining Model (CIMM) based on convolutional neural network (CNN), for identifying whether the user has a consumption intention. The task is domain-dependent, and learning CNN requires a large number of annotated instances, which can be available only in some domains. Hence, we investigate the possibility of transferring the CNN mid-level sentence representation learned from one domain to another by adding an adaptation layer. To demonstrate the effectiveness of CIMM, we conduct experiments on two domains. Our results show that CIMM offers a powerful paradigm for effectively identifying users\u2019 consumption intention based on their social media data. Moreover, our results also confirm that the CNN learned in one domain can be effectively transferred to another domain. This suggests that a great potential for our model to significantly increase effectiveness of product recommendations and targeted advertising.",
        "A1": "In this paper, we investigate the use of social media data to identify consumption intentions for individuals. ",
        "A2": "However, there have been few efforts on mining commercial intents from social media contents.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "This suggests that a great potential for our model to significantly increase effectiveness of product recommendations and targeted advertising.",
        "A7": "To demonstrate the effectiveness of CIMM, we conduct experiments on two domains. ",
        "A83": "",
        "A82": "Moreover, our results also confirm that the CNN learned in one domain can be effectively transferred to another domain.",
        "A81": " Our results show that CIMM offers a powerful paradigm for effectively identifying users\u2019 consumption intention based on their social media data. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "convolutional neural network (CNN),",
        "A42": "Consumption Intention Mining Model (CIMM) ",
        "A45": "",
        "am_id": 130516815
    },
    {
        "Abstract": "The split-delivery vehicle routing problem (SDVRP) is a natural extension of the classical vehicle routing problem (VRP) that allows the same customer to be served by more than one vehicle. This problem is a very challenging combinatorial optimization problem and has attracted much academic attention. To solve it, most of the literature articles adopted heuristic approaches in which the solution is represented by a set of delivery patterns, and the search operators were derived from the traditional VRP operators. Differently, our approach employs the combination of a set of routes and a forest to represent the solution. Several forest-based operators are accordingly introduced. We integrate the new operators into a simple tabu search framework and then demonstrate the efficiency of our approach by conducting experiments on existing benchmark instances.",
        "A1": "Several forest-based operators are accordingly introduced",
        "A2": "The split-delivery vehicle routing problem (SDVRP)",
        "A41": "employs the combination of a set of routes and a forest to represent the solution",
        "A51": "conducting experiments on existing benchmark instances",
        "A61": " our approach employs the combination of a set of routes and a forest to represent the solution",
        "A10": "The split-delivery vehicle routing problem (SDVRP)",
        "A7": "We integrate the new operators into a simple tabu search framework",
        "A83": "",
        "A82": "",
        "A81": "Several forest-based operators",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 258807815
    },
    {
        "Abstract": "We introduce a new hierarchy over monotone set functions, that we refer to as MPH (Maximum over Positive Hypergraphs). Levels of the hierarchy correspond to the degree of complementarity in a given function. The highest level of the hierarchy, MPH-m (where m is the total number of items) captures all monotone functions. The lowest level, MPH-1, captures all monotone submodular functions, and more generally, the class of functions known as XOS. Every monotone function that has a positive hypergraph representation of rank k (in the sense defined by Abraham, Babaioff, Dughmi and Roughgarden [EC 2012]) is in MPH-k. Every monotone function that has supermodular degree k (in the sense defined by Feige and Izsak [ITCS 2013]) is in MPH-(k+1). In both cases, the converse direction does not hold, even in an approximate sense. We present additional results that demonstrate the expressiveness power of MPH-k.One can obtain good approximation ratios for some natural optimization problems, provided that functions are required to lie in low levels of the MPH hierarchy. We present two such applications. One shows that the maximum welfare problem can be approximated within a ratio of k+1 if all players hold valuation functions in MPH-k. The other is an upper bound of 2k on the price of anarchy of simultaneous first price auctions.",
        "A1": "We introduce a new hierarchy over monotone set functions,",
        "A2": "One can obtain good approximation ratios for some natural optimization problems, provided that functions are required to lie in low levels of the MPH hierarchy. We present two such applications. One shows that the maximum welfare problem can be approximated within a ratio of k+1 if all players hold valuation functions in MPH-k. The other is an upper bound of 2k on the price of anarchy of simultaneous first price auctions.",
        "A41": "We introduce a new hierarchy over monotone set functions, ",
        "A51": "The highest level of the hierarchy, MPH-m (where m is the total number of items) captures all monotone functions. The lowest level, MPH-1, captures all monotone submodular functions",
        "A61": " We present additional results that demonstrate the expressiveness power of MPH-k.One can obtain good approximation ratios for some natural optimization problems, provided that functions are required to lie in low levels of the MPH hierarchy. We present two such applications. One shows that the maximum welfare problem can be approximated within a ratio of k+1 if all players hold valuation functions in MPH-k. The other is an upper bound of 2k on the price of anarchy of simultaneous first price auctions.",
        "A10": "We present two such applications. One shows that the maximum welfare problem can be approximated within a ratio of k+1 if all players hold valuation functions in MPH-k. The other is an upper bound of 2k on the price of anarchy of simultaneous first price auctions.",
        "A7": "One shows that the maximum welfare problem can be approximated within a ratio of k+1 if all players hold valuation functions in MPH-k. The other is an upper bound of 2k on the price of anarchy of simultaneous first price auctions.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 388860236
    },
    {
        "Abstract": "Moral reasoning is important to accurately model as AI systems become ever more integrated into our lives. Moral reasoning is rapid and unconscious; analogical reasoning, which can be unconscious, is a promising approach to model moral reasoning. This paper explores the use of analogical generalizations to improve moral reasoning. Analogical reasoning has already been used to successfully model moral reasoning in the MoralDM model, but it exhaustively matches across all known cases, which is computationally intractable and cognitively implausible for human-scale knowledge bases. We investigate the performance of an extension of MoralDM to use the MAC/FAC model of analogical retrieval over three conditions, across a set of highly confusable moral scenarios.",
        "A1": "explores the use of analogical generalizations to improve moral reasoning",
        "A2": "Analogical reasoning has already been used to successfully model moral reasoning in the MoralDM model, but it exhaustively matches across all known cases, which is computationally intractable and cognitively implausible for human-scale knowledge bases.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "investigate the performance of an extension of MoralDM",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "the MAC/FAC model ",
        "A45": "",
        "am_id": 405498966
    },
    {
        "Abstract": "We study the problem of eliciting and aggregating probabilistic information from multiple agents. In order to successfully aggregate the predictions of agents, the principal needs to elicit some notion of confidence from agents, capturing how much experience or knowledge led to their predictions. To formalize this, we consider a principal who wishes to learn the distribution of a random variable. A group of Bayesian agents has each privately observed some independent samples of the random variable. The principal wishes to elicit enough information from each agent, so that her posterior is the same as if she had directly received all of the samples herself. Leveraging techniques from Bayesian statistics, we represent confidence as the number of samples an agent has observed, which is quantified by a hyperparameter from a conjugate family of prior distributions. This then allows us to show that if the principal has access to a few samples, she can achieve her aggregation goal by eliciting predictions from agents using proper scoring rules. In particular, with access to one sample, she can successfully aggregate the agents' predictions if and only if every posterior predictive distribution corresponds to a unique value of the hyperparameter, a property which holds for many common distributions of interest. When this uniqueness property does not hold, we construct a novel and intuitive mechanism where a principal with two samples can elicit and optimally aggregate the agents' predictions.",
        "A1": " study the problem of eliciting and aggregating probabilistic information from multiple agents. ",
        "A2": "aggregate the predictions of agents,",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " When this uniqueness property does not hold, we construct a novel and intuitive mechanism where a principal with two samples can elicit and optimally aggregate the agents' predictions.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " if the principal has access to a few samples, she can achieve her aggregation goal by eliciting predictions from agents using proper scoring rules.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 21128624
    },
    {
        "Abstract": "Recently, a new convex formulation of IBM Model 2 was introduced. In this paper we develop the theory further and introduce a class of convex relaxations for latent variable models which include IBM Model 2. When applied to IBM Model 2, our relaxation class subsumes the previous relaxation as a special case. As proof of concept, we study a new relaxation of IBM Model 2 which is simpler than the previous algorithm: the new relaxation relies on the use of nothing more than a multinomial EM algorithm, does not require the tuning of a learning rate, and has some favorable comparisons to IBM Model 2 in terms of F-Measure. The ideas presented could be applied to a wide range of NLP and machine learning problems.",
        "A1": "we develop the theory further and introduce a class of convex relaxations for latent variable models which include IBM Model 2.",
        "A2": "",
        "A41": "IBM Model 2 was introduced. In this paper we develop the theory further",
        "A51": "IBM Model 2",
        "A61": "simpler than the previous algorithm: the new relaxation relies on the use of nothing more than a multinomial EM algorithm, does not require the tuning of a learning rate, and has some favorable comparisons to IBM Model 2 in terms of F-Measure.",
        "A10": " simpler than the previous algorithm",
        "A7": "",
        "A83": "has some favorable comparisons to IBM Model 2 in terms of F-Measure",
        "A82": "does not require the tuning of a learning rate",
        "A81": " the new relaxation relies on the use of nothing more than a multinomial EM algorithm",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 111944835
    },
    {
        "Abstract": "As Machine Learning (ML) applications embrace greater data size and model complexity, practitioners turn to distributed clusters to satisfy the increased computational and memory demands. Effective use of clusters for ML programs requires considerable expertise in writing distributed code, but existing highly-abstracted frameworks like Hadoop that pose low barriers to distributed-programming have not, in practice, matched the performance seen in highly specialized and advanced ML implementations. The recent Parameter Server (PS) paradigm is a middle ground between these extremes, allowing easy conversion of single-machine parallel ML programs into distributed ones, while maintaining high throughput through relaxed ``consistency models\" that allow asynchronous (and, hence, inconsistent) parameter reads. However, due to insufficient theoretical study, it is not clear which of these consistency models can really ensure correct ML algorithm output; at the same time, there remain many theoretically-motivated but undiscovered opportunities to maximize computational throughput. Inspired by this challenge, we study both the theoretical guarantees and empirical behavior of iterative-convergent ML algorithms in existing PS consistency models. We then use the gleaned insights to improve a consistency model using an \"eager\" PS communication mechanism, and implement it as a new PS system that enables ML programs to reach their solution more quickly.",
        "A1": "We then use the gleaned insights to improve a consistency model using an \"eager\" PS communication mechanism, and implement it as a new PS system that enables ML programs to reach their solution more quickly.",
        "A2": "existing highly-abstracted frameworks like Hadoop that pose low barriers to distributed-programming have not, in practice, matched the performance seen in highly specialized and advanced ML implementations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "enables ML programs to reach their solution more quickly",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "a new PS system that enables ML programs to reach their solution more quickly",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "enables ML programs to reach their solution more quickly",
        "A52": "a consistency model using an \"eager\" PS communication mechanism",
        "A42": "a new PS system that enables ML programs to reach their solution more quickly",
        "A45": "",
        "am_id": 171934601
    },
    {
        "Abstract": "In this paper we propose a wrapper based PSO method for gene selection in microarray datasets, where we gradually refine the feature (gene) space from a very coarse level to a fine grained one, by reducing the gene set at each step of the algorithm. We use the linear support vector machine weight vector to serve as the initial gene pool selection. In addition, we also examine integration of other filter based ranking methods with our proposed approach. Experiments on publicly available datasets, Colon, Leukemia and T2D show that our approach selects only a very small subset of genes while yielding substantial improvements in accuracy over state-of-the-art evolutionary methods.",
        "A1": "In this paper we propose a wrapper based PSO method for gene selection in microarray datasets",
        "A2": "gene selection in microarray datasets",
        "A41": "a wrapper based PSO method for gene selection in microarray datasets",
        "A51": "wrapper based",
        "A61": "reducing the gene set at each step of the algorithm",
        "A10": "our approach selects only a very small subset of genes while yielding substantial improvements in accuracy over state-of-the-art evolutionary methods.",
        "A7": "Experiments on publicly available datasets, Colon, Leukemia and T2D",
        "A83": "",
        "A82": "",
        "A81": "our approach selects only a very small subset of genes while yielding substantial improvements in accuracy over state-of-the-art evolutionary methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 417307300
    },
    {
        "Abstract": "Toponym resolution, or grounding names of places to their actual locations, is an important problem in analysis of both historical corpora and present-day news and web content. Recent approaches have shifted from rule-based spatial minimization methods to machine learned classifiers that use features of the text surrounding a toponym. Such methods have been shown to be highly effective, but they crucially rely on gazetteers and are unable to handle unknown place names or locations. We address this limitation by modeling the geographic distributions of words over the earth's surface: we calculate the geographic profile of each word based on local spatial statistics over a set of geo-referenced language models. These geo-profiles can be further refined by combining in-domain data with background statistics from Wikipedia. Our resolver computes the overlap of all geo-profiles in a given text span; without using a gazetteer, it performs on par with existing classifiers. When combined with a gazetteer, it achieves state-of-the-art performance for two standard toponym resolution corpora (TR-CoNLL and Civil War). Furthermore, it dramatically improves recall when toponyms are identified by named entity recognizers, which often (correctly) find non-standard variants of toponyms.",
        "A1": "Toponym resolution, or grounding names of places to their actual locations,",
        "A2": ", it achieves state-of-the-art performance for two standard toponym resolution corpora (TR-CoNLL and Civil War). Furthermore, it dramatically improves recall when toponyms are identified by named entity recognizers, which often (correctly) find non-standard variants of toponyms.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " When combined with a gazetteer, it achieves state-of-the-art performance for two standard toponym resolution corpora (TR-CoNLL and Civil War). Furthermore, it dramatically improves recall when toponyms are identified by named entity recognizers, which often (correctly) find non-standard variants of toponyms.",
        "A7": " two standard toponym resolution corpora (TR-CoNLL and Civil War)",
        "A83": "",
        "A82": " it dramatically improves recall when toponyms are identified by named entity recognizers, which often (correctly) find non-standard variants of toponyms.",
        "A81": " achieves state-of-the-art performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " When combined with a gazetteer, it achieves state-of-the-art performance for two standard toponym resolution corpora (TR-CoNLL and Civil War). Furthermore, it dramatically improves recall when toponyms are identified by named entity recognizers, which often (correctly) find non-standard variants of toponyms.",
        "A52": " a set of geo-referenced language models.",
        "A42": " we calculate the geographic profile of each word based on local spatial statistics over a set of geo-referenced language models",
        "A45": "",
        "am_id": 305662019
    },
    {
        "Abstract": "In this paper we show that the alpha-beta algorithm and its successor MT-SSS*, as two classic minimax search algorithms, can be implemented as rollout algorithms, a generic algorithmic paradigm widely used in many domains. Specifically, we define a family of rollout algorithms, in which the rollout policy is restricted to select successor nodes only from a certain subset of the children list. We show that any rollout policy in this family (either deterministic or randomized) is guaranteed to evaluate the game tree correctly with a finite number of rollouts. Moreover, we identify simple rollout policies in this family that ``implement'' alpha-beta and MT-SSS*. Specifically, given any game tree, the rollout algorithms with these particular policies always visit the same set of leaf nodes in the same order with alpha-beta and MT-SSS*, respectively. Our results suggest that traditional pruning techniques and the recent Monte Carlo Tree Search algorithms, as two competing approaches for game tree evaluation, may be unified under the rollout paradigm.",
        "A1": " we show that the alpha-beta algorithm and its successor MT-SSS*, as two classic minimax search algorithms, can be implemented as rollout algorithms,",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "traditional pruning techniques and the recent Monte Carlo Tree Search algorithms, as two competing approaches for game tree evaluation, may be unified under the rollout paradigm.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": " alpha-beta algorithm and its successor MT-SSS*",
        "A43": "a generic algorithmic paradigm widely used in many domains",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 211017516
    },
    {
        "Abstract": "Markov decision processes (MDPs) with large number of states are of high practical interest. However, conventional algorithms to solve MDP are computationally infeasible in this scenario. Approximate dynamic programming (ADP) methods tackle this issue by computing approximate solutions. A widely applied ADP method is approximate linear program (ALP) which makes use of linear function approximation and offers theoretical performance guarantees. Nevertheless, the ALP is difficult to solve due to the presence of a large number of constraints and in practice, a reduced linear program (RLP) is solved instead. The RLP has a tractable number of constraints sampled from the original constraints of the ALP. Though the RLP is known to perform well in experiments, theoretical guarantees are available only for a specific RLP obtained under idealized assumptions. In this paper, we generalize the RLP to define a generalized reduced linear program (GRLP) which has a tractable number of constraints that are obtained as positive linear combinations of the original constraints of the ALP. The main contribution of this paper is the novel theoretical framework developed to obtain error bounds for any given GRLP. Central to our framework are two max-norm contraction operators. Our result theoretically justifies linear approximation of constraints. We discuss the implication of our results in the contexts of ADP and reinforcement learning. We also demonstrate via an example in the domain of controlled queues that the experiments conform to the theory.",
        "A1": "we generalize the RLP to define a generalized reduced linear program",
        "A2": "the novel theoretical framework developed to obtain error bounds for any given GRLP",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "two max-norm contraction operators",
        "A44": " GRLP.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " GRLP.",
        "A45": "",
        "am_id": 118984109
    },
    {
        "Abstract": "We propose VecLP, a novel Internet Video recommendation system working for Live TV Programs in this paper. Given little information on the live TV programs, our proposed VecLP system can effectively collect necessary information on both the programs and the subscribers as well as a large volume of related online videos, and then recommend the relevant Internet videos to the subscribers. For that, the key frames are firstly detected from the live TV programs, and then visual and textual features are extracted from these frames to enhance the understanding of the TV broadcasts. Furthermore, by utilizing the subscribers' profiles and their social relationships, a user preference model is constructed, which greatly improves the diversity of the recommendations in our system. The subscriber's browsing history is also recorded and used to make a further personalized recommendation. This work also illustrates how our proposed VecLP system makes it happen. Finally, we dispose some sort of new recommendation strategies in use at the system to meet special needs from diverse live TV programs and throw light upon how to fuse these strategies.",
        "A1": " propose VecLP, a novel Internet Video recommendation system working for Live TV Programs in this paper.",
        "A2": " recommend the relevant Internet videos to the subscribers.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "meet special needs from diverse live TV programs",
        "A7": "",
        "A83": "",
        "A82": "meet special needs from diverse live TV programs ",
        "A81": " recommend the relevant Internet videos to the subscribers.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "effectively collect necessary information on both the programs and the subscribers as well as a large volume of related online videos, and then recommend the relevant Internet videos to the subscribers. ",
        "A52": "utilizing the subscribers' profiles and their social relationships",
        "A42": "a user preference model is constructed, which greatly improves the diversity of the recommendations in our system. ",
        "A45": "",
        "am_id": 318882732
    },
    {
        "Abstract": "Module extraction \u2014 the task of computing a (preferably small) fragment M of an ontology T that preserves entailments over a signature S \u2014 has found many applications in recent years. Extracting modules of minimal size is, however, computationally hard, and often algorithmically infeasible. Thus, practical techniques are based on approximations, where M provably captures the relevant entailments, but is not guaranteed to be minimal. Existing approximations, however, ensure that M preserves all second-order entailments of T w.r.t. S, which is stronger than is required in many applications, and may lead to large modules in practice. In this paper we propose a novel approach in which module extraction is reduced to a reasoning problem in datalog. Our approach not only generalises existing approximations in an elegant way, but it can also be tailored to preserve only specific kinds of entailments, which allows us to extract significantly smaller modules. An evaluation on widely-used ontologies has shown very encouraging results.",
        "A1": "we propose a novel approach in which module extraction is reduced to a reasoning problem in datalog",
        "A2": "practical techniques are based on approximations, where M provably captures the relevant entailments, but is not guaranteed to be minimal",
        "A41": "not only generalises existing approximations in an elegant way, but it can also be tailored to preserve only specific kinds of entailments",
        "A51": "",
        "A61": " module extraction is reduced to a reasoning problem in datalog",
        "A10": " module extraction is reduced to a reasoning problem in datalog",
        "A7": "An evaluation on widely-used ontologies",
        "A83": "",
        "A82": "",
        "A81": "An evaluation on widely-used ontologies has shown very encouraging results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 133371185
    },
    {
        "Abstract": "Markov Decision Problems, MDPs offer an effective mechanism for planning under uncertainty. However, due to unavoidable uncertainty over models, it is difficult to obtain an exact specification of an MDP. We are interested in solving MDPs, where transition and reward functions are not exactly specified. Existing research has primarily focussed on computing infinite horizon stationary policies when optimizing robustness, regret and percentile based objectives. We focus specifically on finite horizon problems with a special emphasis on objectives that are separable over individual instantiations of model uncertainty (i.e., objectives that can be expressed as a sum over instantiations of model uncertainty): (a) First, we identify two separable objectives for uncertain MDPs: Average Value Maximization (AVM) and Confidence Probability Maximisation (CPM). (b) Second, we provide optimization based solutions to compute policies for uncertain MDPs with such objectives. In particular, we exploit the separability of AVM and CPM objectives by employing Lagrangian dual decomposition(LDD). (c) Finally, we demonstrate the utility of the LDD approach on a benchmark problem from the literature.",
        "A1": "We are interested in solving MDPs, where transition and reward functions are not exactly specified. ",
        "A2": "However, due to unavoidable uncertainty over models, it is difficult to obtain an exact specification of an MDP.",
        "A41": "We are interested in solving MDPs, where transition and reward functions are not exactly specified.",
        "A51": " Existing research has primarily focussed on computing infinite horizon stationary policies when optimizing robustness, regret and percentile based objectives. ",
        "A61": "However, due to unavoidable uncertainty over models, it is difficult to obtain an exact specification of an MDP. We are interested in solving MDPs, where transition and reward functions are not exactly specified. ",
        "A10": "due to unavoidable uncertainty over models, it is difficult to obtain an exact specification of an MDP. We are interested in solving MDPs, ",
        "A7": "we exploit the separability of AVM and CPM objectives by employing Lagrangian dual decomposition(LDD).",
        "A83": "",
        "A82": " we identify two separable objectives for uncertain MDPs: Average Value Maximization (AVM) and Confidence Probability Maximisation (CPM). ",
        "A81": "we demonstrate the utility of the LDD approach on a benchmark problem from the literature.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 35690488
    },
    {
        "Abstract": "We consider the problem of classifying micro-posts as churny or non-churny with respect to a given brand. Using Twitter data about three brands, we find that standard machine learning techniques clearly outperform keyword based approaches. However, the three machine learning techniques we employed (linear classification, support vector machines, and logistic regression) do not perform as well on churn classification as on other text classification problems. We investigate demographic, content, and context churn indicators in microblogs and examine factors that make this problem more challenging. Experimental results show an average F1 performance of 75% for target-dependent churn classification in microblogs.",
        "A1": "consider the problem of classifying micro-posts as churny or non-churny with respect to a given brand.",
        "A2": "the problem of classifying micro-posts as churny or non-churny with respect to a given brand.",
        "A41": "standard machine learning techniques clearly outperform keyword based approaches",
        "A51": "machine learning techniques ",
        "A61": "machine learning techniques ",
        "A10": "Experimental results show an average F1 performance of 75% for target-dependent churn classification in microblogs.",
        "A7": "Experimental results show an average F1 performance of 75% for target-dependent churn classification in microblogs.",
        "A83": "",
        "A82": "",
        "A81": "Experimental results show an average F1 performance of 75% for target-dependent churn classification in microblogs.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 289777580
    },
    {
        "Abstract": "We investigate the task of generating coherent survey articles for scientific topics. We introduce an extractive summarization algorithm that combines a content model with a discourse model to generate coherent and readable summaries of scientific topics using text from scientific articles relevant to the topic. Human evaluation on 15 topics in computational linguistics shows that our system produces significantly more coherent summaries than previous systems. Specifically, our system improves the ratings for coherence by 36% in human evaluation compared to C-Lexrank, a state of the art system for scientific article summarization.",
        "A1": "introduce an extractive summarization algorithm that combines a content model with a discourse model to generate coherent and readable summaries of scientific topics using text from scientific articles relevant to the topic",
        "A2": "the task of generating coherent survey articles for scientific topics",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " our system improves the ratings for coherence by 36% in human evaluation compared to C-Lexrank, a state of the art system for scientific article summarization.",
        "A7": "Human evaluation on 15 topics in computational linguistics",
        "A83": "",
        "A82": " our system improves the ratings for coherence by 36% in human evaluation compared to C-Lexrank, a state of the art system for scientific article summarization.",
        "A81": "our system produces significantly more coherent summaries than previous systems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "algorithm that combines a content model with a discourse model to generate coherent and readable summaries of scientific topics using text from scientific articles relevant to the topic",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 155022447
    },
    {
        "Abstract": "We examine the fundamental problem of background modeling which is to model the background scenes in video sequences and segment the moving objects from the background. A novel approach is proposed based on the Restricted Boltzmann Machine (RBM) while exploiting the temporal nature of the problem. In particular, we augment the standard RBM to take a window of sequential video frames as input and generate the background model while enforcing the background smoothly adapting to the temporal changes. As a result, the augmented temporally adaptive model can generate stable background given noisy inputs and adapt quickly to the changes in background while keeping all the advantages of RBMs including exact inference and effective learning procedure. Experimental results demonstrate the effectiveness of the proposed method in modeling the temporal nature in background.",
        "A1": "A novel approach is proposed based on the Restricted Boltzmann Machine (RBM) while exploiting the temporal nature of the problem",
        "A2": "generate stable background given noisy inputs and adapt quickly to the changes in background while keeping all the advantages of RBMs including exact inference and effective learning procedure",
        "A41": "A novel approach",
        "A51": " based on the Restricted Boltzmann Machine (RBM) while exploiting the temporal nature of the problem",
        "A61": "can generate stable background given noisy inputs and adapt quickly to the changes in background while keeping all the advantages of RBMs including exact inference and effective learning procedure",
        "A10": " can generate stable background given noisy inputs and adapt quickly to the changes in background while keeping all the advantages of RBMs including exact inference and effective learning procedure",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of the proposed method in modeling the temporal nature in background",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 49090715
    },
    {
        "Abstract": "Transcribed speech is a critical resource for building statistical speech recognition systems. Recent work has looked towards soliciting transcriptions for large speech corpora from native speakers of the language using crowdsourcing techniques. However, native speakers of the target language may not be readily available for crowdsourcing. We examine the following question: can humans unfamiliar with the target language help transcribe? We follow an information-theoretic approach to this problem: (1) We learn the characteristics of a noisy channel that models the transcribers' systematic perception biases. (2) We use an error-correcting code, specifically a repetition code, to encode the inputs to this channel, in conjunction with a maximum-likelihood decoding rule. To demonstrate the feasibility of this approach, we transcribe isolated Hindi words with the help of Mechanical Turk workers unfamiliar with Hindi. We successfully recover Hindi words with an accuracy of over 85% (and 94% in a 4-best list) using a 15-fold repetition code. We also estimate the conditional entropy of the input to this channel (Hindi words) given the channel output (transcripts from crowdsourced workers) to be less than 2 bits; this serves as a theoretical estimate of the average number of bits of auxiliary information required for errorless recovery.",
        "A1": "",
        "A2": "native speakers of the target language may not be readily available for crowdsourcing",
        "A41": "an information-theoretic approach",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "we transcribe isolated Hindi words with the help of Mechanical Turk workers unfamiliar with Hindi",
        "A83": "",
        "A82": "We also estimate the conditional entropy of the input to this channel (Hindi words) given the channel output (transcripts from crowdsourced workers) to be less than 2 bits",
        "A81": "We successfully recover Hindi words with an accuracy of over 85% (and 94% in a 4-best list) using a 15-fold repetition code.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 309928967
    },
    {
        "Abstract": "The Best Laid Plans is an interactive narrative video game that uses cognitive-inspired fast planning techniques to generate stories with conflict during play. Players alternate between acting out a plan and seeing that plan thwarted by non-player characters. The Glaive narrative planner combines causal-link-based computational models of narrative with the speed of fast heuristic search techniques to adapt the story each time the player attempts a new plan.",
        "A1": "adapt the story each time the player attempts a new plan",
        "A2": "",
        "A41": "adapt the story each time the player attempts a new plan",
        "A51": " combines causal-link-based computational models of narrative with the speed of fast heuristic search techniques",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "adapt the story each time the player attempts a new plan",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 199496549
    },
    {
        "Abstract": "Effectively incorporating external advice is an important problem in reinforcement learning, especially as it moves into the real world. Potential-based reward shaping is a way to provide the agent with a specific form of additional reward, with the guarantee of policy invariance. In this work we give a novel way to incorporate an arbitrary reward function with the same guarantee, by implicitly translating it into the specific form of dynamic advice potentials, which are maintained as an auxiliary value function learnt at the same time. We show that advice provided in this way captures the input reward function in expectation, and demonstrate its efficacy empirically.",
        "A1": "give a novel way to incorporate an arbitrary reward function with the same guarantee, by implicitly translating it into the specific form of dynamic advice potentials, which are maintained as an auxiliary value function learnt at the same time",
        "A2": "Effectively incorporating external advice is an important problem in reinforcement learning",
        "A41": "incorporate an arbitrary reward function with the same guarantee, by implicitly translating it into the specific form of dynamic advice potentials, which are maintained as an auxiliary value function learnt at the same time",
        "A51": "reward shaping is a way to provide the agent with a specific form of additional reward, with the guarantee of policy invariance",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "advice provided in this way captures the input reward function in expectation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 389649268
    },
    {
        "Abstract": "To facilitate interaction with people, robots must not only recognize current actions, but also infer a person's intentions and future behavior. Recent advances in depth camera technology have significantly improved human motion tracking. However, the inherent high dimensionality of interacting with the physical world makes efficiently forecasting human intention and future behavior a challenging task. Predictive methods that estimate uncertainty are therefore critical for supporting appropriate robotic responses to the many ambiguities posed within the human-robot interaction setting. We address these two challenges, high dimensionality and uncertainty, by employing predictive inverse optimal control methods to estimate a probabilistic model of human motion trajectories. Our inverse optimal control formulation estimates quadratic cost functions that best rationalize observed trajectories framed as solutions to linear-quadratic regularization problems. The formulation calibrates its uncertainty from observed motion trajectories, and is efficient in high-dimensional state spaces with linear dynamics. We demonstrate its effectiveness on a task of anticipating the future trajectories, target locations and activity intentions of hand motions.",
        "A1": "estimate a probabilistic model of human motion trajectories",
        "A2": "high dimensionality and uncertainty",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We demonstrate its effectiveness on a task of anticipating the future trajectories, target locations and activity intentions of hand motions.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "employing predictive inverse optimal control methods",
        "A42": "a probabilistic model of human motion trajectories",
        "A45": "",
        "am_id": 265403005
    },
    {
        "Abstract": "Learning from imbalanced data sets is one of the challenging problems in machine learning, which means the number of negative examples is far more than that of positive examples. The main problems of existing methods are: (1) The degree of re-sampling, a key factor greatly affecting performance, needs to be pre-fixed, which is difficult to make the optimal choice; (2) Many useful negative samples are discarded in under-sampling; (3) The effectiveness of algorithm-level methods are limited because they just use the original training data for single classifier. To address the above issues, a novel approach of adaptive sampling with optimal cost is proposed for class-imbalance learning in this paper. The novelty of the proposed approach mainly lies in: adaptively over-sampling the minority positive examples and under-sampling the majority negative examples, forming different sub-classifiers by different subsets of training data with the best cost ratio adaptively chosen, and combining these sub-classifiers according to their accuracy to create a strong classifier. It aims to make full use of the whole training data and improve the performance of class-imbalance learning classifier. The solid experiments are conducted to compare the performance between the proposed approach and 12 state-of-the-art methods on challenging 16 UCI data sets on 3 evaluation metrics, and the results show the proposed approach can achieve superior performance in class-imbalance learning.",
        "A1": "Learning from imbalanced data ",
        "A2": "Learning from imbalanced data sets ",
        "A41": " a novel approach of adaptive sampling with optimal cost is proposed for class-imbalance learning in this paper.",
        "A51": "",
        "A61": " adaptively over-sampling the minority positive examples and under-sampling the majority negative examples, forming different sub-classifiers by different subsets of training data with the best cost ratio adaptively chosen, and combining these sub-classifiers according to their accuracy to create a strong classifier",
        "A10": "the results show the proposed approach can achieve superior performance in class-imbalance learning.",
        "A7": " The solid experiments are conducted to compare the performance between the proposed approach and 12 state-of-the-art methods on challenging 16 UCI data sets on 3 evaluation metrics",
        "A83": "",
        "A82": "",
        "A81": "the results show the proposed approach can achieve superior performance in class-imbalance learning.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 322494640
    },
    {
        "Abstract": "We present an unsupervised approach for abnormal event detection in videos. We propose, given a dictionary of features learned from local spatiotemporal cuboids using the sparse coding objective, the abnormality of an event depends jointly on two factors: the frequency of each feature in reconstructing all events (or, rarity of a feature) and the strength by which it is used in reconstructing the current event (or, the absolute coefficient). The Incremental Coding Length (ICL) of a feature is a measure of its entropy gain. Given a dictionary, the ICL computation does not involve any parameter, is computationally efficient and has been used for saliency detection in images with impressive results. In this paper, the rarity of a dictionary feature is learned online as its average energy, a function of its ICL. The proposed approach is applicable to real world streaming videos. Experiments on three benchmark datasets and evaluations in comparison with a number of mainstream algorithms show that the approach is comparable to the state-of-the-art.",
        "A1": "unsupervised approach for abnormal event detection in videos.",
        "A2": "unsupervised approach for abnormal event detection in videos.",
        "A41": " an unsupervised approach for abnormal event detection in videos",
        "A51": "a dictionary of features learned from local spatiotemporal cuboids using the sparse coding objective",
        "A61": "",
        "A10": " the approach is comparable to the state-of-the-art.",
        "A7": ". Experiments on three benchmark datasets and evaluations in comparison with a number of mainstream algorithms",
        "A83": "",
        "A82": "",
        "A81": " the approach is comparable to the state-of-the-art.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 47287992
    },
    {
        "Abstract": "Applying machine learning and data mining to novel applications is cumbersome. This observation is the prime motivation for the interest in languages for learning and mining. This note provides a gentle introduction to three types of languages that support machine learning and data mining: inductive query languages, which extend database query languages with primitives for mining and learning, modelling languages, which allow to declaratively specify and solve mining and learning problems, and programming languages, that support the learning of functions and subroutines. It uses an example of each type of language to introduce the underlying ideas and puts them into a common perspective. This then forms the basis for a short analysis of the state-of-the-art.",
        "A1": "forms the basis for a short analysis of the state-of-the-art.",
        "A2": "Applying machine learning and data mining to novel applications is cumbersome. ",
        "A41": "This note provides a gentle introduction to three types of languages that support machine learning and data mining:",
        "A51": "three types of languages that support machine learning and data mining",
        "A61": " It uses an example of each type of language to introduce the underlying ideas and puts them into a common perspective. ",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "forms the basis for a short analysis of the state-of-the-art",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 12565264
    },
    {
        "Abstract": "The utilitarian solution criterion, which has been extensively studied in multi-agent decision making under uncertainty, aims to maximize the sum of individual utilities. However, as the utilitarian solution often discriminates against some agents, it is not desirable for many practical applications where agents have their own interests and fairness is expected. To address this issue, this paper introduces egalitarian solution criteria for sequential decision-making under uncertainty, which are based on the maximin principle. Motivated by different application domains, we propose four maximin fairness criteria and develop corresponding algorithms for computing their optimal policies. Furthermore, we analyze the connections between these criteria and discuss and compare their characteristics.",
        "A1": "introduces egalitarian solution criteria",
        "A2": "applications where agents have their own interests and fairness is expected",
        "A41": "egalitarian solution criteria for sequential decision-making under uncertainty",
        "A51": "maximin principle",
        "A61": "egalitarian",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 350982871
    },
    {
        "Abstract": "A user-adaptive information visualization system capable of learning models of users and the visualization tasks they perform could provide interventions optimized for helping specific users in specific task contexts. In this paper, we investigate the accuracy of predicting visualization tasks, user performance on tasks, and user traits from gaze data. We show that predictions made with a logistic regression model are significantly better than a baseline classifier, with particularly strong results for predicting task type and user performance. Furthermore, we compare classifiers built with interface-independent and interface-dependent features, and show that the interface-independent features are comparable or superior to interface-dependent ones. Finally, we discuss how the accuracy of predictive models is affected if they are trained with data from trials that had highlighting interventions added to the visualization.",
        "A1": "we investigate the accuracy of predicting visualization tasks, user performance on tasks, and user traits from gaze data",
        "A2": "A user-adaptive information visualization system capable of learning models of users and the visualization tasks they perform could provide interventions optimized for helping specific users in specific task contexts",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "A user-adaptive information visualization system capable of learning models of users and the visualization tasks they perform could provide interventions optimized for helping specific users in specific task contexts",
        "A7": "",
        "A83": "how the accuracy of predictive models is affected if they are trained with data from trials that had highlighting interventions added to the visualization",
        "A82": "the interface-independent features are comparable or superior to interface-dependent ones",
        "A81": "predictions made with a logistic regression model are significantly better than a baseline classifier",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "with a logistic regression model",
        "A52": "learning models of users",
        "A42": "A user-adaptive information visualization system",
        "A45": "",
        "am_id": 118219030
    },
    {
        "Abstract": "Boolean satisfiability (SAT) solvers have been successfully applied to a wide variety of difficult combinatorial problems. Many further problems can be solved by SAT Modulo Theory (SMT) solvers, which extend SAT solvers to handle additional types of constraints. However, building efficient SMT solvers is often very difficult. In this paper, we define the concept of a Boolean monotonic theory and show how to easily build efficient SMT solvers, including effective theory propagation and clause learning, for such theories. We present examples showing useful constraints that are monotonic, including many graph properties (e.g., shortest paths), and geometric properties (e.g., convex hulls). These constraints arise in problems that are otherwise difficult for SAT solvers to handle, such as procedural content generation. We have implemented several monotonic theory solvers using the techniques we present in this paper and applied these to content generation problems, demonstrating major speed-ups over SAT, SMT, and Answer Set Programming solvers, easily solving instances that were previously out of reach.",
        "A1": " define the concept of a Boolean monotonic theory and show how to easily build efficient SMT solvers",
        "A2": "building efficient SMT solvers",
        "A41": "efficient SMT solvers,",
        "A51": "the concept of a Boolean monotonic theory",
        "A61": "using the techniques we present in this paper ",
        "A10": "effective theory propagation and clause learning",
        "A7": "content generation problems",
        "A83": "",
        "A82": "Answer Set Programming solvers, easily solving instances that were previously out of reach",
        "A81": " major speed-ups over SAT, SMT,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 409337577
    },
    {
        "Abstract": "Is it possible to maximize a monotone submodular function faster than the widely used lazy greedy algorithm (also known as accelerated greedy), both in theory and practice? In this paper, we develop the first linear-time algorithm for maximizing a general monotone submodular function subject to a cardinality constraint. We show that our randomized algorithm, STOCHASTIC-GREEDY, can achieve a (1 \u2212 1/e \u2212 \u03b5) approximation guarantee, in expectation, to the optimum solution in time linear in the size of the data and independent of the cardinality constraint. We empirically demonstrate the effectiveness of our algorithm on submodular functions arising in data summarization, including training large-scale kernel methods, exemplar-based clustering, and sensor placement. We observe that STOCHASTIC-GREEDY practically achieves the same utility value as lazy greedy but runs much faster. More surprisingly, we observe that in many practical scenarios STOCHASTIC-GREEDY does not evaluate the whole fraction of data points even once and still achieves indistinguishable results compared to lazy greedy.",
        "A1": "maximize a monotone submodular function faster than the widely used lazy greedy algorithm",
        "A2": "maximizing a general monotone submodular function subject to a cardinality constraint",
        "A41": "demonstrate the effectiveness of our algorithm on submodular functions arising in data summarization",
        "A51": "training large-scale kernel methods, exemplar-based clustering, and sensor placement",
        "A61": "achieves the same utility value as lazy greedy but runs much faster",
        "A10": "achieves the same utility value as lazy greedy but runs much faster",
        "A7": "to the optimum solution in time linear in the size of the data and independent of the cardinality constraint",
        "A83": "",
        "A82": "achieves indistinguishable results compared to lazy greedy",
        "A81": "our randomized algorithm, STOCHASTIC-GREEDY, can achieve a (1 \u2212 1/e \u2212 \u03b5) approximation guarantee",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "does not evaluate the whole fraction of data points even once and still achieves indistinguishable results compared to lazy greedy",
        "A53": "",
        "A43": "our randomized algorithm, STOCHASTIC-GREEDY, can achieve a (1 \u2212 1/e \u2212 \u03b5) approximation guarantee",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 32716009
    },
    {
        "Abstract": "Recent work has demonstrated the value of social media monitoring for health surveillance (e.g., tracking influenza or depression rates). It is an open question whether such data can be used to make causal inferences (e.g., determining which activities lead to increased depression rates). Even in traditional, restricted domains, estimating causal effects from observational data is highly susceptible to confounding bias. In this work, we estimate the effect of exercise on mental health from Twitter, relying on statistical matching methods to reduce confounding bias. We train a text classifier to estimate the volume of a user's tweets expressing anxiety, depression, or anger, then compare two groups: those who exercise regularly (identified by their use of physical activity trackers like Nike+), and a matched control group. We find that those who exercise regularly have significantly fewer tweets expressing depression or anxiety; there is no significant difference in rates of tweets expressing anger. We additionally perform a sensitivity analysis to investigate how the many experimental design choices in such a study impact the final conclusions, including the quality of the classifier and the construction of the control group.",
        "A1": "estimate the effect of exercise on mental health from Twitter",
        "A2": "such data can be used to make causal inferences",
        "A41": "train a text classifier to estimate the volume of a user's tweets expressing anxiety, depression, or anger,",
        "A51": "text classifier ",
        "A61": "",
        "A10": "",
        "A7": "compare two groups: those who exercise regularly (identified by their use of physical activity trackers like Nike+), and a matched control group",
        "A83": "",
        "A82": "there is no significant difference in rates of tweets expressing anger",
        "A81": "those who exercise regularly have significantly fewer tweets expressing depression or anxiety",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 19405601
    },
    {
        "Abstract": "The leading approach for solving large imperfect-information games is automated abstraction followed by running an equilibrium-finding algorithm. We introduce a distributed version of the most commonly used equilibrium-finding algorithm, counterfactual regret minimization (CFR), which enables CFR to scale to dramatically larger abstractions and numbers of cores. The new algorithm begets constraints on the abstraction so as to make the pieces running on different computers disjoint. We introduce an algorithm for generating such abstractions while capitalizing on state-of-the-art abstraction ideas such as imperfect recall and the earth-mover's-distance similarity metric. Our techniques enabled an equilibrium computation of unprecedented size on a supercomputer with a high inter-blade memory latency. Prior approaches run slowly on this architecture. Our approach also leads to a significant improvement over using the prior best approach on a large shared-memory server with low memory latency. Finally, we introduce a family of post-processing techniques that outperform prior ones. We applied these techniques to generate an agent for two-player no-limit Texas Hold'em. It won the 2014 Annual Computer Poker Competition, beating each opponent with statistical significance.",
        "A1": "enables CFR to scale to dramatically larger abstractions and numbers of cores",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "he 2014 Annual Computer Poker Competition",
        "A83": "",
        "A82": "",
        "A81": "won the 2014 Annual Computer Poker Competition, beating each opponent with statistical significance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "enables CFR to scale to dramatically larger abstractions and numbers of cores",
        "A53": "counterfactual regret minimization",
        "A43": "a distributed version of the most commonly used equilibrium-finding algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 37481879
    },
    {
        "Abstract": "We consider the problem of repeatedly matching a set of alternatives to a set of agents with dynamic ordinal preferences. Despite a recent focus on designing one-shot matching mechanisms in the absence of monetary transfers, little study has been done on strategic behavior of agents in sequential assignment problems. We formulate a generic dynamic matching problem via a sequential stochastic matching process. We design a mechanism based on random serial dictatorship (RSD) that, given any history of preferences and matching decisions, guarantees global stochastic strategyproofness while satisfying desirable local properties. We further investigate the notion of envyfreeness in such sequential settings.",
        "A1": "",
        "A2": "problem of repeatedly matching a set of alternatives to a set of agents with dynamic ordinal preferences",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "given any history of preferences and matching decisions",
        "A83": "",
        "A82": "",
        "A81": " guarantees global stochastic strategyproofness while satisfying desirable local properties",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "random serial dictatorship (RSD)",
        "A42": "design a mechanism",
        "A45": "",
        "am_id": 479624050
    },
    {
        "Abstract": "We study convergence properties of iterative voting procedures. Such procedures are defined by a voting rule and a (restricted) iterative process, where at each step one agent can modify his vote towards a better outcome for himself. It is already known that if the iteration dynamics (the manner in which voters are allowed to modify their votes) are unrestricted, then the voting process may not converge. For most common voting rules this may be observed even under the best response dynamics limitation. It is therefore important to investigate whether and which natural restrictions on the dynamics of iterative voting procedures can guarantee convergence. To this end, we provide two general conditions on the dynamics based on iterative myopic improvements, each of which is sufficient for convergence. We then identify several classes of voting rules (including Positional Scoring Rules, Maximin, Copeland and Bucklin), along with their corresponding iterative processes, for which at least one of these conditions hold.",
        "A1": " study convergence properties of iterative voting procedures.",
        "A2": " convergence properties of iterative voting procedures.",
        "A41": " To this end, we provide two general conditions on the dynamics based on iterative myopic improvements, each of which is sufficient for convergence. We then identify several classes of voting rules (including Positional Scoring Rules, Maximin, Copeland and Bucklin), along with their corresponding iterative processes, for which at least one of these conditions hold.",
        "A51": "investigate whether and which natural restrictions on the dynamics of iterative voting procedures can guarantee convergence.",
        "A61": "investigate whether and which natural restrictions on the dynamics of iterative voting procedures can guarantee convergence.",
        "A10": "each of which is sufficient for convergence",
        "A7": "each of which is sufficient for convergence",
        "A83": "",
        "A82": "identify several classes of voting rules (including Positional Scoring Rules, Maximin, Copeland and Bucklin), along with their corresponding iterative processes, for which at least one of these conditions hold",
        "A81": "provide two general conditions on the dynamics based on iterative myopic improvements, each of which is sufficient for convergence.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 181172956
    },
    {
        "Abstract": "Many AI applications involve the interaction of multiple autonomous agents, requiring those agents to reason about their own beliefs, as well as those of other agents. However, planning involving nested beliefs is known to be computationally challenging. In this work, we address the task of synthesizing plans that necessitate reasoning about the beliefs of other agents. We plan from the perspective of a single agent with the potential for goals and actions that involve nested beliefs, non-homogeneous agents, co-present observations, and the ability for one agent to reason as if it were another. We formally characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology. Our approach represents an important first step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
        "A1": " applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
        "A2": "synthesizing plans that necessitate reasoning about the beliefs of other agents",
        "A41": "epresents an important first step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
        "A51": "plan from the perspective of a single agent",
        "A61": "",
        "A10": "",
        "A7": "characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology",
        "A83": "",
        "A82": "",
        "A81": "represents an important first step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 318738257
    },
    {
        "Abstract": "We provide a novel, flexible, iterative refinement algorithm to automatically construct an approximate statespace representation for Markov Decision Processes (MDPs). Our approach leverages bisimulation metrics, which have been used in prior work to generate features to represent the state space of MDPs.We address a drawback of this approach, which is the expensive computation of the bisimulation metrics. We propose an algorithm to generate an iteratively improving sequence of state space partitions. Partial metric computations guide the representation search and provide much lower space and computational complexity, while maintaining strong convergence properties. We provide theoretical results guaranteeing convergence as well as experimental illustrations of the accuracy and savings (in time and memory usage) of the new algorithm, compared to traditional bisimulation metric computation.",
        "A1": "automatically construct an approximate statespace representation for Markov Decision Processes (MDPs)",
        "A2": " expensive computation of the bisimulation metrics",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the accuracy and savings (in time and memory usage) of the new algorithm",
        "A7": "",
        "A83": "",
        "A82": "the accuracy and savings (in time and memory usage) of the new algorithm",
        "A81": "much lower space and computational complexity, while maintaining strong convergence properties",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "generate an iteratively improving sequence of state space partitions",
        "A53": "bisimulation metrics",
        "A43": "iterative refinement algorithm to automatically construct an approximate statespace representation for Markov Decision Processes (MDPs)",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 373341479
    },
    {
        "Abstract": "In this paper we present a plan-plan distance metric based on Kolmogorov(Algorithmic) complexity. Generating diverse sets of plans is useful for task ssuch as probing user preferences and reasoning about vulnerability to cyberattacks. Generating diverse plans, and comparing different diverse planning approaches requires a domain-independent, theoretically motivated definition of the diversity distance between plans. Previously proposed diversity measures are not theoretically motivated, and can provide inconsistent results on the sameplans. We define the diversity of plans in terms of how surprising one plan is givenanother or, its inverse, the conditional information in one plan givenanother. Kolmogorov complexity provides a domain independent theory of conditional information. While Kolmogorov complexity is not computable, a related metric, Normalized Compression Distance (NCD), provides a well-behaved approximation. In this paper we introduce NCD as an alternative diversity metric, and analyze its performance empirically, in comparison with previous diversity measures, showing strengths and weaknesses of each.We also examine the use of different compressor sin NCD. We show how NCD can be used to select a training set for HTN learning,giving an example of the utility of diversity metrics. We conclude withsuggestions for future work on improving, extending, and applying it to serve new applications.",
        "A1": " present a plan-plan distance metric",
        "A2": "Kolmogorov complexity is not computable",
        "A41": "provides a well-behaved approximation",
        "A51": "Kolmogorov(Algorithmic) complexity",
        "A61": "",
        "A10": "",
        "A7": "in comparison with previous diversity measures, showing strengths and weaknesses of each",
        "A83": "",
        "A82": "NCD can be used to select a training set for HTN learning",
        "A81": "Normalized Compression Distance (NCD), provides a well-behaved approximation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 122451313
    },
    {
        "Abstract": "Hyperparameter optimization is crucial for achieving peak performance with many machine learning algorithms; however, the evaluation of new optimization techniques on real-world hyperparameter optimization problems can be very expensive. Therefore, experiments are often performed using cheap synthetic test functions with characteristics rather different from those of real benchmarks of interest. In this work, we introduce another option: cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces. Specifically, we train regression models on data describing a machine learning algorithm\u2019s performance depending on its hyperparameter setting, and then cheaply evaluate hyperparameter optimization methods using the model\u2019s performance predictions in lieu of running the real algorithm. We evaluated a wide range of regression techniques, both in terms of how well they predict the performance of new hyperparameter settings and in terms of the quality of surrogate benchmarks obtained. We found that tree-based models capture the performance of several machine learning algorithms well and yield surrogate benchmarks that closely resemble real-world benchmarks, while being much easier to use and orders of magnitude cheaper to evaluate.",
        "A1": "",
        "A2": "cheaply evaluate hyperparameter optimization methods",
        "A41": "cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces",
        "A51": "data describing a machine learning algorithm\u2019s performance depending on its hyperparameter setting",
        "A61": "capture the performance of several machine learning algorithms well and yield surrogate benchmarks that closely resemble real-world benchmarks, while being much easier to use and orders of magnitude cheaper to evaluate.",
        "A10": "being much easier to use and orders of magnitude cheaper to evaluate",
        "A7": "a wide range of regression techniques",
        "A83": "",
        "A82": "",
        "A81": " tree-based models capture the performance of several machine learning algorithms well",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 471456265
    },
    {
        "Abstract": "Centerembedding is difficult to process and is known as a rare syntactic construction across languages In this paper we describe a method to incorporate this assumption into the grammar induction tasks by restricting the search space of a model to trees with limited centerembedding The key idea is the tabulation of leftcorner parsing which captures the degree of centerembedding of a parse via its stack depth We apply the technique to learning of famous generative model the dependency model with valence Klein and Manning 2004 Crosslinguistic experiments on Universal Dependencies show that often our method boosts the performance from the baseline and competes with the current stateoftheart model in a number of languages",
        "A1": "",
        "A2": "",
        "A41": "to incorporate this assumption into the grammar induction tasks",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "learning of famous generative model",
        "A83": "",
        "A82": "competes with the current stateoftheart model",
        "A81": "boosts the performance from the baseline",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 368440390
    },
    {
        "Abstract": "A common model for question answering QA is that a good answer is one that is closely related to the question where relatedness is often determined using generalpurpose lexical models such as word embeddings We argue that a better approach is to look for answers that are related to the question in a relevant way according to the information need of the question which may be determined through taskspecific embeddings With causality as a use case we implement this insight in three steps First we generate causal embeddings costeffectively by bootstrapping causeeffect pairs extracted from free text using a small set of seed patterns Second we train dedicated embeddings over this data by using taskspecific contexts ie the context of a cause is its effect Finally we extend a stateoftheart reranking approach for QA to incorporate these causal embeddings We evaluate the causal embedding models both directly with a casual implication task and indirectly in a downstream causal QA task using data from Yahoo Answers We show that explicitly modeling causality improves performance in both tasks In the QA task our best model achieves 373 P1 significantly outperforming a strong baseline by 77 relative",
        "A1": "a better approach is to look for answers that are related to the question",
        "A2": " a better approach is to look for answers that are related to the question",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperforming a strong baseline by 77 relative",
        "A7": "directly with a casual implication task and indirectly in a downstream causal QA task using data from Yahoo Answers",
        "A83": "",
        "A82": " In the QA task our best model achieves 373 P1",
        "A81": " improves performance in both tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "taskspecific embeddings",
        "A42": "",
        "A45": "",
        "am_id": 155140082
    },
    {
        "Abstract": "Situated question answering is the problem of answering questions about an environment such as an image or diagram This problem requires jointly interpreting a question and an environment using background knowledge to select the correct answer We present Parsing to Probabilistic Programs P 3 a novel situated question answering model that can use background knowledge and global features of the questionenvironment interpretation while retaining efficient approximate inference Our key insight is to treat semantic parses as probabilistic programs that execute nondeterministically and whose possible executions represent environmental uncertainty We evaluate our approach on a new publiclyreleased data set of 5000 science diagram questions outperforming several competitive classical and neural baselines",
        "A1": "We present Parsing to Probabilistic Programs P 3",
        "A2": "",
        "A41": "We present Parsing to Probabilistic Programs P 3 a novel situated question answering model that can use background knowledge and global features of the questionenvironment interpretation while retaining efficient approximate inference",
        "A51": "",
        "A61": "",
        "A10": "outperforming several competitive classical and neural baselines",
        "A7": "We evaluate our approach on a new publiclyreleased data set of 5000 science diagram questions",
        "A83": "",
        "A82": "",
        "A81": " outperforming several competitive classical and neural baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 392333786
    },
    {
        "Abstract": "We propose a fast and scalable method for semisupervised learning of sequence models based on anchor words and moment matching Our method can handle hidden Markov models with featurebased loglinear emissions Unlike other semisupervised methods no decoding passes are necessary on the unlabeled data and no graph needs to be constructedonly one pass is necessary to collect moment statistics The model parameters are estimated by solving a small quadratic program for each feature Experiments on partofspeech POS tagging for Twitter and for a lowresource language Malagasy show that our method can learn from very few annotated sentences",
        "A1": " semisupervised learning of sequence models",
        "A2": "",
        "A41": "handle hidden Markov models with featurebased loglinear emissions",
        "A51": "based on anchor words and moment matching",
        "A61": "methods no decoding passes are necessary on the unlabeled data",
        "A10": "",
        "A7": "for Twitter and for a lowresource language Malagasy",
        "A83": "",
        "A82": "",
        "A81": " learn from very few annotated sentences",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 5899523
    },
    {
        "Abstract": "RSTstyle documentlevel discourse parsing remains a difficult task and efficient deep learning models on this task have rarely been presented In this paper we propose an attentionbased hierarchical neural network model for discourse parsing We also incorporate tensorbased transformation function to model complicated feature interactions Experimental results show that our approach obtains comparable performance to the contemporary stateoftheart systems with little manual feature engineering",
        "A1": "propose an attentionbased hierarchical neural network model for discourse parsing",
        "A2": "obtains comparable performance to the contemporary stateoftheart systems with little manual feature engineering",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " our approach obtains comparable performance to the contemporary stateoftheart systems with little manual feature engineering",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "attention",
        "A42": "an attentionbased hierarchical neural network model for discourse parsing",
        "A45": "",
        "am_id": 103888536
    },
    {
        "Abstract": "In this paper we study the task of response selection for multiturn humancomputer conversation Previous approaches take word as a unit and view context and response as sequences of words This kind of approaches do not explicitly take each utterance as a unit therefore it is difficult to catch utterancelevel discourse information and dependencies In this paper we propose a multiview response selection model that integrates information from two different views ie word sequence view and utterance sequence view We jointly model the two views via deep neural networks Experimental results on a public corpus for contextsensitive response selection demonstrate the effectiveness of the proposed multiview model which significantly outperforms other singleview baselines",
        "A1": "we propose a multiview response selection model",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of the proposed multiview model which significantly outperforms other singleview baselines",
        "A7": " on a public corpus for contextsensitive response selection",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of the proposed multiview mode",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "deep neural networks",
        "A42": " a multiview response selection model that integrates information from two different views ie word sequence view and utterance sequence view",
        "A45": "",
        "am_id": 481252338
    },
    {
        "Abstract": "We present the Structured Weighted Violations Perceptron SWVP algorithm a new structured prediction algorithm that generalizes the Collins Structured Perceptron CSP Collins 2002 Unlike CSP the update rule of SWVP explicitly exploits the internal structure of the predicted labels We prove the convergence of SWVP for linearly separable training sets provide mistake and generalization bounds and show that in the general case these bounds are tighter than those of the CSP special case In synthetic data experiments with data drawn from an HMM various variants of SWVP substantially outperform its CSP special case SWVP also provides encouraging initial dependency parsing results",
        "A1": "present the Structured Weighted Violations Perceptron SWVP algorithm a new structured prediction algorithm that generalizes the Collins Structured Perceptron CSP Collins 2002",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "In synthetic data experiments with data drawn from an HMM various variants of SWVP substantially outperform its CSP special case",
        "A7": "synthetic data experiments with data drawn from an HMM",
        "A83": "SWVP also provides encouraging initial dependency parsing results",
        "A82": "various variants of SWVP substantially outperform its CSP special case",
        "A81": "convergence of SWVP for linearly separable training sets provide mistake and generalization bounds and show that in the general case these bounds are tighter than those of the CSP special case",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "the Structured Weighted Violations Perceptron SWVP algorithm a new structured prediction algorithm that generalizes the Collins Structured Perceptron CSP Collins 2002",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 246197008
    },
    {
        "Abstract": "Word embeddings allow natural language processing systems to share statistical information across related words These embeddings are typically based on distributional statistics making it difficult for them to generalize to rare or unseen words We propose to improve word embeddings by incorporating morphological information capturing shared subword features Unlike previous work that constructs word embeddings directly from morphemes we combine morphological and distributional information in a unified probabilistic framework in which the word embedding is a latent variable The morphological information provides a prior distribution on the latent word embeddings which in turn condition a likelihood function over an observed corpus This approach yields improvements on intrinsic word similarity evaluations and also in the downstream task of partofspeech tagging",
        "A1": "improve word embeddings",
        "A2": "difficult for them to generalize to rare or unseen words",
        "A41": "combine morphological and distributional information in a unified probabilistic framework",
        "A51": "",
        "A61": "combine morphological and distributional information in a unified probabilistic framework",
        "A10": "yields improvements on intrinsic word similarity evaluations and also in the downstream task of partofspeech tagging",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 488316835
    },
    {
        "Abstract": "Verbal comprehension questions appear very frequently in Intelligence Quotient IQ tests which measure humans verbal ability including the understanding of the words with multiple senses the synonyms and antonyms and the analogies among words In this work we explore whether such tests can be solved automatically by the deep learning technologies for text data We found that the task was quite challenging and simply applying existing technologies like word embedding could not achieve a good performance due to the multiple senses of words and the complex relations among words To tackle these challenges we propose a novel framework to automatically solve the verbal IQ questions by leveraging improved word embedding by jointly considering the multisense nature of words and the relational information among words Experimental results have shown that the proposed framework can not only outperform existing methods for solving verbal comprehension questions but also exceed the average performance of the Amazon Mechanical Turk workers involved in the study",
        "A1": "we explore whether such tests can be solved automatically by the deep learning technologies for text data ",
        "A2": "the proposed framework can not only outperform existing methods for solving verbal comprehension questions but also exceed the average performance of the Amazon Mechanical Turk workers involved in the study",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed framework can not only outperform existing methods for solving verbal comprehension questions but also exceed the average performance of the Amazon Mechanical Turk workers involved in the study",
        "A7": "",
        "A83": "",
        "A82": "exceed the average performance of the Amazon Mechanical Turk workers involved in the study",
        "A81": "outperform existing methods for solving verbal comprehension questions ",
        "A64": "by leveraging improved word embedding by jointly considering the multisense nature of words and the relational information among words",
        "A54": " deep learning technologies",
        "A44": "by leveraging improved word embedding by jointly considering the multisense nature of words and the relational information among words ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 172328124
    },
    {
        "Abstract": "Multiple treebanks annotated under heterogeneous standards give rise to the research question of best utilizing multiple resources for improving statistical models Prior research has focused on discrete models leveraging stacking and multiview learning to address the problem In this paper we empirically investigate heterogeneous annotations using neural network models building a neural network counterpart to discrete stacking and multiview learning respectively finding that neural models have their unique advantages thanks to the freedom from manual feature engineering Neural model achieves not only better accuracy improvements but also an order of magnitude faster speed compared to its discrete baseline adding little time cost compared to a neural model trained on a single treebank",
        "A1": " best utilizing multiple resources for improving statistical models",
        "A2": "Prior research has focused on discrete models leveraging stacking and multiview learning to address the problem",
        "A41": "heterogeneous annotations using neural network models",
        "A51": "neural network",
        "A61": "",
        "A10": " freedom from manual feature engineering",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "achieves not only better accuracy improvements but also an order of magnitude faster speed",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 112886428
    },
    {
        "Abstract": "Previous work on automatic summarization does not thoroughly consider coherence while generating the summary We introduce a graphbased approach to summarize scientific articles We employ coherence patterns to ensure that the generated summaries are coherent The novelty of our model is twofold we mine coherence patterns in a corpus of abstracts and we propose a method to combine coherence importance and nonredundancy to generate the summary We optimize these factors simultaneously using Mixed Integer Programming Our approach significantly outperforms baseline and stateoftheart systems in terms of coherence summary coherence assessment and relevance ROUGE scores",
        "A1": "We introduce a graphbased approach to summarize scientific articles",
        "A2": "We employ coherence patterns to ensure that the generated summaries are coherent",
        "A41": "a graphbased approach to summarize scientific articles",
        "A51": "",
        "A61": "The novelty of our model is twofold we mine coherence patterns in a corpus of abstracts",
        "A10": "Our approach significantly outperforms baseline and stateoftheart systems in terms of coherence summary coherence assessment and relevance ROUGE scores",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Our approach significantly outperforms baseline and stateoftheart systems in terms of coherence summary coherence assessment and relevance ROUGE scores",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 254574816
    },
    {
        "Abstract": "An exciting outcome of research at the intersection of language and vision is that of zeroshot learning ZSL ZSL promises to scale visual recognition by borrowing distributed semantic models learned from linguistic corpora and turning them into visual recognition models However the popular wordvector DSM embeddings are relatively impoverished in their expressivity as they model each word as a single vector point In this paper we explore worddistribution embeddings for ZSL We present a visuallinguistic mapping for ZSL in the case where words and visual categories are both represented by distributions Experiments show improved results on ZSL benchmarks due to this better exploiting of intraconcept variability in each modality",
        "A1": "we explore worddistribution embeddings for ZSL ",
        "A2": " the popular wordvector DSM embeddings are relatively impoverished in their expressivity as they model each word as a single vector point",
        "A41": " words and visual categories are both represented by distributions",
        "A51": "",
        "A61": "this better exploiting of intraconcept variability in each modality",
        "A10": "this better exploiting of intraconcept variability in each modality",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " improved results on ZSL benchmarks due to this better exploiting of intraconcept variability in each modality",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 227037994
    },
    {
        "Abstract": "Temporal common sense has applications in AI tasks such as QA multidocument summarization and humanAI communication We propose the task of sequencing  given a jumbled set of aligned imagecaption pairs that belong to a story the task is to sort them such that the output sequence forms a coherent story We present multiple approaches via unary position and pairwise order predictions and their ensemblebased combinations achieving strong results on this task We use both textbased and imagebased features which depict complementary improvements Using qualitative examples we demonstrate that our models have learnt interesting aspects of temporal common sense",
        "A1": "",
        "A2": "propose the task of sequencing  given a jumbled set of aligned imagecaption pairs that belong to a story",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "textbased and imagebased features",
        "A83": "",
        "A82": "",
        "A81": "that our models have learnt interesting aspects of temporal common sense",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "unary position and pairwise order predictions",
        "A42": " sort them such that the output sequence forms a coherent story",
        "A45": "",
        "am_id": 65151610
    },
    {
        "Abstract": "This work investigates style and topic aspects of language in online communities looking at both utility as an identifier of the community and correlation with community reception of content Style is characterized using a hybrid word and partofspeech tag ngram language model while topic is represented using Latent Dirichlet Allocation Experiments with several Reddit forums show that style is a better indicator of community identity than topic even for communities organized around specific topics Further there is a positive correlation between the community reception to a contribution and the style similarity to that community but not so for topic similarity",
        "A1": "investigates style and topic aspects of language in online communities",
        "A2": " partofspeech tag ngram language model ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "t both utility as an identifier of the community and correlation with community reception of content ",
        "A7": "Experiments with several Reddit forums ",
        "A83": "",
        "A82": " there is a positive correlation between the community reception to a contribution and the style similarity ",
        "A81": " style is a better indicator of community identity than topic",
        "A64": "topic is represented using Latent Dirichlet Allocation ",
        "A54": "hybrid word and partofspeech tag ngram language model ",
        "A44": "correlation with community reception of content ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 180919163
    },
    {
        "Abstract": "Linguistic research on multilingual societies has indicated that there is usually a preferred language for expression of emotion and sentiment Dewaele 2010 Paucity of data has limited such studies to participant interviews and speech transcriptions from small groups of speakers In this paper we report a study on 430000 unique tweets from Indian users specifically HindiEnglish bilinguals to understand the language of preference if any for expressing opinion and sentiment To this end we develop classifiers for opinion detection in these languages and further classifying opinionated tweets into positive negative and neutral sentiments Our study indicates that Hindi ie the native language is preferred over English for expression of negative opinion and swearing As an aside we explore some common pragmatic functions of codeswitching through sentiment detection",
        "A1": "to understand the language of preference if any for expressing opinion and sentiment ",
        "A2": "to understand the language of preference if any for expressing opinion and sentiment ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a study on 430000 unique tweets from Indian users specifically HindiEnglish bilinguals",
        "A83": "",
        "A82": "we explore some common pragmatic functions of codeswitching through sentiment detection",
        "A81": "Hindi ie the native language is preferred over English for expression of negative opinion and swearing",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "on 430000 unique tweets from Indian users specifically HindiEnglish bilinguals",
        "A42": "classifiers for opinion detection in these languages and further classifying opinionated tweets into positive negative and neutral sentiments",
        "A45": "",
        "am_id": 445691647
    },
    {
        "Abstract": "Convolutional Neural Networks CNNs have shown to yield very strong results in several Computer Vision tasks Their application to language has received much less attention and it has mainly focused on static classification tasks such as sentence classification for Sentiment Analysis or relation extraction In this work we study the application of CNNs to language modeling a dynamic sequential prediction task that needs models to capture local as well as longrange dependency information Our contribution is twofold First we show that CNNs achieve 1126 better absolute performance than feedforward neural language models demonstrating their potential for language representation even in sequential tasks As for recurrent models our model outperforms RNNs but is below state of the art LSTM models Second we gain some understanding of the behavior of the model showing that CNNs in language act as feature detectors at a high level of abstraction like in Computer Vision and that the model can profitably use information from as far as 16 words before the target",
        "A1": "language modeling",
        "A2": "the application of CNNs to language modeling a dynamic sequential prediction task that needs models to capture local as well as longrange dependency ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "the model can profitably use information from as far as 16 words before the target",
        "A81": "our model outperforms RNNs but is below state of the art LSTM models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Convolutional Neural Networks",
        "A52": "Convolutional Neural Networks",
        "A42": "capture local as well as longrange dependency information",
        "A45": "",
        "am_id": 460800032
    },
    {
        "Abstract": "Recent neural models of dialogue generation offer great promise for generating responses for conversational agents but tend to be shortsighted predicting utterances one at a time while ignoring their influence on future outcomes Modeling the future direction of a dialogue is crucial to generating coherent interesting dialogues a need which led traditional NLP models of dialogue to draw on reinforcement learning In this paper we show how to integrate these goals applying deep reinforcement learning to model future reward in chatbot dialogue The model simulates dialogues between two virtual agents using policy gradient methods to reward sequences that display three useful conversational properties informativity coherence and ease of answering related to forwardlooking function We evaluate our model on diversity length as well as with human judges showing that the proposed algorithm generates more interactive responses and manages to foster a more sustained conversation in dialogue simulation This work marks a first step towards learning a neural conversational model based on the longterm success of dialogues",
        "A1": "show how to integrate these goals applying deep reinforcement learning to model future reward in chatbot dialogue",
        "A2": "marks a first step towards learning a neural conversational model based on the longterm success of dialogues",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "This work marks a first step towards learning a neural conversational model based on the longterm success of dialogues",
        "A7": "on diversity length as well as with human judges",
        "A83": "",
        "A82": "",
        "A81": "the proposed algorithm generates more interactive responses and manages to foster a more sustained conversation in dialogue simulation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "applying deep reinforcement learning to model future reward in chatbot dialogue ",
        "A52": "deep reinforcement learning",
        "A42": "applying deep reinforcement learning to model future reward in chatbot dialogue ",
        "A45": "",
        "am_id": 70100303
    },
    {
        "Abstract": "This article tackles a new challenging task in computational argumentation Given a pair of two arguments to a certain controversial topic we aim to directly assess qualitative properties of the arguments in order to explain why one argument is more convincing than the other one We approach this task in a fully empirical manner by annotating 26k explanations written in natural language These explanations describe convincingness of arguments in the given argument pair such as their strengths or flaws We create a new crowdsourced corpus containing 9111 argument pairs multilabeled with 17 classes which was cleaned and curated by employing several strict quality measures We propose two tasks on this data set namely 1 predicting the full label distribution and 2 classifying types of flaws in less convincing arguments Our experiments with featurerich SVM learners and Bidirectional LSTM neural networks with convolution and attention mechanism reveal that such a novel finegrained analysis of Web argument convincingness is a very challenging task We release the new corpus UKPConvArg2 and the accompanying software under permissive licenses to the research community",
        "A1": "",
        "A2": "This article tackles a new challenging task in computational argumentation",
        "A41": "nnotating 26k explanations written in natural language",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Our experiments with featurerich SVM learners and Bidirectional LSTM neural networks with convolution and attention mechanism",
        "A83": "",
        "A82": "",
        "A81": "reveal that such a novel finegrained analysis of Web argument convincingness is a very challenging task ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 353137637
    },
    {
        "Abstract": "For many lowresource languages spoken language resources are more likely to be annotated with translations than with transcriptions Translated speech data is potentially valuable for documenting endangered languages or for training speech translation systems A first step towards making use of such data would be to automatically align spoken words with their translations We present a model that combines Dyer et als reparameterization of IBM Model 2 fastalign and kmeans clustering using Dynamic Time Warping as a distance measure The two components are trained jointly using expectationmaximization In an extremely lowresource scenario our model performs significantly better than both a neural model and a strong baseline",
        "A1": "We present a model ",
        "A2": " automatically align spoken words with their translations ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " performs significantly better than both a neural model and a strong baseline",
        "A7": "an extremely lowresource scenario",
        "A83": "",
        "A82": "",
        "A81": "performs significantly better than both a neural model and a strong baseline",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "combines Dyer et als reparameterization of IBM Model 2 fastalign and kmeans clustering using Dynamic Time Warping",
        "A42": " a model that combines Dyer et als reparameterization of IBM Model 2 fastalign and kmeans clustering using Dynamic Time Warping as a distance measure ",
        "A45": "",
        "am_id": 180175425
    },
    {
        "Abstract": "Crosslingual word embeddings represent lexical items from different languages in the same vector space enabling transfer of NLP tools However previous attempts had expensive resource requirements difficulty incorporating monolingual data or were unable to handle polysemy We address these drawbacks in our method which takes advantage of a high coverage dictionary in an EM style training algorithm over monolingual corpora in two languages Our model achieves stateoftheart performance on bilingual lexicon induction task exceeding models using large bilingual corpora and competitive results on the monolingual word similarity and crosslingual document classification task",
        "A1": "takes advantage of a high coverage dictionary in an EM style training algorithm over monolingual corpora in two languages",
        "A2": "takes advantage of a high coverage dictionary in an EM style training algorithm over monolingual corpora in two languages",
        "A41": "address these drawbacks ",
        "A51": "",
        "A61": "",
        "A10": " large bilingual corpora and competitive results",
        "A7": "bilingual lexicon induction task exceeding models using large bilingual corpora and competitive results on the monolingual word similarity and crosslingual document classification task",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 474315198
    },
    {
        "Abstract": "SequencetoSequence seq2seq modeling has rapidly become an important generalpurpose NLP tool that has proven effective for many textgeneration and sequencelabeling tasks Seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local nextword distributions In this work we introduce a model and beamsearch training scheme based on the work of Daume III and Marcu 2005 that extends seq2seq to learn global sequence scores This structured approach avoids classical biases associated with local training and unifies the training loss with the testtime usage while preserving the proven model architecture of seq2seq and its efficient training approach We show that our system outperforms a highlyoptimized attentionbased seq2seq system and other baselines on three different sequence to sequence tasks word ordering parsing and machine translation",
        "A1": "SequencetoSequence seq2seq modeling ",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our system outperforms a highlyoptimized attentionbased seq2seq system and other baselines ",
        "A7": " three different sequence to sequence tasks word ordering parsing and machine translation",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "extends seq2seq to learn global sequence scores",
        "A52": " the work of Daume III and Marcu 2005",
        "A42": "a model and beamsearch training scheme",
        "A45": "",
        "am_id": 129047800
    },
    {
        "Abstract": "For AI systems to reason about real world situations they need to recognize which processes are at play and which entities play key roles in them Our goal is to extract this kind of rolebased knowledge about processes from multiple sentencelevel descriptions This knowledge is hard to acquire while semantic role labeling SRL systems can extract sentence level role information about individual mentions of a process their results are often noisy and they do not attempt create a globally consistent characterization of a process To overcome this we extend standard within sentence joint inference to inference across multiple sentences This cross sentence inference promotes role assignments that are compatible across different descriptions of the same process When formulated as an Integer Linear Program this leads to improvements over withinsentence inference by nearly 3 in F1 The resulting rolebased knowledge is of high quality with a F1 of nearly 82",
        "A1": "to extract this kind of rolebased knowledge about processes from multiple sentencelevel descriptions",
        "A2": "For AI systems to reason about real world situations they need to recognize which processes are at play and which entities play key roles in them",
        "A41": "extend standard within sentence joint inference to inference across multiple sentences",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "formulated as an Integer Linear Program this leads to improvements over withinsentence inference by nearly 3 in F1",
        "A83": "",
        "A82": "",
        "A81": "of high quality with a F1 of nearly 82",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 32488692
    },
    {
        "Abstract": "We show that a characterlevel encoderdecoder framework can be successfully applied to question answering with a structured knowledge base We use our model for singlerelation question answering and demonstrate the effectiveness of our approach on the SimpleQuestions dataset Bordes et al 2015 where we improve stateoftheart accuracy from 639 to 709 without use of ensembles Importantly our characterlevel model has 16x fewer parameters than an equivalent wordlevel model can be learned with significantly less data compared to previous work which relies on data augmentation and is robust to new entities in testing 1",
        "A1": "show that a characterlevel encoderdecoder framework",
        "A2": "successfully applied to question answering with a structured knowledge base We use our model for singlerelation question answering ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our characterlevel model has 16x fewer parameters than an equivalent wordlevel model can be learned with significantly less data compared to previous work ",
        "A7": "on the SimpleQuestions dataset Bordes et al 2015",
        "A83": "",
        "A82": "",
        "A81": " improve stateoftheart accuracy from 639 to 709 without use of ensembles",
        "A64": " we improve stateoftheart accuracy from 639 to 709 without use of ensembles ",
        "A54": "",
        "A44": "a characterlevel encoderdecoder framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 155307098
    },
    {
        "Abstract": "Texts present coherent stories that have a particular theme or overall setting for example science fiction or western In this paper we present a text generation method called rewriting that edits existing humanauthored narratives to change their theme without changing the underlying story We apply the approach to math word problems where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught Our rewriting method uses a twostage decoding process which proposes new words from the target theme and scores the resulting stories according to a number of factors defining aspects of syntactic semantic and thematic coherence Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts outperforming a number of baselines We also release a new dataset of humanauthored rewrites of math word problems in several themes",
        "A1": "In this paper we present a text generation method called rewriting that edits existing humanauthored narratives to change their theme without changing the underlying story",
        "A2": "we present a text generation method called rewriting that edits existing humanauthored narratives to change their theme without changing the underlying story",
        "A41": " text generation method called rewriting that edits existing humanauthored narratives to change their theme without changing the underlying story",
        "A51": "uses a twostage decoding process ",
        "A61": " We also release a new dataset of humanauthored rewrites of math word problems in several themes",
        "A10": " Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts outperforming a number of baselines We also release a new dataset of humanauthored rewrites of math word problems in several themes",
        "A7": " Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts outperforming a number of baselines ",
        "A83": "",
        "A82": " We also release a new dataset of humanauthored rewrites of math word problems in several themes",
        "A81": "the final stories typically represent the new theme well while still testing the original math concepts outperforming a number of baselines ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 477597401
    },
    {
        "Abstract": "Regulating deep neural networks DNNs with human structured knowledge has shown to be of great benefit for improved accuracy and interpretability We develop a general framework that enables learning knowledge and its confidence jointly with the DNNs so that the vast amount of fuzzy knowledge can be incorporated and automatically optimized with little manual efforts We apply the framework to sentence sentiment analysis augmenting a DNN with massive linguistic constraints on discourse and polarity structures Our model substantially enhances the performance using less training data and shows improved interpretability The principled framework can also be applied to posterior regularization for regulating other statistical models",
        "A1": "develop a general framework ",
        "A2": "enables learning knowledge and its confidence jointly with the DNNs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "posterior regularization for regulating other statistical models",
        "A7": "enhances the performance using less training data and shows improved interpretability",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "We apply the framework to sentence sentiment analysis augmenting a DNN with massive linguistic constraints on discourse and polarity structures ",
        "A54": "",
        "A44": "a general framework that enables learning knowledge and its confidence jointly with the DNNs ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 308914602
    },
    {
        "Abstract": "Recently there is rising interest in modelling the interactions of two sentences with deep neural networks However most of the existing methods encode two sequences with separate encoders in which a sentence is encoded with little or no information from the other sentence In this paper we propose a deep architecture to model the strong interaction of sentence pair with two coupledLSTMs Specifically we introduce two coupled ways to model the interdependences of two LSTMs coupling the local contextualized interactions of two sentences We then aggregate these interactions and use a dynamic pooling to select the most informative features Experiments on two very large datasets demonstrate the efficacy of our proposed architectures",
        "A1": "modelling the interactions of two sentences with deep neural networks",
        "A2": "most of the existing methods encode two sequences with separate encoders in which a sentence is encoded with little or no information from the other sentence",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on two very large datasets ",
        "A83": "",
        "A82": "",
        "A81": "the efficacy of our proposed architectures",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "coupling the local contextualized interactions of two sentences",
        "A52": "coupledLSTM",
        "A42": "a deep architecture to model the strong interaction of sentence pair with two coupledLSTMs",
        "A45": "",
        "am_id": 343587940
    },
    {
        "Abstract": "We describe a neural shiftreduce parsing model for CCG factored into four unidirectional LSTMs and one bidirectional LSTM This factorization allows the linearization of the complete parsing history and results in a highly accurate greedy parser that outperforms all previous beamsearch shiftreduce parsers for CCG By further deriving a globally optimized model using a taskbased loss we improve over the state of the art by up to 267 labeled F1",
        "A1": "linearization of the complete parsing history",
        "A2": "allows the linearization of the complete parsing history",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperforms all previous beamsearch shiftreduce parsers for CCG ",
        "A7": "",
        "A83": "",
        "A82": " improve over the state of the art by up to 267 labeled F1",
        "A81": "outperforms all previous beamsearch shiftreduce parsers for CCG",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " allows the linearization of the complete parsing history and results in a highly accurate greedy parser that outperforms all previous beamsearch shiftreduce parsers for CCG",
        "A52": "LSTM",
        "A42": " a neural shiftreduce parsing model",
        "A45": "",
        "am_id": 463248326
    },
    {
        "Abstract": "Syntactic parsing of web queries is important for query understanding However web queries usually do not observe the grammar of a written language and no labeled syntactic trees for web queries are available In this paper we focus on a querys clicked sentence ie a wellformed sentence that i contains all the tokens of the query and ii appears in the querys top clicked web pages We argue such sentences are semantically consistent with the query We introduce algorithms to derive a querys syntactic structure from the dependency trees of its clicked sentences This gives us a web query treebank without manual labeling We then train a dependency parser on the treebank Our model achieves much better UAS 086 and LAS 080 scores than stateoftheart parsers on web queries",
        "A1": " a querys clicked sentence ie a wellformed sentence",
        "A2": "a dependency parser on the treebank Our model achieves much better",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves much better UAS 086 and LAS 080 scores than stateoftheart parsers on web queries",
        "A7": "a dependency parser on the treebank Our model",
        "A83": "",
        "A82": "",
        "A81": "achieves much better UAS 086 and LAS 080 scores than stateoftheart parsers on web queries",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " a wellformed sentence",
        "A52": "algorithms to derive a querys syntactic structure from the dependency trees of its clicked sentences ",
        "A42": " a web query treebank without manual labeling",
        "A45": "",
        "am_id": 43451960
    },
    {
        "Abstract": "Sequences found at the beginning of TV shows help the audience absorb the essence of previous episodes and grab their attention with upcoming plots In this paper we propose a novel task text recap extraction Compared with conventional summarization text recap extraction captures the duality of summarization and plot contingency between adjacent episodes We present a new dataset TVRecap for text recap extraction on TV shows We propose an unsupervised model that identifies text recaps based on plot descriptions We introduce two contingency factors concept coverage and sparse reconstruction that encourage recaps to prompt the upcoming story development We also propose a multiview extension of our model which can incorporate dialogues and synopses We conduct extensive experiments on TVRecap and conclude that our model outperforms summarization approaches",
        "A1": "propose an unsupervised model that identifies text recaps based on plot descriptions",
        "A2": "Sequences found at the beginning of TV shows help the audience absorb the essence of previous episodes and grab their attention with upcoming plots In this paper we propose a novel task text recap extractio",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We conduct extensive experiments on TVRecap and conclude that our model outperforms summarization approaches",
        "A83": "",
        "A82": "",
        "A81": "our model outperforms summarization approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "plot descriptions",
        "A42": "an unsupervised model that identifies text recaps based on plot descriptions",
        "A45": "",
        "am_id": 60921949
    },
    {
        "Abstract": "Users prefer natural language software requirements because of their usability and accessibility When they describe their wishes for software development they often provide offtopic information We therefore present REaCT1 an automated approach for identifying and semantically annotating the ontopic parts of requirement descriptions It is designed to support requirement engineers in the elicitation process on detecting and analyzing requirements in usergenerated content Since no lexical resources with domainspecific information about requirements are available we created a corpus of requirements written in controlled language by instructed users and uncontrolled language by uninstructed users We annotated these requirements regarding predicateargument structures conditions priorities motivations and semantic roles and used this information to train classifiers for information extraction purposes REaCT achieves an accuracy of 92 for the on and offtopic classification task and an F1measure of 72 for the semantic annotation",
        "A1": "present REaCT",
        "A2": " When they describe their wishes for software development they often provide offtopic information",
        "A41": " an automated approach for identifying and semantically annotating the ontopic parts of requirement descriptions",
        "A51": "",
        "A61": "we created a corpus of requirements written in controlled language by instructed users and uncontrolled language by uninstructed users",
        "A10": "REaCT achieves an accuracy of 92 for the on and offtopic classification task and an F1measure of 72 for the semantic annotation",
        "A7": "We annotated these requirements regarding predicateargument structures conditions priorities motivations and semantic roles and used this information to train classifiers for information extraction purposes",
        "A83": "",
        "A82": "",
        "A81": "REaCT achieves an accuracy of 92 for the on and offtopic classification task and an F1measure of 72 for the semantic annotation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 338321439
    },
    {
        "Abstract": "Existing work on detecting deceptive reviews primarily focuses on feature engineering and applies offtheshelf supervised classification algorithms to the problem Then one real challenge would be to manually recognize plentiful ground truth spam review data for model building which is rather difficult and often requires domain expertise in practice In this paper we propose to exploit the relatedness of multiple review spam detection tasks and readily available unlabeled data to address the scarcity of labeled opinion spam data We first develop a multitask learning method based on logistic regression MTLLR which can boost the learning for a task by sharing the knowledge contained in the training signals of other related tasks To leverage the unlabeled data we introduce a graph Laplacian regularizer into each base model We then propose a novel semisupervised multitask learning method via Laplacian regularized logistic regression SMTLLLR to further improve the review spam detection performance We also develop a stochastic alternating method to cope with the optimization for SMTLLLR Experimental results on realworld review data demonstrate the benefit of SMTLLLR over several wellestablished baseline methods",
        "A1": "In this paper we propose to exploit the relatedness of multiple review spam detection tasks and readily available unlabeled data to address the scarcity of labeled opinion spam data",
        "A2": "Then one real challenge would be to manually recognize plentiful ground truth spam review data for model building which is rather difficult and often requires domain expertise in practice",
        "A41": "a multitask learning method based on logistic regression MTLLR which can boost the learning for a task by sharing the knowledge contained in the training signals of other related tasks",
        "A51": " logistic regression MTLLR",
        "A61": "",
        "A10": " the benefit of SMTLLLR over several wellestablished baseline methods",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the benefit of SMTLLLR over several wellestablished baseline methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 226090998
    },
    {
        "Abstract": "We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial natural language action space A specified number of discussion threads predicted to be popular are recommended chosen from a fixed window of recent comments to track Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent subactions The proposed model which represents dependence between subactions through a bidirectional LSTM gives the best performance across different experimental configurations and domains and it also generalizes well with varying numbers of recommendation requests",
        "A1": "We introduce an online popularity prediction and tracking task as a benchmark task for reinforcement learning with a combinatorial natural language action space ",
        "A2": "online popularity prediction and tracking task",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "bidirectional LSTM ",
        "A42": "The proposed model which represents dependence between subactions through a bidirectional LSTM gives the best performance across different experimental configurations and domains and it also generalizes well with varying numbers of recommendation requests",
        "A45": "",
        "am_id": 158842755
    },
    {
        "Abstract": "Traditional automated essay scoring systems rely on carefully designed features to evaluate and score essays The performance of such systems is tightly bound to the quality of the underlying features However it is laborious to manually design the most informative features for such a system In this paper we develop an approach based on recurrent neural networks to learn the relation between an essay and its assigned score without any feature engineering We explore several neural network models for the task of automated essay scoring and perform some analysis to get some insights of the models The results show that our best system which is based on long shortterm memory networks outperforms a strong baseline by 56 in terms of quadratic weighted Kappa without requiring any feature engineering",
        "A1": "The performance of such systems is tightly bound to the quality of the underlying features ",
        "A2": "manually design the most informative features for such a system In this paper we develop an approach based on recurrent neural networks to learn the relation between an essay and its assigned score without any feature engineering",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our best system which is based on long shortterm memory networks outperforms a strong baseline by 56 in terms of quadratic weighted Kappa without requiring any feature engineering",
        "A7": " perform some analysis to get some insights of the models ",
        "A83": "",
        "A82": "",
        "A81": "our best system which is based on long shortterm memory networks outperforms a strong baseline by 56 in terms of quadratic weighted Kappa without requiring any feature engineering",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Traditional automated essay scoring systems rely on carefully designed features",
        "A52": "neural network",
        "A42": "several neural network models for the task of automated essay scoring",
        "A45": "",
        "am_id": 353850555
    },
    {
        "Abstract": "Technical writing in professional environments such as user manual authoring requires the use of uniform language Nonuniform language detection is a novel task which aims to guarantee the consistency for technical writing by detecting sentences in a document that are intended to have the same meaning within a similar context but use different words or writing style This paper proposes an approach that utilizes text similarity algorithms at lexical syntactic semantic and pragmatic levels Different features are extracted and integrated by applying a machine learning classification method We tested our method using smart phone user manuals and compared its performance against the stateoftheart methods in a related area The experiments demonstrate that our approach achieves the upper bound performance for this task",
        "A1": "Nonuniform language detection",
        "A2": "Nonuniform language detection",
        "A41": "utilizes text similarity algorithms at lexical syntactic semantic and pragmatic levels",
        "A51": "machine learning classification method",
        "A61": "utilizes text similarity algorithms at lexical syntactic semantic and pragmatic levels",
        "A10": "our approach achieves the upper bound performance for this task",
        "A7": "tested our method using smart phone user manuals and compared its performance against the stateoftheart methods in a related area",
        "A83": "",
        "A82": "",
        "A81": "our approach achieves the upper bound performance for this task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 69790396
    },
    {
        "Abstract": "We propose an algorithm that combines supervised and unsupervised methods to ensemble multiple systems for two popular Knowledge Base Population KBP tasks Cold Start Slot Filling CSSF and Trilingual Entity Discovery and Linking TEDL We demonstrate that it outperforms the best system for both tasks in the 2015 competition several ensembling baselines as well as a stateoftheart stacking approach The success of our technique on two different and challenging problems demonstrates the power and generality of our combined approach to ensembling",
        "A1": "Knowledge Base Population",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "2015 competition",
        "A83": "",
        "A82": "the power and generality of our combined approach to ensembling",
        "A81": "outperforms the best system for both tasks in the 2015 competition several ensembling baselines as well as a stateoftheart stacking approach",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "Cold Start Slot Filling CSSF and Trilingual Entity Discovery and Linking TEDL",
        "A43": "combines supervised and unsupervised methods to ensemble multiple systems",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 232585880
    },
    {
        "Abstract": "This paper investigates how linguistic knowledge mined from large text corpora can aid the generation of natural language descriptions of videos Specifically we integrate both a neural language model and distributional semantics trained on large text corpora into a recent LSTMbased architecture for video description We evaluate our approach on a collection of Youtube videos as well as two large movie description datasets showing significant improvements in grammaticality while modestly improving descriptive quality",
        "A1": "investigates how linguistic knowledge mined from large text corpora can aid the generation of natural language descriptions of videos",
        "A2": "how linguistic knowledge mined from large text corpora can aid the generation of natural language descriptions of videos",
        "A41": " integrate both a neural language model and distributional semantics trained on large text corpora into a recent LSTMbased architecture for video description",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a collection of Youtube videos as well as two large movie description datasets",
        "A83": "",
        "A82": "modestly improving descriptive quality",
        "A81": "significant improvements in grammaticality ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a neural language model",
        "A45": "",
        "am_id": 360324805
    },
    {
        "Abstract": "Psychological analysis of language has repeatedly shown that an individuals rate of mentioning 1st person singular pronouns predicts a wealth of important demographic and psychological factors However these analyses are performed out of context  syntactic and semantic  which may change the magnitude or even direction of such relationships In this paper we put pronouns in their context exploring the relationship between selfreference and age gender and depression depending on syntactic position and verbal governor We find that pronouns are overall more predictive when taking dependency relations and verb semantic categories into account and the direction of the relationship can change depending on the semantic class of the verbal governor",
        "A1": "We find that pronouns are overall more predictive when taking dependency relations and verb semantic categories into account and the direction of the relationship can change depending on the semantic class of the verbal governor",
        "A2": "We find that pronouns are overall more predictive when taking dependency relations and verb semantic categories into account and the direction of the relationship can change depending on the semantic class of the verbal governor",
        "A41": "we put pronouns in their context ",
        "A51": "exploring the relationship between selfreference and age gender and depression depending on syntactic position and verbal governor ",
        "A61": "exploring the relationship between selfreference and age gender and depression depending on syntactic position and verbal governor ",
        "A10": "we put pronouns in their context exploring the relationship between selfreference and age gender and depression depending on syntactic position and verbal governor",
        "A7": "we put pronouns in their context exploring the relationship between selfreference and age gender and depression depending on syntactic position and verbal governor",
        "A83": "he direction of the relationship can change depending on the semantic class of the verbal governor",
        "A82": "verb semantic categories into account",
        "A81": "We find that pronouns are overall more predictive when taking dependency relations ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 105406386
    },
    {
        "Abstract": "Recurrent Neural Network RNN and one of its specific architectures Long ShortTerm Memory LSTM have been widely used for sequence labeling Explicitly modeling output label dependencies on top of RNNLSTM is a widelystudied and effective extension We propose another extension to incorporate the global information spanning over the whole input sequence The proposed method encoderlabeler LSTM  first encodes the whole input sequence into a fixed length vector with the encoder LSTM and then uses this encoded vector as the initial state of another LSTM for sequence labeling With this method we can predict the label sequence while taking the whole input sequence information into consideration In the experiments of a slot filling task which is an essential component of natural language understanding with using the standard ATIS corpus we achieved the stateoftheart F1score of 9566",
        "A1": "propose another extension to incorporate the global information spanning over the whole input sequence ",
        "A2": "",
        "A41": "The proposed method encoderlabeler LSTM  first encodes the whole input sequence into a fixed length vector with the encoder LSTM and then uses this encoded vector as the initial state of another LSTM for sequence labeling",
        "A51": "encoderlabeler LSTM ",
        "A61": "encoderlabeler LSTM  first encodes the whole input sequence into a fixed length vector with the encoder LSTM",
        "A10": "",
        "A7": "the experiments of a slot filling task which is an essential component of natural language understanding with using the standard ATIS corpus",
        "A83": "",
        "A82": "",
        "A81": "achieved the stateoftheart F1score of 9566",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "encoderlabeler LSTM  first encodes the whole input sequence into a fixed length vector with the encoder LSTM and then uses this encoded vector as the initial state of another LSTM for sequence labeling",
        "A52": "RNNLSTM",
        "A42": "",
        "A45": "",
        "am_id": 22638197
    },
    {
        "Abstract": "In this paper we investigate case restoration for text without case information Previous such work operates at the word level We propose an approach using characterlevel recurrent neural networks RNN which performs competitively compared to language modeling and conditional random fields CRF approaches We further provide quantitative and qualitative analysis on how RNN helps improve truecasing",
        "A1": "case restoration for text without case information",
        "A2": "case restoration for text without case information",
        "A41": "an approach using characterlevel recurrent neural networks RNN",
        "A51": "RNN",
        "A61": "performs competitively",
        "A10": "performs competitively",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 258948017
    },
    {
        "Abstract": "The production of color language is essential for grounded language generation Color descriptions have many challenging properties they can be vague compositionally complex and denotationally rich We present an effective approach to generating color descriptions using recurrent neural networks and a Fouriertransformed color representation Our model outperforms previous work on a conditional language modeling task over a large corpus of naturalistic color descriptions In addition probing the models output reveals that it can accurately produce not only basic color terms but also descriptors with nonconvex denotations greenish bare modifiers bright dull and compositional phrases faded teal not seen in training",
        "A1": "We present an effective approach to generating color descriptions using recurrent neural networks and a Fouriertransformed color representation ",
        "A2": " Color descriptions have many challenging properties they can be vague compositionally complex and denotationally rich",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "on a conditional language modeling task over a large corpus of naturalistic color descriptions",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "probing the models output reveals that it can accurately produce not only basic color terms but also descriptors with nonconvex denotations greenish bare modifiers bright dull and compositional phrases faded teal not seen in training",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "on a conditional language modeling task over a large corpus of naturalistic color descriptions",
        "A52": "recurrent neural networks and a Fouriertransformed color representation ",
        "A42": "We present an effective approach to generating color descriptions using recurrent neural networks and a Fouriertransformed color representation ",
        "A45": "",
        "am_id": 281156460
    },
    {
        "Abstract": "Most successful information extraction systems operate with access to a large collection of documents In this work we explore the task of acquiring and incorporating external evidence to improve extraction accuracy in domains where the amount of training data is scarce This process entails issuing search queries extraction from new sources and reconciliation of extracted values which are repeated until sufficient evidence is collected We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on contextual information We employ a deep Qnetwork trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort Our experiments on two databases  of shooting incidents and food adulteration cases  demonstrate that our system significantly outperforms traditional extractors and a competitive metaclassifier baseline1",
        "A1": " improve extraction accuracy in domains where the amount of training data is scarce",
        "A2": "we explore the task of acquiring and incorporating external evidence",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our system significantly outperforms traditional extractors and a competitive metaclassifier baseline1",
        "A7": "experiments on two databases  of shooting incidents and food adulteration cases",
        "A83": "our system significantly outperforms traditional extractors and a competitive metaclassifier baseline1",
        "A82": "We employ a deep Qnetwork trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort",
        "A81": "we explore the task of acquiring and incorporating external evidence to improve extraction accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Our experiments on two databases  of shooting incidents and food adulteration cases  demonstrate that our system significantly outperforms traditional extractors and a competitive metaclassifier baseline1",
        "A52": " based on contextual information",
        "A42": "our model learns to select optimal actions based on contextual information",
        "A45": "",
        "am_id": 305595142
    },
    {
        "Abstract": "Language documentation begins by gathering speech Manual or automatic transcription at the word level is typically not possible because of the absence of an orthography or prior lexicon and though manual phonemic transcription is possible it is prohibitively slow On the other hand translations of the minority language into a major language are more easily acquired We propose a method to harness such translations to improve automatic phoneme recognition The method assumes no prior lexicon or translation model instead learning them from phoneme lattices and translations of the speech being transcribed Experiments demonstrate phoneme error rate improvements against two baselines and the models ability to learn useful bilingual lexical entries",
        "A1": "We propose a method to harness such translations to improve automatic phoneme recognition",
        "A2": "",
        "A41": "a method to harness such translations to improve automatic phoneme recognition",
        "A51": "",
        "A61": "The method assumes no prior lexicon or translation model instead learning them from phoneme lattices and translations of the speech being transcribed",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "phoneme error rate improvements against two baselines and the models ability to learn useful bilingual lexical entries",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 252876078
    },
    {
        "Abstract": "We present a simple yet effective approach for linking entities in queries The key idea is to search sentences similar to a query from Wikipedia articles and directly use the humanannotated entities in the similar sentences as candidate entities for the query Then we employ a rich set of features such as linkprobability contextmatching word embeddings and relatedness among candidate entities as well as their related entities to rank the candidates under a regression based framework The advantages of our approach lie in two aspects which contribute to the ranking process and final linking result First it can greatly reduce the number of candidate entities by filtering out irrelevant entities with the words in the query Second we can obtain the query sensitive prior probability in addition to the static linkprobability derived from all Wikipedia articles We conduct experiments on two benchmark datasets on entity linking for queries namely the ERD14 dataset and the GERDAQ dataset Experimental results show that our method outperforms stateoftheart systems and yields 750 in F1 on the ERD14 dataset and 569 on the GERDAQ dataset",
        "A1": "present a simple yet effective approach for linking entities in queries",
        "A2": "linking entities in queries",
        "A41": "search sentences similar to a query from Wikipedia articles and directly use the humanannotated entities in the similar sentences as candidate entities for the query",
        "A51": "under a regression based framework ",
        "A61": "directly use the humanannotated entities in the similar sentences as candidate entities for the query",
        "A10": "",
        "A7": "conduct experiments on two benchmark datasets on entity linking for queries namely the ERD14 dataset and the GERDAQ dataset",
        "A83": "",
        "A82": "",
        "A81": "outperforms stateoftheart systems and yields 750 in F1 on the ERD14 dataset and 569 on the GERDAQ dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 30243577
    },
    {
        "Abstract": "We introduce the first endtoend coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or handengineered mention detector The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each The model computes span embeddings that combine contextdependent boundary representations with a headfinding attention mechanism It is trained to maximize the marginal likelihood of gold antecedent spans from coreference clusters and is factored to enable aggressive pruning of potential mentions Experiments demonstrate stateoftheart performance with a gain of 15 F1 on the OntoNotes benchmark and by 31 F1 using a 5model ensemble despite the fact that this is the first approach to be successfully trained with no external resources",
        "A1": "We introduce the first endtoend coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or handengineered mention detector",
        "A2": "We introduce the first endtoend coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or handengineered mention detector",
        "A41": "We introduce the first endtoend coreference resolution model and show that it significantly outperforms all previous work without using a syntactic parser or handengineered mention detector ",
        "A51": "The key idea is to directly consider all spans in a document as potential mentions and learn distributions over possible antecedents for each",
        "A61": " for each The model computes span embeddings that combine contextdependent boundary representations with a headfinding attention mechanism",
        "A10": "",
        "A7": " Experiments demonstrate stateoftheart performance with a gain of 15 F1 on the OntoNotes benchmark and by 31 F1 using a 5model ensemble despite the fact that this is the first approach to be successfully trained with no external resources",
        "A83": "",
        "A82": "",
        "A81": " Experiments demonstrate stateoftheart performance with a gain of 15 F1 on the OntoNotes benchmark and by 31 F1 using a 5model ensemble despite the fact that this is the first approach to be successfully trained with no external resources",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 260083465
    },
    {
        "Abstract": "The existing word representation methods mostly limit their information source to word cooccurrence statistics In this paper we introduce ngrams into four representation methods SGNS GloVe PPMI matrix and its SVD factorization Comprehensive experiments are conducted on word analogy and similarity tasks The results show that improved word representations are learned from ngram cooccurrence statistics We also demonstrate that the trained ngram representations are useful in many aspects such as finding antonyms and collocations Besides a novel approach of building cooccurrence matrix is proposed to alleviate the hardware burdens brought by ngrams",
        "A1": "SGNS GloVe PPMI matrix and its SVD factorization Comprehensive experiments are conducted on word analogy and similarity tasks ",
        "A2": "improved word representations are learned from ngram cooccurrence statistics ",
        "A41": "SGNS GloVe PPMI matrix and its SVD ",
        "A51": "",
        "A61": "",
        "A10": " introduce ngrams into four representation methods",
        "A7": "word analogy and similarity tasks ",
        "A83": "",
        "A82": "a novel approach of building cooccurrence matrix is proposed to alleviate the hardware burdens brought by ngrams",
        "A81": "the trained ngram representations are useful in many aspects",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 169488391
    },
    {
        "Abstract": "Word embeddings have attracted much attention recently Different from alphabetic writing systems Chinese characters are often composed of subcharacter components which are also semantically informative In this work we propose an approach to jointly embed Chinese words as well as their characters and finegrained subcharacter components We use three likelihoods to evaluate whether the context words characters and components can predict the current target word and collected 13253 subcharacter components to demonstrate the existing approaches of decomposing Chinese characters are not enough Evaluation on both word similarity and word analogy tasks demonstrates the superior performance of our model",
        "A1": "Word embeddings",
        "A2": "jointly embed Chinese words as well as their characters and finegrained subcharacter components ",
        "A41": "jointly embed Chinese words as well as their characters and finegrained subcharacter components ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "collected 13253 subcharacter components to demonstrate",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 382151283
    },
    {
        "Abstract": "We introduce a novel mixed characterword architecture to improve Chinese sentence representations by utilizing rich semantic information of word internal structures Our architecture uses two key strategies The first is a mask gate on characters learning the relation among characters in a word The second is a maxpooling operation on words adaptively finding the optimal mixture of the atomic and compositional word representations Finally the proposed architecture is applied to various sentence composition models which achieves substantial performance gains over baseline models on sentence similarity task",
        "A1": "We introduce a novel mixed characterword architecture to improve Chinese sentence representations by utilizing rich semantic information of word internal structure",
        "A2": "to improve Chinese sentence representations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves substantial performance gains over baseline models on sentence similarity task",
        "A7": "achieves substantial performance gains over baseline models on sentence similarity task",
        "A83": "",
        "A82": "",
        "A81": "achieves substantial performance gains over baseline models on sentence similarity task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "architecture to improve Chinese sentence representations by utilizing rich semantic information of word internal structures ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 210518450
    },
    {
        "Abstract": "Domain similarity measures can be used to gauge adaptability and select suitable data for transfer learning but existing approaches define ad hoc measures that are deemed suitable for respective tasks Inspired by work on curriculum learning we propose to learn data selection measures using Bayesian Optimization and evaluate them across models domains and tasks Our learned measures outperform existing domain similarity measures significantly on three tasks sentiment analysis partofspeech tagging and parsing We show the importance of complementing similarity with diversity and that learned measures areto some degreetransferable across models domains and even tasks",
        "A1": " we propose to learn data selection measures",
        "A2": " but existing approaches define ad hoc measures that are deemed suitable for respective tasks",
        "A41": "using Bayesian Optimization and evaluate them across models domains and tasks",
        "A51": "",
        "A61": "Our learned measures outperform existing domain similarity measures significantly on three tasks sentiment analysis partofspeech tagging and parsing",
        "A10": " Our learned measures outperform existing domain similarity measures significantly ",
        "A7": " three tasks sentiment analysis",
        "A83": "",
        "A82": "",
        "A81": " Our learned measures outperform existing domain similarity measures significantly ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 494728410
    },
    {
        "Abstract": "Vector representation of words improves performance in various NLP tasks but the highdimensional word vectors are very difficult to interpret We apply several rotation algorithms to the vector representation of words to improve the interpretability Unlike previous approaches that induce sparsity the rotated vectors are interpretable while preserving the expressive performance of the original vectors Furthermore any prebuilt word vector representation can be rotated for improved interpretability We apply rotation to skipgrams and glove and compare the expressive power and interpretability with the original vectors and the sparse overcomplete vectors The results show that the rotated vectors outperform the original and the sparse overcomplete vectors for interpretability and expressiveness tasks",
        "A1": "apply several rotation algorithms to the vector representation of words to improve the interpretability",
        "A2": "Vector representation of words improves performance in various NLP tasks but the highdimensional word vectors are very difficult to interpret",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We apply rotation to skipgrams and glove and compare the expressive power and interpretability with the original vectors and the sparse overcomplete vectors",
        "A83": "",
        "A82": "the rotated vectors outperform the original and the sparse overcomplete vectors for interpretability and expressiveness tasks",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Unlike previous approaches that induce sparsity the rotated vectors are interpretable while preserving the expressive performance of the original vectors",
        "A53": "",
        "A43": "several rotation algorithms",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 193189630
    },
    {
        "Abstract": "Sentiment lexicon is an important tool for identifying the sentiment polarity of words and texts How to automatically construct sentiment lexicons has become a research topic in the field of sentiment analysis and opinion mining Recently there were some attempts to employ representation learning algorithms to construct a sentiment lexicon with sentimentaware word embedding However these methods were normally trained under documentlevel sentiment supervision In this paper we develop a neural architecture to train a sentimentaware word embedding by integrating the sentiment supervision at both document and word levels to enhance the quality of word embedding as well as the sentiment lexicon Experiments on the SemEval 20132016 datasets indicate that the sentiment lexicon generated by our approach achieves the stateoftheart performance in both supervised and unsupervised sentiment classification in comparison with several strong sentiment lexicon construction methods",
        "A1": " automatically construct sentiment lexicons",
        "A2": "these methods were normally trained under documentlevel sentiment supervision",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves the stateoftheart performance in both supervised and unsupervised sentiment classification",
        "A7": "SemEval 20132016 datasets",
        "A83": "",
        "A82": "",
        "A81": "achieves the stateoftheart performance in both supervised and unsupervised sentiment classification",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "integrating the sentiment supervision at both document and word levels",
        "A52": "sentimentaware word embedding",
        "A42": " integrating the sentiment supervision at both document and word levels to enhance the quality of word embedding as well as the sentiment lexicon",
        "A45": "",
        "am_id": 151094063
    },
    {
        "Abstract": "Existing sentiment classifiers usually work for only one specific language and different classification models are used in different languages In this paper we aim to build a universal sentiment classifier with a single classification model in multiple different languages In order to achieve this goal we propose to learn multilingual sentimentaware word embeddings simultaneously based only on the labeled reviews in English and unlabeled parallel data available in a few language pairs It is not required that the parallel data exist between English and any other language because the sentiment information can be transferred into any language via pivot languages We present the evaluation results of our universal sentiment classifier in five languages and the results are very promising even when the parallel data between English and the target languages are not used Furthermore the universal single classifier is compared with a few crosslanguage sentiment classifiers relying on direct parallel data between the source and target languages and the results show that the performance of our universal sentiment classifier is very promising compared to that of different crosslanguage classifiers in multiple target languages",
        "A1": "build a universal sentiment classifier with a single classification model in multiple different languages",
        "A2": "Existing sentiment classifiers usually work for only one specific language",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "performance of our universal sentiment classifier is very promising compared to that of different crosslanguage classifiers in multiple target languages",
        "A7": "direct parallel data between the source and target languages",
        "A83": "",
        "A82": "",
        "A81": "the performance of our universal sentiment classifier is very promising compared to that of different crosslanguage classifiers in multiple target languages",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "with a single classification model in multiple different languages",
        "A52": "",
        "A42": "a universal sentiment classifier with a single classification model in multiple different languages",
        "A45": "",
        "am_id": 21504285
    },
    {
        "Abstract": "Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate This is usually done using heuristic selection methods however the effectiveness of such methods is limited and moreover the performance of heuristics varies between datasets To address these shortcomings we introduce a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy where the policy takes the role of the active learning heuristic Importantly our method allows the selection policy learned using simulation on one language to be transferred to other languages We demonstrate our method using crosslingual named entity recognition observing uniform improvements over traditional active learning",
        "A1": "introduce a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy where the policy takes the role of the active learning heuristic",
        "A2": "To address these shortcomings ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We demonstrate our method using crosslingual named entity recognition observing uniform improvements over traditional active learning",
        "A7": "We demonstrate our method using crosslingual named entity recognition observing uniform improvements over traditional active learning",
        "A83": "the policy takes the role of the active learning heuristic",
        "A82": "explicitly learning a data selection policy",
        "A81": "introduce a novel formulation by reframing the active learning as a reinforcement learning problem",
        "A64": "reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy",
        "A54": "the policy takes the role of the active learning heuristic",
        "A44": "a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy where the policy takes the role of the active learning heuristic",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 487432559
    },
    {
        "Abstract": "In this paper we introduce a new distributional method for modeling predicateargument thematic fit judgments We use a syntaxbased DSM to build a prototypical representation of verbspecific roles for every verb we extract the most salient second order contexts for each of its roles ie the most salient dimensions of typical role fillers  and then we compute thematic fit as a weighted overlap between the top features of candidate fillers and role prototypes Our experiments show that our method consistently outperforms a baseline reimplementing a stateoftheart system and achieves better or comparable results to those reported in the literature for the other unsupervised systems Moreover it provides an explicit representation of the features characterizing verbspecific semantic roles",
        "A1": "introduce a new distributional method for modeling predicateargument thematic fit judgments",
        "A2": "modeling predicateargument thematic fit judgments",
        "A41": "method for modeling predicateargument thematic fit judgments",
        "A51": "",
        "A61": "use a syntaxbased DSM to build a prototypical representation of verbspecific roles for every verb",
        "A10": "",
        "A7": "",
        "A83": "provides an explicit representation of the features characterizing verbspecific semantic roles",
        "A82": "achieves better or comparable results to those reported in the literature for the other unsupervised systems",
        "A81": "our method consistently outperforms a baseline reimplementing a stateoftheart system",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 441232551
    },
    {
        "Abstract": "We develop a technique for transfer learning in machine comprehension MC using a novel twostage synthesis network SynNet Given a highperforming MC model in one domain our technique aims to answer questions about documents in another domain where we use no labeled data of questionanswer pairs Using the proposed SynNet with a pretrained model on the SQuAD dataset we achieve an F1 measure of 466 on the challenging NewsQA dataset approaching performance of indomain models F1 measure of 500 and outperforming the outofdomain baseline by 76 without use of provided annotations1",
        "A1": "We develop a technique for transfer learning in machine comprehension MC using a novel twostage synthesis network",
        "A2": "answer questions about documents in another domain where we use no labeled data of questionanswer pairs",
        "A41": "for transfer learning in machine comprehension MC ",
        "A51": "twostage synthesis network ",
        "A61": "",
        "A10": "",
        "A7": "Using the proposed SynNet with a pretrained model on the SQuAD dataset",
        "A83": "",
        "A82": " outperforming the outofdomain baseline by 76 without use of provided annotations1",
        "A81": "an F1 measure of 466 on the challenging NewsQA dataset approaching performance of indomain models F1 measure of 500",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 438776482
    },
    {
        "Abstract": "In this paper we investigate largescale zeroshot activity recognition by modeling the visual and linguistic attributes of action verbs For example the verb salute has several properties such as being a light movement a social act and short in duration We use these attributes as the internal mapping between visual and textual representations to reason about a previously unseen action In contrast to much prior work that assumes access to gold standard attributes for zeroshot classes and focuses primarily on object attributes our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations Experimental results confirm that action attributes inferred from language can provide a predictive signal for zeroshot prediction of previously unseen activities",
        "A1": " investigate largescale zeroshot activity recognition by modeling the visual and linguistic attributes of action verbs",
        "A2": "largescale zeroshot activity recognition",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "action attributes inferred from language can provide a predictive signal for zeroshot prediction of previously unseen activities",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "our model uniquely learns to infer action attributes from dictionary definitions and distributed word representations",
        "A45": "",
        "am_id": 239523473
    },
    {
        "Abstract": "Sports channel video portals offer an exciting domain for research on multimodal multilingual analysis We present methods addressing the problem of automatic video highlight prediction based on joint visual features and textual analysis of the realworld audience discourse with complex slang in both English and traditional Chinese We present a novel dataset based on League of Legends championships recorded from North American and Taiwanese Twitchtv channels will be released for further research and demonstrate strong results on these using multimodal characterlevel CNNRNN model architectures",
        "A1": "We present methods addressing the problem of automatic video highlight prediction based on joint visual features and textual analysis of the realworld audience discourse with complex slang in both English and traditional Chinese We present a novel dataset based on League of Legends championships recorded from North American and Taiwanese Twitchtv channels will be released for further research and demonstrate strong results on these using multimodal characterlevel CNNRNN model architectures",
        "A2": "multimodal multilingual analysis",
        "A41": "addressing the problem of automatic video highlight prediction",
        "A51": "joint visual features ",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a novel dataset based on League of Legends championships recorded from North American and Taiwanese Twitch",
        "am_id": 338191035
    },
    {
        "Abstract": "The input to a neural sequencetosequence model is often determined by an upstream system eg a word segmenter part of speech tagger or speech recognizer These upstream models are potentially errorprone Representing inputs through word lattices allows making this uncertainty explicit by capturing alternative sequences and their posterior probabilities in a compact form In this work we extend the TreeLSTM Tai et al 2015 into a LatticeLSTM that is able to consume word lattices and can be used as encoder in an attentional encoderdecoder model We integrate lattice posterior scores into this architecture by extending the TreeLSTMs childsum and forget gates and introducing a bias term into the attention mechanism We experiment with speech translation lattices and report consistent improvements over baselines that translate either the 1best hypothesis or the lattice without posterior scores",
        "A1": "",
        "A2": "we extend the TreeLSTM Tai et al 2015 into a LatticeLSTM that is able to consume word lattices and can be used as encoder in an attentional encoderdecoder model",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We experiment with speech translation lattices",
        "A83": "",
        "A82": "",
        "A81": "report consistent improvements over baselines that translate either the 1best hypothesis or the lattice without posterior scores",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "We integrate lattice posterior scores into this architecture by extending the TreeLSTMs childsum and forget gates and introducing a bias term into the attention mechanism",
        "A52": "the TreeLSTM Tai et al 2015",
        "A42": "a LatticeLSTM that is able to consume word lattices and can be used as encoder in an attentional encoderdecoder model",
        "A45": "",
        "am_id": 179499372
    },
    {
        "Abstract": "In this paper we introduce a hybrid search for attentionbased neural machine translation NMT A target phrase learned with statistical MT models extends a hypothesis in the NMT beam search when the attention of the NMT model focuses on the source words translated by this phrase Phrases added in this way are scored with the NMT model but also with SMT features including phraselevel translation probabilities and a target language model Experimental results on GermanEnglish news domain and EnglishRussian ecommerce domain translation tasks show that using phrasebased models in NMT search improves MT quality by up to 23 BLEU absolute as compared to a strong NMT baseline",
        "A1": "introduce a hybrid search for attentionbased neural machine translation NMT",
        "A2": " improves MT quality by up to 23 BLEU absolute as compared to a strong NMT baseline",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "GermanEnglish news domain and EnglishRussian ecommerce domain translation tasks",
        "A83": "",
        "A82": "",
        "A81": " phrasebased models in NMT search improves MT quality by up to 23 BLEU absolute as compared to a strong NMT baseline",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "attentionbased neural machine translation",
        "A42": " A target phrase learned with statistical MT models extends a hypothesis in the NMT beam search",
        "A45": "",
        "am_id": 26654507
    },
    {
        "Abstract": "Natural language constitutes a predominant medium for much of human learning and pedagogy We consider the problem of concept learning from natural language explanations and a small number of labeled examples of the concept For example in learning the concept of a phishing email one might say this is a phishing email because it asks for your bank account number Solving this problem involves both learning to interpret openended natural language statements as well as learning the concept itself We present a joint model for 1 language interpretation semantic parsing and 2 concept learning classification that does not require labeling statements with logical forms Instead the model prefers discriminative interpretations of statements in context of observable features of the data as a weak signal for parsing On a dataset of emailrelated concepts this approach yields acrosstheboard improvements in classification performance with a 30 relative improvement in F1 score over competitive classification methods in the low data regime",
        "A1": "Natural language constitutes a predominant medium for much of human learning and pedagogy",
        "A2": "For example in learning the concept of a phishing email one might say this is a phishing email because it asks for your bank account number",
        "A41": "he concept of a phishing email one might say this is a phishing email because it asks for your bank account number Solving this problem involves both learning to interpret openended natural language statements a",
        "A51": "al forms Instead the model prefers discriminative interpretations of state",
        "A61": "On a dataset of emailrelated concepts this approach yields acrosstheboard improvements in classification performance with a 30 relative improvement in F1 score over competitive classification methods in the low data regime",
        "A10": "of a phishing email one might say this is a phishing email because it asks for your bank account number Solving this problem involves both learning to interpret openended nat",
        "A7": "On a dataset of emailrelated concepts this approach yields acrosstheboard improvements in classification performance with a 30 relative improvement in F1 score over competitive classification methods in the low data regime",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 164400550
    },
    {
        "Abstract": "We explore how to detect peoples perspectives that occupy a certain proposition We propose a Bayesian modelling approach where topics or propositions and their associated perspectives or viewpoints are modeled as latent variables Words associated with topics or perspectives follow different generative routes Based on the extracted perspectives we can extract the top associated sentences from text to generate a succinct summary which allows a quick glimpse of the main viewpoints in a document The model is evaluated on debates from the House of Commons of the UK Parliament revealing perspectives from the debates without the use of labelled data and obtaining better results than previous related solutions under a variety of evaluations",
        "A1": "detect peoples perspectives that occupy a certain proposition",
        "A2": "detect peoples perspectives that occupy a certain proposition",
        "A41": "a Bayesian modelling approach where topics or propositions and their associated perspectives or viewpoints are modeled as latent variables",
        "A51": "Bayesian modelling",
        "A61": " a Bayesian modelling approach where topics or propositions and their associated perspectives or viewpoints are modeled as latent variables",
        "A10": "obtaining better results than previous related solutions under a variety of evaluations",
        "A7": "The model is evaluated on debates from the House of Commons of the UK Parliament revealing perspectives from the debates without the use of labelled data",
        "A83": "",
        "A82": "",
        "A81": "obtaining better results than previous related solutions under a variety of evaluations",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 432682078
    },
    {
        "Abstract": "Distantly supervised relation extraction has been widely used to find novel relational facts from plain text To predict the relation between a pair of two target entities existing methods solely rely on those direct sentences containing both entities In fact there are also many sentences containing only one of the target entities which also provide rich useful information but not yet employed by relation extraction To address this issue we build inference chains between two target entities via intermediate entities and propose a pathbased neural relation extraction model to encode the relational semantics from both direct sentences and inference chains Experimental results on realworld datasets show that our model can make full use of those sentences containing only one target entity and achieves significant and consistent improvements on relation extraction as compared with strong baselines The source code of this paper can be obtained from https githubcomthunlpPathNRE",
        "A1": "",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "improvements on relation extraction",
        "A7": "Experimental results on realworld datasets",
        "A83": "",
        "A82": "achieves significant and consistent improvements on relation extraction",
        "A81": "make full use of those sentences containing only one target entity",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "to encode the relational semantics from both direct sentences and inference chains",
        "A45": "",
        "am_id": 240665714
    },
    {
        "Abstract": "Standard accuracy metrics indicate that reading comprehension systems are making rapid progress but the extent to which these systems truly understand language remains unclear To reward systems with real language understanding abilities we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset SQuAD Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences which are automatically generated to distract computer systems without changing the correct answer or misleading humans In this adversarial setting the accuracy of sixteen published models drops from an average of 75 F1 score to 36 when the adversary is allowed to add ungrammatical sequences of words average accuracy on four models decreases further to 7 We hope our insights will motivate the development of new models that understand language more precisely",
        "A1": "To reward systems with real language understanding abilities ",
        "A2": "answer questions about paragraphs that contain adversarially inserted sentences",
        "A41": " an adversarial evaluation scheme for the Stanford Question Answering Dataset SQuAD ",
        "A51": "To reward systems with real language understanding abilities ",
        "A61": "Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences ",
        "A10": "Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences which are automatically generated to distract computer systems without changing the correct answer or misleading humans",
        "A7": "Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences which are automatically generated to distract computer systems without changing the correct answer or misleading humans",
        "A83": "We hope our insights will motivate the development of new models that understand language more precisely",
        "A82": "adversary is allowed to add ungrammatical sequences of words average accuracy on four models decreases further to 7 ",
        "A81": "setting the accuracy of sixteen published models drops from an average of 75 F1 score to 36 ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " Dataset SQuAD",
        "am_id": 48639410
    },
    {
        "Abstract": "Argument mining has become a popular research area in NLP It typically includes the identification of argumentative components eg claims as the central component of an argument We perform a qualitative analysis across six different datasets and show that these appear to conceptualize claims quite differently To learn about the consequences of such different conceptualizations of claim for practical applications we carried out extensive experiments using stateoftheart featurerich and deep learning systems to identify claims in a crossdomain fashion While the divergent conceptualization of claims in different datasets is indeed harmful to crossdomain classification we show that there are shared properties on the lexical level as well as system configurations that can help to overcome these gaps",
        "A1": "To learn about the consequences of such different conceptualizations of claim",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "extensive experiments using stateoftheart featurerich and deep learning systems to identify claims in a crossdomain fashion",
        "A83": "",
        "A82": "we show that there are shared properties on the lexical level as well as system configurations that can help to overcome these gaps",
        "A81": " the divergent conceptualization of claims in different datasets is indeed harmful to crossdomain classification ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 335595309
    },
    {
        "Abstract": "When people recall and digest what they have read for writing summaries the important content is more likely to attract their attention Inspired by this observation we propose a cascaded attention based unsupervised model to estimate the salience information from the text for compressive multidocument summarization The attention weights are learned automatically by an unsupervised data reconstruction framework which can capture the sentence salience By adding sparsity constraints on the number of output vectors we can generate condensed information which can be treated as word salience Finegrained and coarsegrained sentence compression strategies are incorporated to produce compressive summaries Experiments on some benchmark data sets show that our framework achieves better results than the stateoftheart methods The work described in this paper is supported by grants from the Research and Development Grant of Huawei Technologies Co Ltd YB2015100076TH1510257 and the Grant Council of the Hong Kong Special Administrative Region China Project Code 14203414 1A topic represents a real event eg AlphaGo versus Lee Sedol",
        "A1": "",
        "A2": "estimate the salience information from the text for compressive multidocument summarization",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves better results than the stateoftheart methods",
        "A7": "Experiments on some benchmark data",
        "A83": "",
        "A82": "",
        "A81": "achieves better results than the stateoftheart methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a cascaded attention based unsupervised model",
        "A45": "",
        "am_id": 392834309
    },
    {
        "Abstract": "We present an unsupervised model of dialogue act sequences in conversation By modeling topical themes as transitioning more slowly than dialogue acts in conversation our model deemphasizes contentrelated words in order to focus on conversational function words that signal dialogue acts We also incorporate speaker tendencies to use some acts more than others as an additional predictor of dialogue act prevalence beyond temporal dependencies According to the evaluation presented on two dissimilar corpora the CNET forum and NPS Chat corpus the effectiveness of each modeling assumption is found to vary depending on characteristics of the data Deemphasizing contentrelated words yields improvement on the CNET corpus while utilizing speaker tendencies is advantageous on the NPS corpus The components of our model complement one another to achieve robust performance on both corpora and outperform stateoftheart baseline models",
        "A1": "dialogue act sequences in conversation",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperform stateoftheart baseline models",
        "A7": "two dissimilar corpora the CNET forum and NPS Chat corpus",
        "A83": "",
        "A82": "effectiveness of each modeling assumption is found",
        "A81": "achieve robust performance on both corpora",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " topical themes as transitioning",
        "A42": "an unsupervised model ",
        "A45": "",
        "am_id": 228309624
    },
    {
        "Abstract": "Social media collect and spread on the Web personal opinions facts fake news and all kind of information users may be interested in Applying argument mining methods to such heterogeneous data sources is a challenging open research issue in particular considering the peculiarities of the language used to write textual messages on social media In addition new issues emerge when dealing with arguments posted on such platforms such as the need to make a distinction between personal opinions and actual facts and to detect the source disseminating information about such facts to allow for provenance verification In this paper we apply supervised classification to identify arguments on Twitter and we present two new tasks for argument mining namely facts recognition and source identification We study the feasibility of the approaches proposed to address these tasks on a set of tweets related to the Grexit and Brexit news topics",
        "A1": "apply supervised classification to identify arguments on Twitter and we present two new tasks ",
        "A2": "",
        "A41": "Applying argument mining methods to such heterogeneous data sources ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "present two new tasks for argument mining namely facts recognition and source identification ",
        "A83": "",
        "A82": "",
        "A81": "the feasibility of the approaches proposed to address these tasks on a set of tweets related to the Grexit and Brexit news topics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 173600548
    },
    {
        "Abstract": "We propose a languageindependent datadriven method to exhaustively extract bursty phrases of arbitrary forms eg phrases other than simple noun phrases from microblogs The burst ie the rapid increase of the occurrence of a phrase causes the burst of overlapping Ngrams including incomplete ones In other words bursty incomplete Ngrams inevitably overlap bursty phrases Thus the proposed method performs the extraction of bursty phrases as the set cover problem in which all bursty Ngrams are covered by a minimum set of bursty phrases Experimental results using Japanese Twitter data showed that the proposed method outperformed wordbased noun phrasebased and segmentationbased methods both in terms of accuracy and coverage",
        "A1": "propose a languageindependent datadriven method",
        "A2": "extract bursty phrases of arbitrary forms",
        "A41": "",
        "A51": "The burst",
        "A61": "the proposed method performs the extraction of bursty phrases as the set cover problem in which all bursty Ngrams are covered by a minimum set of bursty phrases",
        "A10": "",
        "A7": "Japanese Twitter data",
        "A83": "",
        "A82": "",
        "A81": "he proposed method outperformed wordbased noun phrasebased and segmentationbased methods both in terms of accuracy and coverage",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 359956569
    },
    {
        "Abstract": "We present a novel approach for training artificial neural networks Our approach is inspired by broad evidence in psychology that shows human learners can learn efficiently and effectively by increasing intervals of time between subsequent reviews of previously learned materials spaced repetition We investigate the analogy between training neural models and findings in psychology about human memory model and develop an efficient and effective algorithm to train neural models The core part of our algorithm is a cognitivelymotivated scheduler according to which training instances and their reviews are spaced over time Our algorithm uses only 3450 of data per epoch is 2948 times faster than standard training and outperforms competing stateoftheart baselines1",
        "A1": "present a novel approach for training artificial neural networks",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We investigate the analogy between training neural models and findings in psychology about human memory model and develop an efficient and effective algorithm to train neural models",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Our algorithm uses only 3450 of data per epoch is 2948 times faster than standard training and outperforms competing stateoftheart baselines1",
        "A53": "",
        "A43": "The core part of our algorithm is a cognitivelymotivated scheduler",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 281767640
    },
    {
        "Abstract": "Existing approaches to automatic VerbNetstyle verb classification are heavily dependent on feature engineering and therefore limited to languages with mature NLP pipelines In this work we propose a novel crosslingual transfer method for inducing VerbNets for multiple languages To the best of our knowledge this is the first study which demonstrates how the architectures for learning word embeddings can be applied to this challenging syntacticsemantic task Our method uses crosslingual translation pairs to tie each of the six target languages into a bilingual vector space with English jointly specialising the representations to encode the relational information from English VerbNet A standard clustering algorithm is then run on top of the VerbNetspecialised representations using vector dimensions as features for learning verb classes Our results show that the proposed crosslingual transfer approach sets new stateoftheart verb classification performance across all six target languages explored in this work",
        "A1": "propose a novel crosslingual transfer method for inducing VerbNets for multiple languages",
        "A2": "demonstrates how the architectures for learning word embeddings can be applied to this challenging syntacticsemantic task",
        "A41": "uses crosslingual translation pairs to tie each of the six target languages into a bilingual vector space with English jointly specialising the representations to encode the relational information from English",
        "A51": "VerbNet",
        "A61": "demonstrates how the architectures for learning word embeddings can be applied to this challenging syntacticsemantic task",
        "A10": "sets new stateoftheart verb classification performance across all six target languages explored in this work",
        "A7": "new stateoftheart verb classification",
        "A83": "",
        "A82": "",
        "A81": "the proposed crosslingual transfer approach sets new stateoftheart verb classification performance across all six target languages explored in this work",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "uses crosslingual translation pairs",
        "A53": "A standard clustering algorithm",
        "A43": "uses crosslingual translation pairs to tie each of the six target languages into a bilingual vector space",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 108368904
    },
    {
        "Abstract": "Websites and mobile apps privacy policies written in natural language tend to be long and difficult to understand Information privacy revolves around the fundamental principle of notice and choice namely the idea that users should be able to make informed decisions about what information about them can be collected and how it can be used Internet users want control over their privacy but their choices are often hidden in long and convoluted privacy policy documents Moreover little if any prior work has been done to detect the provision of choices in text We address this challenge of enabling user choice by automatically identifying and extracting pertinent choice language in privacy policies In particular we present a twostage architecture of classification models to identify optout choices in privacy policy text labelling common varieties of choices with a mean F1 score of 0735 Our techniques enable the creation of systems to help Internet users to learn about their choices thereby effectuating notice and choice and improving Internet privacy",
        "A1": "present a twostage architecture",
        "A2": "identify optout choices",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "a mean F1 score of 0735",
        "A82": "creation of systems to help Internet users to learn about their choices",
        "A81": "effectuating notice and choice and improving Internet privacy",
        "A64": "",
        "A54": "",
        "A44": " a twostage architecture of classification models to identify optout choices in privacy policy text",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 275299141
    },
    {
        "Abstract": "In this paper we present a novel approach to infer significance of various textual edits to documents An author may make several edits to a document each edit varies in its impact to the content of the document While some edits are surface changes and introduce negligible change other edits may change the contenttone of the document significantly In this paper we perform an analysis of the human perceptions of edit importance while reviewing documents from one version to the next We identify linguistic features that influence edit importance and model it in a regression based setting We show that the predicted importance by our approach is highly correlated with the human perceived importance established by a Mechanical Turk study",
        "A1": "infer significance of various textual edits to documents",
        "A2": "we perform an analysis of the human perceptions of edit importance while reviewing documents from one version to the next",
        "A41": "a novel approach to infer significance of various textual edits to documents",
        "A51": "in a regression based setting",
        "A61": "An author may make several edits to a document each edit varies in its impact to the content of the document",
        "A10": "the predicted importance by our approach is highly correlated with the human perceived importance established by a Mechanical Turk study",
        "A7": "we perform an analysis of the human perceptions of edit importance while reviewing documents from one version to the next",
        "A83": " model it in a regression based setting",
        "A82": "We show that the predicted importance by our approach is highly correlated with the human perceived importance established by a Mechanical Turk study",
        "A81": "We identify linguistic features that influence edit importance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 411068917
    },
    {
        "Abstract": "In the logic approach to Recognizing Textual Entailment identifying phrasetophrase semantic relations is still an unsolved problem Resources such as the Paraphrase Database offer limited coverage despite their large size whereas unsupervised distributional models of meaning often fail to recognize phrasal entailments We propose to map phrases to their visual denotations and compare their meaning in terms of their images We show that our approach is effective in the task of Recognizing Textual Entailment when combined with specific linguistic and logic features",
        "A1": " Recognizing Textual Entailment ",
        "A2": "offer limited coverage despite their large size whereas unsupervised distributional models of meaning often fail to recognize phrasal entailments ",
        "A41": "map phrases to their visual denotations and compare their meaning in terms of their images ",
        "A51": "",
        "A61": "",
        "A10": "combined with specific linguistic and logic features",
        "A7": "Recognizing Textual Entailment ",
        "A83": "",
        "A82": "",
        "A81": "effective ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 43905459
    },
    {
        "Abstract": "Learning word embeddings has received a significant amount of attention recently Often word embeddings are learned in an unsupervised manner from a large collection of text The genre of the text typically plays an important role in the effectiveness of the resulting embeddings How to effectively train word embedding models using data from different domains remains a problem that is underexplored In this paper we present a simple yet effective method for learning word embeddings based on text from different domains We demonstrate the effectiveness of our approach through extensive experiments on various downstream NLP tasks",
        "A1": "learning word embeddings",
        "A2": "effectively train word embedding models using data from different domains",
        "A41": "a simple yet effective method for learning word embeddings based on text from different domains",
        "A51": " text from different domains",
        "A61": "",
        "A10": "",
        "A7": "extensive experiments on various downstream NLP tasks",
        "A83": "",
        "A82": "",
        "A81": "effectiveness of our approach",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 445022615
    },
    {
        "Abstract": "Portmanteaus are a word formation phenomenon where two words are combined to form a new word We propose characterlevel neural sequencetosequence S2S methods for the task of portmanteau generation that are endtoendtrainable language independent and do not explicitly use additional phonetic information We propose a noisychannelstyle model which allows for the incorporation of unsupervised word lists improving performance over a standard sourcetotarget model This model is made possible by an exhaustive candidate generation strategy specifically enabled by the features of the portmanteau task Experiments find our approach superior to a stateoftheart FSTbased baseline with respect to ground truth accuracy and human evaluation",
        "A1": "propose a noisychannelstyle model which allows for the incorporation of unsupervised word lists improving performance over a standard sourcetotarget model ",
        "A2": "the incorporation of unsupervised word lists improving performance",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our approach superior to a stateoftheart FSTbased baseline with respect to ground truth accuracy and human evaluation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "This model is made possible by an exhaustive candidate generation strategy specifically enabled by the features of the portmanteau task ",
        "A45": "",
        "am_id": 321032924
    },
    {
        "Abstract": "We present a topicbased analysis of agreement and disagreement in political manifestos which relies on a new method for topic detection based on key concept clustering Our approach outperforms both standard techniques like LDA and a stateoftheart graphbased method and provides promising initial results for this new task in computational social science",
        "A1": "present a topicbased analysis of agreement and disagreement in political manifestos",
        "A2": "analysis of agreement and disagreement in political manifestos",
        "A41": "a topicbased analysis of agreement and disagreement in political manifestos",
        "A51": "topic",
        "A61": "outperforms",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 153846854
    },
    {
        "Abstract": "Users suffering from mental health conditions often turn to online resources for support including specialized online support communities or general communities such as Twitter and Reddit In this work we present a framework for supporting and studying users in both types of communities We propose methods for identifying posts in support communities that may indicate a risk of selfharm and demonstrate that our approach outperforms strong previously proposed methods for identifying such posts Selfharm is closely related to depression which makes identifying depressed users on general forums a crucial related task We introduce a largescale general forum dataset consisting of users with selfreported depression diagnoses matched with control users We show how our method can be applied to effectively identify depressed users from their use of language alone We demonstrate that our method outperforms strong baselines on this general forum dataset",
        "A1": "identifying posts in support communities that may indicate a risk of selfharm and demonstrate that our approach outperforms strong previously proposed methods for identifying such posts ",
        "A2": "In this work we present a framework for supporting and studying users in both types of communities",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We demonstrate that our method outperforms strong baselines on this general forum dataset",
        "A7": "We introduce a largescale general forum dataset consisting of users with selfreported depression diagnoses matched with control users ",
        "A83": " We demonstrate that our method outperforms strong baselines on this general forum dataset",
        "A82": "We show how our method can be applied to effectively identify depressed users from their use of language alone",
        "A81": "We introduce a largescale general forum dataset consisting of users with selfreported depression diagnoses matched with control users ",
        "A64": "We show how our method can be applied to effectively identify depressed users from their use of language alone",
        "A54": "Users suffering from mental health conditions often turn to online resources for support including specialized online support communities or general communities such as Twitter and Reddit",
        "A44": "a framework for supporting and studying users in both types of communities",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 293158776
    },
    {
        "Abstract": "This article deals with adversarial attacks towards deep learning systems for Natural Language Processing NLP in the context of privacy protection We study a specific type of attack an attacker eavesdrops on the hidden representations of a neural text classifier and tries to recover information about the input text Such scenario may arise in situations when the computation of a neural network is shared across multiple devices eg some hidden representation is computed by a users device and sent to a cloudbased model We measure the privacy of a hidden representation by the ability of an attacker to predict accurately specific private information from it and characterize the tradeoff between the privacy and the utility of neural representations Finally we propose several defense methods based on modified training objectives and show that they improve the privacy of neural representations",
        "A1": "deals with adversarial attacks towards deep learning systems for Natural Language Processing NLP",
        "A2": "deals with adversarial attacks towards deep learning systems for Natural Language Processing NLP",
        "A41": "several defense methods based on modified training objectives",
        "A51": "modified training objectives",
        "A61": "they improve the privacy of neural representations",
        "A10": "they improve the privacy of neural representations",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "they improve the privacy of neural representations",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137674518
    },
    {
        "Abstract": "Current dialogue systems focus more on textual and speech context knowledge and are usually based on two speakers Some recent work has investigated static imagebased dialogue However several realworld human interactions also involve dynamic visual context similar to videos as well as dialogue exchanges among multiple speakers To move closer towards such multimodal conversational skills and visuallysituated applications we introduce a new videocontext manyspeaker dialogue dataset based on livebroadcast soccer game videos and chats from Twitchtv This challenging testbed allows us to develop visuallygrounded dialogue models that should generate relevant temporal and spatial event language from the live video while also being relevant to the chat history For strong baselines we also present several discriminative and generative models eg based on tridirectional attention flow TriDAF We evaluate these models via retrieval rankingrecall automatic phrasematching metrics as well as human evaluation studies We also present dataset analyses model ablations and visualizations to understand the contribution of different modalities and model components We release all data code and models at https githubcomramakanthpasunuruvideodialogue Figure 1 Sample example from our manyspeaker videocontext dialogue dataset based on live soccer game chat The task is to predict the response bottomright using the video context left and the chat context topright",
        "A1": "To move closer towards such multimodal conversational skills and visuallysituated applications",
        "A2": "introduce a new videocontext manyspeaker dialogue dataset based on livebroadcast soccer game videos and chats from Twitchtv",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "retrieval rankingrecall automatic phrasematching metrics as well as human evaluation studies",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "tridirectional attention flow TriDAF",
        "A42": "several discriminative and generative models",
        "A45": "a new videocontext manyspeaker dialogue dataset based on livebroadcast soccer game videos and chats from Twitchtv",
        "am_id": 388512476
    },
    {
        "Abstract": "The SimpleQuestions dataset is one of the most commonly used benchmarks for studying singlerelation factoid questions In this paper we present new evidence that this benchmark can be nearly solved by standard methods First we show that ambiguity in the data bounds performance at 834 many questions have more than one equally plausible interpretation Second we introduce a baseline that sets a new stateoftheart performance level at 781 accuracy despite using standard methods Finally we report an empirical analysis showing that the upperbound is loose roughly a quarter of the remaining errors are also not resolvable from the linguistic signal Together these results suggest that the SimpleQuestions dataset is nearly solved",
        "A1": "we present new evidence that this benchmark can be nearly solved by standard methods",
        "A2": "studying singlerelation factoid questions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the upperbound is loose roughly a quarter of the remaining errors are also not resolvable from the linguistic signal Together these results suggest that the SimpleQuestions dataset is nearly solved",
        "A7": "we introduce a baseline that sets a new stateoftheart performance level at 781 accuracy despite using standard methods",
        "A83": "we report an empirical analysis showing that the upperbound is loose roughly a quarter of the remaining errors are also not resolvable from the linguistic signal Together these results suggest that the SimpleQuestions dataset is nearly solved",
        "A82": "we introduce a baseline that sets a new stateoftheart performance level at 781 accuracy despite using standard methods",
        "A81": "we show that ambiguity in the data bounds performance at 834 many questions have more than one equally plausible interpretation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 145518735
    },
    {
        "Abstract": "Capturing the semantic relations of words in a vector space contributes to many natural language processing tasks One promising approach exploits lexicosyntactic patterns as features of word pairs In this paper we propose a novel model of this patternbased approach neural latent relational analysis NLRA NLRA can generalize cooccurrences of word pairs and lexicosyntactic patterns and obtain embeddings of the word pairs that do not cooccur This overcomes the critical data sparseness problem encountered in previous patternbased models Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous patternbased models In addition when combined with a vector offset model NLRA achieves a performance comparable to that of the stateoftheart model that exploits additional semantic relational data",
        "A1": " we propose a novel model of this patternbased approach neural latent relational analysis NLRA",
        "A2": "Capturing the semantic relations of words in a vector space",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on measuring relational similarity ",
        "A83": "",
        "A82": "when combined with a vector offset model NLRA achieves a performance comparable to that of the stateoftheart model that exploits additional semantic relational data",
        "A81": "NLRA outperforms the previous patternbased models ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " neural latent relational analysis",
        "A42": " a novel model of this patternbased approach neural latent relational analysis NLRA ",
        "A45": "",
        "am_id": 3163421
    },
    {
        "Abstract": "Word translation or bilingual dictionary induction is an important capability that impacts many multilingual language processing tasks Recent research has shown that word translation can be achieved in an unsupervised manner without parallel seed dictionaries or aligned corpora However state of the art methods for unsupervised bilingual dictionary induction are based on generative adversarial models and as such suffer from their well known problems of instability and hyperparameter sensitivity We present a statistical dependencybased approach to bilingual dictionary induction that is unsupervised  no seed dictionary or parallel corpora required and introduces no adversary  therefore being much easier to train Our method performs comparably to adversarial alternatives and outperforms prior nonadversarial methods",
        "A1": "present a statistical dependencybased approach to bilingual dictionary induction that is unsupervised",
        "A2": "problems of instability and hyperparameter sensitivity",
        "A41": "a statistical dependencybased approach to bilingual dictionary induction that is unsupervised",
        "A51": "",
        "A61": "no seed dictionary or parallel corpora required and introduces no adversary  therefore being much easier to train",
        "A10": "comparably to adversarial alternatives and outperforms prior nonadversarial methods",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 436571982
    },
    {
        "Abstract": "The lack of labeled data is one of the main challenges when building a taskoriented dialogue system Existing dialogue datasets usually rely on human labeling which is expensive limited in size and in low coverage In this paper we instead propose our framework autodialabel to automatically cluster the dialogue intents and slots In this framework we collect a set of context features leverage an autoencoder for feature assembly and adapt a dynamic hierarchical clustering method for intent and slot labeling Experimental results show that our framework can promote human labeling cost to a great extent achieve good intent clustering accuracy 841 and provide reasonable and instructive slot labeling results",
        "A1": "propose our framework autodialabel",
        "A2": "lack of labeled data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "provide reasonable and instructive slot labeling results",
        "A82": "achieve good intent clustering accuracy 841",
        "A81": "can promote human labeling cost to a great extent",
        "A64": "Existing dialogue datasets usually rely on human labeling which is expensive limited in size and in low coverage",
        "A54": "",
        "A44": "automatically cluster the dialogue intents and slots",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 305554354
    },
    {
        "Abstract": "The main goal of this paper is to develop outofdomain OOD detection for dialog systems We propose to use only indomain IND sentences to build a generative adversarial network GAN of which the discriminator generates low scores for OOD sentences To improve basic GANs we apply feature matching loss in the discriminator use domaincategory analysis as an additional task in the discriminator and remove the biases in the generator Thereby we reduce the huge effort of collecting OOD sentences for training OOD detection For evaluation we experimented OOD detection on a multidomain dialog system The experimental results showed the proposed method was most accurate compared to the existing methods",
        "A1": "The main goal of this paper is to develop outofdomain OOD detection for dialog systems ",
        "A2": "the discriminator generates low scores for OOD sentences ",
        "A41": " we apply feature matching loss in the discriminator use domaincategory analysis as an additional task in the discriminator and remove the biases in the generator",
        "A51": "",
        "A61": "Thereby we reduce the huge effort of collecting OOD sentences for training OOD detection For evaluation",
        "A10": " The experimental results showed the proposed method was most accurate compared to the existing methods",
        "A7": "For evaluation we experimented OOD detection on a multidomain dialog system",
        "A83": "",
        "A82": "",
        "A81": "The experimental results showed the proposed method was most accurate compared to the existing methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 170860489
    },
    {
        "Abstract": "Practical summarization systems are expected to produce summaries of varying lengths per user needs While a couple of early summarization benchmarks tested systems across multiple summary lengths this practice was mostly abandoned due to the assumed cost of producing reference summaries of multiple lengths In this paper we raise the research question of whether reference summaries of a single length can be used to reliably evaluate system summaries of multiple lengths For that we have analyzed a couple of datasets as a case study using several variants of the ROUGE metric that are standard in summarization evaluation Our findings indicate that the evaluation protocol in question is indeed competitive This result paves the way to practically evaluating varyinglength summaries with simple possibly existing summarization benchmarks",
        "A1": "whether reference summaries of a single length can be used to reliably evaluate system summaries of multiple lengths ",
        "A2": "whether reference summaries of a single length can be used to reliably evaluate system summaries of multiple lengths ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our findings indicate that the evaluation protocol in question is indeed competitive",
        "A7": "a couple of datasets ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "using several variants of the ROUGE metric that are standard in summarization evaluation",
        "am_id": 314756457
    },
    {
        "Abstract": "Deep neural networks have been displaying superior performance over traditional supervised classifiers in text classification They learn to extract useful features automatically when sufficient amount of data is presented However along with the growth in the number of documents comes the increase in the number of categories which often results in poor performance of the multiclass classifiers In this work we use external knowledge in the form of topic category taxonomies to aide the classification by introducing a deep hierarchical neural attentionbased classifier Our model performs better than or comparable to stateoftheart hierarchical models at significantly lower computational cost while maintaining high interpretability",
        "A1": "use external knowledge in the form of topic category taxonomies to aide the classification by introducing a deep hierarchical neural attentionbased classifier",
        "A2": "performs better than or comparable to stateoftheart hierarchical models at significantly lower computational cost while maintaining high interpretability",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "performs better than or comparable to stateoftheart hierarchical models at significantly lower computational cost while maintaining high interpretability",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "performs better than or comparable to stateoftheart hierarchical models at significantly lower computational cost while maintaining high interpretability",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "significantly lower computational cost while maintaining high interpretability",
        "A52": "external knowledge in the form of topic category taxonomies ",
        "A42": "use external knowledge in the form of topic category taxonomies to aide the classification by introducing a deep hierarchical neural attentionbased classifier",
        "A45": "",
        "am_id": 221814937
    },
    {
        "Abstract": "Video content on social media platforms constitutes a major part of the communication between people as it allows everyone to share their stories However if someone is unable to consume video either due to a disability or network bandwidth this severely limits their participation and communication Automatically telling the stories using multisentence descriptions of videos would allow bridging this gap To learn and evaluate such models we introduce VideoStory a new largescale dataset for video description as a new challenge for multisentence video description Our VideoStory captions dataset is complementary to prior work and contains 20k videos posted publicly on a social media platform amounting to 396 hours of video with 123k sentences temporally aligned to the video Work done while SG was intern at Facebook AI Research",
        "A1": "bridging this gap",
        "A2": " someone is unable to consume video either due to a disability or network bandwidth this severely limits their participation and communication",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our VideoStory captions dataset is complementary to prior work",
        "A7": "we introduce VideoStory a new largescale dataset for video description as a new challenge for multisentence",
        "A83": "Our VideoStory captions dataset is complementary to prior work",
        "A82": "we introduce VideoStory a new largescale dataset for video description as a new challenge for multisentence video description",
        "A81": "To learn and evaluate such models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a new largescale dataset for video description as a new challenge for multisentence video description",
        "am_id": 204090151
    },
    {
        "Abstract": "Entity typing aims to classify semantic types of an entity mention in a specific context Most existing models obtain training data using distant supervision and inevitably suffer from the problem of noisy labels To address this issue we propose entity typing with language model enhancement It utilizes a language model to measure the compatibility between context sentences and labels and thereby automatically focuses more on contextdependent labels Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model and significantly outperforms the stateoftheart baseline Code and data for this paper can be found from httpsgithub comthunlpLME",
        "A1": "Entity typing aims to classify semantic types of an entity mention in a specific context",
        "A2": "Most existing models obtain training data using distant supervision and inevitably suffer from",
        "A41": "Entity typing aims to classify semantic types of an entity mention in a specific context Most existing models obtain training data using distant supervision and inevitably suffer from the problem of noisy labels",
        "A51": "To address this issue we propose entity typing with language model enhancement It utilizes a language model to measure the compatibility between context sentences and labels and thereby automatically focuses more on contextdependent label",
        "A61": "",
        "A10": "Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model and significantly outperforms the stateoftheart baseline Code and data for this paper can be found from httpsgithub comthunlpLME",
        "A7": "It utilizes a language model to measure the compatibility",
        "A83": "",
        "A82": "",
        "A81": "Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model and significantly o",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 353303450
    },
    {
        "Abstract": "Nowcasting based on social media text promises to provide unobtrusive and near realtime predictions of communitylevel outcomes These outcomes are typically regarding people but the data is often aggregated without regard to users in the Twitter populations of each community This paper describes a simple yet effective method for building communitylevel models using Twitter language aggregated by user Results on four different US countylevel tasks spanning demographic health and psychological outcomes show large and consistent improvements in prediction accuracies eg from Pearson r  73 to 82 for median income prediction or r  37 to 47 for life satisfaction prediction over the standard approach of aggregating all tweets We make our aggregated and anonymized communitylevel data derived from 37 billion tweets  over 1 billion of which were mapped to counties available for research",
        "A1": "describes a simple yet effective method for building communitylevel models using Twitter language aggregated by user Results on four different US countylevel tasks spanning demographic health",
        "A2": "data is often aggregated without regard to users in the Twitter populations of each community",
        "A41": "method for building communitylevel models using Twitter language aggregated by user Results on four different US countylevel tasks spanning demographic health",
        "A51": "Twitter language aggregated by user Results on four different US countylevel tasks spanning demographic health",
        "A61": "psychological outcomes show large and consistent improvements in prediction accuracies",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "r  37 to 47 for life satisfaction prediction over the standard approach of aggregating all tweets",
        "A81": "improvements in prediction accuracies eg from Pearson r  73 to 82 for median income prediction",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 335857168
    },
    {
        "Abstract": "We propose a conditional nonautoregressive neural sequence model based on iterative refinement The proposed model is designed based on the principles of latent variable models and denoising autoencoders and is generally applicable to any sequence generation task We extensively evaluate the proposed model on machine translation En De and En Ro and image caption generation and observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart  Equal Contribution",
        "A1": "propose a conditional nonautoregressive neural sequence model",
        "A2": "is generally applicable to any sequence generation task ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart  Equal Contribution",
        "A7": "evaluate the proposed model on machine translation En De and En Ro and image caption generation ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart  Equal Contribution",
        "A52": "iterative refinement",
        "A42": " a conditional nonautoregressive neural sequence model based on iterative refinement",
        "A45": "",
        "am_id": 11795244
    },
    {
        "Abstract": "Despite the tremendous empirical success of neural models in natural language processing many of them lack the strong intuitions that accompany classical machine learning approaches Recently connections have been shown between convolutional neural networks CNNs and weighted finite state automata WFSAs leading to new interpretations and insights In this work we show that some recurrent neural networks also share this connection to WFSAs We characterize this connection formally defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs We show that several recent neural models use rational recurrences Our analysis provides a fresh view of these models and facilitates devising new neural architectures that draw inspiration from WFSAs We present one such model which performs better than two recent baselines on language modeling and text classification Our results demonstrate that transferring intuitions from classical models like WFSAs can be an effective approach to designing and understanding neural models",
        "A1": "We characterize this connection formally defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs ",
        "A2": " many of them lack the strong intuitions that accompany classical machine learning approaches ",
        "A41": "We characterize this connection formally defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs ",
        "A51": " tremendous empirical ",
        "A61": "",
        "A10": "",
        "A7": "We characterize this connection formally defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs",
        "A83": "",
        "A82": "",
        "A81": "We characterize this connection formally defining rational recurrences to be recurrent hidden state update functions that can be written as the Forward calculation of a finite set of WFSAs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 88492294
    },
    {
        "Abstract": "Traditional approaches to the task of ACE event detection primarily regard multiple events in one sentence as independent ones and recognize them separately by using sentencelevel information However events in one sentence are usually interdependent and sentencelevel information is often insufficient to resolve ambiguities for some types of events This paper proposes a novel framework dubbed as Hierarchical and Bias Tagging Networks with Gated Multilevel Attention Mechanisms HBTNGMA to solve the two problems simultaneously Firstly we propose a hierarchical and bias tagging networks to detect multiple events in one sentence collectively Then we devise a gated multilevel attention to automatically extract and dynamically fuse the sentencelevel and documentlevel information The experimental results on the widely used ACE 2005 dataset show that our approach significantly outperforms other stateoftheart methods",
        "A1": "",
        "A2": "events in one sentence are usually interdependent and sentencelevel information is often insufficient to resolve ambiguities for some types of events",
        "A41": "Firstly we propose a hierarchical and bias tagging networks to detect multiple events in one sentence collectively Then we devise a gated multilevel attention to automatically extract and dynamically fuse the sentencelevel and documentlevel information",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on the widely used ACE 2005 dataset ",
        "A83": "",
        "A82": "",
        "A81": "our approach significantly outperforms other stateoftheart methods",
        "A64": "solve the two problems simultaneously ",
        "A54": "",
        "A44": "dubbed as Hierarchical and Bias Tagging Networks with Gated Multilevel Attention Mechanisms HBTNGMA to solve the two problems simultaneously",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "ACE 2005",
        "am_id": 467400717
    },
    {
        "Abstract": "Rare word representation has recently enjoyed a surge of interest owing to the crucial role that effective handling of infrequent words can play in accurate semantic understanding However there is a paucity of reliable benchmarks for evaluation and comparison of these techniques We show in this paper that the only existing benchmark the Stanford Rare Word dataset suffers from lowconfidence annotations and limited vocabulary hence it does not constitute a solid comparison framework In order to fill this evaluation gap we propose CAmbridge Rare word Dataset CARD660 an expertannotated word similarity dataset which provides a highly reliable yet challenging benchmark for rare word representation techniques Through a set of experiments we show that even the best mainstream word embeddings with millions of words in their vocabularies are unable to achieve performances higher than 043 Pearson correlation on the dataset compared to a humanlevel upperbound of 090 We release the dataset and the annotation materials at https pilehvargithubiocard660",
        "A1": "We show in this paper that the only existing benchmark the Stanford Rare Word dataset suffers from lowconfidence annotations and limited vocabulary hence it does not constitute a solid comparison framework",
        "A2": "there is a paucity of reliable benchmarks for evaluation and comparison of these techniques",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "even the best mainstream word embeddings with millions of words in their vocabularies are unable to achieve performances higher than 043 Pearson correlation on the dataset compared to a humanlevel upperbound of 090",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "even the best mainstream word embeddings with millions of words in their vocabularies are unable to achieve performances higher than 043 Pearson correlation on the dataset compared to a humanlevel upperbound of 090",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "an expertannotated word similarity dataset which provides a highly reliable yet challenging benchmark for rare word representation techniques",
        "am_id": 351397280
    },
    {
        "Abstract": "While one of the first steps in many NLP systems is selecting what pretrained word embeddings to use we argue that such a step is better left for neural networks to figure out by themselves To that end we introduce dynamic metaembeddings a simple yet effective method for the supervised learning of embedding ensembles which leads to stateoftheart performance within the same model class on a variety of tasks We subsequently show how the technique can be used to shed new light on the usage of word embeddings in NLP systems",
        "A1": "show how the technique can be used to shed new light on the usage of word embeddings in NLP systems",
        "A2": "show how the technique can be used to shed new light on the usage of word embeddings in NLP systems",
        "A41": "method for the supervised learning of embedding ensembles ",
        "A51": "",
        "A61": "dynamic metaembeddings a simple yet effective",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 128116496
    },
    {
        "Abstract": "Information selection is the most important component in document summarization task In this paper we propose to extend the basic neural encodingdecoding framework with an information selection layer to explicitly model and optimize the information selection process in abstractive document summarization Specifically our information selection layer consists of two parts gated global information filtering and local sentence selection Unnecessary information in the original document is first globally filtered then salient sentences are selected locally while generating each summary sentence sequentially To optimize the information selection process directly distantlysupervised training guided by the golden summary is also imported Experimental results demonstrate that the explicit modeling and optimizing of the information selection process improves document summarization performance significantly which enables our model to generate more informative and concise summaries and thus significantly outperform stateoftheart neural abstractive methods This work was done while the first author was doing internship at Baidu Inc",
        "A1": "propose to extend the basic neural encodingdecoding framework with an information selection layer to explicitly model and optimize the information selection process in abstractive document summarization",
        "A2": "propose to extend the basic neural encodingdecoding framework with an information selection layer to explicitly model and optimize the information selection process in abstractive document summarization",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ignificantly outperform stateoftheart neural abstractive methods",
        "A7": "",
        "A83": "concise summaries",
        "A82": "enables our model to generate more informative",
        "A81": " the explicit modeling and optimizing of the information selection process improves document summarization performance significantly",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "extend the basic neural encodingdecoding framework",
        "A52": "",
        "A42": "an information selection layer",
        "A45": "",
        "am_id": 5108641
    },
    {
        "Abstract": "The existing studies in crosslanguage information retrieval CLIR mostly rely on general text representation models eg vector space model or latent semantic analysis These models are not optimized for the target retrieval task In this paper we follow the success of neural representation in natural language processing NLP and develop a novel text representation model based on adversarial learning which seeks a taskspecific embedding space for CLIR Adversarial learning is implemented as an interplay between the generator process and the discriminator process In order to adapt adversarial learning to CLIR we design three constraints to direct representation learning which are 1 a matching constraint capturing essential characteristics of crosslanguage ranking 2 a translation constraint bridging language gaps and 3 an adversarial constraint forcing both language and source invariant to be reached more efficiently and effectively Through the joint exploitation of these constraints in an adversarial manner the underlying crosslanguage semantics relevant to retrieval tasks are better preserved in the embedding space Standard CLIR experiments show that our model significantly outperforms stateoftheart continuous space models and approaches the strong machine translation and monolingual baselines",
        "A1": "develop a novel text representation model based on adversarial learning",
        "A2": "These models are not optimized for the target retrieval task",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our model significantly outperforms stateoftheart continuous space models and approaches the strong machine translation and monolingual baselines",
        "A7": "the underlying crosslanguage semantics relevant to retrieval tasks are better preserved in the embedding space Standard CLIR",
        "A83": "",
        "A82": "",
        "A81": "our model significantly outperforms stateoftheart continuous space models and approaches the strong machine translation and monolingual baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Adversarial learning is implemented as an interplay between the generator process and the discriminator process",
        "A52": "adversarial learning which seeks a taskspecific embedding space for CLIR",
        "A42": "a novel text representation model",
        "A45": "",
        "am_id": 49945691
    },
    {
        "Abstract": "The availability of large scale annotated corpora for coreference is essential to the development of the field However creating resources at the required scale via expert annotation would be too expensive Crowdsourcing has been proposed as an alternative but this approach has not been widely used for coreference This paper addresses one crucial hurdle on the way to make this possible by introducing a new model of annotation for aggregating crowdsourced anaphoric annotations The model is evaluated along three dimensions the accuracy of the inferred mention pairs the quality of the posthoc constructed silver chains and the viability of using the silver chains as an alternative to the expertannotated chains in training a state of the art coreference system The results suggest that our model can extract from crowdsourced annotations coreference chains of comparable quality to those obtained with expert annotation",
        "A1": "addresses one crucial hurdle on the way to make this possible by introducing a new model",
        "A2": "Crowdsourcing",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "is evaluated along three dimensions the accuracy of the inferred mention pairs the quality of the posthoc constructed silver chains and the viability of using the silver chains",
        "A83": "",
        "A82": "",
        "A81": "our model can extract from crowdsourced annotations coreference chains of comparable quality to those obtained with expert annotation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "annotation for aggregating crowdsourced anaphoric annotations",
        "A45": "",
        "am_id": 325872669
    },
    {
        "Abstract": "Experimental performance on the task of relation classification has generally improved using deep neural network architectures One major drawback of reported studies is that individual models have been evaluated on a very narrow range of datasets raising questions about the adaptability of the architectures while making comparisons between approaches difficult In this work we present a systematic largescale analysis of neural relation classification architectures on six benchmark datasets with widely varying characteristics We propose a novel multichannel LSTM model combined with a CNN that takes advantage of all currently popular linguistic and architectural features Our Man for All Seasons approach achieves stateoftheart performance on two datasets More importantly in our view the model allowed us to obtain direct insights into the continued challenges faced by neural language models on this task Example data and source code are available at httpsgithubcomaidantee MASS y Contributed equally  Names are in alphabetical order Corresponding author",
        "A1": "we present a systematic largescale analysis of neural relation classification architectures on six benchmark datasets with widely varying characteristics ",
        "A2": "we present a systematic largescale analysis of neural relation classification architectures on six benchmark datasets with widely varying characteristics ",
        "A41": "We propose a novel multichannel LSTM model combined with a CNN that takes advantage of all currently popular linguistic and architectural features ",
        "A51": "Experimental performance on the task of relation classification has generally improved using deep neural network architectures",
        "A61": "One major drawback of reported studies is that individual models have been evaluated on a very narrow range of datasets raising questions about the adaptability of the architectures",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 74799024
    },
    {
        "Abstract": "We consider negotiation settings in which two agents use natural language to bargain on goods Agents need to decide on both highlevel strategy eg proposing 50 and the execution of that strategy eg generating The bike is brand new Selling for just 50 Recent work on negotiation trains neural models but their endtoend nature makes it hard to control their strategy and reinforcement learning tends to lead to degenerate solutions In this paper we propose a modular approach based on coarse dialogue acts eg proposeprice50 that decouples strategy and generation We show that we can flexibly set the strategy using supervised learning reinforcement learning or domainspecific knowledge without degeneracy while our retrievalbased generation can maintain contextawareness and produce diverse utterances We test our approach on the recently proposed DEALORNODEAL game and we also collect a richer dataset based on real items on Craigslist Human evaluation shows that our systems achieve higher task success rate and more humanlike negotiation behavior than previous approaches",
        "A1": "We consider negotiation settings in which two agents use natural language to bargain on goods Agents need to decide on both highlevel strategy",
        "A2": "The bike is brand new Selling for just 50 Recent work on negotiation trains neural models but their endtoend nature makes it hard to control their strategy and reinforcement",
        "A41": "we propose a modular approach based on coarse dialogue acts eg proposeprice50 that decouples strategy and generation",
        "A51": "based on coarse dialogue acts eg proposeprice50 that decouples strategy and generation ",
        "A61": " We show that we can flexibly set the strategy using supervised learning reinforcement learning or domainspecific knowledge ",
        "A10": "evaluation shows that our systems achieve higher task success rate and more humanlike negotiation behavior than previous approaches",
        "A7": "evaluation shows that our systems achieve higher task success rate and more humanlike negotiation behavior than previous approaches",
        "A83": "",
        "A82": "",
        "A81": "evaluation shows that our systems achieve higher task success rate and more humanlike negotiation behavior than previous approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 429348646
    },
    {
        "Abstract": "Semantic role labeling SRL aims to recognize the predicateargument structure of a sentence Syntactic information has been paid a great attention over the role of enhancing SRL However the latest advance shows that syntax would not be so important for SRL with the emerging much smaller gap between syntaxaware and syntaxagnostic SRL To comprehensively explore the role of syntax for SRL task we extend existing models and propose a unified framework to investigate more effective and more diverse ways of incorporating syntax into sequential neural networks Exploring the effect of syntactic input quality on SRL performance we confirm that highquality syntactic parse could still effectively enhance syntacticallydriven SRL Using empirically optimized integration strategy we even enlarge the gap between syntaxaware and syntaxagnostic SRL Our framework achieves stateoftheart results on CoNLL2009 benchmarks both for English and Chinese substantially outperforming all previous models",
        "A1": "Semantic role labeling",
        "A2": "syntax would not be so important for SRL with the emerging much smaller gap between syntaxaware and syntaxagnostic SRL",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "substantially outperforming all previous models",
        "A7": "CoNLL2009 benchmarks",
        "A83": "",
        "A82": "substantially outperforming all previous models",
        "A81": "achieves stateoftheart results",
        "A64": "",
        "A54": " syntaxaware and syntaxagnostic SRL",
        "A44": "incorporating syntax into sequential neural networks",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 398444221
    },
    {
        "Abstract": "In this paper we advocate the use of bilingual corpora which are abundantly available for training sentence compression models Our approach borrows much of its machinery from neural machine translation and leverages bilingual pivoting compressions are obtained by translating a source string into a foreign language and then backtranslating it into the source while controlling the translation length Our model can be trained for any language as long as a bilingual corpus is available and performs arbitrary rewrites without access to compression specific data We release1 MOSS a new parallel Multilingual Compression dataset for English German and French which can be used to evaluate compression models across languages and genres",
        "A1": "In this paper we advocate the use of bilingual corpora which are abundantly available for training sentence compression models",
        "A2": "training sentence compression models ",
        "A41": " Our approach borrows much of its machinery from neural machine translation and leverages bilingual pivoting compressions are obtained by translating a source string into a foreign language and then backtranslating it into the source while controlling the translation length ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "Our model can be trained for any language as long as a bilingual corpus is available and performs arbitrary rewrites without access to compression specific data",
        "A45": "MOSS a new parallel Multilingual Compression dataset for English German and French which can be used to evaluate compression models across languages and genres",
        "am_id": 30973335
    },
    {
        "Abstract": "Crosslingual transfer of word embeddings aims to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces Successfully solving this problem would benefit many downstream tasks such as to translate text classification models from resourcerich languages eg English to lowresource languages Supervised methods for this problem rely on the availability of crosslingual supervision either using parallel corpora or bilingual lexicons as the labeled data for training which may not be available for many low resource languages This paper proposes an unsupervised learning approach that does not require any crosslingual labeled data Given two monolingual word embedding spaces for any language pair our algorithm optimizes the transformation functions in both directions simultaneously based on distributional matching as well as minimizing the backtranslation losses We use a neural network implementation to calculate the Sinkhorn distance a welldefined distributional similarity measure and optimize our objective through backpropagation Our evaluation on benchmark datasets for bilingual lexicon induction and crosslingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other stateoftheart supervised and unsupervised baseline methods over many language pairs",
        "A1": " to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces",
        "A2": "to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces ",
        "A41": "This paper proposes an unsupervised learning approach that does not require any crosslingual labeled data Given two monolingual word embedding spaces for any language pair our algorithm optimizes the transformation functions in both directions simultaneously based on distributional matching as well as minimizing the backtranslation losses",
        "A51": "based on distributional matching",
        "A61": " does not require any crosslingual labeled data",
        "A10": " shows stronger or competitive performance of the proposed method ",
        "A7": "Our evaluation on benchmark datasets for bilingual lexicon induction and crosslingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other stateoftheart supervised and unsupervised baseline methods over many language pairs",
        "A83": "",
        "A82": "",
        "A81": "shows stronger or competitive performance of the proposed method ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 366715166
    },
    {
        "Abstract": "This paper proposes to study finegrained coordinated crosslingual text stream alignment through a novel information network decipherment paradigm We use Burst Information Networks as media to represent text streams and present a simple yet effective network decipherment algorithm with diverse clues to decipher the networks for accurate text stream alignment Experiments on ChineseEnglish news streams show our approach not only outperforms previous approaches on bilingual lexicon extraction from coordinated text streams but also can harvest highquality alignments from large amounts of streaming data for endless language knowledge mining which makes it promising to be a new paradigm for automatic language knowledge acquisition",
        "A1": "proposes to study finegrained coordinated crosslingual text stream alignment through a novel information network decipherment paradigm",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our approach not only outperforms previous approaches on bilingual lexicon extraction from coordinated text streams",
        "A7": "Experiments on ChineseEnglish news streams",
        "A83": "",
        "A82": "can harvest highquality alignments from large amounts of streaming data for endless language knowledge mining which makes it promising to be a new paradigm for automatic language knowledge acquisition",
        "A81": "outperforms previous approaches on bilingual lexicon extraction from coordinated text streams",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "We use Burst Information Networks as media to represent text streams and present a simple yet effective network decipherment algorithm with diverse clues to decipher the networks for accurate text stream alignment",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 169131547
    },
    {
        "Abstract": "The configurational information in sentences of a free word order language such as Sanskrit is of limited use Thus the context of the entire sentence will be desirable even for basic processing tasks such as word segmentation We propose a structured prediction framework that jointly solves the word segmentation and morphological tagging tasks in Sanskrit We build an energy based model where we adopt approaches generally employed in graph based parsing techniques McDonald et al 2005a Carreras 2007 Our model outperforms the state of the art with an FScore of 9692 percentage improvement of 706 while using less than one tenth of the taskspecific training data We find that the use of a graph based approach instead of a traditional latticebased sequential labelling approach leads to a percentage gain of 126 in FScore for the segmentation task1",
        "A1": "propose a structured prediction framework",
        "A2": "The configurational information in sentences of a free word order language such as Sanskrit is of limited use ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "with an FScore of 9692 percentage improvement of 706 while using less than one tenth of the taskspecific training data",
        "A7": "We build an energy based model where we adopt approaches generally employed in graph based parsing techniques McDonald et al 2005a Carreras 2007",
        "A83": "",
        "A82": "",
        "A81": "the use of a graph based approach instead of a traditional latticebased sequential labelling approach leads to a percentage gain of 126 in FScore for the segmentation task1",
        "A64": "",
        "A54": "",
        "A44": "framework that jointly solves the word segmentation and morphological tagging tasks in Sanskrit ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 395479363
    },
    {
        "Abstract": "We develop a semantic parser that is trained in a grounded setting using pairs of videos captioned with sentences This setting is both dataefficient requiring little annotation and similar to the experience of children where they observe their environment and listen to speakers The semantic parser recovers the meaning of English sentences despite not having access to any annotated sentences It does so despite the ambiguity inherent in vision where a sentence may refer to any combination of objects object properties relations or actions taken by any agent in a video For this task we collected a new dataset for grounded language acquisition Learning a grounded semantic parser  turning sentences into logical forms using captioned videos  can significantly expand the range of data that parsers can be trained on lower the effort of training a semantic parser and ultimately lead to a better understanding of child language acquisition",
        "A1": "a better understanding of child language acquisition",
        "A2": "develop a semantic parser",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "expand the range of data that parsers can be trained on lower the effort of training a semantic parser and ultimately lead to a better understanding of child language acquisition",
        "A7": "trained in a grounded setting using pairs of videos captioned with sentences",
        "A83": "It does so despite the ambiguity inherent in vision where a sentence may refer to any combination of objects object properties relations or actions taken by any agent in a video",
        "A82": "The semantic parser recovers the meaning of English sentences despite not having access to any annotated sentences",
        "A81": "This setting is both dataefficient requiring little annotation and similar to the experience of children where they observe their environment and listen to speakers",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "a new dataset for grounded language acquisition ",
        "A52": "the experience of children where they observe their environment and listen to speakers",
        "A42": " a semantic parser that is trained in a grounded setting using pairs of videos captioned with sentences",
        "A45": "",
        "am_id": 206825881
    },
    {
        "Abstract": "In natural language processing a common task is to compute the probability of a given phrase appearing or to calculate the probability of all phrases matching a given pattern For instance one computes affix prefix suffix infix etc probabilities of a string or a set of strings with respect to a probability distribution of patterns The problem of computing infix probabilities of strings when the pattern distribution is given by a probabilistic contextfree grammar or by a probabilistic finite automaton is already solved yet it was open to compute the infix probabilities in an incremental manner The incremental computation is crucial when a new query is built from a previous query We tackle this problem and suggest a method that computes infix probabilities incrementally for probabilistic finite automata by representing all the probabilities of matching strings as a series of transition matrix calculations We show that the proposed approach is theoretically faster than the previous method and using real world data demonstrate that our approach has vastly better performance in practice",
        "A1": "suggest a method that computes infix probabilities incrementally for probabilistic finite automata",
        "A2": "compute the infix probabilities in an incremental manner",
        "A41": " a method that computes infix probabilities incrementally for probabilistic finite automata by representing all the probabilities of matching strings as a series of transition matrix calculations",
        "A51": "representing all the probabilities of matching strings as a series of transition matrix calculations",
        "A61": "the proposed approach is theoretically faster than the previous method and using real world data demonstrate that our approach has vastly better performance in practice",
        "A10": "theoretically faster than the previous method and using real world data demonstrate that our approach has vastly better performance in practice",
        "A7": "using real world data",
        "A83": "",
        "A82": "our approach has vastly better performance in practice",
        "A81": "the proposed approach is theoretically faster than the previous method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 435170824
    },
    {
        "Abstract": "The paper introduces endtoend neural network models that tokenize Sanskrit by jointly splitting compounds and resolving phonetic merges Sandhi Tokenization of Sanskrit depends on local phonetic and distant semantic features that are incorporated using convolutional and recurrent elements Contrary to most previous systems our models do not require feature engineering or extern linguistic resources but operate solely on parallel versions of raw and segmented text The models discussed in this paper clearly improve over previous approaches to Sanskrit word segmentation As they are language agnostic we will demonstrate that they also outperform the state of the art for the related task of German compound splitting",
        "A1": " introduces endtoend neural network models",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperform the state of the art for the related task of German compound splitting",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "improve over previous approaches to Sanskrit word segmentation ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Contrary to most previous systems our models do not require feature engineering or extern linguistic resources but operate solely on parallel versions of raw and segmented text",
        "A52": "",
        "A42": "models that tokenize Sanskrit by jointly splitting compounds",
        "A45": "",
        "am_id": 277476337
    },
    {
        "Abstract": "Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots Previous work on task oriented intent and slotfilling work has been restricted to one intent per query and one slot label per token and thus cannot model complex compositional requests Alternative semantic parsing systems have represented queries as logical forms but these are challenging to annotate and parse We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries and can be efficiently and accurately parsed by standard constituency parsing models We release a dataset of 44k annotated queries 1 and show that parsing models outperform sequencetosequence approaches on this dataset",
        "A1": "We propose a hierarchical annotation scheme",
        "A2": "Previous work on task oriented intent and slotfilling work has been restricted to one intent per query and one slot label per token and thus cannot model complex compositional requests Alternative semantic parsing systems have represented queries as logical forms but these are challenging to annotate and parse",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "elease a dataset of 44k annotated queries 1",
        "A83": "",
        "A82": "",
        "A81": "parsing models outperform sequencetosequence approaches on this dataset",
        "A64": "",
        "A54": "",
        "A44": "allows the representation of compositional queries and can be efficiently and accurately parsed by standard constituency parsing models ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 210767916
    },
    {
        "Abstract": "The Paradigm Cell Filling Problem in morphology asks to complete word inflection tables from partial ones We implement novel neural models for this task evaluating them on 18 data sets in 8 languages showing performance that is comparable with previous work with far less training data We also publish a new dataset for this task and code implementing the system described in this paper1",
        "A1": "complete word inflection tables from partial ones",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "performance that is comparable with previous work with far less training data",
        "A7": "evaluating them on 18 data sets in 8 languages",
        "A83": "",
        "A82": "",
        "A81": "performance that is comparable with previous work with far less training data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "novel neural models",
        "A45": "a new dataset for this task and code",
        "am_id": 353542883
    },
    {
        "Abstract": "Chinese pinyin input method engine IME converts pinyin into character so that Chinese characters can be conveniently inputted into computer through common keyboard IMEs work relying on its core component pinyintocharacter conversion P2C Usually Chinese IMEs simply predict a list of character sequences for user choice only according to user pinyin input at each turn However Chinese inputting is a multiturn online procedure which can be supposed to be exploited for further user experience promoting This paper thus for the first time introduces a sequencetosequence model with gatedattention mechanism for the core task in IMEs The proposed neural P2C model is learned by encoding previous input utterance as extra context to enable our IME capable of predicting character sequence with incomplete pinyin input Our model is evaluated in different benchmark datasets showing great user experience improvement compared to traditional models which demonstrates the first engineering practice of building Chinese aided IME",
        "A1": "for further user experience promoting ",
        "A2": "predicting character sequence with incomplete pinyin input",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "great user experience improvement ",
        "A52": "",
        "A42": "neural P2C model",
        "A45": "",
        "am_id": 203545173
    },
    {
        "Abstract": "This work investigates an alternative model for neural machine translation NMT and proposes a novel architecture where we employ a multidimensional long shortterm memory MDLSTM for translation modeling In the stateoftheart methods source and target sentences are treated as onedimensional sequences over time while we view translation as a twodimensional 2D mapping using an MDLSTM layer to define the correspondence between source and target words We extend beyond the current sequence to sequence backbone NMT models to a 2D structure in which the source and target sentences are aligned with each other in a 2D grid Our proposed topology shows consistent improvements over attentionbased sequence to sequence model on two WMT 2017 tasks GermanEnglish",
        "A1": "investigates an alternative model for neural machine translation NMT",
        "A2": "",
        "A41": "a novel architecture where we employ a multidimensional long shortterm memory MDLSTM for translation modeling",
        "A51": "multidimensional long shortterm memory MDLSTM",
        "A61": "extend beyond the current sequence to sequence backbone NMT models to a 2D structure",
        "A10": " shows consistent improvements",
        "A7": "attentionbased sequence to sequence model on two WMT 2017 tasks",
        "A83": "",
        "A82": "",
        "A81": " shows consistent improvements ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 200530868
    },
    {
        "Abstract": "While current stateoftheart NMT models such as RNN seq2seq and Transformers possess a large number of parameters they are still shallow in comparison to convolutional models used for both text and vision applications In this work we attempt to train significantly 23x deeper Transformer and BiRNN encoders for machine translation We propose a simple modification to the attention mechanism that eases the optimization of deeper models and results in consistent gains of 0711 BLEU on the benchmark WMT14 EnglishGerman and WMT15 CzechEnglish tasks for both architectures",
        "A1": "train significantly 23x deeper Transformer and BiRNN encoders for machine translation",
        "A2": "still shallow in comparison to convolutional models used for both text and vision applications",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "eases the optimization of deeper models and results in consistent gains",
        "A7": "0711 BLEU on the benchmark WMT14 EnglishGerman and WMT15 CzechEnglish tasks",
        "A83": "",
        "A82": "results in consistent gains",
        "A81": "eases the optimization of deeper models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "eases the optimization of deeper models and results in consistent gains",
        "A53": "the attention mechanism",
        "A43": "significantly 23x deeper Transformer and BiRNN encoders for machine translation",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 285005428
    },
    {
        "Abstract": "Large multilabel datasets contain labels that occur thousands of times frequent group those that occur only a few times fewshot group and labels that never appear in the training dataset zeroshot group Multilabel few and zeroshot label prediction is mostly unexplored on datasets with large label spaces especially for text classification In this paper we perform a finegrained evaluation to understand how stateoftheart methods perform on infrequent labels Furthermore we develop few and zeroshot methods for multilabel text classification when there is a known structure over the label space and evaluate them on two publicly available medical text datasets MIMIC II and MIMIC III For fewshot labels we achieve improvements of 62 and 48 in R10 for MIMIC II and MIMIC III respectively over prior efforts the corresponding R10 improvements for zeroshot labels are 173 and 19",
        "A1": "In this paper we perform a finegrained evaluation",
        "A2": "Multilabel few and zeroshot label prediction is mostly unexplored on datasets with large label spaces especially for text classification",
        "A41": "we develop few and zeroshot methods for multilabel text classification",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "evaluate them on two publicly available medical text datasets MIMIC II and MIMIC III",
        "A83": "",
        "A82": "the corresponding R10 improvements for zeroshot labels are 173 and 19",
        "A81": "For fewshot labels we achieve improvements of 62 and 48 in R10 for MIMIC II and MIMIC III respectively over prior efforts",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 87331006
    },
    {
        "Abstract": "Sentence simplification aims to reduce the complexity of a sentence while retaining its original meaning Current models for sentence simplification adopted ideas from machine translation studies and implicitly learned simplification mapping rules from normalsimple sentence pairs In this paper we explore a novel model based on a multilayer and multihead attention architecture and we propose two innovative approaches to integrate the Simple PPDB A Paraphrase Database for Simplification an external paraphrase knowledge base for simplification that covers a wide range of realworld simplification rules The experiments show that the integration provides two major benefits 1 the integrated model outperforms multiple stateoftheart baseline models for sentence simplification in the literature 2 through analysis of the rule utilization the model seeks to select more accurate simplification rules The code and models used in the paper are available at httpsgithubcom Sanqiangtextsimplification",
        "A1": "Sentence simplification",
        "A2": "Current models for sentence simplification adopted ideas from machine translation studies and implicitly learned simplification mapping rules from normalsimple sentence pairs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the integration provides two major benefits 1 the integrated model outperforms multiple stateoftheart baseline models for sentence simplification in the literature 2 through analysis of the rule utilization the model seeks to select more accurate simplification rules",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "a multilayer and multihead attention architecture",
        "A42": " integrate the Simple PPDB A Paraphrase Database for Simplification ",
        "A45": "",
        "am_id": 58642317
    },
    {
        "Abstract": "This paper focuses on the most basic implicational universals in phonological theory called Torders after Anttila and Andrus 2006 It shows that the Torders predicted by stochastic and categorical Optimality Theory coincide Analogously the Torders predicted by stochastic and categorical Harmonic Grammar coincide In other words these stochastic constraintbased frameworks do not tamper with the typological structure induced by the corresponding categorical frameworks",
        "A1": "his paper focuses on the most basic implicational universals in phonological theory called Torders after Anttila and Andrus 2006",
        "A2": " these stochastic constraintbased frameworks do not tamper with the typological structure induced by the corresponding categorical frameworks",
        "A41": "",
        "A51": "Torders",
        "A61": "Torders",
        "A10": "Torders",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "these stochastic constraintbased frameworks do not tamper with the typological structure induced by the corresponding categorical frameworks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 363306531
    },
    {
        "Abstract": "We design and build the first neural temporal dependency parser It utilizes a neural ranking model with minimal feature engineering and parses time expressions and events in a text into a temporal dependency tree structure We evaluate our parser on two domains news reports and narrative stories In a parsingonly evaluation setup where gold time expressions and events are provided our parser reaches 081 and 070 fscore on unlabeled and labeled parsing respectively a result that is very competitive against alternative approaches In an endtoend evaluation setup where time expressions and events are automatically recognized our parser beats two strong baselines on both data domains Our experimental results and discussions shed light on the nature of temporal dependency structures in different domains and provide insights that we believe will be valuable to future research in this area",
        "A1": "We design and build the first neural temporal dependency parser",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "evaluate our parser on two domains news reports and narrative stories",
        "A83": "",
        "A82": "provide insights that we believe will be valuable to future research in this area",
        "A81": "shed light on the nature of temporal dependency structures in different domains",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 442057808
    },
    {
        "Abstract": "We propose a novel multigrained attention network MGAN model for aspect level sentiment classification Existing approaches mostly adopt coarsegrained attention mechanism which may bring information loss if the aspect has multiple words or larger context We propose a finegrained attention mechanism which can capture the wordlevel interaction between aspect and context And then we leverage the finegrained and coarsegrained attention mechanisms to compose the MGAN framework Moreover unlike previous works which train each aspect with its context separately we design an aspect alignment loss to depict the aspectlevel interactions among the aspects that have the same context We evaluate the proposed approach on three datasets laptop and restaurant are from SemEval 2014 and the last one is a twitter dataset Experimental results show that the multigrained attention network consistently outperforms the stateoftheart methods on all three datasets We also conduct experiments to evaluate the effectiveness of aspect alignment loss which indicates the aspectlevel interactions can bring extra useful information and further improve the performance",
        "A1": " MGAN model for aspect level sentiment classification",
        "A2": "aspect level sentiment classification",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "further improve the performance",
        "A7": "evaluate the proposed approach on three datasets laptop and restaurant are from SemEval 2014",
        "A83": "further improve the performance",
        "A82": "indicates the aspectlevel interactions can bring extra useful information",
        "A81": "the multigrained attention network consistently outperforms the stateoftheart methods on all three datasets ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "design an aspect alignment loss to depict the aspectlevel interactions among the aspects that have the same contex",
        "A52": "finegrained and coarsegrained attention mechanisms",
        "A42": "network MGAN model",
        "A45": "",
        "am_id": 192894704
    },
    {
        "Abstract": "Multimodal sentiment analysis offers various challenges one being the effective combination of different input modalities namely text visual and acoustic In this paper we propose a recurrent neural network based multimodal attention framework that leverages the contextual information for utterancelevel sentiment prediction The proposed approach applies attention on multimodal multiutterance representations and tries to learn the contributing features amongst them We evaluate our proposed approach on two multimodal sentiment analysis benchmark datasets viz CMU Multimodal Opinionlevel Sentiment Intensity CMUMOSI corpus and the recently released CMU Multimodal Opinion Sentiment and Emotion Intensity CMUMOSEI corpus Evaluation results show the effectiveness of our proposed approach with the accuracies of 8231 and 7980 for the MOSI and MOSEI datasets respectively These are approximately 2 and 1 points performance improvement over the stateoftheart models for the datasets",
        "A1": "",
        "A2": "The proposed approach applies attention on multimodal multiutterance representations and tries to learn the contributing features amongst them",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "These are approximately 2 and 1 points performance improvement over the stateoftheart models for the datasets",
        "A7": "We evaluate our proposed approach on two multimodal sentiment analysis benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": " Evaluation results show the effectiveness of our proposed approach with the accuracies of 8231 and 7980 for the MOSI and MOSEI datasets respectively",
        "A64": "These are approximately 2 and 1 points performance improvement over the stateoftheart models for the datasets",
        "A54": "a recurrent neural network",
        "A44": "multimodal attention framework that leverages the contextual information for utterancelevel sentiment prediction",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 158500578
    },
    {
        "Abstract": "In this paper we propose to extend the recently introduced modelagnostic metalearning algorithm MAML Finn et al 2017 for lowresource neural machine translation NMT We frame lowresource translation as a metalearning problem and we learn to adapt to lowresource languages based on multilingual highresource language tasks We use the universal lexical representation Gu et al 2018b to overcome the inputoutput mismatch across different languages We evaluate the proposed metalearning strategy using eighteen European languages Bg Cs Da De El Es Et Fr Hu It Lt Nl Pl Pt Sk Sl Sv and Ru as source tasks and five diverse languages Ro Lv Fi Tr and Ko as target tasks We show that the proposed approach significantly outperforms the multilingual transfer learning based approach Zoph et al 2016 and enables us to train a competitive NMT system with only a fraction of training examples For instance the proposed approach can achieve as high as 2204 BLEU on RomanianEnglish WMT16 by seeing only 16000 translated words  600 parallel sentences",
        "A1": "extend the recently introduced modelagnostic metalearning algorithm MAML ",
        "A2": "lowresource neural machine translation NMT",
        "A41": "learn to adapt to lowresource languages based on multilingual highresource language tasks ",
        "A51": "modelagnostic metalearning algorithm MAML",
        "A61": "",
        "A10": " significantly outperforms the multilingual transfer learning based approach",
        "A7": " eighteen European languages Bg Cs Da De El Es Et Fr Hu It Lt Nl Pl Pt Sk Sl Sv and Ru as source tasks and five diverse languages Ro Lv Fi Tr and Ko as target tasks",
        "A83": "",
        "A82": "enables us to train a competitive NMT system with only a fraction of training examples",
        "A81": "significantly outperforms the multilingual transfer learning based approach ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 335229094
    },
    {
        "Abstract": "Argument mining is a core technology for automating argument search in large document collections Despite its usefulness for this task most current approaches are designed for use only with specific text types and fall short when applied to heterogeneous texts In this paper we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts We source annotations for over 25000 instances covering eight controversial topics We show that integrating topic information into bidirectional long shortterm memory networks outperforms vanilla BiLSTMs by more than 3 percentage points in F1 in two and threelabel crosstopic settings We also show that these results can be further improved by leveraging additional data for topic relevance using multitask learning",
        "A1": "we propose a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts",
        "A2": "most current approaches are designed for use only with specific text types and fall short when applied to heterogeneous texts",
        "A41": "a new sentential annotation scheme that is reliably applicable by crowd workers to arbitrary Web texts",
        "A51": "bidirectional long shortterm memory networks",
        "A61": "integrating topic information",
        "A10": "",
        "A7": "We source annotations for over 25000 instances covering eight controversial topics",
        "A83": "",
        "A82": "these results can be further improved by leveraging additional data for topic relevance using multitask learning",
        "A81": "integrating topic information into bidirectional long shortterm memory networks outperforms vanilla BiLSTMs by more than 3 percentage points in F1 in two and threelabel crosstopic settings",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 255139183
    },
    {
        "Abstract": "Spoken Language Understanding SLU which typically involves intent determination and slot filling is a core component of spoken dialogue systems Joint learning has shown to be effective in SLU given that slot tags and intents are supposed to share knowledge with each other However most existing joint learning methods only consider joint learning by sharing parameters on surface level rather than semantic level In this work we propose a novel selfattentive model with gate mechanism to fully utilize the semantic correlation between slot and intent Our model first obtains intentaugmented embeddings based on neural network with selfattention mechanism And then the intent semantic representation is utilized as the gate for labelling slot tags The objectives of both tasks are optimized simultaneously via joint learning in an endtoend way We conduct experiment on popular benchmark ATIS The results show that our model achieves stateoftheart and outperforms other popular methods by a large margin in terms of both intent detection error rate and slot filling F1score This paper gives a new perspective for research on SLU",
        "A1": "gives a new perspective for research on SLU",
        "A2": "Spoken Language Understanding SLU",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "by a large margin in terms of both intent detection error rate and slot filling F1score ",
        "A7": "popular benchmark ATIS",
        "A83": "",
        "A82": " outperforms other popular methods",
        "A81": "achieves stateoftheart",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "fully utilize the semantic correlation between slot and intent",
        "A52": "neural network with selfattention mechanism",
        "A42": "a novel selfattentive model with gate mechanism to fully utilize the semantic correlation between slot and intent",
        "A45": "",
        "am_id": 24037648
    },
    {
        "Abstract": "In a dialog there can be multiple valid next utterances at any point The present endtoend neural methods for dialog do not take this into account They learn with the assumption that at any time there is only one correct next utterance In this work we focus on this problem in the goaloriented dialog setting where there are different paths to reach a goal We propose a new method that uses a combination of supervised learning and reinforcement learning approaches to address this issue We also propose a new and more effective testbed permutedbAbI dialog tasks 1 by introducing multiple valid next utterances to the originalbAbI dialog tasks which allows evaluation of goaloriented dialog systems in a more realistic setting We show that there is a significant drop in performance of existing endtoend neural methods from 815 perdialog accuracy on originalbAbI dialog tasks to 303 on permutedbAbI dialog tasks We also show that our proposed method improves the performance and achieves 473 perdialog accuracy on permutedbAbI dialog tasks Equal Contribution 1permutedbAbIdialogtasks  httpsgithub comIBMpermutedbAbIdialogtasks",
        "A1": "improves the performance",
        "A2": "allows evaluation of goaloriented dialog systems in a more realistic setting ",
        "A41": "a new method that uses a combination of supervised learning and reinforcement learning approaches",
        "A51": "supervised learning and reinforcement learning",
        "A61": "in a more realistic setting",
        "A10": "improves the performance and achieves 473 perdialog accuracy on permutedbAbI dialog tasks",
        "A7": " permutedbAbI dialog tasks 1 ",
        "A83": "",
        "A82": " our proposed method improves the performance and achieves 473 perdialog accuracy on permutedbAbI dialog tasks",
        "A81": "here is a significant drop in performance of existing endtoend neural methods from 815 perdialog accuracy on originalbAbI dialog tasks to 303 on permutedbAbI dialog tasks ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 113001319
    },
    {
        "Abstract": "In this paper we introduce Iterative Text Summarization ITS an iterationbased model for supervised extractive text summarization inspired by the observation that it is often necessary for a human to read an article multiple times in order to fully understand and summarize its contents Current summarization approaches read through a document only once to generate a document representation resulting in a suboptimal representation To address this issue we introduce a model which iteratively polishes the document representation on many passes through the document As part of our model we also introduce a selective reading mechanism that decides more accurately the extent to which each sentence in the model should be updated Experimental results on the CNNDailyMail and DUC2002 datasets demonstrate that our model significantly outperforms stateoftheart extractive systems when evaluated by machines and by humans",
        "A1": "introduce Iterative Text Summarization ITS",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "our model significantly outperforms stateoftheart extractive systems when evaluated by machines and by humans",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "iteratively polishes the document representation on many passes through the document ",
        "A52": " iterationbased",
        "A42": "an iterationbased model for supervised extractive text summarization",
        "A45": "",
        "am_id": 109869670
    },
    {
        "Abstract": "We propose a method to perform automatic document summarisation without using reference summaries Instead our method interactively learns from users preferences The merit of preferencebased interactive summarisation is that preferences are easier for users to provide than reference summaries Existing preferencebased interactive learning methods suffer from high sample complexity ie they need to interact with the oracle for many rounds in order to converge In this work we propose a new objective function which enables us to leverage active learning preference learning and reinforcement learning techniques in order to reduce the sample complexity Both simulation and realuser experiments suggest that our method significantly advances the state of the art Our source code is freely available at httpsgithubcomUKPLab emnlp2018april",
        "A1": "We propose a method to perform automatic document summarisation without using reference summaries ",
        "A2": "We propose a method to perform automatic document summarisation without using reference summaries ",
        "A41": "We propose a method to perform automatic document summarisation without using reference summaries ",
        "A51": "interactively learns from users preferences",
        "A61": "interactively learns from users preferences",
        "A10": "We propose a method to perform automatic document summarisation without using reference summaries Instead our method interactively learns from users preferences ",
        "A7": "Both simulation and realuser experiments",
        "A83": "",
        "A82": "",
        "A81": "our method significantly advances the state of the art",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 191796993
    },
    {
        "Abstract": "This paper tackles automation of the pyramid method a reliable manual evaluation framework To construct a pyramid we transform humanmade reference summaries into extractive reference summaries that consist of Elementary Discourse Units EDUs obtained from source documents and then weight every EDU by counting the number of extractive reference summaries that contain the EDU A summary is scored by the correspondences between EDUs in the summary and those in the pyramid Experiments on DUC and TAC data sets show that our methods strongly correlate with various manual evaluations",
        "A1": "tackles automation of the pyramid method a reliable manual evaluation framework ",
        "A2": "automation of the pyramid method",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "automation",
        "A7": " Experiments on DUC and TAC data sets ",
        "A83": "",
        "A82": "",
        "A81": "our methods strongly correlate with various manual evaluations",
        "A64": "",
        "A54": "",
        "A44": "a reliable manual evaluation framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 218644286
    },
    {
        "Abstract": "Recently there has been a surge of interest in reading comprehensionbased RC question answering QA However current approaches suffer from an impractical assumption that every question has a valid answer in the associated passage A practical QA system must possess the ability to determine whether a valid answer exists in a given text passage In this paper we focus on developing QA systems that can extract an answer for a question if and only if the associated passage contains an answer If the associated passage does not contain any valid answer the QA system will correctly return Nil We propose a nilaware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step We show that our proposed framework can be easily integrated with several recently proposed QA models developed for reading comprehension and can be trained in an endtoend fashion Our proposed nilaware answer extraction neural network decomposes pieces of evidence into relevant and irrelevant parts and then combines them to infer the existence of any answer Experiments on the NewsQA dataset show that the integration of our proposed framework significantly outperforms several strong baseline systems that use pipeline or thresholdbased approaches",
        "A1": "propose a nilaware answer span extraction framework",
        "A2": "returning Nil or a text span from the associated passage as an answer in a single step",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significantly outperforms several strong baseline systems that use pipeline or thresholdbased approaches",
        "A7": "Experiments on the NewsQA dataset",
        "A83": "",
        "A82": "can be trained in an endtoend fashion",
        "A81": "our proposed framework can be easily integrated with several recently proposed QA models developed for reading comprehension",
        "A64": "",
        "A54": "nilaware answer span extraction",
        "A44": "a nilaware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 499161614
    },
    {
        "Abstract": "Narrative story generation is a challenging problem because it demands the generated sentences with tight semantic connections which has not been well studied by most existing generative models To address this problem we propose a skeletonbased model to promote the coherence of generated stories Different from traditional models that generate a complete sentence at a stroke the proposed model first generates the most critical phrases called skeleton and then expands the skeleton to a complete and fluent sentence The skeleton is not manually defined but learned by a reinforcement learning method Compared to the stateoftheart models our skeletonbased model can generate significantly more coherent text according to human evaluation and automatic evaluation The Gscore is improved by 201 in human evaluation1",
        "A1": "propose a skeletonbased model",
        "A2": "Narrative story generation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "generate significantly more coherent text according to human evaluation and automatic evaluation ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "first generates the most critical phrases called skeleton and then expands the skeleton to a complete and fluent sentence",
        "A52": "skeleton",
        "A42": "promote the coherence of generated stories",
        "A45": "",
        "am_id": 358425645
    },
    {
        "Abstract": "In order to learn universal sentence representations previous methods focus on complex recurrent neural networks or supervised learning In this paper we propose a meanmax attention autoencoder meanmax AAE within the encoderdecoder framework Our autoencoder rely entirely on the MultiHead selfattention mechanism to reconstruct the input sequence In the encoding we propose a meanmax strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input To enable the information to steer the reconstruction process dynamically the decoder performs attention over the meanmax representation By training our model on a large collection of unlabelled data we obtain highquality representations of sentences Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the stateoftheart unsupervised single methods including the classical skipthoughts Kiros et al 2015 and the advanced skipthoughtsLN model Ba et al 2016 Furthermore compared with the traditional recurrent neural network our meanmax AAE greatly reduce the training time 1",
        "A1": "propose a meanmax attention autoencoder meanmax AAE within the encoderdecoder framework Our autoencoder rely entirely on the MultiHead selfattention mechanism to reconstruct the input sequence",
        "A2": " to learn universal sentence representations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our model outperforms the stateoftheart unsupervised single methods including the classical skipthoughts Kiros et al 2015 and the advanced skipthoughtsLN model Ba et al 2016",
        "A7": " training our model on a large collection of unlabelled data we obtain highquality representations of sentences Experimental results on a broad range of 10 transfer tasks",
        "A83": "",
        "A82": "compared with the traditional recurrent neural network our meanmax AAE greatly reduce the training time",
        "A81": "our model outperforms the stateoftheart unsupervised single methods including the classical skipthoughts Kiros et al 2015 and the advanced skipthoughtsLN model Ba et al 2016",
        "A64": "",
        "A54": "the MultiHead selfattention mechanism",
        "A44": "a meanmax attention autoencoder meanmax AAE within the encoderdecoder framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 289882707
    },
    {
        "Abstract": "Recent work has shown that recurrent neural networks RNNs can implicitly capture and exploit hierarchical information when trained to solve common natural language processing tasks Blevins et al 2018 such as language modeling Linzen et al 2016 Gulordava et al 2018 and neural machine translation Shi et al 2016 In contrast the ability to model structured data with nonrecurrent neural networks has received little attention despite their success in many NLP tasks Gehring et al 2017 Vaswani et al 2017 In this work we compare the two architecturesrecurrent versus nonrecurrentwith respect to their ability to model hierarchical structure and find that recurrency is indeed important for this purpose The code and data used in our experiments is available at httpsgithubcom ketranmfanvsrnn",
        "A1": " compare the two architecturesrecurrent versus nonrecurrentwith",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "compare the two architecturesrecurrent versus nonrecurrentwith respect to their ability to model hierarchical structure",
        "A83": "",
        "A82": "",
        "A81": "recurrency is indeed important",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "RNNs",
        "A45": "",
        "am_id": 348999477
    },
    {
        "Abstract": "Computational detection and understanding of empathy is an important factor in advancing humancomputer interaction Yet to date textbased empathy prediction has the following major limitations It underestimates the psychological complexity of the phenomenon adheres to a weak notion of ground truth where empathic states are ascribed by third parties and lacks a shared corpus In contrast this contribution presents the first publicly available gold standard for empathy prediction It is constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using multiitem scales This is also the first computational work distinguishing between multiple forms of empathy empathic concern and personal distress as recognized throughout psychology Finally we present experimental results for three different predictive models of which a CNN performs the best",
        "A1": "",
        "A2": " presents the first publicly available gold standard for empathy prediction",
        "A41": " reliably captures empathy assessments by the writer of a statement using multiitem scales",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " a CNN performs the best",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " three different predictive models",
        "A45": "",
        "am_id": 65910614
    },
    {
        "Abstract": "We compare the performance of the APT and AutoPRF metrics for pronoun translation against a manually annotated dataset comprising human judgements as to the correctness of translations of the PROTEST test suite Although there is some correlation with the human judgements a range of issues limit the performance of the automated metrics Instead we recommend the use of semiautomatic metrics and test suites in place of fully automatic metrics",
        "A1": " to the correctness of translations of the PROTEST test suite ",
        "A2": "a range of issues limit the performance of the automated metrics Instead",
        "A41": "use of semiautomatic metrics and test suites in place",
        "A51": "compare the performance of the APT and AutoPRF metrics ",
        "A61": "to the correctness of translations of the PROTEST test suite",
        "A10": " use of semiautomatic metrics and test suites in place of fully automatic metrics",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " use of semiautomatic metrics and test suites in place of fully automatic metrics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 112409338
    },
    {
        "Abstract": "Research on link prediction in knowledge graphs has mainly focused on static multirelational data In this work we consider temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time In line with previous work on static knowledge graphs we propose to address this problem by learning latent entity and relation type representations To incorporate temporal information we utilize recurrent neural networks to learn timeaware representations of relation types which can be used in conjunction with existing latent factorization methods The proposed approach is shown to be robust to common challenges in realworld KGs the sparsity and heterogeneity of temporal expressions Experiments show the benefits of our approach on four temporal KGs The data sets are available under a permissive BSD3 license1 Work done while interning at NEC Labs Europe 1httpsgithubcomnlemlmmkb",
        "A1": "temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time",
        "A2": "Research on link prediction in knowledge graphs has mainly focused on static multirelational data",
        "A41": "learning latent entity and relation type representations",
        "A51": "recurrent neural networks",
        "A61": "timeaware representations of relation types",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "the benefits of our approach on four temporal KGs",
        "A81": "The proposed approach is shown to be robust to common challenges in realworld KGs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 218477196
    },
    {
        "Abstract": "This paper addresses the problem of representation learning Using an autoencoder framework we propose and evaluate several loss functions that can be used as an alternative to the commonly used crossentropy reconstruction loss The proposed loss functions use similarities between words in the embedding space and can be used to train any neural model for text generation We show that the introduced loss functions amplify semantic diversity of reconstructed sentences while preserving the original meaning of the input We test the derived autoencodergenerated representations on paraphrase detection and language inference tasks and demonstrate performance improvement compared to the traditional crossentropy loss",
        "A1": "representation learning",
        "A2": "The proposed loss functions use similarities between words in the embedding space and can be used to train any neural model for text generation ",
        "A41": " loss functions use similarities between words in the embedding space",
        "A51": "autoencoder",
        "A61": "",
        "A10": " performance improvement compared to the traditional crossentropy loss",
        "A7": "paraphrase detection and language inference tasks",
        "A83": "",
        "A82": "amplify semantic diversity of reconstructed sentences while preserving the original meaning of the input",
        "A81": "performance improvement compared to the traditional crossentropy loss",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 483099045
    },
    {
        "Abstract": "In Sanskrit small words morphemes are combined to form compound words through a process known as Sandhi Sandhi splitting is the process of splitting a given compound word into its constituent morphemes Although rules governing word splitting exists in the language it is highly challenging to identify the location of the splits in a compound word Though existing Sandhi splitting systems incorporate these predefined splitting rules they have a low accuracy as the same compound word might be broken down in multiple ways to provide syntactically correct splits In this research we propose a novel deep learning architecture called Double Decoder RNN DDRNN which i predicts the location of the splits with 95 accuracy and ii predicts the constituent words learning the Sandhi splitting rules with 795 accuracy outperforming the stateofart by 20 Additionally we show the generalization capability of our deep learning model by showing competitive results in the problem of Chinese word segmentation as well",
        "A1": " we propose a novel deep learning architecture called Double Decoder RNN DDRNN ",
        "A2": "Though existing Sandhi splitting systems incorporate these predefined splitting rules they have a low accuracy as the same compound word might be broken down in multiple ways to provide syntactically correct splits",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "predicts the constituent words learning the Sandhi splitting rules with 795 accuracy outperforming the stateofart by 20",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "predicts the constituent words learning the Sandhi splitting rules with 795 accuracy outperforming the stateofart by 20",
        "A54": "",
        "A44": "i predicts the location of the splits with 95 accuracy and ii predicts the constituent words learning the Sandhi splitting rules with 795 accuracy outperforming the stateofart by 20",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 223427103
    },
    {
        "Abstract": "Slot filling aims to extract the values slot fillers  of specific attributes slots types for a given entity query from a largescale corpus Slot filling remains very challenging over the past seven years We propose a simple yet effective unsupervised approach to extract slot fillers based on the following two observations 1 a trigger is usually a salient node relative to the query and filler nodes in the dependency graph of a context sentence 2 a relation is likely to exist if the query and candidate filler nodes are strongly connected by a relationspecific trigger Thus we design a graphbased algorithm to automatically identify triggers based on personalized PageRank and Affinity Propagation for a given query filler  pair and then label the slot type based on the identified triggers Our approach achieves 11625 higher Fscore over stateoftheart English slot filling methods Our experiments also demonstrate that as long as a few trigger seeds name tagging and dependency parsing capabilities exist this approach can be quickly adapted to any language and new slot types Our promising results on Chinese slot filling can serve as a new benchmark",
        "A1": " We propose a simple yet effective unsupervised approach to extract slot fillers based on the following two observations",
        "A2": "Slot filling aims to extract the values slot fillers  of specific attributes slots types for a given entity query from a largescale corpus Slot filling remains very challenging over the past seven years ",
        "A41": "to extract slot fillers based on the following two observations",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on Chinese slot filling",
        "A83": "",
        "A82": "",
        "A81": "Our promising results on Chinese slot filling can serve as a new benchmark",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 263099228
    },
    {
        "Abstract": "One major drawback of phrasebased translation is that it segments an input sentence into continuous phrases To support linguistically informed source discontinuity in this paper we construct graphs which combine bigram and dependency relations and propose a graphbased translation model The model segments an input graph into connected subgraphs each of which may cover a discontinuous phrase We use beam search to combine translations of each subgraph lefttoright to produce a complete translation Experiments on ChineseEnglish and GermanEnglish tasks show that our system is significantly better than the phrasebased model by up to 1505 BLEU scores By explicitly modeling the graph segmentation our system obtains further improvement especially on GermanEnglish",
        "A1": "To support linguistically informed source discontinuity",
        "A2": "One major drawback of phrasebased translation is that it segments an input sentence into continuous phrases",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " better than the phrasebased model by up to 1505 BLEU scores",
        "A7": "Experiments on ChineseEnglish and GermanEnglish tasks",
        "A83": "",
        "A82": "",
        "A81": "our system is significantly better than the phrasebased model by up to 1505 BLEU scores",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " graphs which combine bigram and dependency relations",
        "A42": "a graphbased translation model ",
        "A45": "",
        "am_id": 456790504
    },
    {
        "Abstract": "We present a novel dependency parsing method which enforces two structural properties on dependency trees bounded block degree and wellnestedness These properties are useful to better represent the set of admissible dependency structures in treebanks and connect dependency parsing to contextsensitive grammatical formalisms We cast this problem as an Integer Linear Program that we solve with Lagrangian Relaxation from which we derive a heuristic and an exact method based on a BranchandBound search Experimentally we see that these methods are efficient and competitive compared to a baseline unconstrained parser while enforcing structural properties in all cases",
        "A1": "present a novel dependency parsing method which enforces two structural properties on dependency trees bounded block degree and wellnestedness",
        "A2": "better represent the set of admissible dependency structures in treebanks and connect dependency parsing to contextsensitive grammatical formalisms",
        "A41": "a novel dependency parsing method which enforces two structural properties on dependency trees bounded block degree and wellnestedness",
        "A51": "a BranchandBound search",
        "A61": "these methods are efficient and competitive",
        "A10": "these methods are efficient and competitive",
        "A7": " compared to a baseline unconstrained parser while enforcing structural properties in all cases",
        "A83": "",
        "A82": "",
        "A81": "these methods are efficient and competitive",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 456076130
    },
    {
        "Abstract": "Graphemetophoneme g2p models are rarely available in lowresource languages as the creation of training and evaluation data is expensive and timeconsuming We use Wiktionary to obtain more than 650k wordpronunciation pairs in more than 500 languages We then develop phoneme and language distance metrics based on phonological and linguistic knowledge applying those we adapt g2p models for highresource languages to create models for related lowresource languages We provide results for models for 229 adapted languages",
        "A1": "We then develop phoneme and language distance metrics based on phonological and linguistic knowledge applying those we adapt g2p models for highresource languages to create models for related lowresource languages",
        "A2": "Graphemetophoneme g2p models are rarely available in lowresource languages",
        "A41": "We then develop phoneme and language distance metrics based on phonological and linguistic knowledge applying those we adapt g2p models for highresource languages to create models for related lowresource languages",
        "A51": "Graphemetophoneme g2p models",
        "A61": "We provide results for models for 229 adapted languages",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We provide results for models for 229 adapted languages",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 455328220
    },
    {
        "Abstract": "Question answering requires access to a knowledge base to check facts and reason about information Knowledge in the form of natural language text is easy to acquire but difficult for automated reasoning Highlystructured knowledge bases can facilitate reasoning but are difficult to acquire In this paper we explore tables as a semistructured formalism that provides a balanced compromise to this tradeoff We first use the structure of tables to guide the construction of a dataset of over 9000 multiplechoice questions with rich alignment annotations easily and efficiently via crowdsourcing We then use this annotated data to train a semistructured featuredriven model for question answering that uses tables as a knowledge base In benchmark evaluations we significantly outperform both a strong unstructured retrieval baseline and a highlystructured Markov Logic Network model",
        "A1": "explore tables as a semistructured formalism that provides a balanced compromise to this tradeoff",
        "A2": "Knowledge in the form of natural language text is easy to acquire but difficult for automated reasoning Highlystructured knowledge bases can facilitate reasoning but are difficult to acquire",
        "A41": "tables as a semistructured formalism",
        "A51": "tables as a semistructured formalism",
        "A61": "",
        "A10": "outperform both a strong unstructured retrieval baseline and a highlystructured Markov Logic Network model",
        "A7": "benchmark evaluation",
        "A83": "",
        "A82": "",
        "A81": "outperform both a strong unstructured retrieval baseline and a highlystructured Markov Logic Network model",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 78116547
    },
    {
        "Abstract": "A major challenge of semantic parsing is the vocabulary mismatch problem between natural language and target ontology In this paper we propose a sentence rewriting based semantic parsing method which can effectively resolve the mismatch problem by rewriting a sentence into a new form which has the same structure with its target logical form Specifically we propose two sentencerewriting methods for two common types of mismatch a dictionarybased method for 1N mismatch and a templatebased method for N1 mismatch We evaluate our sentence rewriting based semantic parser on the benchmark semantic parsing dataset WEBQUESTIONS Experimental results show that our system outperforms the base system with a 34 gain in F1 and generates logical forms more accurately and parses sentences more robustly",
        "A1": " propose a sentence rewriting based semantic parsing method",
        "A2": "vocabulary mismatch problem between natural language and target ontology",
        "A41": " a sentence rewriting based semantic parsing method",
        "A51": "semantic parsing method",
        "A61": "effectively resolve the mismatch problem by rewriting a sentence into a new form which has the same structure with its target logical form ",
        "A10": "with a 34 gain in F1",
        "A7": " We evaluate our sentence rewriting based semantic parser on the benchmark semantic parsing dataset WEBQUESTIONS",
        "A83": "",
        "A82": "generates logical forms more accurately and parses sentences more robustly",
        "A81": "our system outperforms the base system with a 34 gain in F1",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 243213858
    },
    {
        "Abstract": "We prove that loglinearly interpolated backoff language models can be efficiently and exactly collapsed into a single normalized backoff model contradicting Hsu 2007 While prior work reported that loglinear interpolation yields lower perplexity than linear interpolation normalizing at query time was impractical We normalize the model offline in advance which is efficient due to a recurrence relationship between the normalizing factors To tune interpolation weights we apply Newtons method to this convex problem and show that the derivatives can be computed efficiently in a batch process These findings are combined in new opensource interpolation tool which is distributed with KenLM With 21 outofdomain corpora loglinear interpolation yields 7258 perplexity on TED talks compared to 7591 for linear interpolation",
        "A1": "We prove that loglinearly interpolated backoff language models can be efficiently and exactly collapsed into a single normalized backoff model contradicting Hsu 2007",
        "A2": "We prove that loglinearly interpolated backoff language models can be efficiently and exactly collapsed into a single normalized backoff model contradicting Hsu 2007",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " that the derivatives can be computed efficiently in a batch process",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " We normalize the model offline in advance which is efficient due to a recurrence relationship between the normalizing factors",
        "A52": "",
        "A42": "loglinearly interpolated backoff language models",
        "A45": "",
        "am_id": 443638811
    },
    {
        "Abstract": "Several large clozestyle contextquestionanswer datasets have been introduced recently the CNN and Daily Mail news data and the Childrens Book Test Thanks to the size of these datasets the associated text comprehension task is well suited for deeplearning techniques that currently seem to outperform all alternative approaches We present a new simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document as is usual in similar models This makes the model particularly suitable for questionanswering problems where the answer is a single word from the document Ensemble of our models sets new state of the art on all evaluated datasets",
        "A1": "present a new simple model that uses attention to directly pick the answer from the context",
        "A2": "model that uses attention to directly pick the answer from the context",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document as is usual in similar models",
        "A52": "Several large clozestyle contextquestionanswer datasets",
        "A42": "a new simple model that uses attention to directly pick the answer from the context as opposed to computing the answer using a blended representation of words in the document",
        "A45": "",
        "am_id": 48083976
    },
    {
        "Abstract": "Lexicosemantic knowledge of our native language provides an initial foundation for second language learning In this paper we investigate whether and to what extent the lexicosemantic models of the native language L1 are transferred to the second language L2 Specifically we focus on the problem of lexical choice and investigate it in the context of three typologically diverse languages Russian Spanish and English We show that a statistical semantic model learned from L1 data improves automatic error detection in L2 for the speakers of the respective L1 Finally we investigate whether the semantic model learned from a particular L1 is portable to other typologically related languages",
        "A1": "we investigate whether and to what extent the lexicosemantic models of the native language L1 are transferred to the second language L2",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "investigate it in the context of three typologically diverse languages Russian Spanish and English ",
        "A83": "",
        "A82": "",
        "A81": "We show that a statistical semantic model learned from L1 data improves automatic error detection in L2 for the speakers of the respective L1",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "lexicosemantic models of the native language L1",
        "A45": "",
        "am_id": 244685039
    },
    {
        "Abstract": "Context is crucial for identifying argumentative relations in text but many argument mining methods make little use of contextual features This paper presents contextaware argumentative relation mining that uses features extracted from writing topics as well as from windows of context sentences Experiments on student essays demonstrate that the proposed features improve predictive performance in two argumentative relation classification tasks",
        "A1": " identifying argumentative relations ",
        "A2": "uses features extracted from writing topics as well as from windows of context sentences",
        "A41": "contextaware argumentative relation mining that uses features extracted from writing topics as well as from windows of context sentences",
        "A51": "",
        "A61": " use of contextual features",
        "A10": "proposed features improve predictive performance in two argumentative relation classification tasks",
        "A7": "Experiments on student essays ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 155627272
    },
    {
        "Abstract": "A key goal in natural language generation NLG is to enable fast generation even with large vocabularies grammars and worlds In this work we build upon a recently proposed NLG system Sentence Tree Realization with UCT STRUCT We describe four enhancements to this system i pruning the grammar based on the world and the communicative goal ii intelligently caching and pruning the combinatorial space of semantic bindings iii reusing the lookahead search tree at different search depths and iv learning and using a search control heuristic We evaluate the resulting system on three datasets of increasing size and complexity the largest of which has a vocabulary of about 10K words a grammar of about 32K lexicalized trees and a world with about 11K entities and 23K relations between them Our results show that the system has a median generation time of 85s and finds the best sentence on average within 25s These results are based on a sequential interpreted implementation and are significantly better than the state of the art for planningbased NLG systems",
        "A1": "We describe four enhancements to this system i pruning the grammar based on the world and the communicative goal ii intelligently caching and pruning the combinatorial space of semantic bindings iii reusing the lookahead search tree at different search depths and iv learning and using a search control heuristic",
        "A2": "to enable fast generation even with large vocabularies grammars and worlds In this work we build upon a recently proposed NLG system Sentence Tree Realization with UCT STRUCT",
        "A41": "i pruning the grammar based on the world and the communicative goal ii intelligently caching and pruning the combinatorial space of semantic bindings iii reusing the lookahead search tree at different search depths and iv learning and using a search control heuristic ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "These results are based on a sequential interpreted implementation and are significantly better than the state of the art for planningbased NLG systems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 52164418
    },
    {
        "Abstract": "Attention based recurrent neural networks have shown advantages in representing natural language sentences Hermann et al 2015 Rocktaschel et al 2015 Tan et al 2015 Based on recurrent neural networks RNN external attention information was added to hidden representations to get an attentive sentence representation Despite the improvement over nonattentive models the attention mechanism under RNN is not well studied In this work we analyze the deficiency of traditional attention based RNN models quantitatively and qualitatively Then we present three new RNN models that add attention information before RNN hidden representation which shows advantage in representing sentence and achieves new stateofart results in answer selection task",
        "A1": "we present three new RNN models that add attention information before RNN hidden representation",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " achieves new stateofart results in answer selection task",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " achieves new stateofart results in answer selection task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "add attention information before RNN hidden representation which shows advantage in representing sentence",
        "A52": "Attention based recurrent neural networks ",
        "A42": "we present three new RNN models that add attention information before RNN hidden representation",
        "A45": "",
        "am_id": 426745857
    },
    {
        "Abstract": "Knowledge bases KBs are often greatly incomplete necessitating a demand for KB completion The path ranking algorithm PRA is one of the most promising approaches to this task Previous work on PRA usually follows a singletask learning paradigm building a prediction model for each relation independently with its own training data It ignores meaningful associations among certain relations and might not get enough training data for less frequent relations This paper proposes a novel multitask learning framework for PRA referred to as coupled PRA CPRA It first devises an agglomerative clustering strategy to automatically discover relations that are highly correlated to each other and then employs a multitask learning strategy to effectively couple the prediction of such relations As such CPRA takes into account relation association and enables implicit data sharing among them We empirically evaluate CPRA on benchmark data created from Freebase Experimental results show that CPRA can effectively identify coherent clusters in which relations are highly correlated By further coupling such relations CPRA significantly outperforms PRA in terms of both predictive accuracy and model interpretability",
        "A1": "",
        "A2": "Knowledge bases KBs are often greatly incomplete necessitating a demand for KB completion The path ranking algorithm PRA is one of the most promising approaches to this task Previous work on PRA usually follows a singletask learning paradigm building a prediction model for each relation independently with its own training data It ignores meaningful associations among certain relations and might not get enough training data for less frequent relations ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "CPRA significantly outperforms PRA in terms of both predictive accuracy and model interpretability",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "CPRA can effectively identify coherent clusters in which relations are highly correlated By further coupling such relations",
        "A64": "",
        "A54": "",
        "A44": "a novel multitask learning framework for PRA referred to as coupled PRA CPRA",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 169712768
    },
    {
        "Abstract": "Word embeddings  distributed representations of words  in deep learning are beneficial for many tasks in NLP However different embedding sets vary greatly in quality and characteristics of the captured information Instead of relying on a more advanced algorithm for embedding learning this paper proposes an ensemble approach of combining different public embedding sets with the aim of learning metaembeddings Experiments on word similarity and analogy tasks and on partofspeech tagging show better performance of metaembeddings compared to individual embedding sets One advantage of metaembeddings is the increased vocabulary coverage We release our metaembeddings publicly at http cisterncislmudemetaemb",
        "A1": "proposes an ensemble approach of combining different public embedding sets with the aim of learning metaembeddings",
        "A2": "different embedding sets vary greatly in quality and characteristics of the captured information",
        "A41": " an ensemble approach of combining different public embedding sets",
        "A51": "",
        "A61": "",
        "A10": "One advantage of metaembeddings is the increased vocabulary coverage",
        "A7": "xperiments on word similarity and analogy tasks and on partofspeech tagging",
        "A83": "",
        "A82": "",
        "A81": "show better performance of metaembeddings compared to individual embedding sets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 335565900
    },
    {
        "Abstract": "Most of the sequence tagging tasks in natural language processing require to recognize segments with certain syntactic role or semantic meaning in a sentence They are usually tackled with Conditional Random Fields CRFs which do indirect wordlevel modeling over wordlevel features and thus cannot make full use of segmentlevel information SemiMarkov Conditional Random Fields SemiCRFs model segments directly but extracting segmentlevel features for SemiCRFs is still a very challenging problem This paper presents Gated Recursive SemiCRFs grSemiCRFs which model segments directly and automatically learn segmentlevel features through a gated recursive convolutional neural network Our experiments on text chunking and named entity recognition NER demonstrate that grSemiCRFs generally outperform other neural models",
        "A1": "This paper presents Gated Recursive SemiCRFs grSemiCRFs which model segments directly and automatically learn segmentlevel features through a gated recursive convolutional neural network Our experiments on text chunking and named entity recognition NER demonstrate that grSemiCRFs generally outperform other neural models",
        "A2": "Most of the sequence tagging tasks in natural language processing require to recognize segments with certain syntactic role or semantic meaning in a sentence They are usually tackled with Conditional Random Fields CRFs which do indirect wordlevel modeling over wordlevel features and thus cannot make full use of segmentlevel information SemiMarkov Conditional Random Fields SemiCRFs model segments directly but extracting segmentlevel features for SemiCRFs is still a very challenging problem",
        "A41": "Gated Recursive SemiCRFs grSemiCRFs ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on text chunking and named entity recognition NER",
        "A83": "",
        "A82": "",
        "A81": "grSemiCRFs generally outperform other neural models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 414505044
    },
    {
        "Abstract": "We introduce LAMBADA a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage but not if they only see the last sentence preceding the target word To succeed on LAMBADA computational models cannot simply rely on local context but must be able to keep track of information in the broader discourse We show that LAMBADA exemplifies a wide range of linguistic phenomena and that none of several stateoftheart language models reaches accuracy above 1 on this novel benchmark We thus propose LAMBADA as a challenging test set meant to encourage the development of new models capable of genuine understanding of broad context in natural language text",
        "A1": "ntroduce LAMBADA a dataset to evaluate the capabilities of computational models",
        "A2": "LAMBADA exemplifies a wide range of linguistic phenomena and that none of several stateoftheart language models reaches accuracy above 1 on this novel benchmark",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "by means of a word prediction task",
        "A83": "",
        "A82": " none of several stateoftheart language models reaches accuracy above 1 on this novel benchmark",
        "A81": "LAMBADA exemplifies a wide range of linguistic phenomena",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage but not if they only see the last sentence preceding the target word",
        "am_id": 53366716
    },
    {
        "Abstract": "We examine communications in a social network to study user emotional contrast  the propensity of users to express different emotions than those expressed by their neighbors Our analysis is based on a large Twitter dataset consisting of the tweets of 123513 users from the USA and Canada Focusing on Ekmans basic emotions we analyze differences between the emotional tone expressed by these users and their neighbors of different types and correlate these differences with perceived user demographics We demonstrate that many perceived demographic traits correlate with the emotional contrast between users and their neighbors Unlike other approaches on inferring user attributes that rely solely on user communications we explore the network structure and show that it is possible to accurately predict a range of perceived demographic traits based solely on the emotions emanating from users and their neighbors",
        "A1": "We examine communications in a social network to study user emotional contrast  the propensity of users to express different emotions than those expressed by their neighbors",
        "A2": "Our analysis is based on a large Twitter dataset consisting of the tweets of 123513 users from the USA and Canada Focusing on Ekmans basic emotions we analyze differences between the emotional tone expressed by these users ",
        "A41": "Canada Focusing on Ekmans basic emotions we analyze differences between the emotional tone expressed by these users and their neighbors of di",
        "A51": "We demonstrate that many perceived demographic traits correlate with the emotional contrast between users and their neighbors",
        "A61": "Unlike other approaches on inferring user attributes that rely solely on user communications",
        "A10": "",
        "A7": "Unlike other approaches on inferring user attributes that rely solely on user communications we explore the network structure and show that it is possible to accurately predict a range of perceived demographic traits based solely on the emotions emanating from users and their neighbors",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 72639414
    },
    {
        "Abstract": "Languages with rich inflectional morphology exhibit lexical data sparsity since the word used to express a given concept will vary with the syntactic context For instance each count noun in Czech has 12 forms where English uses only singular and plural Even in large corpora we are unlikely to observe all inflections of a given lemma This reduces the vocabulary coverage of methods that induce continuous representations for words from distributional corpus information We solve this problem by exploiting existing morphological resources that can enumerate a words component morphemes We present a latentvariable Gaussian graphical model that allows us to extrapolate continuous representations for words not observed in the training corpus as well as smoothing the representations provided for the observed words The latent variables represent embeddings of morphemes which combine to create embeddings of words Over several languages and training sizes our model improves the embeddings for words when evaluated on an analogy task skipgram predictive accuracy and word similarity",
        "A1": "Languages with rich inflectional morphology exhibit lexical data sparsity since the word used to express a given concept will vary with the syntactic context",
        "A2": "Languages with rich inflectional morphology exhibit lexical data sparsity since the word used to express a given concept will vary with the syntactic context",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "s Over several languages and training sizes our model improves the embeddings for words when evaluated on an analogy task skipgram predictive accuracy and word similarity",
        "A7": " The latent variables represent embeddings of morphemes which combine to create embeddings of words",
        "A83": "s Over several languages and training sizes our model improves the embeddings for words when evaluated on an analogy task skipgram predictive accuracy and word similarity",
        "A82": "",
        "A81": "s Over several languages and training sizes our model improves the embeddings for words when evaluated on an analogy task skipgram predictive accuracy and word similarity",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "We solve this problem by exploiting existing morphological resources that can enumerate a words component morphemes ",
        "A62": "s We present a latentvariable Gaussian graphical model that allows us to extrapolate continuous representations for words not observed in the training corpus as well as smoothing the representations provided for the observed words ",
        "A52": "s We present a latentvariable Gaussian graphical model that allows us to extrapolate continuous representations for words not observed in the training corpus as well as smoothing the representations provided for the observed words ",
        "A42": "We solve this problem by exploiting existing morphological resources that can enumerate a words component morphemes ",
        "A45": "",
        "am_id": 217889490
    },
    {
        "Abstract": "Despite interest in using crosslingual knowledge to learn word embeddings for various tasks a systematic comparison of the possible approaches is lacking in the literature We perform an extensive evaluation of four popular approaches of inducing crosslingual embeddings each requiring a different form of supervision on four typologically different language pairs Our evaluation setup spans four different tasks including intrinsic evaluation on monolingual and crosslingual similarity and extrinsic evaluation on downstream semantic and syntactic applications We show that models which require expensive crosslingual knowledge almost always perform better but cheaply supervised models often prove competitive on certain tasks",
        "A1": "learn word embeddings for various tasks",
        "A2": "a systematic comparison of the possible approaches is lacking in the literature ",
        "A41": "We perform an extensive evaluation of four popular approaches of inducing crosslingual embeddings",
        "A51": "",
        "A61": "setup spans four different tasks including intrinsic evaluation on monolingual and crosslingual similarity and extrinsic evaluation on downstream semantic and syntactic applications",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "cheaply supervised models often prove competitive on certain tasks",
        "A81": "models which require expensive crosslingual knowledge almost always perform",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 453761017
    },
    {
        "Abstract": "Quotation detection is the task of locating spans of quoted speech in text The state of the art treats this problem as a sequence labeling task and employs linearchain conditional random fields We question the efficacy of this choice The Markov assumption in the model prohibits it from making joint decisions about the begin end and internal context of a quotation We perform an extensive analysis with two new model architectures We find that a simple boundary classification combined with a greedy prediction strategy is competitive with the state of the art b a semiMarkov model significantly outperforms all others by relaxing the Markov assumption 1Penn Attributions Relation Corpus PARC wsj 0260",
        "A1": "We question the efficacy of this choice",
        "A2": "We question the efficacy of this choice ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "a simple boundary classification combined with a greedy prediction strategy is competitive with the state of the art b a semiMarkov model significantly outperforms all others by relaxing the Markov assumption ",
        "A52": "the Markov assumption ",
        "A42": "",
        "A45": "",
        "am_id": 475224773
    },
    {
        "Abstract": "This paper describes the first robust approach to automatically labeling clauses with their situation entity type Smith 2003 capturing aspectual phenomena at the clause level which are relevant for interpreting both semantics at the clause level and discourse structure Previous work on this task used a small data set from a limited domain and relied mainly on words as features an approach which is impractical in larger settings We provide a new corpus of texts from 13 genres 40000 clauses annotated with situation entity types We show that our sequence labeling approach using distributional information in the form of Brown clusters as well as syntacticsemantic features targeted to the task is robust across genres reaching accuracies of up to 76",
        "A1": "to automatically labeling clauses with their situation entity type ",
        "A2": "",
        "A41": "rovide a new corpus of texts from 13 genres 40000 clauses annotated with situation entity types",
        "A51": "",
        "A61": "",
        "A10": " reaching accuracies of up to 76",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " reaching accuracies of up to 76",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 125202445
    },
    {
        "Abstract": "There has been an explosion of work in the vision  language community during the past few years from image captioning to video transcription and answering questions about images These tasks have focused on literal descriptions of the image To move beyond the literal we choose to explore how questions about an image are often directed at commonsense inference and the abstract events evoked by objects in the image In this paper we introduce the novel task of Visual Question Generation VQG where the system is tasked with asking a natural and engaging question when shown an image We provide three datasets which cover a variety of images from objectcentric to eventcentric with considerably more abstract training data than provided to stateoftheart captioning systems thus far We train and test several generative and retrieval models to tackle the task of VQG Evaluation results show that while such models ask reasonable questions for a variety of images there is still a wide gap with human performance which motivates further work on connecting images with commonsense knowledge and pragmatics Our proposed task offers a new challenge to the community which we hope furthers interest in exploring deeper connections between vision  language",
        "A1": " explore how questions about an image are often directed at commonsense inference and the abstract events evoked by objects in the image",
        "A2": " These tasks have focused on literal descriptions of the image",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " train and test several generative and retrieval models to tackle the task of VQG ",
        "A83": " offers a new challenge to the community",
        "A82": "there is still a wide gap with human performance ",
        "A81": " such models ask reasonable questions for a variety of images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " three datasets which cover a variety of images from objectcentric to eventcentric with considerably more abstract training data than provided to stateoftheart captioning systems",
        "am_id": 220735967
    },
    {
        "Abstract": "Linguistics studies have shown that action verbs often denote some Change of State CoS as the result of an action However the causality of action verbs and its potential connection with the physical world has not been systematically explored To address this limitation this paper presents a study on physical causality of action verbs and their implied changes in the physical world We first conducted a crowdsourcing experiment and identified eighteen categories of physical causality for action verbs For a subset of these categories we then defined a set of detectors that detect the corresponding change from visual perception of the physical environment We further incorporated physical causality modeling and state detection in grounded language understanding Our empirical studies have demonstrated the effectiveness of causality modeling in grounding language to perception",
        "A1": " this paper presents a study on physical causality of action verbs and their implied changes in the physical world",
        "A2": "However the causality of action verbs and its potential connection with the physical world has not been systematically explored",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We first conducted a crowdsourcing experiment and identified eighteen categories of physical causality for action verbs",
        "A83": "",
        "A82": "",
        "A81": "the effectiveness of causality modeling in grounding language to perception",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 135424529
    },
    {
        "Abstract": "This paper presents a problemreduction approach to extractive multidocument summarization we propose a reduction to the problem of scoring individual sentences with their ROUGE scores based on supervised learning For the summarization we solve an optimization problem where the ROUGE score of the selected summary sentences is maximized To this end we derive an approximation of the ROUGEN score of a set of sentences and define a principled discrete optimization problem for sentence selection Mathematical and empirical evidence suggests that the sentence selection step is solved almost exactly thus reducing the problem to the sentence scoring task We perform a detailed experimental evaluation on two DUC datasets to demonstrate the validity of our approach",
        "A1": "presents a problemreduction approach to extractive multidocument summarization",
        "A2": "an optimization problem where the ROUGE score of the selected summary sentences is maximized",
        "A41": "a reduction to the problem of scoring individual sentences with their ROUGE scores based on supervised learning",
        "A51": "supervised learning",
        "A61": "",
        "A10": "",
        "A7": "a detailed experimental evaluation on two DUC datasets",
        "A83": "",
        "A82": "",
        "A81": "the sentence selection step is solved almost exactly thus reducing the problem to the sentence scoring task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 429431953
    },
    {
        "Abstract": "For many applications the query speed of N gram language models is a computational bottleneck Although massively parallel hardware like GPUs offer a potential solution to this bottleneck exploiting this hardware requires a careful rethinking of basic algorithms and data structures We present the first language model designed for such hardware using Btrees to maximize data parallelism and minimize memory footprint and latency Compared with a singlethreaded instance of KenLM Heafield 2011 a highly optimized CPUbased language model our GPU implementation produces identical results with a smaller memory footprint and a sixfold increase in throughput on a batch query task When we saturate both devices the GPU delivers nearly twice the throughput per hardware dollar even when the CPU implementation uses faster data structures Our implementation is freely available at httpsgithubcomXapaJIaMnugLM",
        "A1": "For many applications the query speed of N gram language models is a computational bottleneck Although massively parallel hardware like GPUs offer a potential solution to this bottleneck exploiting this hardware requires a careful rethinking of basic algorithms and data structures",
        "A2": "We present the first language model designed for such hardware using Btrees to maximize data parallelism and minimize memory footprint and latency Compared with a singlethreaded instance of KenLM Heafield 2011 a highly optimized CPUbased language model",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the GPU delivers nearly twice the throughput per hardware dollar even when the CPU implementation uses faster data structures",
        "A7": "a batch query task",
        "A83": "the GPU delivers nearly twice the throughput per hardware dollar",
        "A82": "a sixfold increase in throughput",
        "A81": "GPU implementation produces identical results with a smaller memory footprint",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "produces identical results with a smaller memory footprint and a sixfold increase in throughput on a batch query task",
        "A52": "Btrees",
        "A42": "the first language model designed for such hardware using Btrees to maximize data parallelism and minimize memory footprint and latency",
        "A45": "",
        "am_id": 140165101
    },
    {
        "Abstract": "We present a discriminative model for singledocument summarization that integrally combines compression and anaphoricity constraints Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus We allow for the deletion of content within a sentence when that deletion is licensed by compression rules in our framework these are implemented as dependencies between subsentential units of text Anaphoricity constraints then improve crosssentence coherence by guaranteeing that for each pronoun included in the summary the pronouns antecedent is included as well or the pronoun is rewritten as a full mention When trained endtoend our final system1 outperforms prior work on both ROUGE as well as on human judgments of linguistic quality",
        "A1": "We present a discriminative model for singledocument summarization",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our final system1 outperforms prior work on both ROUGE as well as on human judgments of linguistic quality",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " based on a rich set of sparse features whose weights are learned on a large corpus",
        "A42": "a discriminative model for singledocument summarization",
        "A45": "",
        "am_id": 245850712
    },
    {
        "Abstract": "Solving simple arithmetic word problems is one of the challenges in Natural Language Understanding This paper presents a novel method to learn to use formulas to solve simple arithmetic word problems Our system analyzes each of the sentences to identify the variables and their attributes and automatically maps this information into a higher level representation It then uses that representation to recognize the presence of a formula along with its associated variables An equation is then generated from the formal description of the formula In the training phase it learns to score the formula variables pair from the systematically generated higher level representation It is able to solve 8607 of the problems in a corpus of standard primary school test questions and beats the stateoftheart by a margin of 807",
        "A1": "",
        "A2": " simple arithmetic word problems",
        "A41": " a novel method to learn to use formulas to solve simple arithmetic word problems",
        "A51": "",
        "A61": "",
        "A10": " beats the stateoftheart by a margin of 807",
        "A7": "standard primary school test questions",
        "A83": "",
        "A82": " beats the stateoftheart by a margin of 807",
        "A81": " It is able to solve 8607 of the problems in a corpus of standard primary school test questions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 122314214
    },
    {
        "Abstract": "Word segmentation is a fundamental task for Chinese language processing However with the successive improvements the standard metric is becoming hard to distinguish stateoftheart word segmentation systems In this paper we propose a new psychometricinspired evaluation metric for Chinese word segmentation which addresses to balance the very skewed word distribution at different levels of difficulty1 The performance on a real evaluation shows that the proposed metric gives more reasonable and distinguishable scores and correlates well with human judgement In addition the proposed metric can be easily extended to evaluate other sequence labelling based NLP tasks",
        "A1": "",
        "A2": "he standard metric is becoming hard to distinguish stateoftheart word segmentation systems",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": " the proposed metric can be easily extended to evaluate other sequence labelling based NLP tasks",
        "A81": " gives more reasonable and distinguishable scores and correlates well with human judgement ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "addresses to balance the very skewed word distribution at different levels of difficulty",
        "A52": "",
        "A42": "new psychometricinspired evaluation metric for Chinese word segmentation ",
        "A45": "",
        "am_id": 463469696
    },
    {
        "Abstract": "Labeling topics learned by topic models is a challenging problem Previous studies have used words phrases and images to label topics In this paper we propose to use text summaries for topic labeling Several sentences are extracted from the most related documents to form the summary for each topic In order to obtain summaries with both high relevance coverage and discrimination for all the topics we propose an algorithm based on submodular optimization Both automatic and manual analysis have been conducted on two real document collections and we find 1 the summaries extracted by our proposed algorithm are superior over the summaries extracted by existing popular summarization methods 2 the use of summaries as labels has obvious advantages over the use of words and phrases",
        "A1": "use text summaries for topic labeling",
        "A2": "Labeling topics learned by topic models ",
        "A41": "use text summaries for topic labeling",
        "A51": "",
        "A61": "superior over the summaries extracted by existing popular summarization methods",
        "A10": "superior over the summaries extracted by existing popular summarization methods",
        "A7": "automatic and manual analysis have been conducted on two real document collections",
        "A83": "",
        "A82": " the use of summaries as labels has obvious advantages over the use of words and phrases",
        "A81": "the summaries extracted by our proposed algorithm are superior over the summaries extracted by existing popular summarization methods ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "superior over the summaries extracted by existing popular summarization methods",
        "A53": "submodular optimization",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 457777186
    },
    {
        "Abstract": "We introduce a new language learning setting relevant to building adaptive natural language interfaces It is inspired by Wittgensteins language games a human wishes to accomplish some task eg achieving a certain configuration of blocks but can only communicate with a computer who performs the actual actions eg removing all red blocks The computer initially knows nothing about language and therefore must learn it from scratch through interaction while the human adapts to the computers capabilities We created a game called SHRDLURN in a blocks world and collected interactions from 100 people playing it First we analyze the humans strategies showing that using compositionality and avoiding synonyms correlates positively with task performance Second we compare computer strategies showing that modeling pragmatics on a semantic parsing model accelerates learning for more strategic players",
        "A1": " introduce a new language learning setting relevant to building adaptive natural language interfaces",
        "A2": "The computer initially knows nothing about language and therefore must learn it from scratch through interaction while the human adapts to the computers capabilities",
        "A41": " introduce a new language learning setting relevant to building adaptive natural language interfaces",
        "A51": " First we analyze the humans strategies showing that using compositionality and avoiding synonyms correlates positively with task performance Second we compare computer strategies showing that modeling pragmatics on a semantic parsing model accelerates learning for more strategic players",
        "A61": " First we analyze the humans strategies showing that using compositionality and avoiding synonyms correlates positively with task performance Second we compare computer strategies showing that modeling pragmatics on a semantic parsing model accelerates learning for more strategic players",
        "A10": " First we analyze the humans strategies showing that using compositionality and avoiding synonyms correlates positively with task performance Second we compare computer strategies showing that modeling pragmatics on a semantic parsing model accelerates learning for more strategic players",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 473769399
    },
    {
        "Abstract": "Linguistic drift is a process that produces slow irreversible changes in the grammar and function of a languages constructions Importantly changes in a part of a language can have trickle down effects triggering changes elsewhere in that language Although such causally triggered chains of changes have long been hypothesized by historical linguists no explicit demonstration of the actual causality has been provided In this study we use cooccurrence statistics and machine learning to demonstrate that the functions of morphological cases experience a slow irreversible drift along history even in a language as conservative as is Icelandic Crucially we then move on to demonstrate using the notion of Grangercausalitythat there are explicit causal connections between the changes in the functions of the different cases which are consistent with documented processes in the history of Icelandic Our technique provides a means for the quantitative reconstruction of connected networks of subtle linguistic changes",
        "A1": "demonstrate that the functions of morphological cases experience a slow irreversible drift along history",
        "A2": "demonstrate that the functions of morphological cases experience a slow irreversible drift along history",
        "A41": "a means for the quantitative reconstruction of connected networks of subtle linguistic changes",
        "A51": " cooccurrence statistics and machine learning ",
        "A61": "",
        "A10": "",
        "A7": "Icelandic ",
        "A83": "",
        "A82": "",
        "A81": " consistent with documented processes in the history of Icelandic ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 51115481
    },
    {
        "Abstract": "Most existing approaches for zero pronoun resolution are heavily relying on annotated data which is often released by shared task organizers Therefore the lack of annotated data becomes a major obstacle in the progress of zero pronoun resolution task Also it is expensive to spend manpower on labeling the data for better performance To alleviate the problem above in this paper we propose a simple but novel approach to automatically generate largescale pseudo training data for zero pronoun resolution Furthermore we successfully transfer the clozestyle reading comprehension neural network model into zero pronoun resolution task and propose a twostep training mechanism to overcome the gap between the pseudo training data and the real one Experimental results show that the proposed approach significantly outperforms the stateoftheart systems with an absolute improvements of 31 Fscore on OntoNotes 50 data",
        "A1": "propose a simple but novel approach to automatically generate largescale pseudo training data for zero pronoun resolution ",
        "A2": "Therefore the lack of annotated data becomes a major obstacle in the progress of zero pronoun resolution task Also it is expensive to spend manpower on labeling the data for better performance",
        "A41": "propose a simple but novel approach to automatically generate largescale pseudo training data for zero pronoun resolution",
        "A51": "successfully transfer the clozestyle reading comprehension neural network model into zero pronoun resolution task and propose a twostep training mechanism to overcome the gap between the pseudo training data and the real one",
        "A61": "automatically generate largescale pseudo training data for zero pronoun resolution",
        "A10": "we propose a simple but novel approach to automatically generate largescale pseudo training data for zero pronoun resolution",
        "A7": " OntoNotes 50 data",
        "A83": "",
        "A82": "",
        "A81": "the proposed approach significantly outperforms the stateoftheart systems with an absolute improvements of 31 Fscore on OntoNotes 50 data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 238683061
    },
    {
        "Abstract": "Solving algebraic word problems requires executing a series of arithmetic operationsa programto obtain a final answer However since programs can be arbitrarily complicated inducing them directly from questionanswer pairs is a formidable challenge To make this task more feasible we solve these problems by generating answer rationales sequences of natural language and humanreadable mathematical expressions that derive the final answer through a series of small steps Although rationales do not explicitly specify programs they provide a scaffolding for their structure via intermediate milestones To evaluate our approach we have created a new 100000sample dataset of questions answers and rationales Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs",
        "A1": "Solving algebraic word problems ",
        "A2": " since programs can be arbitrarily complicated inducing them directly from questionanswer pairs is a formidable challenge ",
        "A41": "make this task more feasible",
        "A51": "generating answer rationales sequences of natural language and humanreadable mathematical expressions that derive the final answer through a series of small steps ",
        "A61": "",
        "A10": "",
        "A7": "we have created a new 100000sample dataset of questions answers",
        "A83": "",
        "A82": "",
        "A81": "rationales Experimental results show that indirect supervision of program learning via answer rationales is a promising strategy for inducing arithmetic programs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " a new 100000sample dataset of questions answers",
        "am_id": 433096579
    },
    {
        "Abstract": "In this paper we present a novel framework for semiautomatically creating linguistically challenging microplanning datatotext corpora from existing Knowledge Bases Because our method pairs data of varying size and shape with texts ranging from simple clauses to short texts a dataset created using this framework provides a challenging benchmark for microplanning Another feature of this framework is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers We apply our framework to DBpedia data and compare the resulting dataset with Wen et al 2016s We show that while Wen et als dataset is more than twice larger than ours it is less diverse both in terms of input and in terms of text We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in microplanning between lexicalisation aggregation surface realisation referring expression generation and sentence segmentation To encourage researchers to take up this challenge we recently made available a dataset created using this framework in the context of the WEBNLG shared task",
        "A1": "present a novel framework for semiautomatically creating linguistically challenging microplanning datatotext corpora from existing Knowledge Bases",
        "A2": "semiautomatically creating linguistically challenging microplanning datatotext corpora from existing Knowledge Bases",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "we recently made available a dataset created using this framework in the context of the WEBNLG shared task",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "a novel framework for semiautomatically creating linguistically challenging microplanning datatotext corpora from existing Knowledge Bases",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 304488791
    },
    {
        "Abstract": "In this paper we present the gated selfmatching networks for reading comprehension style question answering which aims to answer questions from a given passage We first match the question and passage with gated attentionbased recurrent networks to obtain the questionaware passage representation Then we propose a selfmatching attention mechanism to refine the representation by matching the passage against itself which effectively encodes information from the whole passage We finally employ the pointer networks to locate the positions of answers from the passages We conduct extensive experiments on the SQuAD dataset The single model achieves 713 on the evaluation metrics of exact match on the hidden test set while the ensemble model further boosts the results to 759 At the time of submission of the paper our model holds the first place on the SQuAD leaderboard for both single and ensemble model Contribution during internship at Microsoft Research Equal contribution",
        "A1": " we present the gated selfmatching networks for reading comprehension style question answering",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " At the time of submission of the paper our model holds the first place on the SQuAD leaderboard for both single and ensemble model ",
        "A7": "We conduct extensive experiments on the SQuAD dataset ",
        "A83": " At the time of submission of the paper our model holds the first place on the SQuAD leaderboard for both single and ensemble model ",
        "A82": "the ensemble model further boosts the results to 759 ",
        "A81": " The single model achieves 713 on the evaluation metrics of exact match on the hidden test set ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "we present the gated selfmatching networks for reading comprehension style question answering ",
        "A45": "",
        "am_id": 316037127
    },
    {
        "Abstract": "Despite sequences being core to NLP scant work has considered how to handle noisy sequence labels from multiple annotators for the same text Given such annotations we consider two complementary tasks 1 aggregating sequential crowd labels to infer a best single set of consensus annotations and 2 using crowd annotations as training data for a model that can predict sequences in unannotated text For aggregation we propose a novel Hidden Markov Model variant To predict sequences in unannotated text we propose a neural approach using Long Short Term Memory We evaluate a suite of methods across two different applications and text genres NamedEntity Recognition in news articles and Information Extraction from biomedical abstracts Results show improvement over strong baselines Our source code and data are available online1",
        "A1": "Recognition in news articles and Information ",
        "A2": "how to handle noisy sequence labels from multiple annotators for the same text ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Extraction from biomedical abstracts Results",
        "A83": "",
        "A82": "",
        "A81": "improvement over strong baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " evaluate a suite of methods across two different applications and text genres NamedEntity",
        "A52": " a neural approach using Long Short Term ",
        "A42": "a novel Hidden Markov Model",
        "A45": "",
        "am_id": 14071321
    },
    {
        "Abstract": "Automated processing of historical texts often relies on prenormalization to modern word forms Training encoderdecoder architectures to solve such problems typically requires a lot of training data which is not available for the named task We address this problem by using several novel encoderdecoder architectures including a multitask learning MTL architecture using a graphemetophoneme dictionary as auxiliary data pushing the stateoftheart by an absolute 2 increase in performance We analyze the induced models across 44 different texts from Early New High German Interestingly we observe that as previously conjectured multitask learning can learn to focus attention during decoding in ways remarkably similar to recently proposed attention mechanisms This we believe is an important step toward understanding how MTL works",
        "A1": "",
        "A2": "Training encoderdecoder architectures to solve such problems typically requires a lot of training data which is not available for the named task",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "an absolute 2 increase in performance",
        "A7": "We analyze the induced models across 44 different texts from Early New High German",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "several novel encoderdecoder architectures including a multitask learning MTL architecture",
        "A45": "",
        "am_id": 436176066
    },
    {
        "Abstract": "We model a dependency graph as a book a particular kind of topological space for semantic dependency parsing The spine of the book is made up of a sequence of words and each page contains a subset of noncrossing arcs To build a semantic graph for a given sentence we design new Maximum Subgraph algorithms to generate noncrossing graphs on each page and a Lagrangian Relaxationbased algorithm to combine pages into a book Experiments demonstrate the effectiveness of the book embedding framework across a wide range of conditions Our parser obtains comparable results with a stateoftheart transitionbased parser",
        "A1": "semantic dependency parsing",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "obtains comparable results with a stateoftheart transitionbased parser",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "effectiveness of the book embedding framework across a wide range of conditions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "Maximum Subgraph algorithms to generate noncrossing graphs on each page and a Lagrangian Relaxationbased algorithm to combine pages into a book",
        "A62": "",
        "A52": "",
        "A42": "The spine of the book is made up of a sequence of words and each page contains a subset of noncrossing arcs ",
        "A45": "",
        "am_id": 377653256
    },
    {
        "Abstract": "We present a novel attentionbased recurrent neural network for joint extraction of entity mentions and relations We show that attention along with long short term memory LSTM network can extract semantic relations between entity mentions without having access to dependency trees Experiments on Automatic Content Extraction ACE corpora show that our model significantly outperforms featurebased joint model by Li and Ji 2014 We also compare our model with an endtoend treebased LSTM model SPTree by Miwa and Bansal 2016 and show that our model performs within 1 on entity mentions and 2 on relations Our finegrained analysis also shows that our model performs significantly better on AGENTARTIFACT relations while SPTree performs better on PHYSICAL and PARTWHOLE relations",
        "A1": "We present a novel attentionbased recurrent neural network for joint extraction of entity mentions and relations ",
        "A2": "attention along with long short term memory LSTM network can extract semantic relations between entity mentions without having access to dependency trees",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experiments on Automatic Content Extraction ACE corpora show that our model significantly outperforms featurebased joint model by Li and Ji 2014 ",
        "A7": "Experiments on Automatic Content Extraction ACE corpora",
        "A83": "Our finegrained analysis also shows that our model performs significantly better on AGENTARTIFACT relations while SPTree performs better on PHYSICAL and PARTWHOLE relations",
        "A82": "We also compare our model with an endtoend treebased LSTM model SPTree by Miwa and Bansal 2016 and show that our model performs within 1 on entity mentions and 2 on relation",
        "A81": "Experiments on Automatic Content Extraction ACE corpora show that our model significantly outperforms featurebased joint model by Li and Ji 2014",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "long short term memory LSTM network",
        "A42": "We present a novel attentionbased recurrent neural network for joint extraction of entity mentions and relations",
        "A45": "",
        "am_id": 82939471
    },
    {
        "Abstract": "The large and growing amounts of online scholarly data present both challenges and opportunities to enhance knowledge discovery One such challenge is to automatically extract a small set of keyphrases from a document that can accurately describe the documents content and can facilitate fast information processing In this paper we propose PositionRank an unsupervised model for keyphrase extraction from scholarly documents that incorporates information from all positions of a words occurrences into a biased PageRank Our model obtains remarkable improvements in performance over PageRank models that do not take into account word positions as well as over strong baselines for this task Specifically on several datasets of research papers PositionRank achieves improvements as high as 2909",
        "A1": "automatically extract a small set of keyphrases from a document",
        "A2": "enhance knowledge discovery",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "remarkable improvements",
        "A7": " on several datasets",
        "A83": "",
        "A82": " PositionRank achieves improvements as high as 2909",
        "A81": "Our model obtains remarkable improvements in performance over PageRank models that do not take into account word positions as well as over strong baselines for this task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " PositionRank an unsupervised model for keyphrase extraction from scholarly documents that incorporates information from all positions of a words occurrences into a biased PageRank",
        "A45": "",
        "am_id": 167312229
    },
    {
        "Abstract": "We propose a novel geolocation prediction model using a complex neural network Our model unifies text metadata and user network representations with an attention mechanism to overcome previous ensemble approaches In an evaluation using two open datasets the proposed model exhibited a maximum 38 increase in accuracy and a maximum of 66 increase in accuracy161 against previous models We further analyzed several intermediate layers of our model which revealed that their states capture some statistical characteristics of the datasets",
        "A1": "propose a novel geolocation prediction model ",
        "A2": "unifies text metadata and user network representations with an attention mechanism to overcome previous ensemble approaches",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "using two open datasets ",
        "A83": "",
        "A82": "",
        "A81": "xhibited a maximum 38 increase in accuracy and a maximum of 66 increase in accuracy161 against previous models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "unifies text metadata and user network representations with an attention mechanism to overcome previous ensemble approaches ",
        "A52": "a complex neural network O",
        "A42": "a novel geolocation prediction model ",
        "A45": "",
        "am_id": 421346121
    },
    {
        "Abstract": "Finding the correct hypernyms for entities is essential for taxonomy learning finegrained entity categorization knowledge base construction etc Due to the flexibility of the Chinese language it is challenging to identify hypernyms in Chinese accurately Rather than extracting hypernyms from texts in this paper we present a transductive learning approach to establish mappings from entities to hypernyms in the embedding space directly It combines linear and nonlinear embedding projection models with the capacity of encoding arbitrary languagespecific rules Experiments on realworld datasets illustrate that our approach outperforms previous methods for Chinese hypernym prediction",
        "A1": "Finding the correct hypernyms for entities is essential for taxonomy learning finegrained entity categorization knowledge base construction etc ",
        "A2": "Due to the flexibility of the Chinese language it is challenging to identify hypernyms in Chinese accurately",
        "A41": "Due to the flexibility of the Chinese language it is challenging to identify hypernyms in Chinese accurately",
        "A51": "",
        "A61": " It combines linear and nonlinear embedding projection models with the capacity of encoding arbitrary languagespecific rules",
        "A10": "Experiments on realworld datasets illustrate that our approach outperforms previous methods for Chinese hypernym prediction",
        "A7": "Experiments on realworld datasets illustrate that our approach outperforms previous methods for Chinese hypernym prediction",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 330736632
    },
    {
        "Abstract": "Most work on segmenting text does so on the basis of topic changes but it can be of interest to segment by other stylistically expressed characteristics such as change of authorship or native language We propose a Bayesian unsupervised text segmentation approach to the latter While baseline models achieve essentially random segmentation on our task indicating its difficulty a Bayesian model that incorporates appropriately compact language models and alternating asymmetric priors can achieve scores on the standard metrics around halfway to perfect segmentation",
        "A1": "propose a Bayesian unsupervised text segmentation approach",
        "A2": "segmenting text",
        "A41": " a Bayesian unsupervised text segmentation approach to the latter",
        "A51": "Bayesian",
        "A61": "incorporates appropriately compact language models and alternating asymmetric priors",
        "A10": "",
        "A7": "standard metrics around halfway to perfect segmentation",
        "A83": "",
        "A82": "",
        "A81": "achieve scores",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 396149110
    },
    {
        "Abstract": "Network embedding NE is playing a critical role in network analysis due to its ability to represent vertices with efficient lowdimensional embedding vectors However existing NE models aim to learn a fixed contextfree embedding for each vertex and neglect the diverse roles when interacting with other vertices In this paper we assume that one vertex usually shows different aspects when interacting with different neighbor vertices and should own different embeddings respectively Therefore we present ContextAware Network Embedding CANE a novel NE model to address this issue CANE learns contextaware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely In experiments we compare our model with existing NE models on three realworld datasets Experimental results show that CANE achieves significant improvement than stateoftheart methods on link prediction and comparable performance on vertex classification The source code and datasets can be obtained from httpsgithubcom thunlpCANE",
        "A1": "",
        "A2": "Network embedding NE is playing a critical role in network analysis due to its ability to represent vertices with efficient lowdimensional embedding vectors However existing NE models aim to learn a fixed contextfree embedding for each vertex and neglect the diverse roles when interacting with other vertices In this paper we assume that one vertex usually shows different aspects when interacting with different neighbor vertices and should own different embeddings respectively",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "we compare our model with existing NE models on three realworld datasets",
        "A83": "",
        "A82": "",
        "A81": "CANE achieves significant improvement than stateoftheart methods on link prediction and comparable performance on vertex classification",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "CANE learns contextaware embeddings for vertices with mutual attention mechanism and is expected to model the semantic relationships between vertices more precisely",
        "A52": "",
        "A42": "ContextAware Network Embedding CANE a novel NE model",
        "A45": "",
        "am_id": 35121505
    },
    {
        "Abstract": "Recurrent Neural Networks are showing much promise in many subareas of natural language processing ranging from document classification to machine translation to automatic question answering Despite their promise many recurrent models have to read the whole text word by word making it slow to handle long documents For example it is difficult to use a recurrent network to read a book and answer questions about it In this paper we present an approach of reading text while skipping irrelevant information if needed The underlying model is a recurrent network that learns how far to jump after reading a few words of the input text We employ a standard policy gradient method to train the model to make discrete jumping decisions In our benchmarks on four different tasks including number prediction sentiment analysis news article classification and automatic QA our proposed model a modified LSTM with jumping is up to 6 times faster than the standard sequential LSTM while maintaining the same or even better accuracy",
        "A1": "we present an approach of reading text while skipping irrelevant information if needed",
        "A2": "our proposed model a modified LSTM with jumping is up to 6 times faster than the standard sequential LSTM while maintaining the same or even better accuracy",
        "A41": "an approach of reading text while skipping irrelevant information if needed",
        "A51": "The underlying model is a recurrent network that learns how far to jump after reading a few words of the input text",
        "A61": "Despite their promise many recurrent models have to read the whole text word by word making it slow to handle long documents",
        "A10": "our proposed model a modified LSTM with jumping is up to 6 times faster than the standard sequential LSTM while maintaining the same or even better accuracy",
        "A7": "four different tasks including number prediction sentiment analysis news article classification and automatic QA",
        "A83": "",
        "A82": "",
        "A81": "our proposed model a modified LSTM with jumping is up to 6 times faster than the standard sequential LSTM while maintaining the same or even better accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "is up to 6 times faster than the standard sequential LSTM while maintaining the same or even better accuracy",
        "A52": "The underlying model is a recurrent network",
        "A42": "our proposed model a modified LSTM with jumping",
        "A45": "",
        "am_id": 148389409
    },
    {
        "Abstract": "The ambitious goal of this work is to develop a crosslingual name tagging and linking framework for 282 languages that exist in Wikipedia Given a document in any of these languages our framework is able to identify name mentions assign a coarsegrained or finegrained type to each mention and link it to an English Knowledge Base KB if it is linkable We achieve this goal by performing a series of new KB mining methods generating silverstandard annotations by transferring annotations from English to other languages through crosslingual links and KB properties refining annotations through selftraining and topic selection deriving languagespecific morphology features from anchor links and mining word translation pairs from crosslingual links Both name tagging and linking results for 282 languages are promising on Wikipedia data and onWikipedia data All the data sets resources and systems for 282 languages are made publicly available as a new benchmark 1",
        "A1": "The ambitious goal of this work is to develop a crosslingual name tagging and linking framework for 282 languages that exist in Wikipedia",
        "A2": "The ambitious goal of this work is to develop a crosslingual name tagging and linking framework for 282 languages that exist in Wikipedia",
        "A41": "We achieve this goal by performing a series of new KB mining methods generating silverstandard annotations by transferring annotations from English to other languages through crosslingual links and KB properties refining annotations through selftraining and topic selection deriving languagespecific morphology features from anchor links and mining word translation pairs from crosslingual links",
        "A51": "",
        "A61": "We achieve this goal by performing a series of new KB mining methods generating silverstandard annotations by transferring annotations from English to other languages through crosslingual links and KB properties refining annotations through selftraining and topic selection deriving languagespecific morphology features from anchor links and mining word translation pairs from crosslingual links",
        "A10": "",
        "A7": "Both name tagging and linking results for 282 languages are promising on Wikipedia data and onWikipedia data",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 273970134
    },
    {
        "Abstract": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms By using efficient nearly arcfactored inference and a bidirectionalLSTM composed with a multilayer perceptron our base system is able to significantly improve the state of the art for semantic dependency parsing without using handengineered features or syntax We then explore two multitask learning approachesone that shares parameters across formalisms and one that uses higherorder structures to predict the graphs jointly We find that both approaches improve performance across formalisms on average achieving a new state of the art Our code is opensource and available at httpsgithubcom NoahsARKNeurboParser",
        "A1": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms",
        "A2": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We find that both approaches improve performance across formalisms on average achieving a new state of the art ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "By using efficient nearly arcfactored inference and a bidirectionalLSTM composed with a multilayer perceptron our base system is able to significantly improve the state of the art for semantic dependency parsing without using handengineered features or syntax",
        "A52": "By using efficient nearly arcfactored inference and a bidirectionalLSTM composed with a multilayer perceptron our base system is able to significantly improve the state of the art for semantic dependency parsing without using handengineered features or syntax",
        "A42": "We present a deep neural architecture that parses sentences into three semantic dependency graph formalisms",
        "A45": "",
        "am_id": 31792557
    },
    {
        "Abstract": "Previous work has modeled the compositionality of words by creating characterlevel models of meaning reducing problems of sparsity for rare words However in many writing systems compositionality has an effect even on the characterlevel the meaning of a character is derived by the sum of its parts In this paper we model this effect by creating embeddings for characters based on their visual characteristics creating an image for the character and running it through a convolutional neural network to produce a visual character embedding Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese Japanese and Korean Additionally qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content resulting in embeddings that are coherent in visual space",
        "A1": "model this effect by creating embeddings for characters",
        "A2": "compositionality has an effect even on the characterlevel",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "focus on the parts of characters that carry semantic content resulting in embeddings that are coherent in visual space",
        "A7": "Experiments on a text classification task",
        "A83": "",
        "A82": "",
        "A81": "better processing of instances with rare characters",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "convolutional neural network",
        "A52": "visual characteristics creating an image for the character",
        "A42": "model this effect by creating embeddings for characters",
        "A45": "",
        "am_id": 354803511
    },
    {
        "Abstract": "Neural Machine Translation NMT performs poor on the lowresource language pair X Z especially when Z is a rare language By introducing another rich language Y  we propose a novel triangular training architecture TANMT to leverage bilingual data Y Z may be small and X Y  can be rich to improve the translation performance of lowresource pairs In this triangular architecture Z is taken as the intermediate latent variable and translation models of Z are jointly optimized with a unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of X Y  Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets and achieves even better performance combining backtranslation methods",
        "A1": "improve the translation performance of lowresource pairs",
        "A2": "Neural Machine Translation NMT performs poor on the lowresource language pair X Z especially when Z is a rare language ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ur method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets and achieves even better performance combining backtranslation methods",
        "A7": " rare languages on MultiUN and IWSLT2012 datasets",
        "A83": "",
        "A82": "",
        "A81": "ur method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets and achieves even better performance combining backtranslation methods",
        "A64": "",
        "A54": "introducing another rich language Y ",
        "A44": "By introducing another rich language Y  we propose a novel triangular training architecture TANMT to leverage bilingual data Y Z may be small and X Y  can be rich to improve the translation performance of lowresource pairs ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 54985036
    },
    {
        "Abstract": "Knowledge graphs have emerged as an important model for studying complex multirelational data This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledgebased inference for many downstream applications To this end we propose LinkNBed a deep relational learning framework that learns entity and relationship representations across multiple graphs We identify entity linkage across graphs as a vital component to achieve our goal We design a novel objective that leverage entity linkage and build an efficient multitask training procedure Experiments on link prediction and entity linkage demonstrate substantial improvements over the stateoftheart relational learning approaches",
        "A1": "we propose LinkNBed a deep relational learning framework that learns entity and relationship representations across multiple graphs",
        "A2": "An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledgebased inference for many downstream applications",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "substantial improvements over the stateoftheart relational learning approaches",
        "A7": "Experiments on link prediction and entity linkage",
        "A83": "",
        "A82": "",
        "A81": "substantial improvements over the stateoftheart relational learning approaches",
        "A64": "",
        "A54": "",
        "A44": "a deep relational learning framework that learns entity and relationship representations across multiple graphs",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 329735195
    },
    {
        "Abstract": "We present a generative model to map natural language questions into SQL queries Existing neural network based approaches typically generate a SQL query wordbyword however a large portion of the generated results is incorrect or not executable due to the mismatch between question words and table contents Our approach addresses this problem by considering the structure of table and the syntax of SQL language The quality of the generated SQL query is significantly improved through 1 learning to replicate content from column names cells or SQL keywords and 2 improving the generation of WHERE clause by leveraging the columncell relation Experiments are conducted on WikiSQL a recently released dataset with the largest questionSQL pairs Our approach significantly improves the stateoftheart execution accuracy from 690 to 744",
        "A1": "present a generative model to map natural language questions into SQL queries",
        "A2": "present a generative model to map natural language questions into SQL queries",
        "A41": " Our approach addresses this problem by considering the structure of table and the syntax of SQL language",
        "A51": "Our approach addresses this problem by considering the structure of table and the syntax of SQL language The quality of the generated SQL query is significantly improved through 1 learning to replicate content from column names cells or SQL keywords and 2 improving the generation of WHERE clause by leveraging the columncell relation",
        "A61": "Our approach addresses this problem by considering the structure of table and the syntax of SQL language The quality of the generated SQL query is significantly improved through 1 learning to replicate content from column names cells or SQL keywords and 2 improving the generation of WHERE clause by leveraging the columncell relation",
        "A10": " Our approach significantly improves the stateoftheart execution accuracy from 690 to 744",
        "A7": "Experiments are conducted on WikiSQL a recently released dataset with the largest questionSQL pairs ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "We present a generative model to map natural language questions into SQL queries Existing neural network based approaches typically generate a SQL query wordbyword however a large portion of the generated results is incorrect or not executable due to the mismatch between question words and table contents",
        "A52": "",
        "A42": "We present a generative model to map natural language questions into SQL queries",
        "A45": "WikiSQL a recently released dataset with the largest questionSQL pairs",
        "am_id": 298817956
    },
    {
        "Abstract": "To solve math word problems previous statistical approaches attempt at learning a direct mapping from a problem description to its corresponding equation system However such mappings do not include the information of a few higherorder operations that cannot be explicitly represented in equations but are required to solve the problem The gap between natural language and equations makes it difficult for a learned model to generalize from limited data In this work we present an intermediate meaning representation scheme that tries to reduce this gap We use a sequencetosequence model with a novel attention regularization term to generate the intermediate forms then execute them to obtain the final answers Since the intermediate forms are latent we propose an iterative labeling framework for learning by leveraging supervision signals from both equations and answers Our experiments show using intermediate forms outperforms directly predicting equations",
        "A1": "To solve math word problems",
        "A2": "The gap between natural language and equations makes it difficult for a learned model to generalize from limited data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "using intermediate forms outperforms directly predicting equations",
        "A64": "",
        "A54": "",
        "A44": " an iterative labeling framework for learning by leveraging supervision signals from both equations and answers ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " a sequencetosequence model with a novel attention regularization term to generate the intermediate forms",
        "A45": "",
        "am_id": 15738036
    },
    {
        "Abstract": "We introduce an opendomain neural semantic parser which generates formal meaning representations in the style of Discourse Representation Theory DRT Kamp and Reyle 1993 We propose a method which transforms Discourse Representation Structures DRSs to trees and develop a structureaware model which decomposes the decoding process into three stages basic DRS structure prediction condition prediction ie predicates and relations and referent prediction ie variables Experimental results on the Groningen Meaning Bank GMB show that our model outperforms competitive baselines by a wide margin",
        "A1": " generates formal meaning representations in the style of Discourse Representation Theory",
        "A2": "",
        "A41": "a method which transforms Discourse Representation Structures DRSs to trees",
        "A51": "",
        "A61": "",
        "A10": " a wide margin",
        "A7": "Experimental results on the Groningen Meaning Bank GMB",
        "A83": "",
        "A82": "",
        "A81": "our model outperforms competitive baselines by a wide margin",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " a structureaware model which decomposes the decoding process into three stages",
        "A45": "",
        "am_id": 58073195
    },
    {
        "Abstract": "This paper proposes a novel approach for event coreference resolution that models correlations between event coreference chains and document topical structures through an Integer Linear Programming formulation We explicitly model correlations between the main event chains of a document with topic transition sentences intercoreference chain correlations event mention distributional characteristics and subevent structure and use them with scores obtained from a local coreference relation classifier for jointly resolving multiple event chains in a document Our experiments across KBP 2016 and 2017 datasets suggest that each of the structures contribute to improving event coreference resolution performance",
        "A1": "proposes a novel approach for event coreference resolution",
        "A2": "",
        "A41": "a novel approach for event coreference resolution that models correlations between event coreference chains and document topical structures through an Integer Linear Programming formulation ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "experiments across KBP 2016 and 2017 datasets",
        "A83": "",
        "A82": "",
        "A81": "each of the structures contribute to improving event coreference resolution performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 287177074
    },
    {
        "Abstract": "We propose a contextaware neural network model for temporal information extraction with a uniform architecture for eventevent eventtimex and timextimex pairs A Global Context Layer GCL inspired by the Neural Turing Machine NTM stores processed temporal relations in the narrative order and retrieves them for use when the relevant entities are encountered Relations are then classified in this larger context The GCL model uses longterm memory and attention mechanisms to resolve longdistance dependencies that regular RNNs cannot recognize GCL does not use postprocessing to resolve timegraph conflicts outperforming previous approaches that do so To our knowledge GCL is also the first model to use an NTMlike architecture to incorporate the information about global context into discoursescale processing of natural text",
        "A1": "propose a contextaware neural network model",
        "A2": " temporal information extraction",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " outperforming previous approaches",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "does not use postprocessing to resolve timegraph conflicts ",
        "A52": "",
        "A42": "a contextaware neural network model for temporal information extraction with a uniform architecture for eventevent eventtimex and timextimex pairs",
        "A45": "",
        "am_id": 93762197
    },
    {
        "Abstract": "Inspired by the double temporality characteristic of narrative texts we propose a novel approach for acquiring rich temporal beforeafter event knowledge across sentences in narrative stories The double temporality states that a narrative story often describes a sequence of events following the chronological order and therefore the temporal order of events matches with their textual order We explored narratology principles and built a weakly supervised approach that identifies 287k narrative paragraphs from three large text corpora We then extracted rich temporal event knowledge from these narrative paragraphs Such event knowledge is shown useful to improve temporal relation classification and outperform several recent neural network models on the narrative cloze task",
        "A1": "",
        "A2": "a narrative story often describes a sequence of events following the chronological order",
        "A41": " a novel approach for acquiring rich temporal beforeafter event knowledge across sentences in narrative stories ",
        "A51": " double temporality characteristic of narrative texts ",
        "A61": "",
        "A10": " improve temporal relation classification and outperform several recent neural network models",
        "A7": " on the narrative cloze task",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 449604100
    },
    {
        "Abstract": "Sentence scoring and sentence selection are two main steps in extractive document summarization systems However previous works treat them as two separated subtasks In this paper we present a novel endtoend neural network framework for extractive document summarization by jointly learning to score and select sentences It first reads the document sentences with a hierarchical encoder to obtain the representation of sentences Then it builds the output summary by extracting sentences one by one Different from previous methods our approach integrates the selection strategy into the scoring model which directly predicts the relative importance given previously selected sentences Experiments on the CNNDaily Mail dataset show that the proposed framework significantly outperforms the stateoftheart extractive summarization models",
        "A1": "present a novel endtoend neural network framework for extractive document summarization",
        "A2": "present a novel endtoend neural network framework for extractive document summarization by jointly learning to score and select sentences",
        "A41": "",
        "A51": "",
        "A61": "our approach integrates the selection strategy into the scoring model which directly predicts the relative importance given previously selected sentences ",
        "A10": "the proposed framework significantly outperforms the stateoftheart extractive summarization models",
        "A7": "Experiments on the CNNDaily Mail dataset ",
        "A83": "",
        "A82": "",
        "A81": "the proposed framework significantly outperforms the stateoftheart extractive summarization models",
        "A64": " It first reads the document sentences with a hierarchical encoder to obtain the representation of sentences Then it builds the output summary by extracting sentences one by one",
        "A54": "",
        "A44": "a novel endtoend neural network framework for extractive document summarization by jointly learning to score and select sentences",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "CNNDaily Mail dataset ",
        "am_id": 355645260
    },
    {
        "Abstract": "As the popularity of freeform usergenerated reviews in ecommerce and review websites continues to increase there is a growing need for automatic mechanisms that sift through the vast number of reviews and identify quality content Online review helpfulness modeling and prediction is a task which studies the factors that determine review helpfulness and attempts to accurately predict it This survey paper provides an overview of the most relevant work on product review helpfulness prediction and understanding in the past decade discusses gained insights and provides guidelines for future research",
        "A1": "As the popularity of freeform usergenerated reviews in ecommerce and review websites continues to increase there is a growing need for automatic mechanisms that sift through the vast number of reviews and identify quality content ",
        "A2": "Online review helpfulness modeling and prediction is a task which studies the factors that determine review helpfulness and attempts to accurately predict it ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "This survey paper provides an overview of the most relevant work on product review helpfulness prediction and understanding in the past decade discusses gained insights and provides guidelines for future research",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "This survey paper provides an overview of the most relevant work on product review helpfulness prediction and understanding in the past decade discusses gained insights and provides guidelines for future research",
        "A53": "This survey paper provides an overview of the most relevant work on product review helpfulness prediction and understanding in the past decade discusses gained insights and provides guidelines for future research",
        "A43": "This survey paper provides an overview of the most relevant work on product review helpfulness prediction and understanding in the past decade discusses gained insights and provides guidelines for future research",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 2840298
    },
    {
        "Abstract": "Recent work has managed to learn crosslingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training However their evaluation has focused on favorable conditions using comparable corpora or closelyrelated languages and we show that they often fail in more realistic scenarios This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings and a robust selflearning algorithm that iteratively improves this solution Our method succeeds in all tested scenarios and obtains the best published results in standard datasets even surpassing previous supervised systems Our implementation is released as an open source project at httpsgithub comartetxemvecmap",
        "A1": " explicitly exploits the structural similarity of the embeddings and a robust selflearning algorithm that iteratively improves this solution ",
        "A2": "their evaluation has focused on favorable conditions using comparable corpora or closelyrelated languages and we show that they often fail in more realistic scenarios",
        "A41": " an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings and a robust selflearning algorithm that iteratively improves this solution ",
        "A51": "a fully unsupervised initialization",
        "A61": " fully unsupervised initialization",
        "A10": "obtains the best published results in standard datasets even surpassing previous supervised systems",
        "A7": " all tested scenarios",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " in standard datasets",
        "am_id": 14311809
    },
    {
        "Abstract": "Targetoriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence RNN with attention seems a good fit for the characteristics of this task and indeed it achieves the stateoftheart performance After reexamining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task we propose a new model to overcome these issues Instead of attention our model employs a CNN layer to extract salient features from the transformed word representations originated from a bidirectional RNN layer Between the two layers we propose a component to generate targetspecific representations of words in the sentence meanwhile incorporate a mechanism for preserving the original contextual information from the RNN layer Experiments show that our model achieves a new stateoftheart performance on a few benchmarks1",
        "A1": "propose a new model to overcome these issues",
        "A2": "the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our model achieves a new stateoftheart performance on a few benchmarks1",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our model achieves a new stateoftheart performance on a few benchmarks1",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "the transformed word representations originated from a bidirectional RNN layer",
        "A42": "model employs a CNN layer to extract salient features from the transformed word representations originated from a bidirectional RNN layer",
        "A45": "",
        "am_id": 455694362
    },
    {
        "Abstract": "Natural Language Inference NLI also known as Recognizing Textual Entailment RTE is one of the most important problems in natural language processing It requires to infer the logical relationship between two given sentences While current approaches mostly focus on the interaction architectures of the sentences in this paper we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model We observe that people usually use some discourse markers such as so or but to represent the logical relationship between two sentences These words potentially have deep connections with the meanings of the sentences thus can be utilized to help improve the representations of them Moreover we use reinforcement learning to optimize a new objective function with a reward defined by the property of the NLI datasets to make full use of the labels information Experiments show that our method achieves the stateoftheart performance on several largescale datasets",
        "A1": "Natural Language Inference NLI also known as Recognizing Textual Entailment RTE is one of the most important problems in natural language processing It requires to infer the logical relationship between two given sentences ",
        "A2": "in this paper we propose to transfer knowledge from some important discourse markers to augment the quality of the NLI model ",
        "A41": "These words potentially have deep connections with the meanings of the sentences thus can be utilized to help improve the representations of them Moreover we use reinforcement learning to optimize a new objective function with a reward defined by the property of the NLI datasets to make full use of the labels information",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments show that our method achieves the stateoftheart performance on several largescale datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 163718640
    },
    {
        "Abstract": "Existing automated essay scoring AES models rely on rated essays for the target prompt as training data Despite their successes in promptdependent AES how to effectively predict essay ratings under a promptindependent setting remains a challenge where the rated essays for the target prompt are not available To close this gap a twostage deep neural network TDNN is proposed In particular in the first stage using the rated essays for nontarget prompts as the training data a shallow model is learned to select essays with an extreme quality for the target prompt serving as pseudo training data in the second stage an endtoend hybrid deep model is proposed to learn a promptdependent rating model consuming the pseudo training data from the first step Evaluation of the proposed TDNN on the standard ASAP dataset demonstrates a promising improvement for the promptindependent AES task",
        "A1": "to effectively predict essay ratings under a promptindependent setting",
        "A2": " how to effectively predict essay ratings under a promptindependent setting remains a challenge ",
        "A41": "a twostage deep neural network TDNN is proposed In particular",
        "A51": "automated essay scoring AES ",
        "A61": "to effectively predict essay ratings under a promptindependent setting",
        "A10": "TDNN on the standard ASAP dataset demonstrates a promising improvement for the promptindependent AES task",
        "A7": " a twostage deep neural network TDNN is proposed In particular in the first stage using the rated essays for nontarget prompts as the training data a shallow model ",
        "A83": "",
        "A82": "",
        "A81": "TDNN on the standard ASAP dataset demonstrates a promising improvement for the promptindependent AES task",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 304210044
    },
    {
        "Abstract": "Revealing the implicit semantic relation between the constituents of a nouncompound is important for many NLP applications It has been addressed in the literature either as a classification task to a set of predefined relations or by producing free text paraphrases explicating the relations Most existing paraphrasing methods lack the ability to generalize and have a hard time interpreting infrequent or new nouncompounds We propose a neural model that generalizes better by representing paraphrases in a continuous space generalizing for both unseen nouncompounds and rare paraphrases Our model helps improving performance on both the nouncompound paraphrasing and classification tasks",
        "A1": "propose a neural model",
        "A2": "Revealing the implicit semantic relation between the constituents of a nouncompound",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our model helps improving performance on both the nouncompound paraphrasing and classification tasks",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " representing paraphrases in a continuous space generalizing for both unseen nouncompounds and rare paraphrases ",
        "A52": "",
        "A42": "a neural model that generalizes better by representing paraphrases in a continuous space generalizing for both unseen nouncompounds and rare paraphrases ",
        "A45": "",
        "am_id": 415463761
    },
    {
        "Abstract": "Metaphoric expressions are widespread in natural language posing a significant challenge for various natural language processing tasks such as Machine Translation Current word embedding based metaphor identification models cannot identify the exact metaphorical words within a sentence In this paper we propose an unsupervised learning method that identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task Our model extends to interpret the identified metaphors paraphrasing them into their literal counterparts so that they can be better translated by machines We evaluated this with two popular translation systems for English to Chinese showing that our model improved the systems significantly",
        "A1": " propose an unsupervised learning method that identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task",
        "A2": "identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task",
        "A41": "an unsupervised learning method that identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task",
        "A51": "interpret the identified metaphors",
        "A61": "identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task",
        "A10": "",
        "A7": " evaluated this with two popular translation systems for English to Chinese",
        "A83": "",
        "A82": "",
        "A81": "our model improved the systems significantly",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "an unsupervised learning method that identifies and interprets metaphors at wordlevel without any preprocessing outperforming strong baselines in the metaphor identification task",
        "A45": "",
        "am_id": 142510484
    },
    {
        "Abstract": "Acronyms are abbreviations formed from the initial components of words or phrases In enterprises people often use acronyms to make communications more efficient However acronyms could be difficult to understand for people who are not familiar with the subject matter new employees etc thereby affecting productivity To alleviate such troubles we study how to automatically resolve the true meanings of acronyms in a given context Acronym disambiguation for enterprises is challenging for several reasons First acronyms may be highly ambiguous since an acronym used in the enterprise could have multiple internal and external meanings Second there are usually no comprehensive knowledge bases such as Wikipedia available in enterprises Finally the system should be generic to work for any enterprise In this work we propose an endtoend framework to tackle all these challenges The framework takes the enterprise corpus as input and produces a highquality acronym disambiguation system as output Our disambiguation models are trained via distant supervised learning without requiring any manually labeled training examples Therefore our proposed framework can be deployed to any enterprise to support highquality acronym disambiguation Experimental results on real world data justified the effectiveness of our system",
        "A1": " study how to automatically resolve the true meanings of acronyms in a given context",
        "A2": "acronyms could be difficult to understand for people who are not familiar with the subject matter new employees etc thereby affecting productivity",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on real world data",
        "A83": "",
        "A82": "",
        "A81": "justified the effectiveness of our system",
        "A64": "",
        "A54": "distant supervised learning ",
        "A44": "an endtoend framework to tackle all these challenges",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 370488214
    },
    {
        "Abstract": "We introduce a novel architecture for dependency parsing stackpointer networks STACKPTR Combining pointer networks Vinyals et al 2015 with an internal stack the proposed model first reads and encodes the whole sentence then builds the dependency tree topdown from roottoleaf in a depthfirst fashion The stack tracks the status of the depthfirst search and the pointer networks select one child for the word at the top of the stack at each step The STACKPTR parser benefits from the information of the whole sentence and all previously derived subtree structures and removes the lefttoright restriction in classical transitionbased parsers Yet the number of steps for building any including nonprojective parse tree is linear in the length of the sentence just as other transitionbased parsers yielding an efficient decoding algorithm with On2 time complexity We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas and achieve stateoftheart performance on 21 of them",
        "A1": "We introduce a novel architecture for dependency parsing stackpointer networks STACKPTR",
        "A2": "removes the lefttoright restriction in classical transitionbased parsers ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas and achieve stateoftheart performance on 21 of them",
        "A7": "We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas ",
        "A83": "",
        "A82": "",
        "A81": "achieve stateoftheart performance on 21 of them",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Combining pointer networks Vinyals et al 2015 with an internal stack the proposed model first reads and encodes the whole sentence then builds the dependency tree topdown from roottoleaf in a depthfirst fashion",
        "A52": "pointer networks Vinyals et al 2015",
        "A42": "We introduce a novel architecture for dependency parsing stackpointer networks STACKPTR",
        "A45": "",
        "am_id": 395758019
    },
    {
        "Abstract": "This paper examines the problem of generating natural language descriptions of chess games We introduce a new largescale chess commentary dataset and propose methods to generate commentary for individual moves in a chess game The introduced dataset consists of more than 298K chess movecommentary pairs across 11K chess games We highlight how this task poses unique research challenges in natural language generation the data contain a large variety of styles of commentary and frequently depend on pragmatic context We benchmark various baselines and propose an endtoend trainable neural model which takes into account multiple pragmatic aspects of the game state that may be commented upon to describe a given chess move Through a human study on predictions for a subset of the data which deals with direct move descriptions we observe that outputs from our models are rated similar to ground truth commentary texts in terms of correctness and fluency1",
        "A1": "introduce a new largescale chess commentary dataset and propose methods to generate commentary for individual moves in a chess game",
        "A2": "generating natural language descriptions of chess games",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a human study on predictions for a subset of the data which deals with direct move descriptions",
        "A83": "",
        "A82": "",
        "A81": "that outputs from our models are rated similar to ground truth commentary texts in terms of correctness and fluency",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "largescale chess commentary dataset",
        "am_id": 403664600
    },
    {
        "Abstract": "While sophisticated neuralbased techniques have been developed in reading comprehension most approaches model the answer in an independent manner ignoring its relations with other answer candidates This problem can be even worse in opendomain scenarios where candidates from multiple passages should be combined to answer a single question In this paper we formulate reading comprehension as an extractthenselect twostage procedure We first extract answer candidates from passages then select the final answer by combining information from all the candidates Furthermore we regard candidate extraction as a latent variable and train the twostage process jointly with reinforcement learning As a result our approach has improved the stateoftheart performance significantly on two challenging opendomain reading comprehension datasets Further analysis demonstrates the effectiveness of our model components especially the information fusion of all the candidates and the joint training of the extractthenselect procedure",
        "A1": " In this paper we formulate reading comprehension as an extractthenselect twostage procedure",
        "A2": "While sophisticated neuralbased techniques have been developed in reading comprehension most approaches model the answer in an independent manner ignoring its relations with other answer candidates This problem can be even worse in opendomain scenarios where candidates from multiple passages should be combined to answer a single question",
        "A41": "reading comprehension as an extractthenselect twostage procedure We first extract answer candidates from passages then select the final answer by combining information from all the candidates",
        "A51": "",
        "A61": "",
        "A10": "Further analysis demonstrates the effectiveness of our model components especially the information fusion of all the candidates and the joint training of the extractthenselect procedure",
        "A7": "on two challenging opendomain reading",
        "A83": "",
        "A82": "",
        "A81": "Further analysis demonstrates the effectiveness of our model components especially the information fusion of all the candidates and the joint training of the extractthenselect procedure",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 383894290
    },
    {
        "Abstract": "Answer selection is an important subtask of community question answering CQA In a realworld CQA forum a question is often represented as two parts a subject that summarizes the main points of the question and a body that elaborates on the subject in detail Previous researches on answer selection usually ignored the difference between these two parts and concatenated them as the question representation In this paper we propose the Question Condensing Networks QCN to make use of the subjectbody relationship of community questions In this model the question subject is the primary part of the question representation and the question body information is aggregated based on similarity and disparity with the question subject Experimental results show that QCN outperforms all existing models on two CQA datasets",
        "A1": "In this paper we propose the Question Condensing Networks QCN to make use of the subjectbody relationship of community questions",
        "A2": "Previous researches on answer selection usually ignored the difference between these two parts and concatenated them as the question representation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experimental results show that QCN outperforms all existing models on two CQA datasets",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experimental results show that QCN outperforms all existing models on two CQA datasets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "make use of the subjectbody relationship of community questions",
        "A52": "",
        "A42": "the Question Condensing Networks QCN",
        "A45": "",
        "am_id": 54451618
    },
    {
        "Abstract": "We analyze stateoftheart deep learning models for three tasks question answering on 1 images 2 tables and 3 passages of text Using the notion of attribution word importance we find that these deep networks often ignore important question terms Leveraging such behavior we perturb questions to craft a variety of adversarial examples Our strongest attacks drop the accuracy of a visual question answering model from 611 to 19 and that of a tabular question answering model from 335 to 33 Additionally we show how attributions can strengthen attacks proposed by Jia and Liang 2017 on paragraph comprehension models Our results demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance When a model is accurate but for the wrong reasons attributions can surface erroneous logic in the model that indicates inadequacies in the test data",
        "A1": "perturb questions to craft a variety of adversarial examples",
        "A2": "these deep networks often ignore important question terms",
        "A41": "perturb questions to craft a variety of adversarial examples",
        "A51": "the notion of attribution word importance",
        "A61": "",
        "A10": "Our strongest attacks drop the accuracy of a visual question answering model from 611 to 19 and that of a tabular question answering model from 335 to 33",
        "A7": "how attributions can strengthen attacks proposed by Jia and Liang 2017 on paragraph comprehension models",
        "A83": "",
        "A82": "When a model is accurate but for the wrong reasons attributions can surface erroneous logic in the model that indicates inadequacies in the test data",
        "A81": "demonstrate that attributions can augment standard measures of accuracy and empower investigation of model performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 317730115
    },
    {
        "Abstract": "A DAG automaton is a formal device for manipulating graphs By augmenting a DAG automaton with transduction rules a DAG transducer has potential applications in fundamental NLP tasks In this paper we propose a novel DAG transducer to perform graphtoprogram transformation The target structure of our transducer is a program licensed by a declarative programming language rather than linguistic structures By executing such a program we can easily get a surface string Our transducer is designed especially for natural language generation NLG from typelogical semantic graphs Taking Elementary Dependency Structures a format of English Resource Semantics as input our NLG system achieves a BLEU4 score of 6807 This remarkable result demonstrates the feasibility of applying a DAG transducer to resolve NLG as well as the effectiveness of our design",
        "A1": "we propose a novel DAG transducer to perform graphtoprogram transformation",
        "A2": "a DAG transducer has potential applications in fundamental NLP tasks ",
        "A41": "The target structure of our transducer is a program licensed by a declarative programming language rather than linguistic structures",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Structures a format of English Resource Semantics as input our NLG system",
        "A83": "",
        "A82": "the feasibility of applying a DAG transducer to resolve NLG as well as the effectiveness of our design",
        "A81": "achieves a BLEU4 score of 6807",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 418217750
    },
    {
        "Abstract": "In this paper we propose a joint architecture that captures language rhyme and meter for sonnet modelling We assess the quality of generated poems using crowd and expert judgements The stress and rhyme models perform very well as generated poems are largely indistinguishable from humanwritten poems Expert evaluation however reveals that a vanilla language model captures meter implicitly and that machinegenerated poems still underperform in terms of readability and emotion Our research shows the importance expert evaluation for poetry generation and that future research should look beyond rhymemeter and focus on poetic language",
        "A1": " we propose a joint architecture that captures language rhyme and meter for sonnet modelling ",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We assess the quality of generated poems using crowd and expert judgements",
        "A83": "machinegenerated poems still underperform in terms of readability and emotion",
        "A82": "Expert evaluation however reveals that a vanilla language model captures meter implicitly",
        "A81": "The stress and rhyme models perform very well as generated poems are largely indistinguishable from humanwritten poems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "we propose a joint architecture that captures language rhyme and meter for sonnet modelling ",
        "A45": "",
        "am_id": 435408585
    },
    {
        "Abstract": "Automatic rumor detection is technically very challenging In this work we try to learn discriminative features from tweets content by following their nonsequential propagation structure and generate more powerful representations for identifying different type of rumors We propose two recursive neural models based on a bottomup and a topdown treestructured neural networks for rumor representation learning and classification which naturally conform to the propagation layout of tweets Results on two public Twitter datasets demonstrate that our recursive neural models 1 achieve much better performance than stateoftheart approaches 2 demonstrate superior capacity on detecting rumors at very early stage",
        "A1": "Automatic rumor detection",
        "A2": "",
        "A41": " learn discriminative feature",
        "A51": " by following their nonsequential propagation structure and generate more powerful representations for identifying different type of rumors ",
        "A61": "",
        "A10": "",
        "A7": " two public Twitter datasets",
        "A83": "",
        "A82": "approaches 2 demonstrate superior capacity on detecting rumors at very early stage",
        "A81": "neural models 1 achieve much better performance than stateoftheart",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " a bottomup and a topdown treestructured neural networks",
        "A42": "two recursive neural models based on a bottomup and a topdown treestructured neural networks for rumor representation learning and classification",
        "A45": "",
        "am_id": 17620772
    },
    {
        "Abstract": "Multimodal affective computing learning to recognize and interpret human affect and subjective information from multiple data sources is still challenging because i it is hard to extract informative features to represent human affects from heterogeneous inputs ii current fusion strategies only fuse different modalities at abstract levels ignoring timedependent interactions between modalities Addressing such issues we introduce a hierarchical multimodal architecture with attention and wordlevel fusion to classify utterancelevel sentiment and emotion from text and audio data Our introduced model outperforms stateoftheart approaches on published datasets and we demonstrate that our models synchronized attention over modalities offers visual interpretability",
        "A1": " we introduce a hierarchical multimodal architecture with attention and wordlevel fusion to classify utterancelevel sentiment and emotion from text and audio data",
        "A2": "Multimodal affective computing learning to recognize and interpret human affect and subjective information from multiple data sources is still challenging ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "we demonstrate that our models synchronized attention over modalities offers visual interpretability",
        "A81": "outperforms stateoftheart approaches on published datasets",
        "A64": "",
        "A54": "",
        "A44": "a hierarchical multimodal architecture with attention and wordlevel fusion to classify utterancelevel sentiment and emotion from text and audio data",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 428988572
    },
    {
        "Abstract": "Understanding temporal and causal relations between events is a fundamental natural language understanding task Because a cause must occur earlier than its effect temporal and causal relations are closely related and one relation often dictates the value of the other However limited attention has been paid to studying these two relations jointly This paper presents a joint inference framework for them using constrained conditional models CCMs Specifically we formulate the joint problem as an integer linear programming ILP problem enforcing constraints that are inherent in the nature of time and causality We show that the joint inference framework results in statistically significant improvement in the extraction of both temporal and causal relations from text1",
        "A1": "Understanding temporal and causal relations between events",
        "A2": "limited attention has been paid to studying these two relations jointly",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "statistically significant improvement in the extraction of both temporal and causal relations from text",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "an integer linear programming ILP problem",
        "A44": "using constrained conditional models CCMs",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 171840597
    },
    {
        "Abstract": "Predicting a readers rating of text quality is a challenging task that involves estimating different subjective aspects of the text like structure clarity etc Such subjective aspects are better handled using cognitive information One such source of cognitive information is gaze behaviour In this paper we show that gaze behaviour does indeed help in effectively predicting the rating of text quality To do this we first model text quality as a function of three properties  organization coherence and cohesion Then we demonstrate how capturing gaze behaviour helps in predicting each of these properties and hence the overall quality by reporting improvements obtained by adding gaze features to traditional textual features for score prediction We also hypothesize that if a reader has fully understood the text the corresponding gaze behaviour would give a better indication of the assigned rating as opposed to partial understanding Our experiments validate this hypothesis by showing greater agreement between the given rating and the predicted rating when the reader has a full understanding of the text",
        "A1": "we show that gaze behaviour does indeed help in effectively predicting the rating of text quality",
        "A2": "a challenging task that involves estimating different subjective aspects of the text like structure clarity",
        "A41": "we first model text quality as a function of three properties  organization coherence and cohesion Then we demonstrate how capturing gaze behaviour helps in predicting each of these properties and hence the overall quality by reporting improvements obtained by adding gaze features to traditional textual features for score prediction",
        "A51": "gaze behaviour",
        "A61": "",
        "A10": "",
        "A7": " Our experiments validate this hypothesis by showing greater agreement between the given rating and the predicted rating when the reader has a full understanding of the text",
        "A83": "",
        "A82": "we show that gaze behaviour does indeed help in effectively predicting the rating of text quality",
        "A81": "we demonstrate how capturing gaze behaviour helps in predicting each of these properties and hence the overall quality",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 356581715
    },
    {
        "Abstract": "Text in many domains involves a significant amount of named entities Predicting the entity names is often challenging for a language model as they appear less frequent on the training corpus In this paper we propose a novel and effective approach to building a discriminative language model which can learn the entity names by leveraging their entity type information We also introduce two benchmark datasets based on recipes and Java programming codes on which we evaluate the proposed model Experimental results show that our model achieves 522 better perplexity in recipe generation and 2206 on code generation than the stateoftheart language models",
        "A1": "Predicting the entity names",
        "A2": "Predicting the entity names is often challenging for a language model",
        "A41": "we propose a novel and effective approach to building a discriminative language model which can learn the entity names ",
        "A51": "",
        "A61": "by leveraging their entity type information ",
        "A10": " Experimental results show that our model achieves 522 better perplexity in recipe generation and 2206 on code generation than the stateoftheart language models",
        "A7": "We also introduce two benchmark datasets based on recipes and Java programming codes on which we evaluate the proposed model ",
        "A83": "",
        "A82": " 2206 on code generation than the stateoftheart language models",
        "A81": "our model achieves 522 better perplexity in recipe generation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "two benchmark datasets based on recipes and Java programming codes",
        "am_id": 194737717
    },
    {
        "Abstract": "This paper presents the EntityDuet Neural Ranking Model EDRM which introduces knowledge graphs to neural search systems EDRM represents queries and documents by their words and entity annotations The semantics from knowledge graphs are integrated in the distributed representations of their entities while the ranking is conducted by interactionbased neural ranking networks The two components are learned endtoend making EDRM a natural combination of entityoriented search and neural information retrieval Our experiments on a commercial search log demonstrate the effectiveness of EDRM Our analyses reveal that knowledge graph semantics significantly improve the generalization ability of neural ranking models",
        "A1": "presents the EntityDuet Neural Ranking Model EDRM",
        "A2": "introduces knowledge graphs to neural search systems EDRM represents queries and documents by their words and entity annotations",
        "A41": " the EntityDuet Neural Ranking Model EDRM which introduces knowledge graphs to neural search systems EDRM represents queries and documents by their words and entity annotations",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Our experiments on a commercial search log demonstrate the effectiveness of EDRM ",
        "A83": "",
        "A82": "",
        "A81": " demonstrate the effectiveness of EDRM ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 349445131
    },
    {
        "Abstract": "Sememes are minimum semantic units of concepts in human languages such that each word sense is composed of one or multiple sememes Words are usually manually annotated with their sememes by linguists and form linguistic commonsense knowledge bases widely used in various NLP tasks Recently the lexical sememe prediction task has been introduced It consists of automatically recommending sememes for words which is expected to improve annotation efficiency and consistency However existing methods of lexical sememe prediction typically rely on the external context of words to represent the meaning which usually fails to deal with lowfrequency and outofvocabulary words To address this issue for Chinese we propose a novel framework to take advantage of both internal character information and external context information of words We experiment on HowNet a Chinese sememe knowledge base and demonstrate that our framework outperforms stateoftheart baselines by a large margin and maintains a robust performance even for lowfrequency words i",
        "A1": "propose a novel framework to take advantage of both internal character information and external context information of words",
        "A2": "methods of lexical sememe prediction typically rely on the external context of words to represent the meaning which usually fails to deal with lowfrequency and outofvocabulary words",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our framework outperforms stateoftheart baselines by a large margin and maintains a robust performance even for lowfrequency words i",
        "A7": "We experiment on HowNet a Chinese sememe knowledge base",
        "A83": "",
        "A82": "",
        "A81": "our framework outperforms stateoftheart baselines by a large margin and maintains a robust performance even for lowfrequency words i",
        "A64": "our framework outperforms stateoftheart baselines by a large margin and maintains a robust performance even for lowfrequency words i",
        "A54": "",
        "A44": "we propose a novel framework to take advantage of both internal character information and external context information of words",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 234218193
    },
    {
        "Abstract": "Sentiment analysis in lowresource languages suffers from a lack of annotated corpora to estimate highperforming models Machine translation and bilingual word embeddings provide some relief through crosslingual sentiment approaches However they either require large amounts of parallel data or do not sufficiently capture sentiment information We introduce Bilingual Sentiment Embeddings BLSE which jointly represent sentiment information in a source and target language This model only requires a small bilingual lexicon a sourcelanguage corpus annotated for sentiment and monolingual word embeddings for each language We perform experiments on three language combinations Spanish Catalan Basque for sentencelevel crosslingual sentiment classification and find that our model significantly outperforms stateoftheart methods on four out of six experimental setups as well as capturing complementary information to machine translation Our analysis of the resulting embedding space provides evidence that it represents sentiment information in the resourcepoor target language without any annotated data in that language",
        "A1": "Sentiment analysis",
        "A2": "Sentiment analysis in lowresource languages suffers from a lack of annotated corpo",
        "A41": "only requires a small bilingual lexicon a sourcelanguage corpus annotated for sentiment and monolingual word embeddings for each language",
        "A51": "",
        "A61": "",
        "A10": " significantly",
        "A7": "three language combinations Spanish Catalan Basque for sentencelevel crosslingual sentiment classification",
        "A83": "",
        "A82": "capturing complementary information to machine translation",
        "A81": "our model significantly outperforms stateoftheart methods on four out of six experimental setups",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 156296661
    },
    {
        "Abstract": "The task of adopting a model with good performance to a target domain that is different from the source domain used for training has received considerable attention in sentiment analysis Most existing approaches mainly focus on learning representations that are domaininvariant in both the source and target domains Few of them pay attention to domain specific information which should also be informative In this work we propose a method to simultaneously extract domain specific and invariant representations and train a classifier on each of the representation respectively And we introduce a few target domain labeled data for learning domainspecific information To effectively utilize the target domain labeled data we train the domaininvariant representation based classifier with both the source and target domain labeled data and train the domainspecific representation based classifier with only the target domain labeled data These two classifiers then boost each other in a cotraining style Extensive sentiment analysis experiments demonstrated that the proposed method could achieve better performance than stateoftheart methods",
        "A1": "The task of adopting a model with good performance to a target domain that is different from the source domain used for training",
        "A2": "Most existing approaches mainly focus on learning representations that are domaininvariant in both the source and target domains Few of them pay attention to domain specific information which should also be informative",
        "A41": "a method to simultaneously extract domain specific and invariant representations and train a classifier on each of the representation respectively",
        "A51": "",
        "A61": "Most existing approaches mainly focus on learning representations that are domaininvariant in both the source and target domains Few of them pay attention to domain specific information which should also be informative",
        "A10": "the proposed method could achieve better performance than stateoftheart methods",
        "A7": "Extensive sentiment analysis experiments",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 273081775
    },
    {
        "Abstract": "Deep convolutional neural networks excel at sentiment polarity classification but tend to require substantial amounts of training data which moreover differs quite significantly between domains In this work we present an approach to feed generic cues into the training process of such networks leading to better generalization abilities given limited training data We propose to induce sentiment embeddings via supervision on extrinsic data which are then fed into the model via a dedicated memorybased component We observe significant gains in effectiveness on a range of different datasets in seven different languages",
        "A1": " feed generic cues into the training process of such networks leading to better generalization abilities ",
        "A2": " require substantial amounts of training data ",
        "A41": " an approach to feed generic cues into the training process",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on a range of different datasets in seven different languages",
        "A83": "",
        "A82": "",
        "A81": "observe significant gains in effectiveness ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 132191114
    },
    {
        "Abstract": "We propose Objectoriented Neural Programming OONP a framework for semantically parsing documents in specific domains Basically OONP reads a document and parses it into a predesigned objectoriented data structure that reflects the domainspecific semantics of the document An OONP parser models semantic parsing as a decision process a neural netbased Reader sequentially goes through the document and builds and updates an intermediate ontology during the process to summarize its partial understanding of the text OONP supports a big variety of forms both symbolic and differentiable for representing the state and the document and a rich family of operations to compose the representation An OONP parser can be trained with supervision of different forms and strength including supervised learning SL  reinforcement learning RL and hybrid of the two Our experiments on both synthetic and realworld document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes",
        "A1": "We propose Objectoriented Neural Programming OONP a framework for semantically parsing documents in specific domains",
        "A2": " Basically OONP reads a document and parses it into a predesigned objectoriented data structure that reflects the domainspecific semantics of the document ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " Our experiments on both synthetic and realworld document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes",
        "A7": " An OONP parser can be trained with supervision of different forms and strength including supervised learning SL  reinforcement learning RL and hybrid of the two",
        "A83": "",
        "A82": "",
        "A81": " Our experiments on both synthetic and realworld document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes",
        "A64": "OONP supports a big variety of forms both symbolic and differentiable for representing the state and the document and a rich family of operations to compose the representation",
        "A54": "An OONP parser models semantic parsing as a decision process a neural netbased Reader sequentially goes through the document and builds and updates an intermediate ontology during the process to summarize its partial understanding of the text ",
        "A44": "Objectoriented Neural Programming OONP",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 354263755
    },
    {
        "Abstract": "Recurrent neural network grammars RNNGs are generative models of tree string pairs that rely on neural networks to evaluate derivational choices Parsing with them using beam search yields a variety of incremental complexity metrics such as word surprisal and parser action count When used as regressors against human electrophysiological responses to naturalistic text they derive two amplitude effects an early peak and a P600like later peak By contrast a nonsyntactic neural language model yields no reliable effects Model comparisons attribute the early peak to syntactic composition within the RNNG This pattern of results recommends the RNNGbeam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension",
        "A1": "Recurrent neural network grammars RNNGs",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "RNNGbeam search combination as a mechanistic model of the syntactic processing that occurs during normal human language comprehension",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "neural networks",
        "A42": "generative models of tree string pairs ",
        "A45": "",
        "am_id": 400537224
    },
    {
        "Abstract": "We introduce the task of predicting adverbial presupposition triggers such as also and again Solving such a task requires detecting recurring or similar events in the discourse context and has applications in natural language generation tasks such as summarization and dialogue systems We create two new datasets for the task derived from the Penn Treebank and the Annotated English Gigaword corpora as well as a novel attention mechanism tailored to this task Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters minimizing the added computational cost of our mechanism We demonstrate that our model statistically outperforms a number of baselines including an LSTMbased language model",
        "A1": "We create two new datasets for the task derived from the Penn Treebank and the Annotated English Gigaword corpora as well as a novel attention mechanism tailored to this task",
        "A2": "predicting adverbial presupposition triggers such as also and again",
        "A41": "augments a baseline recurrent neural network without the need for additional trainable parameters minimizing the added computational cost of our mechanism",
        "A51": "recurrent neural network ",
        "A61": "without the need for additional trainable parameters ",
        "A10": "We demonstrate that our model statistically outperforms a number of baselines including an LSTMbased language model",
        "A7": "predicting adverbial presupposition triggers",
        "A83": "",
        "A82": "",
        "A81": "We demonstrate that our model statistically outperforms a number of baselines including an LSTMbased language model",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "two new datasets for the task derived from the Penn Treebank and the Annotated English Gigaword corpora",
        "am_id": 327756423
    },
    {
        "Abstract": "Search engines play a crucial role in our daily lives. Relevance is the core problem of a commercial search engine. It has attracted thousands of researchers from both academia and industry and has been studied for decades. Relevance in a modern search engine has gone far beyond text matching, and now involves tremendous challenges. The semantic gap between queries and URLs is the main barrier for improving base relevance. Clicks help provide hints to improve relevance, but unfortunately for most tail queries, the click information is too sparse, noisy, or missing entirely. For comprehensive relevance, the recency and location sensitivity of results is also critical. In this paper, we give an overview of the solutions for relevance in the Yahoo search engine. We introduce three key techniques for base relevance -- ranking functions, semantic matching features and query rewriting. We also describe solutions for recency sensitive relevance and location sensitive relevance. This work builds upon 20 years of existing efforts on Yahoo search, summarizes the most recent advances and provides a series of practical relevance solutions. The performance reported is based on Yahoo's commercial search engine, where tens of billions of urls are indexed and served by the ranking system.",
        "A1": "summarizes the most recent advances and provides a series of practical relevance solutions",
        "A2": "Relevance",
        "A41": " ranking functions, semantic matching features and query rewriting.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "solutions for recency sensitive relevance and location sensitive relevance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 113834176
    },
    {
        "Abstract": "Every year, millions of new students enter higher educational programs. Publicly available rankings of academic programs play a key role in prospective students' decisions regarding which universities to apply to and enroll in. While surveys indicate that majority of freshmen enter college to get good jobs after graduation, established methodologies for ranking universities rely on indirect indicators of career outcomes such as reputational assessments of the universities among academic peers, acceptance and graduation rates, learning environment, and availability of research funding. In addition, many of these methodologies rely on arbitrary choices of weighting factors for the different ranking indicators, and suffer from lack of analyses of statistical stability. In this paper, we addresses these challenges holistically by developing a novel methodology for ranking and recommending universities for different professions on the basis of career outcomes of professionals who graduated from those schools. Our methodology incorporates a number of techniques for achieving statistical stability, and represents a step towards personalized educational recommendations based on interests and ambitions of individuals. We have applied this methodology on LinkedIn's Economic Graph data of over 400 million professional from around the world. The resulting university rankings have been made available to the public and demonstrate that there are valuable insights to be gleaned from professional career data on LinkedIn.",
        "A1": "In this paper, we addresses these challenges holistically by developing a novel methodology for ranking and recommending universities for different professions on the basis of career outcomes of professionals who graduated from those schools. ",
        "A2": "Every year, millions of new students enter higher educational programs. Publicly available rankings of academic programs play a key role in prospective students' decisions regarding which universities to apply to and enroll in. While surveys indicate that majority of freshmen enter college to get good jobs after graduation, established methodologies for ranking universities rely on indirect indicators of career outcomes such as reputational assessments of the universities among academic peers, acceptance and graduation rates, learning environment, and availability of research funding. In addition, many of these methodologies rely on arbitrary choices of weighting factors for the different ranking indicators, and suffer from lack of analyses of statistical stability. ",
        "A41": " we addresses these challenges holistically by developing a novel methodology for ranking and recommending universities for different professions on the basis of career outcomes of professionals who graduated from those schools",
        "A51": "on the basis of career outcomes of professionals who graduated from those schools",
        "A61": " Our methodology incorporates a number of techniques for achieving statistical stability, and represents a step towards personalized educational recommendations based on interests and ambitions of individuals",
        "A10": "We have applied this methodology on LinkedIn's Economic Graph data of over 400 million professional from around the world. The resulting university rankings have been made available to the public and demonstrate that there are valuable insights to be gleaned from professional career data on LinkedIn.",
        "A7": "We have applied this methodology on LinkedIn's Economic Graph data of over 400 million professional from around the world",
        "A83": "",
        "A82": "",
        "A81": "he resulting university rankings have been made available to the public and demonstrate that there are valuable insights to be gleaned from professional career data on LinkedIn.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 321796909
    },
    {
        "Abstract": "We have seen an explosive growth of mobile usage, particularly on mobile apps. It is more important than ever to be able to properly evaluate mobile app release. A/B testing is a standard framework to evaluate new ideas. We have seen much of its applications in the online world across the industry [9,10,12]. Running A/B tests on mobile apps turns out to be quite different, and much of it is attributed to the fact that we cannot ship code easily to mobile apps other than going through a lengthy build, review and release process. Mobile infrastructure and user behavior differences also contribute to how A/B tests are conducted differently on mobile apps, which will be discussed in details in this paper. In addition to measuring features individually in the new app version through randomized A/B tests, we have a unique opportunity to evaluate the mobile app as a whole using the quasi-experimental framework [21]. Not all features can be A/B tested due to infrastructure changes and wholistic product redesign. We propose and establish quasi-experimental techniques for measuring impact from mobile app release, with results shared from a recent major app launch at LinkedIn.",
        "A1": " to be able to properly evaluate mobile app release",
        "A2": " We propose and establish quasi-experimental techniques for measuring impact from mobile app release, with results shared from a recent major app launch at LinkedIn.",
        "A41": " quasi-experimental techniques for measuring impact from mobile app release",
        "A51": "A/B testing",
        "A61": "",
        "A10": " Running A/B tests on mobile apps turns out to be quite different, and much of it is attributed to the fact that we cannot ship code easily to mobile apps other than going through a lengthy build, review and release process",
        "A7": "We propose and establish quasi-experimental techniques for measuring impact from mobile app release",
        "A83": " we have a unique opportunity to evaluate the mobile app as a whole using the quasi-experimental framework ",
        "A82": "In addition to measuring features individually in the new app version through randomized A/B tests",
        "A81": " properly evaluate mobile app release",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 412988737
    },
    {
        "Abstract": "The overwhelming majority of existing domain adaptation methods makes an assumption of freely available source domain data. An equal access to both source and target data makes it possible to measure the discrepancy between their distributions and to build representations common to both target and source domains. In reality, such a simplifying assumption rarely holds, since source data are routinely a subject of legal and contractual constraints between data owners and data customers. When source domain data can not be accessed, decision making procedures are often available for adaptation nevertheless. These procedures are often presented in the form of classification, identification, ranking etc. rules trained on source data and made ready for a direct deployment and later reuse. In other cases, the owner of a source data is allowed to share a few representative examples such as class means. In this paper we address the domain adaptation problem in real world applications, where the reuse of source domain data is limited to classification rules or a few representative examples. We extend the recent techniques of feature corruption and their marginalization , both in supervised and unsupervised settings. We test and compare them on private and publicly available source datasets and show that significant performance gains can be achieved despite the absence of source data and shortage of labeled target data.",
        "A1": "address the domain adaptation problem in real world applications",
        "A2": "address the domain adaptation problem in real world applications",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " test and compare them on private and publicly available source datasets",
        "A83": "",
        "A82": "",
        "A81": " significant performance gains can be achieved despite the absence of source data and shortage of labeled target data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 281238453
    },
    {
        "Abstract": "Entity linking links entity mentions in text to the corresponding entities in a knowledge base (KB) and has many applications in both open domain and specific domains. For example, in the recruitment domain, linking employer names in job postings or resumes to entities in an employer KB is very important to many business applications. In this paper, we focus on this employer name normalization task, which has several unique challenges: handling employer names from both job postings and resumes, leveraging the corresponding location context, and handling name variations, irrelevant input data, and noises in the KB. We present a system called CompanyDepot which contains a machine learning based approach CompanyDepot-ML and a heuristic approach CompanyDepot-H to address these challenges in three steps: (1) searching for candidate entities based on a customized search engine for the KB; (2) ranking the candidate entities using learning-to-rank methods or heuristics; and (3) validating the top-ranked entity via binary classification or heuristics. While CompanyDepot-ML shows better extendability and flexibility, CompanyDepot-H serves as a strong baseline and useful way to collect training data for CompanyDepot-ML. The proposed system achieves 2.5%-21.4% higher coverage at the same precision level compared to an existing system used at CareerBuilder over multiple real-world datasets. Applying the system to a similar task of academic institution name normalization further shows the generalization ability of the method.",
        "A1": "we focus on this employer name normalization task, which has several unique challenges: handling employer names from both job postings and resumes, leveraging the corresponding location context, and handling name variations, irrelevant input data, and noises in the KB. ",
        "A2": "Entity linking links entity mentions in text to the corresponding entities in a knowledge base (KB) and has many applications in both open domain and specific domains.",
        "A41": "a system called CompanyDepot which contains a machine learning based approach CompanyDepot-ML and a heuristic approach CompanyDepot-H to address these challenges in three steps",
        "A51": " CompanyDepot",
        "A61": "CompanyDepot-H serves as a strong baseline and useful way to collect training data for CompanyDepot-ML. The proposed system achieves 2.5%-21.4% higher coverage at the same precision level compared to an existing system used at CareerBuilder over multiple real-world datasets.",
        "A10": "",
        "A7": "Applying the system to a similar task of academic institution name normalization",
        "A83": "",
        "A82": "",
        "A81": "further shows the generalization ability of the method.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 219825063
    },
    {
        "Abstract": "The first step to saving energy in the home is often to create an energy breakdown: the amount of energy used by each individual appliance in the home. Unfortunately, current techniques that produce an energy breakdown are not scalable: they require hardware to be installed in each and every home. In this paper, we propose a more scalable solution called Gemello that estimates the energy breakdown for one home by matching it with similar homes for which the breakdown is already known. This matching requires only the monthly energy bill and household characteristics such as square footage of the home and the size of the household. We evaluate this approach using 57 homes and results indicate that the accuracy of Gemello is comparable to or better than existing techniques that use sensing infrastructure in each home. The information required by Gemello is often publicly available and, as such, it can be immediately applied to many homes around the world.",
        "A1": "estimates the energy breakdown for one home",
        "A2": " current techniques that produce an energy breakdown are not scalable: they require hardware to be installed in each and every home",
        "A41": "a more scalable solution called Gemello that estimates the energy breakdown for one home ",
        "A51": "by matching it with similar homes for which the breakdown is already known",
        "A61": "This matching requires only the monthly energy bill and household characteristics such as square footage of the home and the size of the household",
        "A10": "more scalable",
        "A7": "evaluate this approach using 57 homes and results indicate that the accuracy",
        "A83": "",
        "A82": "",
        "A81": "Gemello is comparable to or better than existing techniques that use sensing infrastructure in each home",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 448920147
    },
    {
        "Abstract": "In aerodynamics related design, analysis and optimization problems, flow fields are simulated using computational fluid dynamics (CFD) solvers. However, CFD simulation is usually a computationally expensive, memory demanding and time consuming iterative process. These drawbacks of CFD limit opportunities for design space exploration and forbid interactive design. We propose a general and flexible approximation model for real-time prediction of non-uniform steady laminar flow in a 2D or 3D domain based on convolutional neural networks (CNNs). We explored alternatives for the geometry representation and the network architecture of CNNs. We show that convolutional neural networks can estimate the velocity field two orders of magnitude faster than a GPU-accelerated CFD solver and four orders of magnitude faster than a CPU-based CFD solver at a cost of a low error rate. This approach can provide immediate feedback for real-time design iterations at the early stage of design. Compared with existing approximation models in the aerodynamics domain, CNNs enable an efficient estimation for the entire velocity field. Furthermore, designers and engineers can directly apply the CNN approximation model in their design space exploration algorithms without training extra lower-dimensional surrogate models.",
        "A1": " We propose a general and flexible approximation model for real-time prediction of non-uniform steady laminar flow in a 2D or 3D domain based on convolutional neural networks (CNNs). ",
        "A2": "real-time prediction of non-uniform steady laminar flow in a 2D or 3D domain ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " provide immediate feedback for real-time design iterations at the early stage of design",
        "A7": "",
        "A83": "",
        "A82": "apply the CNN approximation model in their design space exploration algorithms without training extra lower-dimensional surrogate models.",
        "A81": "CNNs enable an efficient estimation for the entire velocity field.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " enable an efficient estimation for the entire velocity field.",
        "A52": "",
        "A42": "model for real-time prediction of non-uniform steady laminar flow in a 2D or 3D domain based on convolutional neural networks (CNNs).",
        "A45": "",
        "am_id": 308871320
    },
    {
        "Abstract": "Can we find heterogeneous clusters hidden in data sets with 80% noise? Although such settings occur in the real-world, we struggle to find methods from the abundance of clustering techniques that perform well with noise at this level. Indeed, perhaps this is enough of a departure from classical clustering to warrant its study as a separate problem. In this paper we present SkinnyDip which, based on Hartigan's elegant dip test of unimodality, represents an intriguing approach to clustering with an attractive set of properties. Specifically, SkinnyDip is highly noise-robust, practically parameter-free and completely deterministic. SkinnyDip never performs multivariate distance calculations, but rather employs insightful recursion based on \"dips\" into univariate projections of the data. It is able to detect a range of cluster shapes and densities, assuming only that each cluster admits a unimodal shape. Practically, its run-time grows linearly with the data. Finally, for high-dimensional data, continuity properties of the dip enable SkinnyDip to exploit multimodal projection pursuit in order to find an appropriate basis for clustering. Although not without its limitations, SkinnyDip compares favorably to a variety of clustering approaches on synthetic and real data, particularly in high-noise settings.",
        "A1": "Can we find heterogeneous clusters hidden in data sets with 80% noise?",
        "A2": "find methods from the abundance of clustering techniques that perform well with noise at this level",
        "A41": "represents an intriguing approach to clustering with an attractive set of properties",
        "A51": "based on Hartigan's elegant dip test of unimodality",
        "A61": "SkinnyDip never performs multivariate distance calculations, but rather employs insightful recursion based on \"dips\" into univariate projections of the data",
        "A10": "SkinnyDip compares favorably to a variety of clustering approaches on synthetic and real data, particularly in high-noise settings.",
        "A7": "",
        "A83": "for high-dimensional data, continuity properties of the dip enable SkinnyDip to exploit multimodal projection pursuit in order to find an appropriate basis for clustering.",
        "A82": "It is able to detect a range of cluster shapes and densities, assuming only that each cluster admits a unimodal shape.",
        "A81": "SkinnyDip is highly noise-robust, practically parameter-free and completely deterministic",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 68634557
    },
    {
        "Abstract": "One of the overarching tasks of document analysis is to find what topics people talk about. One of the main techniques for this purpose is topic modeling. So far many models have been proposed. However, the existing models typically perform full analysis on the whole data to find all topics. This is certainly useful, but in practice we found that the user almost always also wants to perform more detailed analyses on some specific aspects, which we refer to as targets (or targeted aspects). Current full-analysis models are not suitable for such analyses as their generated topics are often too coarse and may not even be on target. For example, given a set of tweets about e-cigarette, one may want to find out what topics under discussion are specifically related to children. Likewise, given a collection of online reviews about a camera, a consumer or camera manufacturer may be interested in finding out all topics about the camera's screen, the targeted aspect. As we will see in our experiments, current full topic models are ineffective for such targeted analyses. This paper studies this problem and proposes a novel targeted topic model (TTM) to enable focused analyses on any specific aspect of interest. Our experimental results demonstrate the effectiveness of the TTM.",
        "A1": "This paper studies this problem and proposes a novel targeted topic model (TTM) to enable focused analyses on any specific aspect of interest",
        "A2": "Current full-analysis models are not suitable for such analyses as their generated topics are often too coarse and may not even be on target.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our experimental results demonstrate the effectiveness of the TTM.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Our experimental results demonstrate the effectiveness of the TTM.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a novel targeted topic model (TTM) to enable focused analyses on any specific aspect of interest",
        "A45": "",
        "am_id": 357522049
    },
    {
        "Abstract": "Given a bipartite graph of users and the products that they review, or followers and followees, how can we detect fake reviews or follows? Existing fraud detection methods (spectral, etc.) try to identify dense subgraphs of nodes that are sparsely connected to the remaining graph. Fraudsters can evade these methods using camouflage, by adding reviews or follows with honest targets so that they look \"normal\". Even worse, some fraudsters use hijacked accounts from honest users, and then the camouflage is indeed organic. Our focus is to spot fraudsters in the presence of camouflage or hijacked accounts. We propose FRAUDAR, an algorithm that (a) is camouflage-resistant, (b) provides upper bounds on the effectiveness of fraudsters, and (c) is effective in real-world data. Experimental results under various attacks show that FRAUDAR outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud. Additionally, in real-world experiments with a Twitter follower-followee graph of 1.47 billion edges, FRAUDAR successfully detected a subgraph of more than 4000 detected accounts, of which a majority had tweets showing that they used follower-buying services.",
        "A1": "spot fraudsters in the presence of camouflage or hijacked accounts",
        "A2": "detect fake reviews or follows",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "a Twitter follower-followee graph of 1.47 billion edges",
        "A83": "",
        "A82": "esults under various attacks show that FRAUDAR outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud",
        "A81": "FRAUDAR successfully detected a subgraph of more than 4000 detected accounts",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "outperforms the top competitor in accuracy of detecting both camouflaged and non-camouflaged fraud",
        "A53": "fraud detection",
        "A43": "FRAUDAR",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 458413455
    },
    {
        "Abstract": "Representing and summarizing human behaviors with rich contexts facilitates behavioral sciences and user-oriented services. Traditional behavioral modeling represents a behavior as a tuple in which each element is one contextual factor of one type, and the tensor-based summaries look for high-order dense blocks by clustering the values (including timestamps) in each dimension. However, the human behaviors are multicontextual and dynamic: (1) each behavior takes place within multiple contexts in a few dimensions, which requires the representation to enable non-value and set-values for each dimension; (2) many behavior collections, such as tweets or papers, evolve over time. In this paper, we represent the behavioral data as a two-level matrix (temporal-behaviors by dimensional-values) and propose a novel representation for behavioral summary called Tartan that includes a set of dimensions, the values in each dimension, a list of consecutive time slices and the behaviors in each slice. We further develop a propagation method CatchTartan to catch the dynamic multicontextual patterns from the temporal multidimensional data in a principled and scalable way: it determines the meaningfulness of updating every element in the Tartan by minimizing the encoding cost in a compression manner. CatchTartan outperforms the baselines on both the accuracy and speed. We apply CatchTartan to four Twitter datasets up to 10 million tweets and the DBLP data, providing comprehensive summaries for the events, human life and scientific development.",
        "A1": "Representing and summarizing human behaviors with rich contexts facilitates behavioral sciences and user-oriented services",
        "A2": "represent the behavioral data as a two-level matrix (temporal-behaviors by dimensional-values) and propose a novel representation for behavioral summary",
        "A41": "a propagation method CatchTartan to catch the dynamic multicontextual patterns from the temporal multidimensional data in a principled and scalable way",
        "A51": "by minimizing the encoding cost in a compression manner",
        "A61": "",
        "A10": "",
        "A7": "apply CatchTartan to four Twitter datasets up to 10 million tweets and the DBLP data, providing comprehensive summaries for the events, human life and scientific development",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 191340581
    },
    {
        "Abstract": "Given a large, online stream of multiple co-evolving event sequences, such as sensor data and Web-click logs, that contains various types of non-linear dynamic evolving patterns of different durations, how can we efficiently and effectively capture important patterns? How do we go about forecasting long-term future events? In this paper, we present REGIMECAST, an efficient and effective method for forecasting co-evolving data streams. REGIMECAST is designed as an adaptive non-linear dynamical system, which is inspired by the concept of \"regime shifts\" in natural dynamical systems. Our method has the following properties: (a) Effective: it operates on large data streams, captures important patterns and performs long-term forecasting; (b) Adaptive: it automatically and incrementally recognizes the latent trends and dynamic evolution patterns (i.e., regimes) that are unknown in advance; (c) Scalable: it is fast and the computation cost does not depend on the length of data streams; (d) Any-time: it provides a response at any time and generates long-range future events. Extensive experiments on real datasets demonstrate that REGIMECAST does indeed make long-range forecasts, and it outperforms state-of-the-art competitors as regards accuracy and speed.",
        "A1": "present REGIMECAST",
        "A2": "How do we go about forecasting long-term future events?",
        "A41": "REGIMECAST",
        "A51": "the concept of \"regime shifts\"",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "REGIMECAST does indeed make long-range forecasts, and it outperforms state-of-the-art competitors as regards accuracy and speed.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 151341315
    },
    {
        "Abstract": "The all-distances sketch (ADS) has recently emerged as a promising paradigm of graph neighborhood sketching. An ADS is a probabilistic data structure that is defined for each vertex of a graph. ADSs facilitate accurate estimation of many useful indicators for network analysis with the guarantee of accuracy, and the ADSs for all the vertices in a graph can be computed in near-linear time. Because of these useful properties, ADS has attracted considerable attention. However, a critical drawback of ADS is its space requirement, which tends to be much larger than that of the graph itself. In the present study, we address this issue by designing a new graph sketching scheme, namely, sketch retrieval shortcuts (SRS). Although SRSs are more space-efficient than ADSs by an order of magnitude, an ADS of any vertex can be quickly retrieved from the SRSs. The retrieved ADSs can be used to estimate the aforementioned indicators in exactly the same manner as with plain ADSs, inheriting the same accuracy guarantee. Our experiments on real-world networks demonstrate the usefulness of SRSs as a practical back-end of large-scale graph data mining.",
        "A1": "designing a new graph sketching scheme, namely, sketch retrieval shortcuts ",
        "A2": "However, a critical drawback of ADS is its space requirement, which tends to be much larger than that of the graph itself.",
        "A41": "sketch retrieval shortcuts (SRS)",
        "A51": "",
        "A61": " The retrieved ADSs can be used to estimate the aforementioned indicators in exactly the same manner as with plain ADSs, inheriting the same accuracy guarantee",
        "A10": "",
        "A7": "Our experiments on real-world networks",
        "A83": "",
        "A82": "",
        "A81": "the usefulness of SRSs as a practical back-end of large-scale graph data mining.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 17092311
    },
    {
        "Abstract": "Measuring node proximity on large scale networks is a fundamental building block in many application domains, ranging from computer vision, e-commerce, social networks, software engineering, disaster management to biology and epidemiology. The state of the art (e.g., random walk based methods) typically assumes the input network is given a priori, with the known network topology and the associated edge weights. A few recent works aim to further infer the optimal edge weights based on the side information. This paper generalizes the challenge in multiple dimensions, aiming to learn optimal networks for node proximity measures. First ( optimization scope ), our proposed formulation explores a much larger parameter space, so that it is able to simultaneously infer the optimal network topology and the associated edge weights. This is important as a noisy or missing edge could greatly mislead the network node proximity measures. Second ( optimization granularity ), while all the existing works assume one common optimal network, be it given as the input or learned by the algorithms, exists for all queries, our method performs optimization at a much finer granularity, essentially being able to infer an optimal network that is specific to a given query. Third ( optimization efficiency ), we carefully design our algorithms with a linear complexity wrt the neighborhood size of the user preference set. We perform extensive empirical evaluations on a diverse set of 10+ real networks, which show that the proposed algorithms (1) consistently outperform the existing methods on all six commonly used metrics; (2) empirically scale sub-linearly to billion-scale networks and (3) respond in a fraction of a second.",
        "A1": "learn optimal networks for node proximity measures.",
        "A2": "generalizes the challenge in multiple dimensions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "empirically scale sub-linearly to billion-scale networks and (3) respond in a fraction of a second",
        "A7": "extensive empirical evaluations on a diverse set of 10+ real networks,",
        "A83": " respond in a fraction of a second",
        "A82": "empirically scale sub-linearly to billion-scale networks",
        "A81": "consistently outperform the existing methods on all six commonly used metrics;",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "proposed formulation explores a much larger parameter space",
        "A53": "a linear complexity wrt the neighborhood size of the user preference set",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 464844370
    },
    {
        "Abstract": "Point-of-interest (POI) recommendation, which helps mobile users explore new places, has become an important location-based service. Existing approaches for POI recommendation have been mainly focused on exploiting the information about user preferences, social influence, and geographical influence. However, these approaches cannot handle the scenario where users are expecting to have POI recommendation for a specific time period. To this end, in this paper, we propose a unified recommender system, named the 'Where and When to gO' (WWO) recommender system, to integrate the user interests and their evolving sequential preferences with temporal interval assessment. As a result, the WWO system can make recommendations dynamically for a specific time period and the traditional POI recommender system can be treated as the special case of the WWO system by setting this time period long enough. Specifically, to quantify users' sequential preferences, we consider the distributions of the temporal intervals between dependent POIs in the historical check-in sequences. Then, to estimate the distributions with only sparse observations, we develop the low-rank graph construction model, which identifies a set of bi-weighted graph bases so as to learn the static user preferences and the dynamic sequential preferences in a coherent way. Finally, we evaluate the proposed approach using real-world data sets from several location-based social networks (LBSNs). The experimental results show that our method outperforms the state-of-the-art approaches for POI recommendation in terms of various metrics, such as F-measure and NDCG, with a significant margin.",
        "A1": "to integrate the user interests and their evolving sequential preferences with temporal interval assessment.",
        "A2": "the WWO system can make recommendations dynamically for a specific time period and the traditional POI recommender system can be treated as the special case of the WWO system by setting this time period long enough.",
        "A41": "a unified recommender system",
        "A51": "",
        "A61": "",
        "A10": "The experimental results show that our method outperforms the state-of-the-art approaches for POI recommendation in terms of various metrics, such as F-measure and NDCG, with a significant margin.",
        "A7": "real-world data sets from several location-based social networks (LBSNs).",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms the state-of-the-art approaches for POI recommendation in terms of various metrics, such as F-measure and NDCG, with a significant margin.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " identifies a set of bi-weighted graph bases so as to learn the static user preferences and the dynamic sequential preferences in a coherent way.",
        "A52": "",
        "A42": "the low-rank graph construction model",
        "A45": "",
        "am_id": 364184967
    },
    {
        "Abstract": "This paper introduces the first generic version of data dependent dissimilarity and shows that it provides a better closest match than distance measures for three existing algorithms in clustering, anomaly detection and multi-label classification. For each algorithm, we show that by simply replacing the distance measure with the data dependent dissimilarity measure, it overcomes a key weakness of the otherwise unchanged algorithm.",
        "A1": "introduces the first generic version of data dependent dissimilarity",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "overcomes a key weakness of the otherwise unchanged algorithm",
        "A7": "by simply replacing the distance measure with the data dependent dissimilarity measure",
        "A83": "",
        "A82": "",
        "A81": "overcomes a key weakness of the otherwise unchanged algorithm",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "provides a better closest match than distance measures for three existing algorithms in clustering, anomaly detection and multi-label classification",
        "A53": "",
        "A43": "the first generic version of data dependent dissimilarity",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 75005309
    },
    {
        "Abstract": "In this work we consider the problem of anomaly detection in heterogeneous, multivariate, variable-length time series datasets. Our focus is on the aviation safety domain, where data objects are flights and time series are sensor readings and pilot switches. In this context the goal is to detect anomalous flight segments, due to mechanical, environmental, or human factors in order to identifying operationally significant events and highlight potential safety risks. For this purpose, we propose a framework which represents each flight using a semi-Markov switching vector autoregressive (SMS-VAR) model. Detection of anomalies is then based on measuring dissimilarities between the model's prediction and data observation. The framework is scalable, due to the inherent parallel nature of most computations, and can be used to perform online anomaly detection. Extensive experimental results on simulated and real datasets illustrate that the framework can detect various types of anomalies along with the key parameters involved.",
        "A1": "propose a framework which represents each flight using a semi-Markov switching vector autoregressive (SMS-VAR) model",
        "A2": "detect anomalous flight segments",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " on simulated and real datasets",
        "A83": "",
        "A82": "",
        "A81": "the framework can detect various types of anomalies along with the key parameters involved",
        "A64": "using a semi-Markov switching vector autoregressive (SMS-VAR) model",
        "A54": "",
        "A44": "a framework which represents each flight",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 356645958
    },
    {
        "Abstract": "Forecasting large-scale societal events like civil unrest movements, disease outbreaks, and elections is an important and challenging problem. From the perspective of human analysts and policy makers, forecasting algorithms must not only make accurate predictions but must also provide supporting evidence, e.g., the causal factors related to the event of interest. We develop a novel multiple instance learning based approach that jointly tackles the problem of identifying evidence-based precursors and forecasts events into the future. Specifically, given a collection of streaming news articles from multiple sources we develop a nested multiple instance learning approach to forecast significant societal events such as protests. Using data from three countries in Latin America, we demonstrate how our approach is able to consistently identify news articles considered as precursors for protests. Our empirical evaluation demonstrates the strengths of our proposed approach in filtering candidate precursors, in forecasting the occurrence of events with a lead time advantage and in accurately predicting the characteristics of civil unrest events.",
        "A1": "Forecasting large-scale societal events like civil unrest movements, disease outbreaks, and elections ",
        "A2": "Forecasting large-scale societal events like civil unrest movements, disease outbreaks, and elections ",
        "A41": "a novel multiple instance learning based approach that jointly tackles the problem of identifying evidence-based precursors and forecasts events into the future. ",
        "A51": "a novel multiple instance learning based",
        "A61": "",
        "A10": "",
        "A7": "Using data from three countries in Latin America, we demonstrate how our approach is able to consistently identify news articles considered as precursors for protest",
        "A83": "",
        "A82": "in forecasting the occurrence of events with a lead time advantage and in accurately predicting the characteristics of civil unrest events.",
        "A81": " the strengths of our proposed approach in filtering candidate precursors,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 497671625
    },
    {
        "Abstract": "Detecting communities (or modular structures) and structural hole spanners, the nodes bridging different communities in a network, are two essential tasks in the realm of network analytics. Due to the topological nature of communities and structural hole spanners, these two tasks are naturally tangled with each other, while there has been little synergy between them. In this paper, we propose a novel harmonic modularity method to tackle both tasks simultaneously. Specifically, we apply a harmonic function to measure the smoothness of community structure and to obtain the community indicator. We then investigate the sparsity level of the interactions between communities, with particular emphasis on the nodes connecting to multiple communities, to discriminate the indicator of SH spanners and assist the community guidance. Extensive experiments on real-world networks demonstrate that our proposed method outperforms several state-of-the-art methods in the community detection task and also in the SH spanner identification task (even the methods that require the supervised community information). Furthermore, by removing the SH spanners spotted by our method, we show that the quality of other community detection methods can be further improved.",
        "A1": "tackle both tasks simultaneously",
        "A2": "we propose a novel harmonic modularity method to tackle both tasks simultaneously",
        "A41": " a novel harmonic modularity method to tackle both tasks simultaneously. ",
        "A51": " a harmonic function to measure the smoothness of community structure and to obtain the community indicator",
        "A61": " Due to the topological nature of communities and structural hole spanners, these two tasks are naturally tangled with each other, while there has been little synergy between them. In this paper, we propose a novel harmonic modularity method to tackle both tasks simultaneously",
        "A10": " Extensive experiments on real-world networks demonstrate that our proposed method outperforms several state-of-the-art methods in the community detection task and also in the SH spanner identification task (even the methods that require the supervised community information)",
        "A7": "Specifically, we apply a harmonic function to measure the smoothness of community structure and to obtain the community indicator. We then investigate the sparsity level of the interactions between communities, with particular emphasis on the nodes connecting to multiple communities, to discriminate the indicator of SH spanners and assist the community guidance.",
        "A83": "the quality of other community detection methods can be further improved.",
        "A82": "and also in the SH spanner identification task (even the methods that require the supervised community information)",
        "A81": "our proposed method outperforms several state-of-the-art methods in the community detection task ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 494901604
    },
    {
        "Abstract": "In multi-view learning applications, like multimedia analysis and information retrieval, we often encounter the corrupted view problem in which the data are corrupted by two different types of noises, i.e., the intra- and inter-view noises. The noises may affect these applications that commonly acquire complementary representations from different views. Therefore, how to denoise corrupted views from multi-view data is of great importance for applications that integrate and analyze representations from different views. However, the heterogeneity among multi-view representations brings a significant challenge on denoising corrupted views. To address this challenge, we propose a general framework to jointly denoise corrupted views in this paper. Specifically, aiming at capturing the semantic complementarity and distributional similarity among different views, a novel Heterogeneous Linear Metric Learning (HLML) model with low-rank regularization, leave-one-out validation, and pseudo-metric constraints is proposed. Our method linearly maps multi-view data to a high-dimensional feature-homogeneous space that embeds the complementary information from different views. Furthermore, to remove the intra- and inter-view noises, we present a new Multi-view Semi-supervised Collaborative Denoising (MSCD) method with elementary transformation constraints and gradient energy competition to establish the complementary relationship among the heterogeneous representations. Experimental results demonstrate that our proposed methods are effective and efficient.",
        "A1": " we propose a general framework to jointly denoise corrupted views in this paper",
        "A2": " denoise corrupted views from multi-view data",
        "A41": "Multi-view Semi-supervised Collaborative Denoising (MSCD) method",
        "A51": "elementary transformation constraints and gradient energy competition",
        "A61": " establish the complementary relationship among the heterogeneous representations",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our proposed methods are effective and efficient",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "low-rank regularization",
        "A42": "Heterogeneous Linear Metric Learning (HLML) model",
        "A45": "",
        "am_id": 456917741
    },
    {
        "Abstract": "Convolutional neural networks (CNN) are increasingly used in many areas of computer vision. They are particularly attractive because of their ability to \"absorb\" great quantities of labeled data through millions of parameters. However, as model sizes increase, so do the storage and memory requirements of the classifiers, hindering many applications such as image and speech recognition on mobile phones and other devices. In this paper, we present a novel net- work architecture, Frequency-Sensitive Hashed Nets (FreshNets), which exploits inherent redundancy in both convolutional layers and fully-connected layers of a deep learning model, leading to dramatic savings in memory and storage consumption. Based on the key observation that the weights of learned convolutional filters are typically smooth and low-frequency, we first convert filter weights to the frequency domain with a discrete cosine transform (DCT) and use a low-cost hash function to randomly group frequency parameters into hash buckets. All parameters assigned the same hash bucket share a single value learned with standard back-propagation. To further reduce model size, we allocate fewer hash buckets to high-frequency components, which are generally less important. We evaluate FreshNets on eight data sets, and show that it leads to better compressed performance than several relevant baselines.",
        "A1": "we present a novel net- work architecture",
        "A2": " as model sizes increase, so do the storage and memory requirements of the classifiers",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " it leads to better compressed performance than several relevant baselines",
        "A7": "evaluate FreshNets on eight data sets",
        "A83": "",
        "A82": "",
        "A81": " it leads to better compressed performance than several relevant baselines",
        "A64": "use a low-cost hash function to randomly group frequency parameters into hash buckets",
        "A54": "key observation that the weights of learned convolutional filters are typically smooth and low-frequency",
        "A44": " Frequency-Sensitive Hashed Nets (FreshNets)",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 408326367
    },
    {
        "Abstract": "Methods that find insightful low-dimensional projections are essential to effectively explore high-dimensional data. Principal Component Analysis is used pervasively to find low-dimensional projections, not only because it is straightforward to use, but it is also often effective, because the variance in data is often dominated by relevant structure. However, even if the projections highlight real structure in the data, not all structure is interesting to every user. If a user is already aware of, or not interested in the dominant structure, Principal Component Analysis is less effective for finding interesting components. We introduce a new method called Subjectively Interesting Component Analysis (SICA), designed to find data projections that are subjectively interesting , i.e, projections that truly surprise the end-user. It is rooted in information theory and employs an explicit model of a user's prior expectations about the data. The corresponding optimization problem is a simple eigenvalue problem, and the result is a trade-off between explained variance and novelty. We present five case studies on synthetic data, images, time-series, and spatial data, to illustrate how SICA enables users to find (subjectively) interesting projections.",
        "A1": "introduce a new method called Subjectively Interesting Component Analysis (SICA)",
        "A2": " find data projections that are subjectively interesting",
        "A41": "Subjectively Interesting Component Analysis (SICA)",
        "A51": "information theory",
        "A61": "",
        "A10": " enables users to find (subjectively) interesting projections.",
        "A7": " five case studies on synthetic data, images, time-series, and spatial data,",
        "A83": "",
        "A82": "",
        "A81": "how SICA enables users to find (subjectively) interesting projections.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 340872231
    },
    {
        "Abstract": "In this paper, we propose a text clustering algorithm using an online clustering scheme for initialization called FGSDMM+. FGSDMM+ assumes that there are at most K max clusters in the corpus, and regards these K max potential clusters as one large potential cluster at the beginning. During initialization, FGSDMM+ processes the documents one by one in an online clustering scheme. The first document will choose the potential cluster, and FGSDMM+ will create a new cluster to store this document. Later documents will choose one of the non-empty clusters or the potential cluster with probabilities derived from the Dirichlet multinomial mixture model. Each time a document chooses the potential cluster, FGSDMM+ will create a new cluster to store that document and decrease the probability of later documents choosing the potential cluster. After initialization, FGSDMM+ will run a collapsed Gibbs sampling algorithm several times to obtain the final clustering result. Our extensive experimental study shows that FGSDMM+ can achieve better performance than three other clustering methods on both short and long text datasets.",
        "A1": "propose a text clustering algorithm",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "FGSDMM+ can achieve better performance than three other clustering methods on both short and long text datasets",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "FGSDMM+ can achieve better performance than three other clustering methods on both short and long text datasets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a text clustering algorithm using an online clustering scheme for initialization called FGSDMM+",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 44860461
    },
    {
        "Abstract": "Multi-scale data which contains structures at different scales of size and density is a big challenge for spectral clustering. Even given a suitable locally scaled affinity matrix, the first k eigenvectors of such a matrix still cannot separate clusters well. Thus, in this paper, we exploit the fusion of the cluster-separation information from all eigenvectors to achieve a better clustering result. Our method FU ll S pectral Clust E ring (FUSE) is based on Power Iteration (PI) and Independent Component Analysis (ICA). PI is used to fuse all eigenvectors to one pseudo-eigenvector which inherits all the cluster-separation information. To conquer the cluster-collision problem, we utilize PI to generate p ( p > k ) pseudo-eigenvectors. Since these pseudo-eigenvectors are redundant and the cluster-separation information is contaminated with noise, ICA is adopted to rotate the pseudo-eigenvectors to make them pairwise statistically independent. To let ICA overcome local optima and speed up the search process, we develop a self-adaptive and self-learning greedy search method. Finally, we select k rotated pseudo-eigenvectors (independent components) which have more cluster-separation information measured by kurtosis for clustering. Various synthetic and real-world data verifies the effectiveness and efficiency of our FUSE method.",
        "A1": " exploit the fusion of the cluster-separation information from all eigenvectors to achieve a better clustering result",
        "A2": "Multi-scale data which contains structures at different scales of size and density is a big challenge for spectral clustering",
        "A41": "FU ll S pectral Clust E ring (FUSE) ",
        "A51": " Power Iteration (PI) and Independent Component Analysis (ICA).",
        "A61": "",
        "A10": "Various synthetic and real-world data verifies the effectiveness and efficiency of our FUSE method.",
        "A7": " Various synthetic and real-world data ",
        "A83": "",
        "A82": "",
        "A81": "Various synthetic and real-world data verifies the effectiveness and efficiency of our FUSE method.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 279854844
    },
    {
        "Abstract": "We consider the problem of reconstructing an epidemic over time, or, more general, reconstructing the propagation of an activity in a network. Our input consists of a temporal network , which contains information about when two nodes interacted, and a sample of nodes that have been reported as infected. The goal is to recover the flow of the spread, including discovering the starting nodes, and identifying other likely-infected nodes that are not reported. The problem we consider has multiple applications, from public health to social media and viral marketing purposes. Previous work explicitly factor-in many unrealistic assumptions: it is assumed that (a) the underlying network does not change;(b) we have access to perfect noise-free data; or (c) we know the exact propagation model. In contrast, we avoid these simplifications: we take into account the temporal network, we require only a small sample of reported infections, and we do not make any restrictive assumptions about the propagation model. We develop CulT, a scalable and effective algorithm to reconstruct epidemics that is also suited for online settings. CulT works by formulating the problem as that of a temporal Steiner-tree computation, for which we design a fast algorithm leveraging the specific problem structure. We demonstrate the efficacy of the proposed approach through extensive experiments on diverse datasets.",
        "A1": " The goal is to recover the flow of the spread, including discovering the starting nodes, and identifying other likely-infected nodes that are not reported.",
        "A2": " The goal is to recover the flow of the spread, including discovering the starting nodes, and identifying other likely-infected nodes that are not reported.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " demonstrate the efficacy of the proposed approach through extensive experiments",
        "A7": "on diverse datasets.",
        "A83": "",
        "A82": "",
        "A81": " demonstrate the efficacy of the proposed approach through extensive experiments",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a scalable and effective algorithm to reconstruct epidemics that is also suited for online settings. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 112291646
    },
    {
        "Abstract": "The analysis of large-scale Electrical Medical Records (EMRs) has the potential to develop and optimize clinical treatment regimens. A treatment regimen usually includes a series of doctor orders containing rich temporal and heterogeneous information. However, in many existing studies, a doctor order is simplified as an event code and a treatment record is simplified as a code sequence. Thus, the information inherent in doctor orders is not fully used for in-depth analysis. In this paper, we aim at exploiting the rich information in doctor orders and developing data-driven approaches for improving clinical treatments. To this end, we first propose a novel method to measure the similarities between treatment records with consideration of sequential and multifaceted information in doctor orders. Then, we propose an efficient density-based clustering algorithm to summarize large-scale treatment records, and extract a semantic representation of each treatment cluster. Finally, we develop a unified framework to evaluate the discovered treatment regimens, and find the most effective treatment regimen for new patients. In the empirical study, we validate our methods with EMRs of 27,678 patients from 14 hospitals. The results show that: 1) Our method can successfully extract typical treatment regimens from large-scale treatment records. The extracted treatment regimens are intuitive and provide managerial implications for treatment regimen design and optimization. 2) By recommending the most effective treatment regimens, the total cure rate in our data improves from 19.89% to 21.28%, and the effective rate increases up to 98.29%.",
        "A1": "exploiting the rich information in doctor orders and developing data-driven approaches for improving clinical treatments.",
        "A2": "the information inherent in doctor orders is not fully used for in-depth analysis.",
        "A41": "measure the similarities between treatment records with consideration of sequential and multifaceted information in doctor orders.",
        "A51": "",
        "A61": "",
        "A10": "the total cure rate in our data improves from 19.89% to 21.28%, and the effective rate increases up to 98.29%.",
        "A7": "In the empirical study, we validate our methods with EMRs of 27,678 patients from 14 hospitals.",
        "A83": "",
        "A82": "By recommending the most effective treatment regimens, the total cure rate in our data improves from 19.89% to 21.28%, and the effective rate increases up to 98.29%.",
        "A81": "Our method can successfully extract typical treatment regimens from large-scale treatment records.",
        "A64": "",
        "A54": "",
        "A44": "to evaluate the discovered treatment regimens, and find the most effective treatment regimen for new patients",
        "A63": "",
        "A53": "",
        "A43": " to summarize large-scale treatment records, and extract a semantic representation of each treatment cluster.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 280697251
    },
    {
        "Abstract": "Many users in online social networks are constantly trying to gain attention from their followers by broadcasting posts to them. These broadcasters are likely to gain greater attention if their posts can remain visible for a longer period of time among their followers' most recent feeds. Then when to post? In this paper, we study the problem of smart broadcasting using the framework of temporal point processes, where we model users feeds and posts as discrete events occurring in continuous time. Based on such continuous-time model, then choosing a broadcasting strategy for a user becomes a problem of designing the conditional intensity of her posting events. We derive a novel formula which links this conditional intensity with the visibility of the user in her followers' feeds. Furthermore, by exploiting this formula, we develop an efficient convex optimization framework for the when-to-post problem. Our method can find broadcasting strategies that reach a desired visibility level with provable guarantees. We experimented with data gathered from Twitter, and show that our framework can consistently make broadcasters' post more visible than alternatives.",
        "A1": "",
        "A2": "the problem of smart broadcasting",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our framework can consistently make broadcasters' post more visible than alternatives.",
        "A64": "",
        "A54": "",
        "A44": " the framework of temporal point processes",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " continuous-time model",
        "A45": "data gathered from Twitter",
        "am_id": 208082359
    },
    {
        "Abstract": "Deep neural network representations play an important role in computer vision, speech, computational linguistics, robotics, reinforcement learning and many other data-rich domains. In this talk I will show that learning-to-learn and compositionality are key ingredients for dealing with knowledge transfer so as to solve a wide range of tasks, for dealing with small-data regimes, and for continual learning. I will demonstrate this with several examples from my research team: learning to learn by gradient descent by gradient descent, neural programmers and interpreters, and learning communication.",
        "A1": "In this talk I will show that learning-to-learn and compositionality are key ingredients for dealing with knowledge transfer so as to solve a wide range of tasks, for dealing with small-data regimes, and for continual learning",
        "A2": "Deep neural network representations play an important role in computer vision, speech, computational linguistics, robotics, reinforcement learning and many other data-rich domains",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " learning to learn by gradient descent by gradient descent, neural programmers and interpreters, and learning communication.",
        "A83": "",
        "A82": "",
        "A81": "learning-to-learn and compositionality are key ingredients for dealing with knowledge transfer so as to solve a wide range of tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "learning-to-learn and compositionality are key ingredients for dealing with knowledge transfer so as to solve a wide range of tasks",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 188694447
    },
    {
        "Abstract": "Recent years have witnessed the continuous growth of megalopolises worldwide, which makes urban safety a top priority in modern city life. Among various threats, dangerous goods such as gas and hazardous chemicals transported through and around cities have increasingly become the deadly \"bomb\" we sleep with every day. In both academia and government, tremendous efforts have been dedicated to dealing with dangerous goods transportation (DGT) issues, but further study is still in great need to quantify the problem and explore its intrinsic dynamics in a big data perspective. In this paper, we present a novel system called DGeye, which features a \"duet\" between DGT trajectory data and human mobility data for risky zones identification. Moreover, DGeye innovatively takes risky patterns as the keystones in DGT management, and builds causality networks among them for pain point identification, attribution and prediction. Experiments on both Beijing and Tianjin cities demonstrate the effectiveness of DGeye. In particular, the report generated by DGeye driven the Beijing government to lay down gas pipelines for the famous Guijie food street.",
        "A1": "we present a novel system called DGeye, which features a \"duet\" between DGT trajectory data and human mobility data for risky zones identification",
        "A2": " tremendous efforts have been dedicated to dealing with dangerous goods transportation (DGT) issues, but further study is still in great need to quantify the problem and explore its intrinsic dynamics in a big data perspective",
        "A41": "a novel system called DGeye, which features a \"duet\" between DGT trajectory data and human mobility data for risky zones identification",
        "A51": " risky patterns",
        "A61": "",
        "A10": "",
        "A7": "Experiments on both Beijing and Tianjin cities demonstrate the effectiveness of DGeye",
        "A83": "",
        "A82": "",
        "A81": "the report generated by DGeye driven the Beijing government to lay down gas pipelines for the famous Guijie food street",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 473606288
    },
    {
        "Abstract": "The PART-WHOLE relationship routinely finds itself in many disciplines, ranging from collaborative teams, crowdsourcing, autonomous systems to networked systems. From the algorithmic perspective, the existing work has primarily focused on predicting the outcomes of the whole and parts, by either separate models or linear joint models, which assume the outcome of the parts has a linear and independent effect on the outcome of the whole. In this paper, we propose a joint predictive method named PAROLE to simultaneously and mutually predict the part and whole outcomes. The proposed method offers two distinct advantages over the existing work. First ( Model Generality ), we formulate joint PART-WHOLE outcome prediction as a generic optimization problem, which is able to encode a variety of complex relationships between the outcome of the whole and parts, beyond the linear independence assumption. Second ( Algorithm Efficacy ), we propose an effective and efficient block coordinate descent algorithm, which is able to find the coordinate-wise optimum with a linear complexity in both time and space. Extensive empirical evaluations on real-world datasets demonstrate that the proposed PAROLE (1) leads to consistent prediction performance improvement by modeling the non-linear part-whole relationship as well as part-part interdependency, and (2) scales linearly in terms of the size of the training dataset.",
        "A1": "simultaneously and mutually predict the part and whole outcomes",
        "A2": "",
        "A41": "a joint predictive method named PAROLE to simultaneously and mutually predict the part and whole outcomes",
        "A51": "",
        "A61": "the existing work has primarily focused on predicting the outcomes of the whole and parts, by either separate models or linear joint models",
        "A10": "leads to consistent prediction performance improvement ",
        "A7": " Extensive empirical evaluations on real-world datasets",
        "A83": "",
        "A82": "scales linearly in terms of the size of the training dataset.",
        "A81": "leads to consistent prediction performance improvement by modeling the non-linear part-whole relationship as well as part-part interdependency",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "an effective and efficient block coordinate descent algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 106661182
    },
    {
        "Abstract": "A text corpus typically contains two types of context information -- global context and local context. Global context carries topical information which can be utilized by topic models to discover topic structures from the text corpus, while local context can train word embeddings to capture semantic regularities reflected in the text corpus. This encourages us to exploit the useful information in both the global and the local context information. In this paper, we propose a unified language model based on matrix factorization techniques which 1) takes the complementary global and local context information into consideration simultaneously, and 2) models topics and learns word embeddings collaboratively. We empirically show that by incorporating both global and local context, this collaborative model can not only significantly improve the performance of topic discovery over the baseline topic models, but also learn better word embeddings than the baseline word embedding models. We also provide qualitative analysis that explains how the cooperation of global and local context information can result in better topic structures and word embeddings.",
        "A1": "to exploit the useful information in both the global and the local context information",
        "A2": "how the cooperation of global and local context information can result in better topic structures and word embeddings",
        "A41": "incorporating both global and local context",
        "A51": "a unified language model",
        "A61": "",
        "A10": "this collaborative model can not only significantly improve the performance of topic discovery over the baseline topic models, but also learn better word embeddings than the baseline word embedding models",
        "A7": "",
        "A83": "",
        "A82": "but also learn better word embeddings than the baseline word embedding models",
        "A81": "this collaborative model can not only significantly improve the performance of topic discovery over the baseline topic models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "this collaborative model can not only significantly improve the performance of topic discovery over the baseline topic models, but also learn better word embeddings than the baseline word embedding models",
        "A52": "based on matrix factorization techniques",
        "A42": "1) takes the complementary global and local context information into consideration simultaneously, and 2) models topics and learns word embeddings collaboratively",
        "A45": "",
        "am_id": 138777630
    },
    {
        "Abstract": "Feature selection is one of the most important data mining research topics with many applications. In practical problems, features often have group structure to effect the outcomes. Thus, it is crucial to automatically identify homogenous groups of features for high-dimensional data analysis. Octagonal shrinkage and clustering algorithm for regression (OSCAR) is an important sparse regression approach with automatic feature grouping and selection by \u2113 1 norm and pairwise \u2113 \u221e norm. However, due to over-complex representation of the penalty (especially the pairwise \u2113 \u221e norm), so far OSCAR has no solution path algorithm which is mostly useful for tuning the model. To address this challenge, in this paper, we propose a groups-keeping solution path algorithm to solve the OSCAR model (OscarGKPath). Given a set of homogenous groups of features and an accuracy bound \u03b5, OscarGKPath can fit the solutions in an interval of regularization parameters while keeping the feature groups. The entire solution path can be obtained by combining multiple such intervals. We prove that all solutions in the solution path produced by OscarGKPath can strictly satisfy the given accuracy bound \u03b5. The experimental results on benchmark datasets not only confirm the effectiveness of our OscarGKPath algorithm, but also show the superiority of our OscarGKPath in cross validation compared with the existing batch algorithm.",
        "A1": "propose a groups-keeping solution path algorithm to solve the OSCAR model (OscarGKPath)",
        "A2": "Feature selection",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "superiority of our OscarGKPath in cross validation compared with the existing batch algorithm",
        "A7": "experimental results on benchmark datasets",
        "A83": "",
        "A82": "superiority of our OscarGKPath in cross validation compared with the existing batch algorithm",
        "A81": "effectiveness of our OscarGKPath algorithm",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "superiority of our OscarGKPath in cross validation compared with the existing batch algorithm",
        "A53": "combining multiple such intervals",
        "A43": "a groups-keeping solution path algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 284765428
    },
    {
        "Abstract": "With the widespread growth of various social network tools and platforms, analyzing and understanding societal response and crowd reaction to important and emerging social issues and events through social media data is increasingly an important problem. However, there are numerous challenges towards realizing this goal effectively and efficiently, due to the unstructured and noisy nature of social media data. The large volume of the underlying data also presents a fundamental challenge. Furthermore, in many application scenarios, it is often interesting, and in some cases critical, to discover patterns and trends based on geographical and/or temporal partitions, and keep track of how they will change overtime. This brings up the interesting problem of spatio-temporal sentiment analysis from large-scale social media data. This paper investigates this problem through a data science project called \"US Election 2016, What Twitter Says\". The objective is to discover sentiment on Twitter towards either the democratic or the republican party at US county and state levels over any arbitrary temporal intervals, using a large collection of geotagged tweets from a period of 6 months leading up to the US Presidential Election in 2016. Our results demonstrate that by integrating and developing a combination of machine learning and data management techniques, it ispossible to do this at scale with effective outcomes. The results of our project have the potential to be adapted towards solving and influencing other interesting social issues such as building neighborhood happiness and health indicators.",
        "A1": "analyzing and understanding societal response and crowd reaction ",
        "A2": "large volume of the underlying data",
        "A41": "a combination of machine learning and data management techniques",
        "A51": "machine learning and data management techniques",
        "A61": "",
        "A10": "towards solving and influencing other interesting social issues",
        "A7": "either the democratic or the republican party at US county and state levels over any arbitrary temporal intervals",
        "A83": "",
        "A82": "towards solving and influencing other interesting social issues",
        "A81": " it ispossible to do this at scale with effective outcomes",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 405461229
    },
    {
        "Abstract": "Given a database and a target attribute of interest, how can we tell whether there exists a functional, or approximately functional dependence of the target on any set of other attributes in the data? How can we reliably, without bias to sample size or dimensionality, measure the strength of such a dependence? And, how can we efficiently discover the optimal or \u03b1-approximate top- k dependencies? These are exactly the questions we answer in this paper. As we want to be agnostic on the form of the dependence, we adopt an information-theoretic approach, and construct a reliable, bias correcting score that can be efficiently computed. Moreover, we give an effective optimistic estimator of this score, by which for the first time we can mine the approximate functional dependencies from data with guarantees of optimality. Empirical evaluation shows that the derived score achieves a good bias for variance trade-off, can be used within an efficient discovery algorithm, and indeed discovers meaningful dependencies. Most important, it remains reliable in the face of data sparsity.",
        "A1": "As we want to be agnostic on the form of the dependence, we adopt an information-theoretic approach, and construct a reliable, bias correcting score that can be efficiently computed. ",
        "A2": "Given a database and a target attribute of interest, how can we tell whether there exists a functional, or approximately functional dependence of the target on any set of other attributes in the data? How can we reliably, without bias to sample size or dimensionality, measure the strength of such a dependence? And, how can we efficiently discover the optimal or \u03b1-approximate top- k dependencies?",
        "A41": "an information-theoretic approach, and construct a reliable, bias correcting score that can be efficiently computed",
        "A51": "",
        "A61": "for the first time we can mine the approximate functional dependencies from data with guarantees of optimality",
        "A10": "",
        "A7": "Empirical evaluation",
        "A83": "",
        "A82": "it remains reliable in the face of data sparsity.",
        "A81": "the derived score achieves a good bias for variance trade-off, can be used within an efficient discovery algorithm, and indeed discovers meaningful dependencies.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 263398853
    },
    {
        "Abstract": "Heterogeneous Information Network (HIN) is a natural and general representation of data in modern large commercial recommender systems which involve heterogeneous types of data. HIN based recommenders face two problems: how to represent the high-level semantics of recommendations and how to fuse the heterogeneous information to make recommendations. In this paper, we solve the two problems by first introducing the concept of meta-graph to HIN-based recommendation, and then solving the information fusion problem with a \"matrix factorization (MF) + factorization machine (FM)\" approach. For the similarities generated by each meta-graph, we perform standard MF to generate latent features for both users and items. With different meta-graph based features, we propose to use FM with Group lasso (FMG) to automatically learn from the observed ratings to effectively select useful meta-graph based features. Experimental results on two real-world datasets, Amazon and Yelp, show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.",
        "A1": "we solve the two problems by first introducing the concept of meta-graph to HIN-based recommendation, and then solving the information fusion problem with a \"matrix factorization (MF) + factorization machine (FM)\" approach.",
        "A2": "how to represent the high-level semantics of recommendations and how to fuse the heterogeneous information to make recommendations",
        "A41": " a \"matrix factorization (MF) + factorization machine (FM)\" approach",
        "A51": " HIN",
        "A61": "show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.",
        "A10": "show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.",
        "A7": "Experimental results on two real-world datasets",
        "A83": "",
        "A82": "",
        "A81": "show the effectiveness of our approach compared to state-of-the-art FM and other HIN-based recommendation algorithms.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 218244104
    },
    {
        "Abstract": "Existing machine learning methods typically assume consistency in how semantically equivalent information is encoded. However, the way information is recorded in databases differs across institutions and over time, often rendering potentially useful data obsolescent. To address this problem, we map database-specific representations of information to a shared set of semantic concepts, thus allowing models to be built from or transition across different databases. We demonstrate our method on machine learning models developed in a healthcare setting. In particular, we evaluate our method using two different intensive care unit (ICU) databases and on two clinically relevant tasks, in-hospital mortality and prolonged length of stay. For both outcomes, a feature representation mapping EHR-specific events to a shared set of clinical concepts yields better results than using EHR-specific events alone.",
        "A1": "",
        "A2": "the way information is recorded in databases differs across institutions and over time, often rendering potentially useful data obsolescent",
        "A41": "map database-specific representations of information to a shared set of semantic concepts, thus allowing models to be built from or transition across different databases",
        "A51": "machine learning models developed in a healthcare setting",
        "A61": " map database-specific representations of information to a shared set of semantic concepts",
        "A10": "yields better results than using EHR-specific events alone.",
        "A7": "using two different intensive care unit (ICU) databases and on two clinically relevant tasks, in-hospital mortality and prolonged length of stay.",
        "A83": "",
        "A82": "",
        "A81": "yields better results than using EHR-specific events alone.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 168393439
    },
    {
        "Abstract": "Evaluating whether machines improve on human performance is one of the central questions of machine learning. However, there are many domains where the data is selectively labeled, in the sense that the observed outcomes are themselves a consequence of the existing choices of the human decision-makers. For instance, in the context of judicial bail decisions, we observe the outcome of whether a defendant fails to return for their court appearance only if the human judge decides to release the defendant on bail. This selective labeling makes it harder to evaluate predictive models as the instances for which outcomes are observed do not represent a random sample of the population. Here we propose a novel framework for evaluating the performance of predictive models on selectively labeled data. We develop an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference. Our methodology harnesses the heterogeneity of human decision-makers and facilitates effective evaluation of predictive models even in the presence of unmeasured confounders (unobservables) which influence both human decisions and the resulting outcomes. Experimental results on real world datasets spanning diverse domains such as health care, insurance, and criminal justice demonstrate the utility of our evaluation metric in comparing human decisions and machine predictions.",
        "A1": "propose a novel framework for evaluating the performance of predictive models on selectively labeled data. We develop an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference",
        "A2": "Evaluating whether machines improve on human performance",
        "A41": " an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference",
        "A51": "harnesses the heterogeneity of human decision-makers",
        "A61": "the utility of our evaluation metric in comparing human decisions and machine predictions",
        "A10": "",
        "A7": "Experimental results on real world datasets spanning diverse domains such as health care, insurance, and criminal justice ",
        "A83": "",
        "A82": "",
        "A81": "the utility of our evaluation metric in comparing human decisions and machine predictions.",
        "A64": "",
        "A54": "",
        "A44": "a novel framework for evaluating the performance of predictive models on selectively labeled data",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 375501449
    },
    {
        "Abstract": "Motifs are a powerful tool for analyzing physiological waveform data. Standard motif methods, however, ignore important contextual information (e.g., what the patient was doing at the time the data were collected). We hypothesize that these additional contextual data could increase the utility of motifs. Thus, we propose an extension to motifs, contextual motifs, that incorporates context. Recognizing that, oftentimes, context may be unobserved or unavailable, we focus on methods to jointly infer motifs and context. Applied to both simulated and real physiological data, our proposed approach improves upon existing motif methods in terms of the discriminative utility of the discovered motifs. In particular, we discovered contextual motifs in continuous glucose monitor (CGM) data collected from patients with type 1 diabetes. Compared to their contextless counterparts, these contextual motifs led to better predictions of hypo- and hyperglycemic events. Our results suggest that even when inferred, context is useful in both a long- and short-term prediction horizon when processing and interpreting physiological waveform data.",
        "A1": "propose an extension to motifs, contextual motifs, that incorporates context. ",
        "A2": "propose an extension to motifs, contextual motifs, that incorporates context. ",
        "A41": "propose an extension to motifs, contextual motifs",
        "A51": "",
        "A61": " our proposed approach improves upon existing motif methods in terms of the discriminative utility of the discovered motifs",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 134758741
    },
    {
        "Abstract": "In this paper, we consider the Collaborative Ranking (CR) problem for recommendation systems. Given a set of pairwise preferences between items for each user, collaborative ranking can be used to rank un-rated items for each user, and this ranking can be naturally used for recommendation. It is observed that collaborative ranking algorithms usually achieve better performance since they directly minimize the ranking loss; however, they are rarely used in practice due to the poor scalability. All the existing CR algorithms have time complexity at least O (|\u03a9| r ) per iteration, where r is the target rank and |\u03a9| is number of pairs which grows quadratically with number of ratings per user. For example, the Netflix data contains totally 20 billion rating pairs, and at this scale all the current algorithms have to work with significant subsampling, resulting in poor prediction on testing data. In this paper, we propose a new collaborative ranking algorithm called Primal-CR that reduces the time complexity to O (|\u03a9|+ d 1 | d 2 r ), where d 1 is number of users and | d 2 is the averaged number of items rated by a user. Note that d 1 |d 2 is strictly smaller and often much smaller than |\u03a9|. Furthermore, by exploiting the fact that most data is in the form of numerical ratings instead of pairwise comparisons, we propose Primal-CR++ with O ( d 1 | d 2 ( r + log | d 2 )) time complexity. Both algorithms have better theoretical time complexity than existing approaches and also outperform existing approaches in terms of NDCG and pairwise error on real data sets. To the best of our knowledge, this is the first collaborative ranking algorithm capable of working on the full Netflix dataset using all the 20 billion rating pairs, and this leads to a model with much better recommendation compared with previous models trained on subsamples. Finally, compared with classical matrix factorization algorithm which also requires O ( d 1 d 2 r ) time, our algorithm has almost the same efficiency while making much better recommendations since we consider the ranking loss.",
        "A1": "consider the Collaborative Ranking (CR) problem for recommendation systems",
        "A2": "reduces the time complexity",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "consider the ranking loss",
        "A7": "working on the full Netflix dataset using all the 20 billion rating pairs",
        "A83": "compared with classical matrix factorization algorithm which also requires O ( d 1 d 2 r ) time, our algorithm has almost the same efficiency while making much better recommendations",
        "A82": "leads to a model with much better recommendation compared with previous models trained on subsamples",
        "A81": "capable of working on the full Netflix dataset using all the 20 billion rating pairs",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "this is the first collaborative ranking algorithm capable of working on the full Netflix dataset using all the 20 billion rating pairs, and this leads to a model with much better recommendation compared with previous models trained on subsamples. Finally, compared with classical matrix factorization algorithm which also requires O ( d 1 d 2 r ) time, our algorithm has almost the same efficiency while making much better recommendations since we consider the ranking loss",
        "A53": "by exploiting the fact that most data is in the form of numerical ratings instead of pairwise comparisons",
        "A43": "a new collaborative ranking algorithm called Primal-CR that reduces the time complexity to O (|\u03a9|+ d 1 | d 2 r )",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 170725393
    },
    {
        "Abstract": "Extreme Classification comprises multi-class or multi-label prediction where there is a large number of classes, and is increasingly relevant to many real-world applications such as text and image tagging. In this setting, standard classification methods, with complexity linear in the number of classes, become intractable, while enforcing structural constraints among classes (such as low-rank or tree-structure) to reduce complexity often sacrifices accuracy for efficiency. The recent PD-Sparse method addresses this via an algorithm that is sub-linear in the number of variables, by exploiting primal-dual sparsity inherent in a specific loss function, namely the max-margin loss. In this work, we extend PD-Sparse to be efficiently parallelized in large-scale distributed settings. By introducing separable loss functions, we can scale out the training, with network communication and space efficiency comparable to those in one-versus-all approaches while maintaining an overall complexity sub-linear in the number of classes. On several large-scale benchmarks our proposed method achieves accuracy competitive to the state-of-the-art while reducing the training time from days to tens of minutes compared with existing parallel or sparse methods on a cluster of 100 cores.",
        "A1": "",
        "A2": "multi-class or multi-label prediction",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "reducing the training time",
        "A7": " large-scale benchmarks",
        "A83": "",
        "A82": " reducing the training time",
        "A81": "achieves accuracy competitive to the state-of-the-art ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "extend PD-Sparse to be efficiently parallelized in large-scale distributed settings",
        "A53": "PD-Sparse method",
        "A43": "extend PD-Sparse",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 382297819
    },
    {
        "Abstract": "Consider a stream of retweet events - how can we spot fraudulent lock-step behavior in such multi-aspect data (i.e., tensors) evolving over time? Can we detect it in real time, with an accuracy guarantee? Past studies have shown that dense subtensors tend to indicate anomalous or even fraudulent behavior in many tensor data, including social media, Wikipedia, and TCP dumps. Thus, several algorithms have been proposed for detecting dense subtensors rapidly and accurately. However, existing algorithms assume that tensors are static, while many real-world tensors, including those mentioned above, evolve over time. We propose DENSESTREAM, an incremental algorithm that maintains and updates a dense subtensor in a tensor stream (i.e., a sequence of changes in a tensor), and DENSESALERT, an incremental algorithm spotting the sudden appearances of dense subtensors. Our algorithms are: (1) Fast and \"any time\" : updates by our algorithms are up to a million times faster than the fastest batch algorithms, (2) Provably accurate : our algorithms guarantee a lower bound on the density of the subtensor they maintain, and (3) Effective : our DENSESALERT successfully spots anomalies in real-world tensors, especially those overlooked by existing algorithms.",
        "A1": "propose DENSESTREAM, an incremental algorithm",
        "A2": "existing algorithms assume that tensors are static, while many real-world tensors, including those mentioned above, evolve over time",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "(1) Fast and \"any time\" : updates by our algorithms are up to a million times faster than the fastest batch algorithms, (2) Provably accurate : our algorithms guarantee a lower bound on the density of the subtensor they maintain, and (3) Effective : our DENSESALERT successfully spots anomalies in real-world tensors, especially those overlooked by existing algorithms",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "(1) Fast and \"any time\" : updates by our algorithms are up to a million times faster than the fastest batch algorithms, (2) Provably accurate : our algorithms guarantee a lower bound on the density of the subtensor they maintain, and (3) Effective : our DENSESALERT successfully spots anomalies in real-world tensors, especially those overlooked by existing algorithms",
        "A53": "",
        "A43": "DENSESTREAM, an incremental algorithm that maintains and updates a dense subtensor in a tensor stream (i.e., a sequence of changes in a tensor), and DENSESALERT, an incremental algorithm spotting the sudden appearances of dense subtensors",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 427080297
    },
    {
        "Abstract": "As aggregators, online news portals face great challenges in continuously selecting a pool of candidate articles to be shown to their users. Typically, those candidate articles are recommended manually by platform editors from a much larger pool of articles aggregated from multiple sources. Such a hand-pick process is labor intensive and time-consuming. In this paper, we study the editor article selection behavior and propose a learning by demonstration system to automatically select a subset of articles from the large pool. Our data analysis shows that (i) editors' selection criteria are non-explicit , which are less based only on the keywords or topics, but more depend on the quality and attractiveness of the writing from the candidate article, which is hard to capture based on traditional bag-of-words article representation. And (ii) editors' article selection behaviors are dynamic : articles with different data distribution come into the pool everyday and the editors' preference varies, which are driven by some underlying periodic or occasional patterns. To address such problems, we propose a meta-attention model across multiple deep neural nets to (i) automatically catch the editors' underlying selection criteria via the automatic representation learning of each article and its interaction with the meta data and (ii) adaptively capture the change of such criteria via a hybrid attention model. The attention model strategically incorporates multiple prediction models, which are trained in previous days. The system has been deployed in a commercial article feed platform. A 9-day A/B testing has demonstrated the consistent superiority of our proposed model over several strong baselines.",
        "A1": "we study the editor article selection behavior and propose a learning by demonstration system to automatically select a subset of articles from the large pool",
        "A2": "",
        "A41": "propose a learning by demonstration system to automatically select a subset of articles from the large pool",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "editors' article selection behaviors are dynamic ",
        "A81": "editors' selection criteria are non-explicit ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 163055437
    },
    {
        "Abstract": "Land cover prediction is essential for monitoring global environmental change. Unfortunately, traditional classification models are plagued by temporal variation and emergence of novel/unseen land cover classes in the prediction process. In this paper, we propose an LSTM-based spatio-temporal learning framework with a dual-memory structure. The dual-memory structure captures both long-term and short-term temporal variation patterns, and is updated incrementally to adapt the model to the ever-changing environment. Moreover, we integrate zero-shot learning to identify unseen classes even without labelled samples. Experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed framework over multiple baselines in land cover prediction.",
        "A1": "adapt the model to the ever-changing environment.",
        "A2": "propose an LSTM-based spatio-temporal learning framework with a dual-memory structure. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the superiority of the proposed framework over multiple baselines in land cover prediction.",
        "A7": " synthetic and real-world datasets ",
        "A83": "",
        "A82": "",
        "A81": "the superiority of the proposed framework over multiple baselines in land cover prediction.",
        "A64": "with a dual-memory structure",
        "A54": "LSTM",
        "A44": "spatio-temporal learning framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 67920491
    },
    {
        "Abstract": "Neural network based sequence-to-sequence models in an encoder-decoder framework have been successfully applied to solve Question Answering (QA) problems, predicting answers from statements and questions. However, almost all previous models have failed to consider detailed context information and unknown states under which systems do not have enough information to answer given questions. These scenarios with incomplete or ambiguous information are very common in the setting of Interactive Question Answering (IQA). To address this challenge, we develop a novel model, employing context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. We also generate unique IQA datasets to test our model, which will be made publicly available. Employing these attention mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input depending on different contexts. When available, user's feedback is encoded and directly applied to update sentence-level attention to infer an answer. Extensive experiments on QA and IQA datasets quantitatively demonstrate the effectiveness of our model with significant improvement over state-of-the-art conventional QA models.",
        "A1": " To address this challenge, we develop a novel model, employing context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. ",
        "A2": "However, almost all previous models have failed to consider detailed context information and unknown states under which systems do not have enough information to answer given questions.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significant improvement over state-of-the-art conventional QA models.",
        "A7": "Extensive experiments on QA and IQA datasets quantitatively",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the effectiveness of our model ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a novel model, employing context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. ",
        "A45": "",
        "am_id": 323843152
    },
    {
        "Abstract": "A wide range of modern web applications are only possible because of the composable nature of the web services they are built upon. It is, therefore, often critical to ensure proper functioning of these web services. As often, the server-side of web services is not directly accessible, several log message based analysis have been developed to monitor the status of web services. Existing techniques focus on using clusters of messages (log patterns) to detect important system events. We argue that meaningful system events are often representable by groups of cohesive log messages and the relationships among these groups. We propose a novel method to mine structural events as directed workflow graphs (where nodes represent log patterns, and edges represent relations among patterns). The structural events are inclusive and correspond to interpretable episodes in the system. The problem is non-trivial due to the nature of log data: (i) Individual log messages contain limited information, and (ii) Log messages in a large scale web system are often interleaved even though the log messages from individual components are ordered. As a result, the patterns and relationships mined directly from the messages and their ordering can be erroneous and unreliable in practice. Our solution is based on the observation that meaningful log patterns and relations often form workflow structures that are connected. Our method directly models the overall quality of structural events. Through both qualitative and quantitative experiments on real world datasets, we demonstrate the effectiveness and the expressiveness of our event detection method.",
        "A1": " meaningful system events are often representable by groups of cohesive log messages and the relationships among these groups",
        "A2": " It is, therefore, often critical to ensure proper functioning of these web services.",
        "A41": "a novel method to mine structural events as directed workflow graphs (where nodes represent log patterns, and edges represent relations among patterns)",
        "A51": " Our solution is based on the observation that meaningful log patterns and relations often form workflow structures that are connected.",
        "A61": "Our method directly models the overall quality of structural events.",
        "A10": "The problem is non-trivial due to the nature of log data: (i) Individual log messages contain limited information, and (ii) Log messages in a large scale web system are often interleaved even though the log messages from individual components are ordered.",
        "A7": "on real world datasets",
        "A83": "",
        "A82": "and the expressiveness of our event detection method.",
        "A81": " we demonstrate the effectiveness ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 107502023
    },
    {
        "Abstract": "In the shale oil & gas industry, operators are looking toward big data analytics to optimize operations and reduce cost. In this paper, we mainly focus on how to assist operators in understanding the subsurface formation, thereby helping them make optimal decisions. A large number of geology reports and well logs describing the sub-surface have been accumulated over years. Issuing geology reports is more time consuming and depends more on the expertise of engineers than acquiring the well logs. To assist in issuing geology reports, we propose an encoder-decoder-based model to automatically generate rock descriptions in human-readable format from multivariate well logs. Due to the different formats of data, this task differs dramatically from image and video captioning. The challenges are how to model structured rock descriptions and leverage the information in multivariate well logs. To achieve this, we design a hierarchical structure and two forms of attention for the decoder. Extensive validations are conducted on public well data of North Dakota in the United States. We show that our model is effective in generating rock descriptions. The two forms of attention enable the provision of a better insight into relations between well-log types and rock properties with our model from a data-driven perspective.",
        "A1": "focus on how to assist operators in understanding the subsurface formation",
        "A2": "enable the provision of a better insight into relations between well-log types and rock properties with our model from a data-driven perspective.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Extensive validations are conducted on public well data of North Dakota in the United States",
        "A83": "",
        "A82": "The two forms of attention enable the provision of a better insight into relations between well-log types and rock properties with our model from a data-driven perspective.",
        "A81": "our model is effective in generating rock descriptions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "an encoder-decoder-based model",
        "A45": "",
        "am_id": 236733678
    },
    {
        "Abstract": "Nowadays real-time industrial applications are generating a huge amount of data continuously every day. To process these large data streams, we need fast and efficient methodologies and systems. A useful feature desired for data scientists and analysts is to have easy to visualize and understand machine learning models. Decision trees are preferred in many real-time applications for this reason, and also, because combined in an ensemble, they are one of the most powerful methods in machine learning. In this paper, we present a new system called STREAMDM-C++, that implements decision trees for data streams in C++, and that has been used extensively at Huawei. Streaming decision trees adapt to changes on streams, a huge advantage since standard decision trees are built using a snapshot of data, and can not evolve over time. STREAMDM-C++ is easy to extend, and contains more powerful ensemble methods, and a more efficient and easy to use adaptive decision trees. We compare our new implementation with VFML, the current state of the art implementation in C, and show how our new system outperforms VFML in speed using less resources.",
        "A1": "present a new system called STREAMDM-C++",
        "A2": "A useful feature desired for data scientists and analysts is to have easy to visualize and understand machine learning models. ",
        "A41": "we present a new system called STREAMDM-C++",
        "A51": "",
        "A61": "",
        "A10": "show how our new system outperforms VFML in speed using less resources.",
        "A7": "We compare our new implementation with VFML, the current state of the art implementation in C",
        "A83": "",
        "A82": "",
        "A81": "show how our new system outperforms VFML in speed using less resources.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 50320187
    },
    {
        "Abstract": "Extensive information on 3 million randomly sampled United States citizens is used to construct a statistical model of constituent preferences for each U.S. congressional district. This model is linked to the legislative voting record of the legislator from each district, yielding an integrated model for constituency data, legislative roll-call votes, and the text of the legislation. The model is used to examine the extent to which legislators' voting records are aligned with constituent preferences, and the implications of that alignment (or lack thereof) on subsequent election outcomes. The analysis is based on a Bayesian formalism, with fast inference via a stochastic variational Bayesian analysis.",
        "A1": " to construct a statistical model of constituent preferences for each U.S. congressional district.",
        "A2": " to examine the extent to which legislators' voting records are aligned with constituent preferences, and the implications of that alignment (or lack thereof) on subsequent election outcomes",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "This model is linked to the legislative voting record of the legislator from each district, yielding an integrated model for constituency data, legislative roll-call votes, and the text of the legislation",
        "A83": "and the text of the legislation",
        "A82": "legislative roll-call votes",
        "A81": " integrated model for constituency data",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "with fast inference via a stochastic variational Bayesian analysis.",
        "A52": "The analysis is based on a Bayesian formalism, with fast inference via a stochastic variational Bayesian analysis",
        "A42": "constituent preferences for each U.S. congressional district",
        "A45": "",
        "am_id": 73159737
    },
    {
        "Abstract": "In this paper, we propose a novel end-to-end approach for scalable visual search infrastructure. We discuss the challenges we faced for a massive volatile inventory like at eBay and present our solution to overcome those. We harness the availability of large image collection of eBay listings and state-of-the-art deep learning techniques to perform visual search at scale. Supervised approach for optimized search limited to top predicted categories and also for compact binary signature are key to scale up without compromising accuracy and precision. Both use a common deep neural network requiring only a single forward inference. The system architecture is presented with in-depth discussions of its basic components and optimizations for a trade-off between search relevance and latency. This solution is currently deployed in a distributed cloud infrastructure and fuels visual search in eBay ShopBot and Close5. We show benchmark on ImageNet dataset on which our approach is faster and more accurate than several unsupervised baselines. We share our learnings with the hope that visual search becomes a first class citizen for all large scale search engines rather than an afterthought.",
        "A1": "In this paper, we propose a novel end-to-end approach for scalable visual search infrastructure",
        "A2": "",
        "A41": " a novel end-to-end approach for scalable visual search infrastructure",
        "A51": "a common deep neural network ",
        "A61": "",
        "A10": "",
        "A7": "This solution is currently deployed in a distributed cloud infrastructure and fuels visual search in eBay ShopBot and Close5",
        "A83": "",
        "A82": "",
        "A81": " our approach is faster and more accurate than several unsupervised baselines. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 426638778
    },
    {
        "Abstract": "Effectively making sense of short texts is a critical task for many real world applications such as search engines, social media services, and recommender systems. The task is particularly challenging as a short text contains very sparse information, often too sparse for a machine learning algorithm to pick up useful signals. A common practice for analyzing short text is to first expand it with external information, which is usually harvested from a large collection of longer texts. In literature, short text expansion has been done with all kinds of heuristics. We propose an end-to-end solution that automatically learns how to expand short text to optimize a given learning task. A novel deep memory network is proposed to automatically find relevant information from a collection of longer documents and reformulate the short text through a gating mechanism. Using short text classification as a demonstrating task, we show that the deep memory network significantly outperforms classical text expansion methods with comprehensive experiments on real world data sets.",
        "A1": "Effectively making sense of short texts",
        "A2": "a short text contains very sparse information, often too sparse for a machine learning algorithm to pick up useful signals.",
        "A41": ". We propose an end-to-end solution that automatically learns how to expand short text to optimize a given learning task.",
        "A51": "",
        "A61": "A novel deep memory network is proposed to automatically find relevant information from a collection of longer documents and reformulate the short text through a gating mechanism",
        "A10": "Using short text classification as a demonstrating task, we show that the deep memory network significantly outperforms classical text expansion methods with comprehensive experiments on real world data sets.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Using short text classification as a demonstrating task, we show that the deep memory network significantly outperforms classical text expansion methods with comprehensive experiments on real world data sets.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 78377496
    },
    {
        "Abstract": "Point-of-Interest (POI) demand modeling in urban regions is critical for many applications such as business site selection and real estate investment. While some efforts have been made for the demand analysis of some specific POI categories, such as restaurants, it lacks systematic means to support POI demand modeling. To this end, in this paper, we develop a systematic POI demand modeling framework, named Region POI Demand Identification (RPDI), to model POI demands by exploiting the daily needs of people identified from their large-scale mobility data. Specifically, we first partition the urban space into spatially differentiated neighborhood regions formed by many small local communities. Then, the daily activity patterns of people traveling in the city will be extracted from human mobility data. Since the trip activities, even aggregated, are sparse and insufficient to directly identify the POI demands, especially for underdeveloped regions, we develop a latent factor model that integrates human mobility data, POI profiles, and demographic data to robustly model the POI demand of urban regions in a holistic way. In this model, POI preferences and supplies are used together with demographic features to estimate the POI demands simultaneously for all the urban regions interconnected in the city. Moreover, we also design efficient algorithms to optimize the latent model for large-scale data. Finally, experimental results on real-world data in New York City (NYC) show that our method is effective for identifying POI demands for different regions.",
        "A1": "p a systematic POI demand modeling framework, named Region POI Demand Identification (RPDI),",
        "A2": "to model POI demands by exploiting the daily needs of people identified from their large-scale mobility data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Finally, experimental results on real-world data in New York City (NYC) show that our method is effective for identifying POI demands for different regions.",
        "A7": "we develop a latent factor model that integrates human mobility data, POI profiles, and demographic data to robustly model the POI demand of urban regions in a holistic way",
        "A83": "",
        "A82": "oreover, we also design efficient algorithms to optimize the latent model for large-scale data. ",
        "A81": "POI preferences and supplies are used together with demographic features to estimate the POI demands simultaneously for all the urban regions interconnected in the city.",
        "A64": "Finally, experimental results on real-world data in New York City (NYC) show that our method is effective for identifying POI demands for different regions.",
        "A54": "",
        "A44": "demand modeling framework, named Region POI Demand Identification (RPDI), ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " Finally, experimental results on real-world data in New York City (NYC) show that our method is effective for identifying POI demands for different regions.",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 192071358
    },
    {
        "Abstract": "In this paper, we propose a recommendation technique that not only can recommend items of interest to the user as traditional recommendation systems do but also specific aspects of consumption of the items to further enhance the user experience with those items. For example, it can recommend the user to go to a specific restaurant (item) and also order some specific foods there, e.g., seafood (an aspect of consumption). Our method is called Sentiment Utility Logistic Model (SULM). As its name suggests, SULM uses sentiment analysis of user reviews. It first predicts the sentiment that the user may have about the item based on what he/she might express about the aspects of the item and then identifies the most valuable aspects of the user's potential experience with that item. Furthermore, the method can recommend items together with those most important aspects over which the user has control and can potentially select them, such as the time to go to a restaurant, e.g. lunch vs. dinner, and what to order there, e.g., seafood. We tested the proposed method on three applications (restaurant, hotel, and beauty & spa) and experimentally showed that those users who followed our recommendations of the most valuable aspects while consuming the items, had better experiences, as defined by the overall rating.",
        "A1": "propose a recommendation technique",
        "A2": "n recommend items of interest to the user as traditional recommendation systems do",
        "A41": " Sentiment Utility Logistic Model (SULM)",
        "A51": "sentiment analysis of user reviews",
        "A61": "",
        "A10": " had better experiences",
        "A7": " on three applications (restaurant, hotel, and beauty & spa) ",
        "A83": "",
        "A82": "",
        "A81": "those users who followed our recommendations of the most valuable aspects while consuming the items, had better experiences",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 472913442
    },
    {
        "Abstract": "Understanding how to group a set of binary files into the piece of software they belong to is highly desirable for software profiling, malware detection, or enterprise audits, among many other applications. Unfortunately, it is also extremely challenging: there is absolutely no uniformity in the ways different applications rely on different files, in how binaries are signed, or in the versioning schemes used across different pieces of software. In this paper, we show that, by combining information gleaned from a large number of endpoints (millions of computers), we can accomplish large-scale application identification automatically and reliably. Our approach relies on collecting metadata on billions of files every day, summarizing it into much smaller \"sketches\", and performing approximate k-nearest neighbor clustering on non-metric space representations derived from these sketches. We design and implement our proposed system using Apache Spark, show that it can process billions of files in a matter of hours, and thus could be used for daily processing. We further show our system manages to successfully identify which files belong to which application with very high precision, and adequate recall.",
        "A1": "we show that, by combining information gleaned from a large number of endpoints (millions of computers), we can accomplish large-scale application identification automatically and reliably. ",
        "A2": ": there is absolutely no uniformity in the ways different applications rely on different files, in how binaries are signed, or in the versioning schemes used across different pieces of software. ",
        "A41": "by combining information gleaned from a large number of endpoints (millions of computers), we can accomplish large-scale application identification automatically and reliably. ",
        "A51": "Our approach relies on collecting metadata on billions of files every day, summarizing it into much smaller \"sketches\", and performing approximate k-nearest neighbor clustering on non-metric space representations derived from these sketches. ",
        "A61": "We design and implement our proposed system using Apache Spark, show that it can process billions of files in a matter of hours, and thus could be used for daily processing",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We further show our system manages to successfully identify which files belong to which application with very high precision, and adequate recall.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 301752678
    },
    {
        "Abstract": "Mosquito-borne illnesses such as dengue, chikungunya, and Zika are major global health problems, which are not yet addressable with vaccines and must be countered by reducing mosquito populations. The Sterile Insect Technique (SIT) is a promising alternative to pesticides; however, effective SIT relies on minimal releases of female insects. This paper describes a multi-objective convolutional neural net to significantly streamline the process of counting male and female mosquitoes released from a SIT factory and provides a statistical basis for verifying strict contamination rate limits from these counts despite measurement noise. These results are a promising indication that such methods may dramatically reduce the cost of effective SIT methods in practice.",
        "A1": " describes a multi-objective convolutional neural net ",
        "A2": "significantly streamline the process of counting male and female mosquitoes",
        "A41": " multi-objective convolutional neural net",
        "A51": "",
        "A61": "provides a statistical basis for verifying strict contamination rate limits",
        "A10": "dramatically reduce the cost of effective SIT methods in practice.",
        "A7": " these counts despite measurement noise",
        "A83": "",
        "A82": "dramatically reduce the cost of effective SIT methods in practice.",
        "A81": "promising indication ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 141742425
    },
    {
        "Abstract": "We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MSCOCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/ mjhucla/Google_Refexp_toolbox.",
        "A1": "propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image",
        "A2": "generate an unambiguous description (known as a referring expression) of a specific object or region in an image",
        "A41": "a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "present a new large-scale dataset for referring expressions, based on MSCOCO",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 75313358
    },
    {
        "Abstract": "Interactive image segmentation is an important problem in computer vision with many applications including image editing, object recognition and image retrieval. Most existing interactive segmentation methods only operate on color images. Until recently, very few works have been proposed to leverage depth information from low-cost sensors to improve interactive segmentation. While these methods achieve better results than color-based methods, they are still limited in either using depth as an additional color channel or simply combining depth with color in a linear way. We propose a novel interactive segmentation algorithm which can incorporate multiple feature cues like color, depth, and normals in an unified graph cut framework to leverage these cues more effectively. A key contribution of our method is that it automatically selects a single cue to be used at each pixel, based on the intuition that only one cue is necessary to determine the segmentation label locally. This is achieved by optimizing over both segmentation labels and cue labels, using terms designed to decide where both the segmentation and label cues should change. Our algorithm thus produces not only the segmentation mask but also a cue label map that indicates where each cue contributes to the final result. Extensive experiments on five large scale RGBD datasets show that our proposed algorithm performs significantly better than both other color-based and RGBD based algorithms in reducing the amount of user inputs as well as increasing segmentation accuracy.",
        "A1": "propose a novel interactive segmentation algorithm",
        "A2": "While these methods achieve better results than color-based methods, they are still limited in either using depth as an additional color channel or simply combining depth with color in a linear way.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our proposed algorithm performs significantly better than both other color-based and RGBD based algorithms in reducing the amount of user inputs as well as increasing segmentation accuracy.",
        "A7": "Extensive experiments on five large scale RGBD datasets",
        "A83": "",
        "A82": "",
        "A81": "our proposed algorithm performs significantly better than both other color-based and RGBD based algorithms in reducing the amount of user inputs as well as increasing segmentation accuracy.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "which can incorporate multiple feature cues like color, depth, and normals in an unified graph cut framework to leverage these cues more effectively.",
        "A53": "based on the intuition that only one cue is necessary to determine the segmentation label locally.",
        "A43": "a novel interactive segmentation algorithm which can incorporate multiple feature cues like color, depth, and normals in an unified graph cut framework to leverage these cues more effectively",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 3202015
    },
    {
        "Abstract": "We propose using relaxed deep supervision (RDS) within convolutional neural networks for edge detection. The conventional deep supervision utilizes the general groundtruth to guide intermediate predictions. Instead, we build hierarchical supervisory signals with additional relaxed labels to consider the diversities in deep neural networks. We begin by capturing the relaxed labels from simple detectors (e.g. Canny). Then we merge them with the general groundtruth to generate the RDS. Finally we employ the RDS to supervise the edge network following a coarse-to-fine paradigm. These relaxed labels can be seen as some false positives that are difficult to be classified. Weconsider these false positives in the supervision, and are able to achieve high performance for better edge detection. Wecompensate for the lack of training images by capturing coarse edge annotations from a large dataset of image segmentations to pretrain the model. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on the well-known BSDS500 dataset (ODS F-score of .792) and obtains superior cross-dataset generalization results on NYUD dataset.",
        "A1": "edge detection",
        "A2": "propose using relaxed deep supervision (RDS) within convolutional neural networks for edge detection",
        "A41": "using relaxed deep supervision (RDS) within convolutional neural networks",
        "A51": "relaxed deep supervision (RDS",
        "A61": "build hierarchical supervisory signals",
        "A10": "",
        "A7": "achieves state-of-the-art performance on the well-known BSDS500 dataset",
        "A83": "",
        "A82": "superior cross-dataset generalization results on NYUD dataset",
        "A81": "state-of-the-art performance on the well-known BSDS500 dataset ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 168577075
    },
    {
        "Abstract": "We interact everyday with tiny objects such as the door handle of a car or the light switch in a room. These little landmarks are barely visible and hard to localize in images. We describe a method to find such landmarks by finding a sequence of latent landmarks, each with a prediction model. Each latent landmark predicts the next in sequence, and the last localizes the target landmark. For example, to find the door handle of a car, our method learns to start with a latent landmark near the wheel, as it is globally distinctive, subsequent latent landmarks use the context from the earlier ones to get closer to the target. Our method is supervised solely by the location of the little landmark and displays strong performance on more difficult variants of established tasks and on two new tasks.",
        "A1": "We interact everyday with tiny objects such as the door handle of a car or the light switch in a room.",
        "A2": "find such landmarks by finding a sequence of latent landmarks, each with a prediction model",
        "A41": "We describe a method to find such landmarks by finding a sequence of latent landmarks, each with a prediction model.",
        "A51": "",
        "A61": " Our method is supervised solely by the location of the little landmark",
        "A10": "displays strong performance on more difficult variants of established tasks and on two new tasks.",
        "A7": "Our method is supervised solely by the location of the little landmark and displays strong performance on more difficult variants of established tasks and on two new tasks.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 130083526
    },
    {
        "Abstract": "In this paper we present a deep neural network topology that incorporates a simple to implement transformationinvariant pooling operator (TI-POOLING). This operator is able to efficiently handle prior knowledge on nuisance variations in the data, such as rotation or scale changes. Most current methods usually make use of dataset augmentation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under-or overfitting. The main reason for these drawbacks is that that the learned model needs to capture adequate features for all the possible transformations of the input. On the other hand, we formulate features in convolutional neural networks to be transformation-invariant. We achieve that using parallel siamese architectures for the considered transformation set and applying the TI-POOLING operator on their outputs before the fully-connected layers. We show that this topology internally finds the most optimal \"canonical\" instance of the input image for training and therefore limits the redundancy in learned features. This more efficient use of training data results in better performance on popular benchmark datasets with smaller number of parameters when comparing to standard convolutional neural networks with dataset augmentation and to other baselines.",
        "A1": "In this paper we present a deep neural network topology that incorporates a simple to implement transformationinvariant pooling operator (TI-POOLING). ",
        "A2": "This operator is able to efficiently handle prior knowledge on nuisance variations in the data, such as rotation or scale changes.",
        "A41": " Most current methods usually make use of dataset augmentation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under-or overfitting.",
        "A51": "The main reason for these drawbacks is that that the learned model needs to capture adequate features for all the possible transformations of the input.",
        "A61": "",
        "A10": "",
        "A7": "Most current methods usually make use of dataset augmentation to address this issue, but this requires larger number of model parameters and more training data, and results in significantly increased training time and larger chance of under-or overfitting.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 408294543
    },
    {
        "Abstract": "We present a new algorithm for multi-region segmentation of 2D images with objects that may partially occlude each other. Our algorithm is based on the observation that human performance on this task is based both on prior knowledge about plausible shapes and taking into account the presence of occluding objects whose shape is already known - once an occluded region is identified, the shape prior can be used to guess the shape of the missing part. We capture the former aspect using a deep learning model of shape, for the latter, we simultaneously minimize the energy of all regions and consider only unoccluded pixels for data agreement. Existing algorithms incorporating object shape priors consider every object separately in turn and can't distinguish genuine deviation from the expected shape from parts missing due to occlusion. We show that our method significantly improves on the performance of a representative algorithm, as evaluated on both preprocessed natural and synthetic images. Furthermore, on the synthetic images, we recover the ground truth segmentation with good accuracy.",
        "A1": "We present a new algorithm for multi-region segmentation of 2D images with objects that may partially occlude each other.",
        "A2": "multi-region segmentation of 2D images with objects that may partially occlude each other.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our method significantly improves on the performance of a representative algorithm",
        "A7": "evaluated on both preprocessed natural and synthetic images.",
        "A83": "",
        "A82": "our method significantly improves on the performance of a representative algorithm",
        "A81": "we recover the ground truth segmentation with good accuracy.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "We capture the former aspect using a deep learning model of shape, for the latter, we simultaneously minimize the energy of all regions and consider only unoccluded pixels for data agreement.",
        "A53": "the observation that human performance on this task is based both on prior knowledge about plausible shapes and taking into account the presence of occluding objects whose shape is already known - once an occluded region is identified, the shape prior can be used to guess the shape of the missing part. ",
        "A43": " a new algorithm for multi-region segmentation of 2D images with objects that may partially occlude each other. ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 209762858
    },
    {
        "Abstract": "This paper examines the problem of white-balance correction when a scene contains two illuminations. This is a two step process: 1) estimate the two illuminants, and 2) correct the image. Existing methods attempt to estimate a spatially varying illumination map, however, results are error prone and the resulting illumination maps are too lowresolution to be used for proper spatially varying whitebalance correction. In addition, the spatially varying nature of these methods make them computationally intensive. We show that this problem can be effectively addressed by not attempting to obtain a spatially varying illumination map, but instead by performing illumination estimation on large sub-regions of the image. Our approach is able to detect when distinct illuminations are present in the image and accurately measure these illuminants. Since our proposed strategy is not suitable for spatially varying image correction, a user study is performed to see if there is a preference for how the image should be corrected when two illuminants are present, but only a global correction can be applied. The user study shows that when the illuminations are distinct, there is a preference for the outdoor illumination to be corrected resulting in warmer final result. We use these collective findings to demonstrate an effective two illuminant estimation scheme that produces corrected images that users prefer.",
        "A1": "examines the problem of white-balance correction when a scene contains two illuminations",
        "A2": " the problem of white-balance correction when a scene contains two illuminations",
        "A41": "an effective two illuminant estimation scheme that produces corrected images that users prefer",
        "A51": "performing illumination estimation on large sub-regions of the image",
        "A61": "Existing methods attempt to estimate a spatially varying illumination map, however, results are error prone and the resulting illumination maps are too lowresolution to be used for proper spatially varying whitebalance correction.",
        "A10": "",
        "A7": "a user study is performed to see if there is a preference for how the image should be corrected when two illuminants are present, but only a global correction can be applied",
        "A83": "",
        "A82": "",
        "A81": " when the illuminations are distinct, there is a preference for the outdoor illumination to be corrected resulting in warmer final result",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 395785680
    },
    {
        "Abstract": "Photo aesthetics assessment is challenging. Deep convolutional neural network (ConvNet) methods have recently shown promising results for aesthetics assessment. The performance of these deep ConvNet methods, however, is often compromised by the constraint that the neural network only takes the fixed-size input. To accommodate this requirement, input images need to be transformed via cropping, scaling, or padding, which often damages image composition, reduces image resolution, or causes image distortion, thus compromising the aesthetics of the original images. In this paper, we present a composition-preserving deep Con-vNet method that directly learns aesthetics features from the original input images without any image transformations. Specifically, our method adds an adaptive spatial pooling layer upon the regular convolution and pooling layers to directly handle input images with original sizes and aspect ratios. To allow for multi-scale feature extraction, we develop the Multi-Net Adaptive Spatial Pooling ConvNet architecture which consists of multiple sub-networks with different adaptive spatial pooling sizes and leverage a scene-based aggregation layer to effectively combine the predictions from multiple sub-networks. Our experiments on the large-scale aesthetics assessment benchmark (AVA [29]) demonstrate that our method can significantly improve the state-of-the-art results in photo aesthetics assessment.",
        "A1": "Photo aesthetics assessment ",
        "A2": "",
        "A41": "a composition-preserving deep Con-vNet method that directly learns aesthetics features from the original input images without any image transformations",
        "A51": "",
        "A61": "The performance of these deep ConvNet methods, however, is often compromised by the constraint that the neural network only takes the fixed-size input. To accommodate this requirement, input images need to be transformed via cropping, scaling, or padding, which often damages image composition, reduces image resolution, or causes image distortion, thus compromising the aesthetics of the original images.",
        "A10": "our method can significantly improve the state-of-the-art results in photo aesthetics assessment.",
        "A7": "experiments on the large-scale aesthetics assessment benchmark (AVA [29])",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 172743497
    },
    {
        "Abstract": "We propose an unsupervised bottom-up saliency detection approach by exploiting novel graph structure and background priors. The input image is represented as an undirected graph with superpixels as nodes. Feature vectors are extracted from each node to cover regional color, contrast and texture information. A novel graph model is proposed to effectively capture local and global saliency cues. To obtain more accurate saliency estimations, we optimize the saliency map by using a robust background measure. Comprehensive evaluations on benchmark datasets indicate that our algorithm universally surpasses state-of-the-art unsupervised solutions and performs favorably against supervised approaches.",
        "A1": "We propose an unsupervised bottom-up saliency detection approach by exploiting novel graph structure and background priors",
        "A2": " A novel graph model is proposed to effectively capture local and global saliency cues. ",
        "A41": "an unsupervised bottom-up saliency detection approach ",
        "A51": " by exploiting novel graph structure and background priors",
        "A61": "The input image is represented as an undirected graph with superpixels as nodes. Feature vectors are extracted from each node to cover regional color, contrast and texture information. ",
        "A10": "",
        "A7": "Comprehensive evaluations on benchmark datasets ",
        "A83": "",
        "A82": "",
        "A81": "our algorithm universally surpasses state-of-the-art unsupervised solutions and performs favorably against supervised approaches.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "effectively capture local and global saliency cues",
        "A52": "",
        "A42": " A novel graph model is proposed to effectively capture local and global saliency cues. ",
        "A45": " benchmark datasets",
        "am_id": 186844669
    },
    {
        "Abstract": "Using fiducial markers ensures reliable detection and identification of planar features in images. Fiducials are used in a wide range of applications, especially when a reliable visual reference is needed, e.g., to track the camera in cluttered or textureless environments. A marker designed for such applications must be robust to partial occlusions, varying distances and angles of view, and fast camera motions. In this paper, we present a robust, highly accurate fiducial system, whose markers consist of concentric rings, along with its theoretical foundations. Relying on projective properties, it allows to robustly localize the imaged marker and to accurately detect the position of the image of the (common) circle center. We demonstrate that our system can detect and accurately localize these circular fiducials under very challenging conditions and the experimental results reveal that it outperforms other recent fiducial systems.",
        "A1": "",
        "A2": "Using fiducial markers ensures reliable detection and identification of planar features in images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " it outperforms other recent fiducial systems.",
        "A7": "under very challenging conditions",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " projective properties",
        "A42": " a robust, highly accurate fiducial system, whose markers consist of concentric rings, along with its theoretical foundations.",
        "A45": "",
        "am_id": 396150778
    },
    {
        "Abstract": "Since scenes are composed in part of objects, accurate recognition of scenes requires knowledge about both scenes and objects. In this paper we address two related problems: 1) scale induced dataset bias in multi-scale convolutional neural network (CNN) architectures, and 2) how to combine effectively scene-centric and object-centric knowledge (i.e. Places and ImageNet) in CNNs. An earlier attempt, Hybrid-CNN[23], showed that incorporating ImageNet did not help much. Here we propose an alternative method taking the scale into account, resulting in significant recognition gains. By analyzing the response of ImageNet-CNNs and Places-CNNs at different scales we find that both operate in different scale ranges, so using the same network for all the scales induces dataset bias resulting in limited performance. Thus, adapting the feature extractor to each particular scale (i.e. scale-specific CNNs) is crucial to improve recognition, since the objects in the scenes have their specific range of scales. Experimental results show that the recognition accuracy highly depends on the scale, and that simple yet carefully chosen multi-scale combinations of ImageNet-CNNs and Places-CNNs, can push the stateof-the-art recognition accuracy in SUN397 up to 66.26% (and even 70.17% with deeper architectures, comparable to human performance).",
        "A1": " we address two related problems",
        "A2": "1) scale induced dataset bias in multi-scale convolutional neural network (CNN) architectures, and 2) how to combine effectively scene-centric and object-centric knowledge (i.e. Places and ImageNet) in CNNs",
        "A41": "an alternative method taking the scale into account",
        "A51": "ImageNet-CNNs and Places-CNNs",
        "A61": " taking the scale into account",
        "A10": "",
        "A7": " in SUN397",
        "A83": "the recognition accuracy highly depends on the scale",
        "A82": " even 70.17% with deeper architectures, comparable to human performance).",
        "A81": "simple yet carefully chosen multi-scale combinations of ImageNet-CNNs and Places-CNNs, can push the stateof-the-art recognition accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 182224120
    },
    {
        "Abstract": "We consider the problem of estimating the spatial layout of an indoor scene from a monocular RGB image, modeled as the projection of a 3D cuboid. Existing solutions to this problem often rely strongly on hand-engineered features and vanishing point detection, which are prone to failure in the presence of clutter. In this paper, we present a method that uses a fully convolutional neural network (FCNN) in conjunction with a novel optimization framework for generating layout estimates. We demonstrate that our method is robust in the presence of clutter and handles a wide range of highly challenging scenes. We evaluate our method on two standard benchmarks and show that it achieves state of the art results, outperforming previous methods by a wide margin.",
        "A1": "present a method that uses a fully convolutional neural network (FCNN) in conjunction with a novel optimization framework for generating layout estimates",
        "A2": " the problem of estimating the spatial layout of an indoor scene from a monocular RGB image",
        "A41": "present a method that uses a fully convolutional neural network (FCNN) in conjunction with a novel optimization framework for generating layout estimates",
        "A51": "FCNN",
        "A61": "it achieves state of the art results, outperforming previous methods by a wide margin.",
        "A10": "outperforming previous methods by a wide margin",
        "A7": " two standard benchmarks",
        "A83": "",
        "A82": "our method is robust in the presence of clutter and handles a wide range of highly challenging scenes",
        "A81": " it achieves state of the art results, outperforming previous methods by a wide margin",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 41073799
    },
    {
        "Abstract": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8&#x00D7; deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
        "A1": " present a residual learning framework ",
        "A2": "ease the training of networks that are substantially deeper than those used previously.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.",
        "A83": "",
        "A82": "gain accuracy from considerably increased depth",
        "A81": "asier to optimize",
        "A64": "nstead of learning unreferenced functions",
        "A54": "explicitly reformulate the layers as learning residual functions with reference to the layer inputs",
        "A44": "residual learning framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 483425525
    },
    {
        "Abstract": "We investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images. This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based image retrieval application. We introduce a new database of 1,432 sketchphoto pairs from two categories with 32,000 fine-grained triplet ranking annotations. We then develop a deep tripletranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data. Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for finegrained cross-domain ranking tasks.",
        "A1": "We investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images.",
        "A2": "This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for finegrained cross-domain ranking tasks.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "We introduce a new database of 1,432 sketchphoto pairs from two categories with 32,000 fine-grained triplet ranking annotations. ",
        "am_id": 334670029
    },
    {
        "Abstract": "We focus on the task of amodal 3D object detection in RGB-D images, which aims to produce a 3D bounding box of an object in metric form at its full extent. We introduce Deep Sliding Shapes, a 3D ConvNet formulation that takes a 3D volumetric scene from a RGB-D image as input and outputs 3D object bounding boxes. In our approach, we propose the first 3D Region Proposal Network (RPN) to learn objectness from geometric shapes and the first joint Object Recognition Network (ORN) to extract geometric features in 3D and color features in 2D. In particular, we handle objects of various sizes by training an amodal RPN at two different scales and an ORN to regress 3D bounding boxes. Experiments show that our algorithm outperforms the state-of-the-art by 13.8 in mAP and is 200\u00d7 faster than the original Sliding Shapes.",
        "A1": "amodal 3D object detection in RGB-D images",
        "A2": "amodal 3D object detection in RGB-D images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our algorithm outperforms the state-of-the-art by 13.8 in mAP and is 200\u00d7 faster than the original Sliding Shapes.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "a 3D ConvNet formulation that takes a 3D volumetric scene from a RGB-D image as input and outputs 3D object bounding boxes.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 255749535
    },
    {
        "Abstract": "Almost all of the current top-performing object detection networks employ region proposals to guide the search for object instances. State-of-the-art region proposal methods usually need several thousand proposals to get high recall, thus hurting the detection efficiency. Although the latest Region Proposal Network method gets promising detection accuracy with several hundred proposals, it still struggles in small-size object detection and precise localization (e.g., large IoU thresholds), mainly due to the coarseness of its feature maps. In this paper, we present a deep hierarchical network, namely HyperNet, for handling region proposal generation and object detection jointly. Our HyperNet is primarily based on an elaborately designed Hyper Feature which aggregates hierarchical feature maps first and then compresses them into a uniform space. The Hyper Features well incorporate deep but highly semantic, intermediate but really complementary, and shallow but naturally high-resolution features of the image, thus enabling us to construct HyperNet by sharing them both in generating proposals and detecting objects via an end-to-end joint training strategy. For the deep VGG16 model, our method achieves completely leading recall and state-of-the-art object detection accuracy on PASCAL VOC 2007 and 2012 using only 100 proposals per image. It runs with a speed of 5 fps (including all steps) on a GPU, thus having the potential for real-time processing.",
        "A1": "detection efficiency",
        "A2": "object detection ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "PASCAL VOC 2007 and 2012",
        "A83": "runs with a speed of 5 fps (including all steps) on a GPU",
        "A82": "using only 100 proposals per image",
        "A81": "method achieves completely leading recall and state-of-the-art object detection ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "handling region proposal generation and object detection jointly",
        "A52": "an elaborately designed Hyper Feature which aggregates hierarchical feature maps first and then compresses them into a uniform space",
        "A42": "HyperNet, for handling region proposal generation and object detection jointly",
        "A45": "",
        "am_id": 68031842
    },
    {
        "Abstract": "Fine grained video action analysis often requires reliable detection and tracking of various interacting objects and human body parts, denoted as Interactional Object Parsing. However, most of the previous methods based on either independent or joint object detection might suffer from high model complexity and challenging image content, e.g., illumination/pose/appearance/scale variation, motion, and occlusion etc. In this work, we propose an end-to-end system based on recurrent neural network to perform frame by frame interactional object parsing, which can alleviate the difficulty through an incremental/progressive manner. Our key innovation is that: instead of jointly outputting all object detections at once, for each frame we use a set of long-short term memory (LSTM) nodes to incrementally refine the detections. After passing through each LSTM node, more object detections are consolidated and thus more contextual information could be utilized to localize more difficult objects. The object parsing results are further utilized to form object specific action representation for fine grained action detection. Extensive experiments on two benchmark fine grained activity datasets demonstrate that our proposed algorithm achieves better interacting object detection performance, which in turn boosts the action recognition performance over the state-of-the-art.",
        "A1": "perform frame by frame interactional object parsing",
        "A2": " high model complexity and challenging image content",
        "A41": "perform frame by frame interactional object parsing",
        "A51": " recurrent neural network",
        "A61": "a set of long-short term memory",
        "A10": "",
        "A7": " two benchmark fine grained activity datasets",
        "A83": "",
        "A82": "",
        "A81": "achieves better interacting object detection performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 182388782
    },
    {
        "Abstract": "Recent advances in clothes recognition have been driven by the construction of clothes datasets. Existing datasets are limited in the amount of annotations and are difficult to cope with the various challenges in real-world applications. In this work, we introduce DeepFashion1, a large-scale clothes dataset with comprehensive annotations. It contains over 800,000 images, which are richly annotated with massive attributes, clothing landmarks, and correspondence of images taken under different scenarios including store, street snapshot, and consumer. Such rich annotations enable the development of powerful algorithms in clothes recognition and facilitating future researches. To demonstrate the advantages of DeepFashion, we propose a new deep model, namely FashionNet, which learns clothing features by jointly predicting clothing attributes and landmarks. The estimated landmarks are then employed to pool or gate the learned features. It is optimized in an iterative manner. Extensive experiments demonstrate the effectiveness of FashionNet and the usefulness of DeepFashion.",
        "A1": "introduce DeepFashion1",
        "A2": "Existing datasets are limited in the amount of annotations and are difficult to cope with the various challenges in real-world applications",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Extensive experiments",
        "A83": "",
        "A82": "the usefulness of DeepFashion.",
        "A81": "demonstrate the effectiveness of FashionNet",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " FashionNet, which learns clothing features by jointly predicting clothing attributes and landmarks",
        "A45": "a large-scale clothes dataset with comprehensive annotations",
        "am_id": 68268069
    },
    {
        "Abstract": "We present an attention-based model that reasons on human body shape and motion dynamics to identify individuals in the absence of RGB information, hence in the dark. Our approach leverages unique 4D spatio-temporal signatures to address the identification problem across days. Formulated as a reinforcement learning task, our model is based on a combination of convolutional and recurrent neural networks with the goal of identifying small, discriminative regions indicative of human identity. We demonstrate that our model produces state-of-the-art results on several published datasets given only depth images. We further study the robustness of our model towards viewpoint, appearance, and volumetric changes. Finally, we share insights gleaned from interpretable 2D, 3D, and 4D visualizations of our model's spatio-temporal attention.",
        "A1": "present an attention-based model",
        "A2": "identify individuals in the absence of RGB information, hence in the dark",
        "A41": "Our approach leverages unique 4D spatio-temporal signatures to address the identification problem across days",
        "A51": "unique 4D spatio-temporal signatures",
        "A61": "",
        "A10": "our model produces state-of-the-art results on several published datasets given only depth images",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our model produces state-of-the-art results on several published datasets given only depth images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "our model produces state-of-the-art results on several published datasets given only depth images",
        "A52": "human body shape and motion dynamics",
        "A42": " an attention-based model",
        "A45": "several published datasets",
        "am_id": 441791405
    },
    {
        "Abstract": "In this paper, we propose training very deep neural networks (DNNs) for supervised learning of hash codes. Existing methods in this context train relatively \"shallow\" networks limited by the issues arising in back propagation (e.g. vanishing gradients) as well as computational efficiency. We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations. Our method decomposes the training process into independent layer-wise local updates through auxiliary variables. Empirically we observe that our training algorithm always converges and its computational complexity is linearly proportional to the number of edges in the networks. Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU. Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-theart on several benchmark datasets.",
        "A1": " we propose training very deep neural networks (DNNs) for supervised learning of hash codes",
        "A2": " back propagation (e.g. vanishing gradients) as well as computational efficiency",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-theart on several benchmark datasets.",
        "A7": "on several benchmark datasets.",
        "A83": "",
        "A82": "Our proposed very deep supervised hashing (VDSH) method significantly outperforms the state-of-theart on several benchmark datasets.",
        "A81": "Empirically we manage to train DNNs with 64 hidden layers and 1024 nodes per layer for supervised hashing in about 3 hours using a single GPU.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": " We propose a novel and efficient training algorithm inspired by alternating direction method of multipliers (ADMM) that overcomes some of these limitations.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 198064405
    },
    {
        "Abstract": "We describe a method to automatically detect contours, i.e. lines along which the surface orientation sharply changes, in large-scale outdoor point clouds. Contours are important intermediate features for structuring point clouds and converting them into high-quality surface or solid models, and are extensively used in graphics and mapping applications. Yet, detecting them in unstructured, inhomogeneous point clouds turns out to be surprisingly difficult, and existing line detection algorithms largely fail. We approach contour extraction as a two-stage discriminative learning problem. In the first stage, a contour score for each individual point is predicted with a binary classifier, using a set of features extracted from the point's neighborhood. The contour scores serve as a basis to construct an overcomplete graph of candidate contours. The second stage selects an optimal set of contours from the candidates. This amounts to a further binary classification in a higher-order MRF, whose cliques encode a preference for connected contours and penalize loose ends. The method can handle point clouds > 107 points in a couple of minutes, and vastly outperforms a baseline that performs Canny-style edge detection on a range image representation of the point cloud.",
        "A1": "automatically detect contours",
        "A2": "detecting them in unstructured, inhomogeneous point clouds turns out to be surprisingly difficult",
        "A41": " approach contour extraction as a two-stage discriminative learning problem",
        "A51": "",
        "A61": "approach contour extraction as a two-stage discriminative learning problem",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "vastly outperforms a baseline that performs Canny-style edge detection on a range image representation of the point cloud.",
        "A81": "handle point clouds > 107 points in a couple of minutes",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 452809296
    },
    {
        "Abstract": "Data-driven approaches for edge detection have proven effective and achieve top results on modern benchmarks. However, all current data-driven edge detectors require manual supervision for training in the form of hand-labeled region segments or object boundaries. Specifically, human annotators mark semantically meaningful edges which are subsequently used for training. Is this form of strong, highlevel supervision actually necessary to learn to accurately detect edges? In this work we present a simple yet effective approach for training edge detectors without human supervision. To this end we utilize motion, and more specifically, the only input to our method is noisy semi-dense matches between frames. We begin with only a rudimentary knowledge of edges (in the form of image gradients), and alternate between improving motion estimation and edge detection in turn. Using a large corpus of video data, we show that edge detectors trained using our unsupervised scheme approach the performance of the same methods trained with full supervision (within 3-5%). Finally, we show that when using a deep network for the edge detector, our approach provides a novel pre-training scheme for object detection.",
        "A1": "Data-driven approaches for edge detection ",
        "A2": "",
        "A41": "a simple yet effective approach for training edge detectors without human supervision.",
        "A51": "",
        "A61": " without human supervision",
        "A10": "",
        "A7": "a large corpus of video data",
        "A83": "",
        "A82": "when using a deep network for the edge detector, our approach provides a novel pre-training scheme for object detection.",
        "A81": "edge detectors trained using our unsupervised scheme approach the performance of the same methods trained with full supervision (within 3-5%)",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 322697835
    },
    {
        "Abstract": "We present a simple and effective blind image deblurring method based on the dark channel prior. Our work is inspired by the interesting observation that the dark channel of blurred images is less sparse. While most image patches in the clean image contain some dark pixels, these pixels are not dark when averaged with neighboring highintensity pixels during the blur process. This change in the sparsity of the dark channel is an inherent property of the blur process, which we both prove mathematically and validate using training data. Therefore, enforcing the sparsity of the dark channel helps blind deblurring on various scenarios, including natural, face, text, and low-illumination images. However, sparsity of the dark channel introduces a non-convex non-linear optimization problem. We introduce a linear approximation of the min operator to compute the dark channel. Our look-up-table-based method converges fast in practice and can be directly extended to non-uniform deblurring. Extensive experiments show that our method achieves state-of-the-art results on deblurring natural images and compares favorably methods that are well-engineered for specific scenarios.",
        "A1": "We present a simple and effective blind image deblurring method based on the dark channel prior. Our work is inspired by the interesting observation that the dark channel of blurred images is less sparse. While most image patches in the clean image contain some dark pixels, these pixels are not dark when averaged with neighboring highintensity pixels during the blur process.",
        "A2": "While most image patches in the clean image contain some dark pixels, these pixels are not dark when averaged with neighboring highintensity pixels during the blur process. ",
        "A41": "While most image patches in the clean image contain some dark pixels, these pixels are not dark when averaged with neighboring highintensity pixels during the blur process.",
        "A51": "This change in the sparsity of the dark channel is an inherent property of the blur process, which we both prove mathematically and validate using training data.",
        "A61": " which we both prove mathematically and validate using training data.",
        "A10": "Extensive experiments show that our method achieves state-of-the-art results on deblurring natural images and compares favorably methods that are well-engineered for specific scenarios.",
        "A7": " Therefore, enforcing the sparsity of the dark channel helps blind deblurring on various scenarios, including natural, face, text, and low-illumination images. ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 187506473
    },
    {
        "Abstract": "Numerous single image blind deblurring algorithms have been proposed to restore latent sharp images under camera motion. However, these algorithms are mainly evaluated using either synthetic datasets or few selected real blurred images. It is thus unclear how these algorithms would perform on images acquired \"in the wild\" and how we could gauge the progress in the field. In this paper, we aim to bridge this gap. We present the first comprehensive perceptual study and analysis of single image blind deblurring using real-world blurred images. First, we collect a dataset of real blurred images and a dataset of synthetically blurred images. Using these datasets, we conduct a large-scale user study to quantify the performance of several representative state-of-the-art blind deblurring algorithms. Second, we systematically analyze subject preferences, including the level of agreement, significance tests of score differences, and rationales for preferring one method over another. Third, we study the correlation between human subjective scores and several full-reference and noreference image quality metrics. Our evaluation and analysis indicate the performance gap between synthetically blurred images and real blurred image and sheds light on future research in single image blind deblurring.",
        "A1": "bridge this gap",
        "A2": "It is thus unclear how these algorithms would perform on images acquired \"in the wild\" and how we could gauge the progress in the field",
        "A41": "present the first comprehensive perceptual study and analysis of single image blind deblurring using real-world blurred images",
        "A51": "",
        "A61": "a dataset of real blurred images and a dataset of synthetically blurred images",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "real blurred image and sheds light on future research in single image blind deblurring",
        "A81": "the performance gap between synthetically blurred images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a dataset of real blurred images and a dataset of synthetically blurred images",
        "am_id": 248553899
    },
    {
        "Abstract": "The depth image based rendering (DIBR) plays a key role in 3D video synthesis, by which other virtual views can be generated from a 2D video and its depth map. However, in the synthesis process, the background occluded by the foreground objects might be exposed in the new view, resulting in some holes in the synthetized video. In this paper, a hole filling approach based on background reconstruction is proposed, in which the temporal correlation information in both the 2D video and its corresponding depth map are exploited to construct a background video. To construct a clean background video, the foreground objects are detected and removed. Also motion compensation is applied to make the background reconstruction model suitable for moving camera scenario. Each frame is projected to the current plane where a modified Gaussian mixture model is performed. The constructed background video is used to eliminate the holes in the synthetized video. Our experimental results have indicated that the proposed approach has better quality of the synthetized 3D video compared with the other methods.",
        "A1": "",
        "A2": "the background occluded by the foreground objects might be exposed in the new view",
        "A41": " a hole filling approach",
        "A51": "background reconstruction",
        "A61": "",
        "A10": "as better quality of the synthetized 3D video compared with the other methods.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "better quality of the synthetized 3D video",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 203872186
    },
    {
        "Abstract": "In this paper, we present a new algorithm for finding all intersections of three quadrics. The proposed method is algebraic in nature and it is considerably more efficient than the Grobner basis and resultant-based solutions previously used in computer vision applications. We identify several computer vision problems that are formulated and solved as systems of three quadratic equations and for which our algorithm readily delivers considerably faster results. Also, we propose new formulations of three important vision problems: absolute camera pose with unknown focal length, generalized pose-and-scale, and hand-eye calibration with known translation. These new formulations allow our algorithm to significantly outperform the state-of-the-art in speed.",
        "A1": " present a new algorithm",
        "A2": "inding all intersections of three quadrics",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " These new formulations allow our algorithm to significantly outperform the state-of-the-art in speed.",
        "A7": "identify several computer vision problems",
        "A83": "",
        "A82": "These new formulations allow our algorithm to significantly outperform the state-of-the-art in speed.",
        "A81": "delivers considerably faster results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "faster results",
        "A53": "The proposed method is algebraic in nature and it is considerably more efficient than the Grobner basis and resultant-based solutions previously used in computer vision applications.",
        "A43": "finding all intersections of three quadrics.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 26585280
    },
    {
        "Abstract": "Knowing how hands move and what object is being manipulated are two key sub-tasks for analyzing first-person (egocentric) action. However, lack of fully annotated hand data as well as imprecise foreground segmentation make either sub-task challenging. This work aims to explicitly ad dress these two issues via introducing a cascaded interactional targeting (i.e., infer both hand and active object regions) deep neural network. Firstly, a novel EM-like learning framework is proposed to train the pixel-level deep convolutional neural network (DCNN) by seamlessly integrating weakly supervised data (i.e., massive bounding box annotations) with a small set of strongly supervised data (i.e., fully annotated hand segmentation maps) to achieve state-of-the-art hand segmentation performance. Secondly, the resulting high-quality hand segmentation maps are further paired with the corresponding motion maps and object feature maps, in order to explore the contextual information among object, motion and hand to generate interactional foreground regions (operated objects). The resulting interactional target maps (hand + active object) from our cascaded DCNN are further utilized to form discriminative action representation. Experiments show that our framework has achieved the state-of-the-art egocentric action recognition performance on the benchmark dataset Activities of Daily Living (ADL).",
        "A1": "a novel EM-like learning framework is proposed to train the pixel-level deep convolutional neural network (DCNN) by seamlessly integrating weakly supervised data (i.e., massive bounding box annotations) with a small set of strongly supervised data (i.e., fully annotated hand segmentation maps) to achieve state-of-the-art hand segmentation performance",
        "A2": "explicitly ad dress these two issues via introducing a cascaded interactional targeting (i.e., infer both hand and active object regions) deep neural network",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our framework has achieved the state-of-the-art egocentric action recognition performance on the benchmark dataset Activities of Daily Living (ADL).",
        "A7": "The resulting interactional target maps (hand + active object) from our cascaded DCNN are further utilized to form discriminative action representation",
        "A83": "",
        "A82": "",
        "A81": "our framework has achieved the state-of-the-art egocentric action recognition performance on the benchmark dataset Activities of Daily Living (ADL).",
        "A64": "Experiments show that our framework has achieved the state-of-the-art egocentric action recognition performance on the benchmark dataset Activities of Daily Living (ADL).",
        "A54": "cascaded interactional targeting (i.e., infer both hand and active object regions) deep neural networ",
        "A44": "Activities of Daily Living (ADL)",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 468835919
    },
    {
        "Abstract": "In group activity recognition, the temporal dynamics of the whole activity can be inferred based on the dynamics of the individual people representing the activity. We build a deep model to capture these dynamics based on LSTM (long short-term memory) models. To make use of these observations, we present a 2-stage deep temporal model for the group activity recognition problem. In our model, a LSTM model is designed to represent action dynamics of individual people in a sequence and another LSTM model is designed to aggregate person-level information for whole activity understanding. We evaluate our model over two datasets: the Collective Activity Dataset and a new volleyball dataset. Experimental results demonstrate that our proposed model improves group activity recognition performance compared to baseline methods.",
        "A1": "build a deep model to capture these dynamics based on LSTM (long short-term memory) models",
        "A2": "improves group activity recognition performance compared to baseline methods.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "evaluate our model over two datasets: the Collective Activity Dataset and a new volleyball dataset. ",
        "A83": "Experimental results demonstrate that our proposed model improves group activity recognition performance compared to baseline methods.",
        "A82": "",
        "A81": "improves group activity recognition performance compared to baseline methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "improves group activity recognition performance compared to baseline methods.",
        "A52": "LSTM (long short-term memory) models",
        "A42": "a deep model to capture these dynamics based on LSTM (long short-term memory) models",
        "A45": "",
        "am_id": 348191576
    },
    {
        "Abstract": "In this paper, we present a new hashing method to learn compact binary codes for highly efficient image retrieval on large-scale datasets. While the complex image appearance variations still pose a great challenge to reliable retrieval, in light of the recent progress of Convolutional Neural Networks (CNNs) in learning robust image representation on various vision tasks, this paper proposes a novel Deep Supervised Hashing (DSH) method to learn compact similarity-preserving binary code for the huge body of image data. Specifically, we devise a CNN architecture that takes pairs of images (similar/dissimilar) as training inputs and encourages the output of each image to approximate discrete values (e.g. +1/-1). To this end, a loss function is elaborately designed to maximize the discriminability of the output space by encoding the supervised information from the input image pairs, and simultaneously imposing regularization on the real-valued outputs to approximate the desired discrete values. For image retrieval, new-coming query images can be easily encoded by propagating through the network and then quantizing the network outputs to binary codes representation. Extensive experiments on two large scale datasets CIFAR-10 and NUS-WIDE show the promising performance of our method compared with the state-of-the-arts.",
        "A1": " learn compact binary codes for highly efficient image retrieval on large-scale datasets",
        "A2": "complex image appearance variations still pose a great challenge to reliable retrieval",
        "A41": " method to learn compact similarity-preserving binary code for the huge body of image data",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " experiments on two large scale datasets CIFAR-10 and NUS-WIDE",
        "A83": "",
        "A82": "",
        "A81": " the promising performance of our method compared with the state-of-the-arts.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 358909512
    },
    {
        "Abstract": "Bird migration is a critical indicator of environmental health, biodiversity, and climate change. Existing techniques for monitoring bird migration are either expensive (e.g., satellite tracking), labor-intensive (e.g., moon watching), indirect and thus less accurate (e.g., weather radar), or intrusive (e.g., attaching geolocators on captured birds). In this paper, we present a vision-based system for detecting migrating birds in flight at night. Our system takes stereo videos of the night sky as inputs, detects multiple flying birds and estimates their orientations, speeds, and altitudes. The main challenge lies in detecting flying birds of unknown trajectories under high noise level due to the low-light environment. We address this problem by incorporating stereo constraints for rejecting physically implausible configurations and gathering evidence from two (or more) views. Specifically, we develop a robust stereo-based 3D line fitting algorithm for geometric verification and a deformable part response accumulation strategy for trajectory verification. We demonstrate the effectiveness of the proposed approach through quantitative evaluation of real videos of birds migrating at night collected with near-infrared cameras.",
        "A1": "we present a vision-based system for detecting migrating birds in flight at night",
        "A2": "Existing techniques for monitoring bird migration are either expensive (e.g., satellite tracking), labor-intensive (e.g., moon watching), indirect and thus less accurate (e.g., weather radar), or intrusive (e.g., attaching geolocators on captured birds). ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "quantitative evaluation of real videos of birds migrating at night collected with near-infrared cameras",
        "A83": "",
        "A82": "",
        "A81": "demonstrate the effectiveness of the proposed approach",
        "A64": "",
        "A54": "",
        "A44": "we present a vision-based system for detecting migrating birds in flight at night",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 45477175
    },
    {
        "Abstract": "Although promising results have been achieved in the areas of traffic-sign detection and classification, few works have provided simultaneous solutions to these two tasks for realistic real world images. We make two contributions to this problem. Firstly, we have created a large traffic-sign benchmark from 100000 Tencent Street View panoramas, going beyond previous benchmarks. It provides 100000 images containing 30000 traffic-sign instances. These images cover large variations in illuminance and weather conditions. Each traffic-sign in the benchmark is annotated with a class label, its bounding box and pixel mask. We call this benchmark Tsinghua-Tencent 100K. Secondly, we demonstrate how a robust end-to-end convolutional neural network (CNN) can simultaneously detect and classify trafficsigns. Most previous CNN image processing solutions target objects that occupy a large proportion of an image, and such networks do not work well for target objects occupying only a small fraction of an image like the traffic-signs here. Experimental results show the robustness of our network and its superiority to alternatives. The benchmark, source code and the CNN model introduced in this paper is publicly available1.",
        "A1": "benchmark Tsinghua-Tencent 100K",
        "A2": "few works have provided simultaneous solutions to these two tasks for realistic real world images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The benchmark, source code and the CNN model introduced in this paper is publicly available1.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the robustness of our network and its superiority to alternatives",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a large traffic-sign benchmark from 100000 Tencent Street View panoramas, going beyond previous benchmarks. It provides 100000 images containing 30000 traffic-sign instances",
        "am_id": 489890594
    },
    {
        "Abstract": "Classifying a visual concept merely from its associated online textual source, such as a Wikipedia article, is an attractive research topic in zero-shot learning because it alleviates the burden of manually collecting semantic attributes. Recent work has pursued this approach by exploring various ways of connecting the visual and text domains. In this paper, we revisit this idea by going further to consider one important factor: the textual representation is usually too noisy for the zero-shot learning application. This observation motivates us to design a simple yet effective zero-shot learning method that is capable of suppressing noise in the text. Specifically, we propose an l2,1-norm based objective function which can simultaneously suppress the noisy signal in the text and learn a function to match the text document and visual features. We also develop an optimization algorithm to efficiently solve the resulting problem. By conducting experiments on two large datasets, we demonstrate that the proposed method significantly outperforms those competing methods which rely on online information sources but with no explicit noise suppression. Furthermore, we make an in-depth analysis of the proposed method and provide insight as to what kind of information in documents is useful for zero-shot learning.",
        "A1": "design a simple yet effective zero-shot learning method that is capable of suppressing noise in the text. ",
        "A2": "the textual representation is usually too noisy for the zero-shot learning application",
        "A41": "design a simple yet effective zero-shot learning method that is capable of suppressing noise in the text. ",
        "A51": "",
        "A61": "we propose an l2,1-norm based objective function which can simultaneously suppress the noisy signal in the text and learn a function to match the text document and visual features.",
        "A10": "we demonstrate that the proposed method significantly outperforms those competing methods which rely on online information sources but with no explicit noise suppression",
        "A7": "By conducting experiments on two large datasets",
        "A83": "",
        "A82": "we make an in-depth analysis of the proposed method and provide insight as to what kind of information in documents is useful for zero-shot learning.",
        "A81": "we demonstrate that the proposed method significantly outperforms those competing methods which rely on online information sources but with no explicit noise suppression",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 18673620
    },
    {
        "Abstract": "In this paper we introduce a new method for text detection in natural images. The method comprises two contributions: First, a fast and scalable engine to generate synthetic images of text in clutter. This engine overlays synthetic text to existing background images in a natural way, accounting for the local 3D scene geometry. Second, we use the synthetic images to train a Fully-Convolutional Regression Network (FCRN) which efficiently performs text detection and bounding-box regression at all locations and multiple scales in an image. We discuss the relation of FCRN to the recently-introduced YOLO detector, as well as other end-to-end object detection systems based on deep learning. The resulting detection network significantly out performs current methods for text detection in natural images, achieving an F-measure of 84.2% on the standard ICDAR 2013 benchmark. Furthermore, it can process 15 images per second on a GPU.",
        "A1": "text detection in natural images",
        "A2": "",
        "A41": "a new method for text detection in natural images",
        "A51": "Fully-Convolutional Regression Network (FCRN)",
        "A61": "",
        "A10": "significantly out performs current methods for text detection in natural images, achieving an F-measure of 84.2% on the standard ICDAR 2013 benchmark. Furthermore, it can process 15 images per second on a GPU.",
        "A7": "on the standard ICDAR 2013 benchmark",
        "A83": "",
        "A82": "can process 15 images per second on a GPU",
        "A81": "out performs current methods for text detection in natural images, achieving an F-measure of 84.2%",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 167207340
    },
    {
        "Abstract": "Current people detectors operate either by scanning an image in a sliding window fashion or by classifying a discrete set of proposals. We propose a model that is based on decoding an image into a set of people detections. Our system takes an image as input and directly outputs a set of distinct detection hypotheses. Because we generate predictions jointly, common post-processing steps such as nonmaximum suppression are unnecessary. We use a recurrent LSTM layer for sequence generation and train our model end-to-end with a new loss function that operates on sets of detections. We demonstrate the effectiveness of our approach on the challenging task of detecting people in crowded scenes1.",
        "A1": "propose a model that is based on decoding an image into a set of people detections",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "directly outputs a set of distinct detection hypotheses",
        "A52": "takes an image as input",
        "A42": "a model that is based on decoding an image into a set of people detections",
        "A45": "",
        "am_id": 48903611
    },
    {
        "Abstract": "In this paper, we present a real-time salient object detection system based on the minimum spanning tree. Due to the fact that background regions are typically connected to the image boundaries, salient objects can be extracted by computing the distances to the boundaries. However, measuring the image boundary connectivity efficiently is a challenging problem. Existing methods either rely on superpixel representation to reduce the processing units or approximate the distance transform. Instead, we propose an exact and iteration free solution on a minimum spanning tree. The minimum spanning tree representation of an image inherently reveals the object geometry information in a scene. Meanwhile, it largely reduces the search space of shortest paths, resulting an efficient and high quality distance transform algorithm. We further introduce a boundary dissimilarity measure to compliment the shortage of distance transform for salient object detection. Extensive evaluations show that the proposed algorithm achieves the leading performance compared to the state-of-the-art methods in terms of efficiency and accuracy.",
        "A1": "present a real-time salient object detection system based on the minimum spanning tree",
        "A2": "measuring the image boundary connectivity efficiently is a challenging problem",
        "A41": "a real-time salient object detection system",
        "A51": "minimum spanning tree",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 11205774
    },
    {
        "Abstract": "This work presents an approach to category-based action recognition in video using sparse coding techniques. The proposed approach includes two main contributions: i) A new method to handle intra-class variations by decomposing each video into a reduced set of representative atomic action acts or key-sequences, and ii) A new video descriptor, ITRA: Inter-Temporal Relational Act Descriptor, that exploits the power of comparative reasoning to capture relative similarity relations among key-sequences. In terms of the method to obtain key-sequences, we introduce a loss function that, for each video, leads to the identification of a sparse set of representative key-frames capturing both, relevant particularities arising in the input video, as well as relevant generalities arising in the complete class collection. In terms of the method to obtain the ITRA descriptor, we introduce a novel scheme to quantify relative intra and inter-class similarities among local temporal patterns arising in the videos. The resulting ITRA descriptor demonstrates to be highly effective to discriminate among action categories. As a result, the proposed approach reaches remarkable action recognition performance on several popular benchmark datasets, outperforming alternative state-of the-art techniques by a large margin.",
        "A1": "This work presents an approach to category-based action recognition in video using sparse coding techniques.",
        "A2": "The proposed approach includes two main contributions: i) A new method to handle intra-class variations by decomposing each video into a reduced set of representative atomic action acts or key-sequences, and ii) A new video descriptor,",
        "A41": "Inter-Temporal Relational Act Descriptor, that exploits the power of comparative reasoning to capture relative similarity relations among key-sequences.",
        "A51": "In terms of the method to obtain key-sequences, we introduce a loss function that,",
        "A61": "f the method to obtain key-sequences, we introduce a loss function that,",
        "A10": "eralities arising in the complete ",
        "A7": "nal Act Descriptor, that exploits the power of comparative reasoning to capture relative similarity relations among key-sequences. In ter",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 376443807
    },
    {
        "Abstract": "We tackle the problem of large-scale object detection in images, where the number of objects can be arbitrarily large, and can exhibit significant overlap/occlusion. A successful approach to modelling the large-scale nature of this problem has been via point process density functions which jointly encode object qualities and spatial interactions. But the corresponding optimisation problem is typically difficult or intractable, and many of the best current methods rely on Monte Carlo Markov Chain (MCMC) simulation, which converges slowly in a large solution space. We propose an efficient point process inference for largescale object detection using discrete energy minimization. In particular, we approximate the solution space by a finite set of object proposals and cast the point process density function to a corresponding energy function of binary variables whose values indicate which object proposals are accepted. We resort to the local submodular approximation (LSA) based trust-region optimisation to find the optimal solution. Furthermore we analyse the error of LSA approximation, and show how to adjust the point process energy to dramatically speed up the convergence without harming the optimality. We demonstrate the superior efficiency and accuracy of our method using a variety of large-scale object detection applications such as crowd human detection, birds, cells counting/localization.",
        "A1": "",
        "A2": "the problem of large-scale object detection in images, where the number of objects can be arbitrarily large, and can exhibit significant overlap/occlusion",
        "A41": "an efficient point process inference for largescale object detection using discrete energy minimization",
        "A51": "local submodular approximation",
        "A61": "superior efficiency and accuracy",
        "A10": "superior efficiency and accuracy",
        "A7": "applications such as crowd human detection, birds, cells counting/localization",
        "A83": "",
        "A82": "",
        "A81": "superior efficiency and accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 497192256
    },
    {
        "Abstract": "One of the most widely used strategies for visual object detection is based on exhaustive spatial hypothesis search. While methods like sliding windows have been successful and effective for many years, they are still brute-force, independent of the image content and the visual category being searched. In this paper we present principled sequential models that accumulate evidence collected at a small set of image locations in order to detect visual objects effectively. By formulating sequential search as reinforcement learning of the search policy (including the stopping condition), our fully trainable model can explicitly balance for each class, specifically, the conflicting goals of exploration - sampling more image regions for better accuracy -, and exploitation - stopping the search efficiently when sufficiently confident about the target's location. The methodology is general and applicable to any detector response function. We report encouraging results in the PASCAL VOC 2012 object detection test set showing that the proposed methodology achieves almost two orders of magnitude speed-up over sliding window methods.",
        "A1": "present principled sequential models",
        "A2": "detect visual objects effectively",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves almost two orders of magnitude speed-up over sliding window methods",
        "A7": "the PASCAL VOC 2012 object detection test set ",
        "A83": "",
        "A82": "",
        "A81": " the proposed methodology achieves almost two orders of magnitude speed-up over sliding window methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "reinforcement learning",
        "A42": " principled sequential models that accumulate evidence collected at a small set of image locations",
        "A45": "",
        "am_id": 42566458
    },
    {
        "Abstract": "When human annotators are given a choice about what to label in an image, they apply their own subjective judgments on what to ignore and what to mention. We refer to these noisy \"human-centric\" annotations as exhibiting human reporting bias. Examples of such annotations include image tags and keywords found on photo sharing sites, or in datasets containing image captions. In this paper, we use these noisy annotations for learning visually correct image classifiers. Such annotations do not use consistent vocabulary, and miss a significant amount of the information present in an image, however, we demonstrate that the noise in these annotations exhibits structure and can be modeled. We propose an algorithm to decouple the human reporting bias from the correct visually grounded labels. Our results are highly interpretable for reporting \"what's in the image\" versus \"what's worth saying.\" We demonstrate the algorithm's efficacy along a variety of metrics and datasets, including MS COCO and Yahoo Flickr 100M.We show significant improvements over traditional algorithms for both image classification and image captioning, doubling the performance of existing methods in some cases.",
        "A1": " In this paper, we use these noisy annotations for learning visually correct image classifiers.",
        "A2": "When human annotators are given a choice about what to label in an image, they apply their own subjective judgments on what to ignore and what to mention. We refer to these noisy \"human-centric\" annotations as exhibiting human reporting bias.",
        "A41": "we use these noisy annotations for learning visually correct image classifiers. ",
        "A51": "",
        "A61": "",
        "A10": "We show significant improvements over traditional algorithms for both image classification and image captioning, doubling the performance of existing methods in some cases.",
        "A7": "along a variety of metrics and datasets, including MS COCO and Yahoo Flickr 100M",
        "A83": "",
        "A82": "",
        "A81": "We show significant improvements over traditional algorithms for both image classification and image captioning, doubling the performance of existing methods in some cases.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 283242079
    },
    {
        "Abstract": "Conventional representation based classifiers, ranging from the classical nearest neighbor classifier and nearest subspace classifier to the recently developed sparse representation based classifier (SRC) and collaborative representation based classifier (CRC), are essentially distance based classifiers. Though SRC and CRC have shown interesting classification results, their intrinsic classification mechanism remains unclear. In this paper we propose a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. Consequently, we present a probabilistic collaborative representation based classifier (ProCRC), which jointly maximizes the likelihood that a test sample belongs to each of the multiple classes. The final classification is performed by checking which class has the maximum likelihood. The proposed ProCRC has a clear probabilistic interpretation, and it shows superior performance to many popular classifiers, including SRC, CRC and SVM. Coupled with the CNN features, it also leads to state-of-the-art classification results on a variety of challenging visual datasets.",
        "A1": "Conventional representation based classifiers, ranging from the classical nearest neighbor classifier and nearest subspace classifier to the recently developed sparse representation based classifier (SRC) and collaborative representation based classifier (CRC), are essentially distance based classifiers.",
        "A2": "Conventional representation based classifiers, ranging from the classical nearest neighbor classifier and nearest subspace classifier to the recently developed sparse representation based classifier (SRC) and collaborative representation based classifier (CRC), are essentially distance based classifiers.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Consequently, we present a probabilistic collaborative representation based classifier (ProCRC), which jointly maximizes the likelihood that a test sample belongs to each of the multiple classes. ",
        "A7": "Conventional representation based classifiers, ranging from the classical nearest neighbor classifier and nearest subspace classifier to the recently developed sparse representation based classifier (SRC) and collaborative representation based classifier (CRC), are essentially distance based classifiers. ",
        "A83": " In this paper we propose a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. ",
        "A82": " In this paper we propose a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. ",
        "A81": ". Though SRC and CRC have shown interesting classification results, their intrinsic classification mechanism remains unclear. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": ". Though SRC and CRC have shown interesting classification results, their intrinsic classification mechanism remains unclear. ",
        "A52": ". In this paper we propose a probabilistic collaborative representation framework, where the probability that a test sample belongs to the collaborative subspace of all classes can be well defined and computed. ",
        "A42": ". Though SRC and CRC have shown interesting classification results, their intrinsic classification mechanism remains unclear. ",
        "A45": "",
        "am_id": 388309466
    },
    {
        "Abstract": "The success of an image classification algorithm largely depends on how it incorporates local information in the global decision. Popular approaches such as average-pooling and max-pooling are suboptimal in many situations. In this paper we propose Region Ranking SVM (RRSVM), a novel method for pooling local information from multiple regions. RRSVM exploits the correlation of local regions in an image, and it jointly learns a region evaluation function and a scheme for integrating multiple regions. Experiments on PASCAL VOC 2007, VOC 2012, and ILSVRC2014 datasets show that RRSVM outperforms the methods that use the same feature type and extract features from the same set of local regions. RRSVM achieves similar to or better than the state-of-the-art performance on all datasets.",
        "A1": " propose Region Ranking SVM (RRSVM), a novel method for pooling local information from multiple regions",
        "A2": "pooling local information from multiple regions",
        "A41": "Region Ranking SVM (RRSVM), a novel method for pooling local information from multiple regions",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Experiments on PASCAL VOC 2007, VOC 2012, and ILSVRC2014 datasets",
        "A83": "",
        "A82": "",
        "A81": "RRSVM outperforms the methods that use the same feature type and extract features from the same set of local regions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 431966503
    },
    {
        "Abstract": "This paper argues that large-scale action recognition in video can be greatly improved by providing an additional modality in training data - namely, 3D human-skeleton sequences - aimed at complementing poorly represented or missing features of human actions in the training videos. For recognition, we use Long Short Term Memory (LSTM) grounded via a deep Convolutional Neural Network (CNN) onto the video. Training of LSTM is regularized using the output of another encoder LSTM (eLSTM) grounded on 3D human-skeleton training data. For such regularized training of LSTM, we modify the standard backpropagation through time (BPTT) in order to address the wellknown issues with gradient descent in constraint optimization. Our evaluation on three benchmark datasets - Sports-1M, HMDB-51, and UCF101 - shows accuracy improvements from 1.7% up to 14.8% relative to the state of the art.",
        "A1": "",
        "A2": " that large-scale action recognition in video can be greatly improved by providing an additional modality in training data",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "accuracy improvements from 1.7% up to 14.8% relative to the state of the art.",
        "A7": "evaluation on three benchmark datasets - Sports-1M, HMDB-51, and UCF101 ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " a deep Convolutional Neural Network (CNN) onto the video",
        "A42": " Long Short Term Memory (LSTM) grounded ",
        "A45": "",
        "am_id": 23989007
    },
    {
        "Abstract": "Actor-action semantic segmentation made an important step toward advanced video understanding: what action is happening, who is performing the action, and where is the action happening in space-time. Current methods based on layered CRFs for this problem are local and unable to capture the long-ranging interactions of video parts. We propose a new model that combines the labeling CRF with a supervoxel hierarchy, where supervoxels at various scales provide cues for possible groupings of nodes in the CRF to encourage adaptive and long-ranging interactions. The new model defines a dynamic and continuous process of information exchange: the CRF influences what supervoxels in the hierarchy are active, and these active supervoxels, in turn, affect the connectivities in the CRF, we hence call it a grouping process model. By further incorporating the video-level recognition, the proposed method achieves a large margin of 60% relative improvement over the state of the art on the recent A2D large-scale video labeling dataset, which demonstrates the effectiveness of our modeling.",
        "A1": "propose a new model that combines the labeling CRF with a supervoxel hierarchy, where supervoxels at various scales provide cues for possible groupings of nodes in the CRF to encourage adaptive and long-ranging interactions",
        "A2": "Current methods based on layered CRFs for this problem are local and unable to capture the long-ranging interactions of video parts",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed method achieves a large margin of 60% relative improvement over the state of the art on the recent A2D large-scale video labeling dataset",
        "A7": "further incorporating the video-level recognition",
        "A83": "",
        "A82": "",
        "A81": "the proposed method achieves a large margin of 60% relative improvement over the state of the art on the recent A2D large-scale video labeling dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "the labeling CRF with a supervoxel hierarchy",
        "A42": "a new model that combines the labeling CRF with a supervoxel hierarchy, where supervoxels at various scales provide cues for possible groupings of nodes in the CRF to encourage adaptive and long-ranging interactions",
        "A45": "",
        "am_id": 118715771
    },
    {
        "Abstract": "Aiming at simultaneous detection and segmentation (SD-S), we propose a proposal-free framework, which detect and segment object instances via mid-level patches. We design a unified trainable network on patches, which is followed by a fast and effective patch aggregation algorithm to infer object instances. Our method benefits from end-to-end training. Without object proposal generation, computation time can also be reduced. In experiments, our method yields results 62.1% and 61.8% in terms of mAPr on VOC2012 segmentation val and VOC2012 SDS val, which are state-of-the-art at the time of submission. We also report results on Microsoft COCO test-std/test-dev dataset in this paper.",
        "A1": "propose a proposal-free framework",
        "A2": "simultaneous detection and segmentation (SD-S)",
        "A41": "design a unified trainable network on patches, which is followed by a fast and effective patch aggregation algorithm to infer object instances",
        "A51": "end-to-end training",
        "A61": " Without object proposal generation, computation time can also be reduced",
        "A10": "state-of-the-art at the time of submission",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our method yields results 62.1% and 61.8% in terms of mAPr on VOC2012 segmentation val and VOC2012 SDS val",
        "A64": "",
        "A54": "mid-level patches",
        "A44": "a proposal-free framework, which detect and segment object instances",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "Microsoft COCO test-std/test-dev dataset",
        "am_id": 497553150
    },
    {
        "Abstract": "Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information, specifically, we explore 'patch-patch' context between image regions, and 'patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-overunion score of 78:0 on the challenging PASCAL VOC 2012 dataset.",
        "A1": "semantic image segmentation",
        "A2": "how to improve semantic segmentation through the use of contextual information",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow",
        "A83": "",
        "A82": "achieve an intersection-overunion score of 78:0 on the challenging PASCAL VOC 2012 dataset",
        "A81": "Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Conditional Random Fields",
        "A42": "formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches",
        "A45": "",
        "am_id": 222239569
    },
    {
        "Abstract": "This paper deals with the extraction of multiple models from noisy or outlier-contaminated data. We cast the multi-model fitting problem in terms of set coverage, deriving a simple and effective method that generalizes Ransac to multiple models and deals with intersecting structures and outliers in a straightforward and principled manner, while avoiding the typical shortcomings of sequential approaches and those of clustering. The method compares favorably against the state-of-the-art on simulated and publicly available real data-sets.",
        "A1": "deals with the extraction of multiple models from noisy or outlier-contaminated data.",
        "A2": "deals with the extraction of multiple models from noisy or outlier-contaminated data. ",
        "A41": "a simple and effective method that generalizes Ransac to multiple models and deals with intersecting structures and outliers in a straightforward and principled manner",
        "A51": "",
        "A61": "The method compares favorably against the state-of-the-art on simulated and publicly available real data-sets.",
        "A10": "The method compares favorably against the state-of-the-art on simulated and publicly available real data-sets.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "The method compares favorably against the state-of-the-art on simulated and publicly available real data-sets.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 354889103
    },
    {
        "Abstract": "This paper approximates the 3D geometry of a scene by a small number of 3D planes. The method is especially suited to man-made scenes, and only requires two calibrated wide-baseline views as inputs. It relies on the computation of a dense but noisy 3D point cloud, as for example obtained by matching DAISY descriptors [35] between the views. It then segments one of the two reference images, and adopts a multi-model fitting process to assign a 3D plane to each region, when the region is not detected as occluded. A pool of 3D plane hypotheses is first derived from the 3D point cloud, to include planes that reasonably approximate the part of the 3D point cloud observed from each reference view between randomly selected triplets of 3D points. The hypothesis-to-region assignment problem is then formulated as an energy-minimization problem, which simultaneously optimizes an original data-fidelity term, the assignment smoothness over neighboring regions, and the number of assigned planar proxies. The synthesis of intermediate viewpoints demonstrates the effectiveness of our 3D reconstruction, and thereby the relevance of our proposed data fidelity-metric.",
        "A1": " approximates the 3D geometry of a scene",
        "A2": "suited to man-made scenes,",
        "A41": " approximates the 3D geometry",
        "A51": "the computation of a dense ",
        "A61": "optimizes an original data-fidelity term,",
        "A10": "The synthesis of intermediate viewpoints demonstrates the effectiveness of our 3D reconstruction, and thereby the relevance of our proposed data fidelity-metric.",
        "A7": "A pool of 3D plane hypotheses is first derived from the 3D point cloud,",
        "A83": "",
        "A82": "",
        "A81": "The synthesis of intermediate viewpoints demonstrates the effectiveness of our 3D reconstruction, and thereby the relevance of our proposed data fidelity-metric.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 226880943
    },
    {
        "Abstract": "We present a solution to the rolling shutter (RS) absolute camera pose problem with known vertical direction. Our new solver, R5Pup, is an extension of the general minimal solution R6P, which uses a double linearized RS camera model initialized by the standard perspective P3P. Here, thanks to using known vertical directions, we avoid double linearization and can get the camera absolute pose directly from the RS model without the initialization by a standard P3P. Moreover, we need only five 2D-to-3D matches while R6P needed six such matches. We demonstrate in simulated and real experiments that our new R5Pup is robust, fast and a very practical method for absolute camera pose computation for modern cameras on mobile devices. We compare our R5Pup to the state of the art RS and perspective methods and demonstrate that it outperforms them when vertical direction is known in the range of accuracy available on modern mobile devices. We also demonstrate that when using R5Pup solver in structure from motion (SfM) pipelines, it is better to transform already reconstructed scenes into the standard position, rather than using hard constraints on the verticality of up vectors.",
        "A1": "rolling shutter (RS) absolute camera pose problem with known vertical direction",
        "A2": "rolling shutter (RS) absolute camera pose problem with known vertical direction",
        "A41": "a solution to the rolling shutter (RS) absolute camera pose problem with known vertical direction.",
        "A51": "",
        "A61": "we avoid double linearization and can get the camera absolute pose directly from the RS model without the initialization by a standard P3P. Moreover, we need only five 2D-to-3D matches while R6P needed six such matches. ",
        "A10": " it outperforms them when vertical direction is known in the range of accuracy available on modern mobile devices. We also demonstrate that when using R5Pup solver in structure from motion (SfM) pipelines, it is better to transform already reconstructed scenes into the standard position, rather than using hard constraints on the verticality of up vectors.",
        "A7": "",
        "A83": "when using R5Pup solver in structure from motion (SfM) pipelines, it is better to transform already reconstructed scenes into the standard position, rather than using hard constraints on the verticality of up vectors.",
        "A82": " it outperforms them when vertical direction is known in the range of accuracy available on modern mobile devices. ",
        "A81": "our new R5Pup is robust, fast and a very practical method for absolute camera pose computation for modern cameras on mobile devices.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 257805618
    },
    {
        "Abstract": "We present a practical approach to address the problem of unconstrained face alignment for a single image. In our unconstrained problem, we need to deal with large shape and appearance variations under extreme head poses and rich shape deformation. To equip cascaded regressors with the capability to handle global shape variation and irregular appearance-shape relation in the unconstrained scenario, we partition the optimisation space into multiple domains of homogeneous descent, and predict a shape as a composition of estimations from multiple domain-specific regressors. With a specially formulated learning objective and a novel tree splitting function, our approach is capable of estimating a robust and meaningful composition. In addition to achieving state-of-the-art accuracy over existing approaches, our framework is also an efficient solution (350 FPS), thanks to the on-the-fly domain exclusion mechanism and the capability of leveraging the fast pixel feature.",
        "A1": "",
        "A2": "the problem of unconstrained face alignment for a single image",
        "A41": "partition the optimisation space into multiple domains of homogeneous descent, and predict a shape as a composition of estimations from multiple domain-specific regressors",
        "A51": "",
        "A61": "With a specially formulated learning objective and a novel tree splitting function, our approach is capable of estimating a robust and meaningful composition. ",
        "A10": "achieving state-of-the-art accuracy over existing approaches",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "efficient",
        "A54": "he on-the-fly domain exclusion mechanism and the capability of leveraging the fast pixel feature",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 360716323
    },
    {
        "Abstract": "We introduce the novel problem of identifying the photographer behind a photograph. To explore the feasibility of current computer vision techniques to address this problem, we created a new dataset of over 180,000 images taken by 41 well-known photographers. Using this dataset, we examined the effectiveness of a variety of features (low and high-level, including CNN features) at identifying the photographer. We also trained a new deep convolutional neural network for this task. Our results show that high-level features greatly outperform low-level features. We provide qualitative results using these learned models that give insight into our method's ability to distinguish between photographers, and allow us to draw interesting conclusions about what specific photographers shoot. We also demonstrate two applications of our method.",
        "A1": "explore the feasibility of current computer vision techniques to address this problem",
        "A2": "identifying the photographer behind a photograph",
        "A41": "trained a new deep convolutional neural network for this task.",
        "A51": "deep convolutional neural network ",
        "A61": "",
        "A10": "",
        "A7": "examined the effectiveness of a variety of features ",
        "A83": "",
        "A82": "",
        "A81": "high-level features greatly outperform low-level features.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a new dataset of over 180,000 images taken by 41 well-known photographers",
        "am_id": 326228214
    },
    {
        "Abstract": "This paper proposes a novel technique to extract training data from free space in a scene using a stereo camera. The proposed technique exploits the projection of planes in the v-disparity image paired with Bayesian linear regression to reliably identify training image pixels belonging to free space in a scene. Unlike other methods in the literature, the algorithm does not require any prior training, has only one free parameter, and is shown to provide consistent results over a variety of terrains without the need for any manual tuning. The proposed method is compared to two other data extraction methods from the literature. Results of Support Vector classifiers using training data extracted by the proposed technique are superior in terms of quality and consistency of free space estimation. Furthermore, the computation time required by the proposed technique is shown to be smaller and more consistent than that of other training data extraction methods.",
        "A1": "proposes a novel technique",
        "A2": "extract training data",
        "A41": "a novel technique to extract training data from free space ",
        "A51": " exploits the projection of planes in the v-disparity image paired with Bayesian linear regression to reliably identify training image pixels belonging to free space in a scene.",
        "A61": "o provide consistent results over a variety of terrains without the need for any manual tuning. ",
        "A10": "to be smaller and more consistent than that of other training data extraction methods.",
        "A7": "Results of Support Vector classifiers ",
        "A83": "",
        "A82": "",
        "A81": "to be smaller and more consistent than that of other training data extraction methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 8371196
    },
    {
        "Abstract": "The state-of-the-art in semantic segmentation is currently represented by fully convolutional networks (FCNs). However, FCNs use large receptive fields and many pooling layers, both of which cause blurring and low spatial resolution in the deep layers. As a result FCNs tend to produce segmentations that are poorly localized around object boundaries. Prior work has attempted to address this issue in post-processing steps, for example using a color-based CRF on top of the FCN predictions. However, these approaches require additional parameters and low-level features that are difficult to tune and integrate into the original network architecture. Additionally, most CRFs use colorbased pixel affinities, which are not well suited for semantic segmentation and lead to spatially disjoint predictions. To overcome these problems, we introduce a Boundary Neural Field (BNF), which is a global energy model integrating FCN predictions with boundary cues. The boundary information is used to enhance semantic segment coherence and to improve object localization. Specifically, we first show that the convolutional filters of semantic FCNs provide good features for boundary detection. We then employ the predicted boundaries to define pairwise potentials in our energy. Finally, we show that our energy decomposes semantic segmentation into multiple binary problems, which can be relaxed for efficient global optimization. We report extensive experiments demonstrating that minimization of our global boundary-based energy yields results superior to prior globalization methods, both quantitatively as well as qualitatively.",
        "A1": "semantic segmentation",
        "A2": "ause blurring and low spatial resolution in the deep layers",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "extensive experiments ",
        "A83": "",
        "A82": "",
        "A81": "minimization of our global boundary-based energy yields results superior to prior globalization methods, both quantitatively as well as qualitatively",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a Boundary Neural Field (BNF), which is a global energy model integrating FCN predictions with boundary cues",
        "A45": "",
        "am_id": 387902058
    },
    {
        "Abstract": "Scene labeling task is to segment the image into meaningful regions and categorize them into classes of objects which comprised the image. Commonly used methods typically find the local features for each segment and label them using classifiers. Afterwards, labeling is smoothed in order to make sure that neighboring regions receive similar labels. However, these methods ignore expressive connections between labels and non-local dependencies among regions. In this paper, we propose to use a sparse estimation of precision matrix (also called concentration matrix), which is the inverse of covariance matrix of data obtained by graphical lasso to find interaction between labels and regions. To do this, we formulate the problem as an energy minimization over a graph, whose structure is captured by applying sparse constraint on the elements of the precision matrix. This graph encodes (or represents) only significant interactions and avoids a fully connected graph, which is typically used to reflect the long distance associations. We use local and global information to achieve better labeling. We assess our approach on three datasets and obtained promising results.",
        "A1": "we propose to use a sparse estimation of precision matrix (also called concentration matrix), which is the inverse of covariance matrix of data obtained by graphical lasso to find interaction between labels and regions",
        "A2": "find interaction between labels and regions",
        "A41": " a sparse estimation of precision matrix (also called concentration matrix), which is the inverse of covariance matrix of data obtained by graphical lasso ",
        "A51": "",
        "A61": "these methods ignore expressive connections between labels and non-local dependencies among regions",
        "A10": "",
        "A7": "We assess our approach on three datasets and obtained promising results.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 54166878
    },
    {
        "Abstract": "Conventional scanning and multiplexing techniques for hyperspectral imaging suffer from limited temporal and/or spatial resolution. To resolve this issue, coding techniques are becoming increasingly popular in developing snapshot systems for high-resolution hyperspectral imaging. For such systems, it is a critical task to accurately restore the 3D hyperspectral image from its corresponding coded 2D image. In this paper, we propose an effective method for coded hyperspectral image restoration, which exploits extensive structure sparsity in the hyperspectral image. Specifically, we simultaneously explore spectral and spatial correlation via low-rank regularizations, and formulate the restoration problem into a variational optimization model, which can be solved via an iterative numerical algorithm. Experimental results using both synthetic data and real images show that the proposed method can significantly outperform the state-of-the-art methods on several popular coding-based hyperspectral imaging systems.",
        "A1": "",
        "A2": "exploits extensive structure sparsity in the hyperspectral image",
        "A41": "we propose an effective method for coded hyperspectral image restoration",
        "A51": "",
        "A61": "",
        "A10": "proposed method can significantly outperform the state-of-the-art methods on several popular coding-based hyperspectral imaging systems.",
        "A7": "Experimental results using both synthetic data and real images",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 320366202
    },
    {
        "Abstract": "In this paper, we propose a new framework for 3D tracking by detection based on fully volumetric representations. On one hand, 3D tracking by detection has shown robust use in the context of interaction (Kinect) and surface tracking. On the other hand, volumetric representations have recently been proven efficient both for building 3D features and for addressing the 3D tracking problem. We leverage these benefits by unifying both families of approaches into a single, fully volumetric tracking-by-detection framework. We use a centroidal Voronoi tessellation (CVT) representation to compactly tessellate shapes with optimal discretization, construct a feature space, and perform the tracking according to the correspondences provided by trained random forests. Our results show improved tracking and training computational efficiency and improved memory performance. This in turn enables the use of larger training databases than state of the art approaches, which we leverage by proposing a cross-tracking subject training scheme to benefit from all subject sequences for all tracking situations, thus yielding better detection and less overfitting.",
        "A1": "In this paper, we propose a new framework for 3D tracking by detection based on fully volumetric representations.",
        "A2": "In this paper, we propose a new framework for 3D tracking by detection based on fully volumetric representations.",
        "A41": "We leverage these benefits by unifying both families of approaches into a single, fully volumetric tracking-by-detection framework.",
        "A51": " We use a centroidal Voronoi tessellation (CVT) representation to compactly tessellate shapes with optimal discretization, construct a feature space,",
        "A61": "",
        "A10": "we leverage by proposing a cross-tracking subject training scheme to benefit from all subject sequences for all tracking situations, thus yielding better detection and less overfitting.",
        "A7": "Our results show improved tracking and training computational efficiency and improved memory performance. ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 478409594
    },
    {
        "Abstract": "We propose a novel spatially continuous framework for convex relaxations based on functional lifting. Our method can be interpreted as a sublabel-accurate solution to multilabel problems. We show that previously proposed functional lifting methods optimize an energy which is linear between two labels and hence require (often infinitely) many labels for a faithful approximation. In contrast, the proposed formulation is based on a piecewise convex approximation and therefore needs far fewer labels - see Fig. 1. In comparison to recent MRF-based approaches, our method is formulated in a spatially continuous setting and shows less grid bias. Moreover, in a local sense, our formulation is the tightest possible convex relaxation. It is easy to implement and allows an efficient primal-dual optimization on GPUs. We show the effectiveness of our approach on several computer vision problems.",
        "A1": "convex relaxations based on functional liftin",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "several computer vision problems.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "the proposed formulation is based on a piecewise convex approximation and therefore needs far fewer labels",
        "A54": "functional lifting",
        "A44": "spatially continuous framework for convex relaxations based on functional lifting",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 197210837
    },
    {
        "Abstract": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision. However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes. To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input. The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm. This enables us to generate a huge amount of training data in a fully automated manner. Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.",
        "A1": "we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.",
        "A2": "Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision.",
        "A41": "we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input.",
        "A51": "",
        "A61": "The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm. ",
        "A10": " Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.",
        "A7": " Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 191003337
    },
    {
        "Abstract": "In this paper, we propose a novel approach for text detection in natural images. Both local and global cues are taken into account for localizing text lines in a coarse-to-fine procedure. First, a Fully Convolutional Network (FCN) model is trained to predict the salient map of text regions in a holistic manner. Then, text line hypotheses are estimated by combining the salient map and character components. Finally, another FCN classifier is used to predict the centroid of each character, in order to remove the false hypotheses. The framework is general for handling text in multiple orientations, languages and fonts. The proposed method consistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013.",
        "A1": "propose a novel approach for text detection in natural images",
        "A2": "",
        "A41": "a novel approach for text detection in natural images",
        "A51": "",
        "A61": "method consistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013.",
        "A10": "The proposed method consistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "The proposed method consistently achieves the state-of-the-art performance on three text detection benchmarks: MSRA-TD500, ICDAR2015 and ICDAR2013.",
        "A64": "handling text in multiple orientations, languages and fonts",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 114948017
    },
    {
        "Abstract": "We propose a new technique to jointly recover cosegmentation and dense per-pixel correspondence in two images. Our method parameterizes the correspondence field using piecewise similarity transformations and recovers a mapping between the estimated common \"foreground\" regions in the two images allowing them to be precisely aligned. Our formulation is based on a hierarchical Markov random field model with segmentation and transformation labels. The hierarchical structure uses nested image regions to constrain inference across multiple scales. Unlike prior hierarchical methods which assume that the structure is given, our proposed iterative technique dynamically recovers the structure along with the labeling. This joint inference is performed in an energy minimization framework using iterated graph cuts. We evaluate our method on a new dataset of 400 image pairs with manually obtained ground truth, where it outperforms state-of-the-art methods designed specifically for either cosegmentation or correspondence estimation.",
        "A1": "We propose a new technique to jointly recover cosegmentation and dense per-pixel correspondence in two images.",
        "A2": "",
        "A41": "We propose a new technique to jointly recover cosegmentation and dense per-pixel correspondence in two images. ",
        "A51": "",
        "A61": "Unlike prior hierarchical methods which assume that the structure is given, our proposed iterative technique dynamically recovers the structure along with the labeling.",
        "A10": " it outperforms state-of-the-art methods designed specifically for either cosegmentation or correspondence estimation.",
        "A7": " We evaluate our method on a new dataset of 400 image pairs with manually obtained ground truth",
        "A83": "",
        "A82": "",
        "A81": " it outperforms state-of-the-art methods designed specifically for either cosegmentation or correspondence estimation.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 65082107
    },
    {
        "Abstract": "This paper proposes a novel method for tracking multiple moving objects and recovering their three-dimensional (3D) models separately using multiple calibrated cameras. For robustly tracking objects with similar appearances, the proposed method uses geometric information regarding 3D scene structure rather than appearance. A major limitation of previous techniques is foreground confusion, in which the shapes of objects and/or ghosting artifacts are ignored and are hence not appropriately specified in foreground regions. To overcome this limitation, our method classifies foreground voxels into targets (objects and artifacts) in each frame using a novel, probabilistic two-stage framework. This is accomplished by step-wise application of a track graph describing how targets interact and the maximum a posteriori expectation-maximization algorithm for the estimation of target parameters. We introduce mixture models with semiparametric component distributions regarding 3D target shapes. In order to not confuse artifacts with objects of interest, we automatically detect and track artifacts based on a closed-world assumption. Experimental results show that our method outperforms state-of-the-art trackers on seven public sequences while achieving real-time performance.",
        "A1": "This paper proposes a novel method for tracking multiple moving objects and recovering their three-dimensional (3D) models separately using multiple calibrated cameras. ",
        "A2": "A major limitation of previous techniques is foreground confusion, in which the shapes of objects and/or ghosting artifacts are ignored and are hence not appropriately specified in foreground regions. ",
        "A41": " our method classifies foreground voxels into targets (objects and artifacts) in each frame using a novel, probabilistic two-stage framework. ",
        "A51": "",
        "A61": "A major limitation of previous techniques is foreground confusion, in which the shapes of objects and/or ghosting artifacts are ignored and are hence not appropriately specified in foreground regions.",
        "A10": " our method outperforms state-of-the-art trackers on seven public sequences while achieving real-time performance.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " our method outperforms state-of-the-art trackers on seven public sequences while achieving real-time performance.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 346977271
    },
    {
        "Abstract": "In recent years, several methods have been developed to utilize hierarchical features learned from a deep convolutional neural network (CNN) for visual tracking. However, as features from a certain CNN layer characterize an object of interest from only one aspect or one level, the performance of such trackers trained with features from one layer (usually the second to last layer) can be further improved. In this paper, we propose a novel CNN based tracking framework, which takes full advantage of features from different CNN layers and uses an adaptive Hedge method to hedge several CNN based trackers into a single stronger one. Extensive experiments on a benchmark dataset of 100 challenging image sequences demonstrate the effectiveness of the proposed algorithm compared to several state-of-theart trackers.",
        "A1": "visual tracking",
        "A2": "as features from a certain CNN layer characterize an object of interest from only one aspect or one level, the performance of such trackers trained with features from one layer (usually the second to last layer) can be further improved",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of the proposed algorithm compared to several state-of-theart trackers.",
        "A7": "a benchmark dataset of 100 challenging image sequences",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "CNN",
        "A44": "takes full advantage of features from different CNN layers and uses an adaptive Hedge method to hedge several CNN based trackers into a single stronger one",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 368880826
    },
    {
        "Abstract": "Infinite dimensional covariance descriptors can provide richer and more discriminative information than their low dimensional counterparts. In this paper, we propose a novel image descriptor, namely, robust approximate infinite dimensional Gaussian (RAID-G). The challenges of RAID-G mainly lie on two aspects: (1) description of infinite dimensional Gaussian is difficult due to its non-linear Riemannian geometric structure and the infinite dimensional setting, hence effective approximation is necessary, (2) traditional maximum likelihood estimation (MLE) is not robust to high (even infinite) dimensional covariance matrix in Gaussian setting. To address these challenges, explicit feature mapping (EFM) is first introduced for effective approximation of infinite dimensional Gaussian induced by additive kernel function, and then a new regularized MLE method based on von Neumann divergence is proposed for robust estimation of covariance matrix. The EFM and proposed regularized MLE allow a closed-form of RAID-G, which is very efficient and effective for high dimensional features. We extend RAID-G by using the outputs of deep convolutional neural networks as original features, and apply it to material recognition. Our approach is evaluated on five material benchmarks and one fine-grained benchmark. It achieves 84.9% accuracy on FMD and 86.3% accuracy on UIUC material database, which are much higher than state-of-the-arts.",
        "A1": "Infinite dimensional covariance descriptors can provide richer and more discriminative information than their low dimensional counterparts.",
        "A2": " (1) description of infinite dimensional Gaussian is difficult due to its non-linear Riemannian geometric structure and the infinite dimensional setting, hence effective approximation is necessary, (2) traditional maximum likelihood estimation (MLE) is not robust to high (even infinite) dimensional covariance matrix in Gaussian setting.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "To address these challenges, explicit feature mapping (EFM) is first introduced for effective approximation of infinite dimensional Gaussian induced by additive kernel function, ",
        "A7": "Infinite dimensional covariance descriptors can provide richer and more discriminative information than their low dimensional counterparts. ",
        "A83": ", (2) traditional maximum likelihood estimation (MLE) is not robust to high (even infinite) dimensional covariance matrix in Gaussian setting. ",
        "A82": " The challenges of RAID-G mainly lie on two aspects: (1) description of infinite dimensional Gaussian is difficult due to its non-linear Riemannian geometric structure and the infinite dimensional setting, hence effective approximation is necessary,",
        "A81": " In this paper, we propose a novel image descriptor, namely, robust approximate infinite dimensional Gaussian (RAID-G). ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " (1) description of infinite dimensional Gaussian is difficult due to its non-linear Riemannian geometric structure and the infinite dimensional setting, hence effective approximation is necessary, (2) traditional maximum likelihood estimation (MLE) is not robust to high (even infinite) dimensional covariance matrix in Gaussian setting. ",
        "A52": " In this paper, we propose a novel image descriptor, namely, robust approximate infinite dimensional Gaussian (RAID-G). ",
        "A42": "Infinite dimensional covariance descriptors can provide richer and more discriminative information than their low dimensional counterparts.",
        "A45": "",
        "am_id": 377051059
    },
    {
        "Abstract": "We present a real-time body orientation estimation in a micro-Unmanned Air Vehicle video stream. This work is part ofafully autonomous UAVsystem which can maneuver to face a single individual in challenging outdoor environments. Our body orientation estimation consists of the following steps: (a) obtaining a set ofvisual appearance models for each body orientation, where each model is tagged with a set of scene information (obtained from sensors), (b) exploiting the mutual information of on-board sensors using latent-dynamic conditional random fields (WCRF), (c) Characterizing each visual appearance model with the most discriminative sensor information, (d) fast estimation ofbody orientation during the test flights given theWCRF parameters and the corresponding sensor readings. The key aspects of our approach is to add sparsity to the sensor readings with latent variables followed by long range dependency analysis. Experimental results obtained over real-time video streams demonstrate a significant improvement in both speed (l5-fps) and accuracy (72%) compared to the state of the art techniques that only rely on visual data. Video demonstration ofour autonomous flights (both from ground view and aerial view) are included in the supplementary material.",
        "A1": "We present a real-time body orientation estimation in a micro-Unmanned Air Vehicle video stream.",
        "A2": "We present a real-time body orientation estimation in a micro-Unmanned Air Vehicle video stream.",
        "A41": "The key aspects of our approach is to add sparsity to the sensor readings with latent variables followed by long range dependency analysis.",
        "A51": "",
        "A61": " the state of the art techniques that only rely on visual data.",
        "A10": " Experimental results obtained over real-time video streams demonstrate a significant improvement in both speed (l5-fps) and accuracy (72%) compared to the state of the art techniques ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " Experimental results obtained over real-time video streams demonstrate a significant improvement in both speed (l5-fps) and accuracy (72%) compared to the state of the art techniques ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 116069326
    },
    {
        "Abstract": "We propose a method for visual question answering which combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. This allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible. It particularly allows questions to be asked about the contents of an image, even when the image itself does not contain the whole answer. The method constructs a textual representation of the semantic content of an image, and merges it with textual information sourced from a knowledge base, to develop a deeper understanding of the scene viewed. Priming a recurrent neural network with this combined information, and the submitted question, leads to a very flexible visual question answering approach. We are specifically able to answer questions posed in natural language, that refer to information not contained in the image. We demonstrate the effectiveness of our model on two publicly available datasets, Toronto COCO-QA [23] and VQA [1] and show that it produces the best reported results in both cases.",
        "A1": " propose a method for visual question answering ",
        "A2": "allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible",
        "A41": "a method for visual question answering",
        "A51": "using the predominant neural network-based approach",
        "A61": "allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible",
        "A10": "produces the best reported results in both cases.",
        "A7": "two publicly available datasets, Toronto COCO-QA [23] and VQA [1] and show that it produces the best reported results in both cases.",
        "A83": "leads to a very flexible visual question answering approach.",
        "A82": "constructs a textual representation of the semantic content of an image, and merges it with textual information sourced from a knowledge base, to develop a deeper understanding of the scene viewed",
        "A81": "combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 292549823
    },
    {
        "Abstract": "Recently, there have been many progresses for the problem of non-rigid structure reconstruction based on 2D trajectories, but it is still challenging to deal with complex deformations or restricted view ranges. Promising alternatives are the piecewise reconstruction approaches, which divide trajectories into several local parts and stitch their individual reconstructions to produce an entire 3D structure. These methods show the state-of-the-art performance, however, most of them are specialized for relatively smooth surfaces and some are quite complicated. Meanwhile, it has been reported numerously in the field of pattern recognition that obtaining consensus from many weak hypotheses can give a strong, powerful result. Inspired by these reports, in this paper, we push the concept of part-based reconstruction to the limit: Instead of considering the parts as explicitly-divided local patches, we draw a large number of small random trajectory sets. From their individual reconstructions, we pull out a statistic of each 3D point to retrieve a strong reconstruction, of which the procedure can be expressed as a sparse l<sub>1</sub>-norm minimization problem. In order to resolve the reflection ambiguity between weak (and possibly bad) reconstructions, we propose a novel optimization framework which only involves a single eigenvalue decomposition. The proposed method can be applied to any type of data and outperforms the existing methods for the benchmark sequences, even though it is composed of a few, simple steps. Furthermore, it is easily parallelizable, which is another advantage.",
        "A1": "in this paper, we push the concept of part-based reconstruction to the limit",
        "A2": "it is still challenging to deal with complex deformations or restricted view ranges",
        "A41": "we push the concept of part-based reconstruction to the limit",
        "A51": "",
        "A61": "Instead of considering the parts as explicitly-divided local patches, we draw a large number of small random trajectory sets",
        "A10": "The proposed method can be applied to any type of data and outperforms the existing methods for the benchmark sequences",
        "A7": "any type of data",
        "A83": "",
        "A82": "easily parallelizable,",
        "A81": "can be applied to any type of data and outperforms the existing methods for the benchmark sequences",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 117621947
    },
    {
        "Abstract": "In this paper, we introduce a novel framework for WEakly supervised Learning of Deep cOnvolutional neural Networks (WELDON). Our method is dedicated to automatically selecting relevant image regions from weak annotations, e.g. global image labels, and encompasses the following contributions. Firstly, WELDON leverages recent improvements on the Multiple Instance Learning paradigm, i.e. negative evidence scoring and top instance selection. Secondly, the deep CNN is trained to optimize Average Precision, and fine-tuned on the target dataset with efficient computations due to convolutional feature sharing. A thorough experimental validation shows that WELDON outperforms state-of-the-art results on six different datasets.",
        "A1": "ntroduce a novel framework for WEakly supervised Learning of Deep cOnvolutional neural Networks (WELDON)",
        "A2": "outperforms state-of-the-art results",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "WELDON outperforms state-of-the-art results ",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "WELDON outperforms state-of-the-art results on six different datasets.",
        "A64": "outperforms state-of-the-art results",
        "A54": "WEakly supervised Learning of Deep cOnvolutional neural Networks (WELDON)",
        "A44": " is dedicated to automatically selecting relevant image regions from weak annotations",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 104669080
    },
    {
        "Abstract": "We present a deep layered architecture that generalizes convolutional neural networks (ConvNets). The architecture, called SimNets, is driven by two operators: (i) a similarity function that generalizes inner-product, and (ii) a log-mean-exp function called MEX that generalizes maximum and average. The two operators applied in succession give rise to a standard neuron but in \"feature space\". The feature spaces realized by SimNets depend on the choice of the similarity operator. The simplest setting, which corresponds to a convolution, realizes the feature space of the Exponential kernel, while other settings realize feature spaces of more powerful kernels (Generalized Gaussian, which includes as special cases RBF and Laplacian), or even dynamically learned feature spaces (Generalized Multiple Kernel Learning). As a result, the SimNet contains a higher abstraction level compared to a traditional ConvNet. We argue that enhanced expressiveness is important when the networks are small due to run-time constraints (such as those imposed by mobile applications). Empirical evaluation validates the superior expressiveness of SimNets, showing a significant gain in accuracy over ConvNets when computational resources at run-time are limited. We also show that in large-scale settings, where computational complexity is less of a concern, the additional capacity of SimNets can be controlled with proper regularization, yielding accuracies comparable to state of the art ConvNets.",
        "A1": "We present a deep layered architecture that generalizes convolutional neural networks (ConvNets).",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Empirical evaluation",
        "A83": "",
        "A82": " showing a significant gain in accuracy over ConvNets when computational resources at run-time are limited",
        "A81": "he superior expressiveness of SimNets",
        "A64": "",
        "A54": "driven by two operators",
        "A44": "SimNets",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 278306338
    },
    {
        "Abstract": "Recently, convolutional neural networks (CNN) have demonstrated impressive performance in various computer vision tasks. However, high performance hardware is typically indispensable for the application of CNN models due to the high computation complexity, which prohibits their further extensions. In this paper, we propose an efficient framework, namely Quantized CNN, to simultaneously speed-up the computation and reduce the storage and memory overhead of CNN models. Both filter kernels in convolutional layers and weighting matrices in fully-connected layers are quantized, aiming at minimizing the estimation error of each layer's response. Extensive experiments on the ILSVRC-12 benchmark demonstrate 4 ~ 6\u00d7 speed-up and 15 ~ 20\u00d7 compression with merely one percentage loss of classification accuracy. With our quantized CNN model, even mobile devices can accurately classify images within one second.",
        "A1": "simultaneously speed-up the computation and reduce the storage and memory overhead of CNN models",
        "A2": "Recently, convolutional neural networks (CNN) have demonstrated impressive performance in various computer vision tasks. However, high performance hardware is typically indispensable for the application of CNN models due to the high computation complexity, which prohibits their further extensions. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Extensive experiments on the ILSVRC-12 benchmark",
        "A83": "",
        "A82": "With our quantized CNN model, even mobile devices can accurately classify images within one second.",
        "A81": "4 ~ 6\u00d7 speed-up and 15 ~ 20\u00d7 compression with merely one percentage loss of classification accuracy. ",
        "A64": "Both filter kernels in convolutional layers and weighting matrices in fully-connected layers are quantized, aiming at minimizing the estimation error of each layer's response",
        "A54": "",
        "A44": "an efficient framework, namely Quantized CNN",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 209085628
    },
    {
        "Abstract": "Due to its wide range of applications, matching between two graphs has been extensively studied and remains an active topic. By contrast, it is still under-exploited on how to jointly match multiple graphs, partly due to its intrinsic combinatorial intractability. In this work, we address this challenging problem in a principled way under the rank-1 tensor approximation framework. In particular, we formulate multi-graph matching as a combinational optimization problem with two main ingredients: unary matching over graph vertices and structure matching over graph edges, both of which across multiple graphs. Then we propose an efficient power iteration solution for the resulting NP-hard optimization problem. The proposed algorithm has several advantages: (1) the intrinsic matching consistency across multiple graphs based on the high-order tensor optimization, (2) the free employment of powerful high-order node affinity, (3) the flexible integration between various types of node affinities and edge/hyper-edge affinities. Experiments on diverse and challenging datasets validate the effectiveness of the proposed approach in comparison with state-of the-arts.",
        "A1": "address this challenging problem in a principled way",
        "A2": " it is still under-exploited on how to jointly match multiple graphs, partly due to its intrinsic combinatorial intractability",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of the proposed approach in comparison with state-of the-arts",
        "A7": "Experiments on diverse and challenging datasets",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "power iteration",
        "A43": "an efficient power iteration solution for the resulting NP-hard optimization problem",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 110399698
    },
    {
        "Abstract": "Machine learning algorithms for the analysis of timeseries often depend on the assumption that the utilised data are temporally aligned. Any temporal discrepancies arising in the data is certain to lead to ill-generalisable models, which in turn fail to correctly capture the properties of the task at hand. The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. Nevertheless, the vast majority of algorithms oriented towards the temporal alignment of time-series are applied directly on the observation space, or utilise simple linear projections. Thus, they fail to capture complex, hierarchical non-linear representations which may prove to be beneficial towards the task of temporal alignment, particularly when dealing with multi-modal data (e.g., aligning visual and acoustic information). To this end, we present the Deep Canonical Time Warping (DCTW), a method which automatically learns complex non-linear representations of multiple time-series, generated such that (i) they are highly correlated, and (ii) temporally in alignment. By means of experiments on four real datasets, we show that the representations learnt via the proposed DCTW significantly outperform state-of-the-art methods in temporal alignment, elegantly handling scenarios with highly heterogeneous features, such as the temporal alignment of acoustic and visual features.",
        "A1": " The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. ",
        "A2": " The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. ",
        "A41": " we present the Deep Canonical Time Warping (DCTW), a method which automatically learns complex non-linear representations of multiple time-series, generated such that (i) they are highly correlated, and (ii) temporally in alignment",
        "A51": "By means of experiments on four real datasets",
        "A61": "elegantly handling scenarios with highly heterogeneous features",
        "A10": "",
        "A7": "experiments on four real datasets,",
        "A83": "",
        "A82": "",
        "A81": "we show that the representations learnt via the proposed DCTW significantly outperform state-of-the-art methods in temporal alignment, elegantly handling scenarios with highly heterogeneous features",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 479587977
    },
    {
        "Abstract": "This paper considers the problem of recovering a subspace arrangement from noisy samples, potentially corrupted with outliers. Our main result shows that this problem can be formulated as a convex semi-definite optimization problem subject to an additional rank constrain that involves only a very small number of variables. This is established by first reducing the problem to a quadratically constrained quadratic problem and then using its special structure to find conditions guaranteeing that a suitably built convex relaxation is indeed exact. When combined with the standard nuclear norm relaxation for rank, the results above lead to computationally efficient algorithms with optimality guarantees. A salient feature of the proposed approach is its ability to incorporate existing a-priori information about the noise, co-ocurrences, and percentage of outliers. These results are illustrated with several examples.",
        "A1": " considers the problem of recovering a subspace arrangement from noisy samples, potentially corrupted with outliers. ",
        "A2": "the problem of recovering a subspace arrangement from noisy samples, potentially corrupted with outliers. ",
        "A41": "",
        "A51": "",
        "A61": " its ability to incorporate existing a-priori information about the noise, co-ocurrences, and percentage of outliers.",
        "A10": "ability to incorporate existing a-priori information about the noise, co-ocurrences, and percentage of outliers.",
        "A7": "",
        "A83": "",
        "A82": " computationally efficient algorithms with optimality guarantees.",
        "A81": "problem can be formulated as a convex semi-definite optimization problem subject to an additional rank constrain that involves only a very small number of variables. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "computationally efficient algorithms",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 347170499
    },
    {
        "Abstract": "Because of the limitations of matrix factorization, such as losing spatial structure information, the concept of tensor factorization has been applied for the recovery of a low dimensional subspace from high dimensional visual data. Generally, the recovery is achieved by minimizing the loss function between the observed data and the factorization representation. Under different assumptions of the noise distribution, the loss functions are in various forms, like L1 and L2 norms. However, real data are often corrupted by noise with an unknown distribution. Then any specific form of loss function for one specific kind of noise often fails to tackle such real data with unknown noise. In this paper, we propose a tensor factorization algorithm to model the noise as a Mixture of Gaussians (MoG). As MoG has the ability of universally approximating any hybrids of continuous distributions, our algorithm can effectively recover the low dimensional subspace from various forms of noisy observations. The parameters of MoG are estimated under the EM framework and through a new developed algorithm of weighted low-rank tensor factorization (WLRTF). The effectiveness of our algorithm are substantiated by extensive experiments on both of synthetic data and real image data.",
        "A1": "matrix factorization",
        "A2": " However, real data are often corrupted by noise with an unknown distribution. Then any specific form of loss function for one specific kind of noise often fails to tackle such real data with unknown noise",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "extensive experiments on both of synthetic data and real image data.",
        "A83": "",
        "A82": "",
        "A81": "The effectiveness of our algorithm are substantiated by extensive experiments on both of synthetic data and real image data.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "Mixture of Gaussians ",
        "A43": " we propose a tensor factorization algorithm to model the noise as a Mixture of Gaussians (MoG). ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 240823363
    },
    {
        "Abstract": "Deep Recurrent Neural Network architectures, though remarkably capable at modeling sequences, lack an intuitive high-level spatio-temporal structure. That is while many problems in computer vision inherently have an underlying high-level structure and can benefit from it. Spatiotemporal graphs are a popular tool for imposing such high-level intuitions in the formulation of real world problems. In this paper, we propose an approach for combining the power of high-level spatio-temporal graphs and sequence learning success of Recurrent Neural Networks (RNNs). We develop a scalable method for casting an arbitrary spatio-temporal graph as a rich RNN mixture that is feedforward, fully differentiable, and jointly trainable. The proposed method is generic and principled as it can be used for transforming any spatio-temporal graph through employing a certain set of well defined steps. The evaluations of the proposed approach on a diverse set of problems, ranging from modeling human motion to object interactions, shows improvement over the state-of-the-art with a large margin. We expect this method to empower new approaches to problem formulation through high-level spatio-temporal graphs and Recurrent Neural Networks.",
        "A1": "Deep Recurrent Neural Network architecture",
        "A2": " lack an intuitive high-level spatio-temporal structure",
        "A41": " a scalable method for casting an arbitrary spatio-temporal graph as a rich RNN mixture that is feedforward, fully differentiable, and jointly trainable",
        "A51": "the power of high-level spatio-temporal graphs and sequence learning success of Recurrent Neural Networks (RNNs)",
        "A61": "",
        "A10": "",
        "A7": "modeling human motion to object interactions",
        "A83": "",
        "A82": "",
        "A81": "improvement over the state-of-the-art with a large margin",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 407689036
    },
    {
        "Abstract": "We propose a Bayesian evidence framework to facilitate transfer learning from pre-trained deep convolutional neural networks (CNNs). Our framework is formulated on top of a least squares SVM (LS-SVM) classifier, which is simple and fast in both training and testing, and achieves competitive performance in practice. The regularization parameters in LS-SVM is estimated automatically without grid search and cross-validation by maximizing evidence, which is a useful measure to select the best performing CNN out of multiple candidates for transfer learning, the evidence is optimized efficiently by employing Aitken's delta-squared process, which accelerates convergence of fixed point update. The proposed Bayesian evidence framework also provides a good solution to identify the best ensemble of heterogeneous CNNs through a greedy algorithm. Our Bayesian evidence framework for transfer learning is tested on 12 visual recognition datasets and illustrates the state-of-the-art performance consistently in terms of prediction accuracy and modeling efficiency.",
        "A1": " facilitate transfer learning from pre-trained deep convolutional neural networks ",
        "A2": "identify the best ensemble of heterogeneous CNNs",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " is tested on 12 visual recognition datasets",
        "A83": "",
        "A82": "",
        "A81": " illustrates the state-of-the-art performance ",
        "A64": "",
        "A54": " a least squares SVM (LS-SVM) classifier",
        "A44": "framework to facilitate transfer learning from pre-trained deep convolutional neural networks ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 256109086
    },
    {
        "Abstract": "Despite significant progress in object categorization, in recent years, a number of important challenges remain, mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels. Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa. We propose the notion of semi-supervised vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition using a unified framework. Specifically, we propose a maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms, ensuring that labeled samples are projected closest to their correct prototypes, in the embedding space, than to others. We show that resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.",
        "A1": "We propose the notion of semi-supervised vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition using a unified framework. ",
        "A2": " resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "shows improvements in supervised, zero-shot, and large open set recognition",
        "A7": "We show that resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.",
        "A83": "",
        "A82": "",
        "A81": "up to 310K class vocabulary on AwA and ImageNet datasets.",
        "A64": " to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition",
        "A54": "a maximum margin framework",
        "A44": " a maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms, ensuring that labeled samples are projected closest to their correct prototypes, in the embedding space, than to others. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 300704252
    },
    {
        "Abstract": "In real world applications, more and more data, for example, image/video data, are high dimensional and repre-sented by multiple views which describe different perspectives of the data. Efficiently clustering such data is a challenge. To address this problem, this paper proposes a novel multi-view clustering method called Discriminatively Embedded K-Means (DEKM), which embeds the synchronous learning of multiple discriminative subspaces into multi-view K-Means clustering to construct a unified framework, and adaptively control the intercoordinations between these subspaces simultaneously. In this framework, we firstly design a weighted multi-view Linear Discriminant Analysis (LDA), and then develop an unsupervised optimization scheme to alternatively learn the common clustering indicator, multiple discriminative subspaces and weights for heterogeneous features with convergence. Comprehensive evaluations on three benchmark datasets and comparisons with several state-of-the-art multi-view clustering algorithms demonstrate the superiority of the proposed work.",
        "A1": "Efficiently clustering",
        "A2": "proposes a novel multi-view clustering method called Discriminatively Embedded K-Means (DEKM),",
        "A41": "a novel multi-view clustering method called Discriminatively Embedded K-Means (DEKM)",
        "A51": "K-Means",
        "A61": "adaptively control the intercoordinations between these subspaces simultaneously",
        "A10": "",
        "A7": "Comprehensive evaluations on three benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "comparisons with several state-of-the-art multi-view clustering algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 322146826
    },
    {
        "Abstract": "Recent innovations in training deep convolutional neural network (ConvNet) models have motivated the design of new methods to automatically learn local image descriptors. The latest deep ConvNets proposed for this task consist of a siamese network that is trained by penalising misclassification of pairs of local image patches. Current results from machine learning show that replacing this siamese by a triplet network can improve the classification accuracy in several problems, but this has yet to be demonstrated for local image descriptor learning. Moreover, current siamese and triplet networks have been trained with stochastic gradient descent that computes the gradient from individual pairs or triplets of local image patches, which can make them prone to overfitting. In this paper, we first propose the use of triplet networks for the problem of local image descriptor learning. Furthermore, we also propose the use of a global loss that minimises the overall classification error in the training set, which can improve the generalisation capability of the model. Using the UBC benchmark dataset for comparing local image descriptors, we show that the triplet network produces a more accurate embedding than the siamese network in terms of the UBC dataset errors. Moreover, we also demonstrate that a combination of the triplet and global losses produces the best embedding in the field, using this triplet network. Finally, we also show that the use of the central-surround siamese network trained with the global loss produces the best result of the field on the UBC dataset.",
        "A1": "we first propose the use of triplet networks for the problem of local image descriptor learning",
        "A2": "we first propose the use of triplet networks for the problem of local image descriptor learning",
        "A41": " we first propose the use of triplet networks for the problem of local image descriptor learning",
        "A51": "Recent innovations in training deep convolutional neural network (ConvNet) models have motivated the design of new methods to automatically learn local image descriptors",
        "A61": "can make them prone to overfitting.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 466103990
    },
    {
        "Abstract": "Super-symmetric tensors - a higher-order extension of scatter matrices - are becoming increasingly popular in machine learning and computer vision for modeling data statistics, co-occurrences, or even as visual descriptors. They were shown recently to outperform second-order approaches, however, the size of these tensors are exponential in the data dimensionality, which is a significant concern. In this paper, we study third-order supersymmetric tensor descriptors in the context of dictionary learning and sparse coding. For this purpose, we propose a novel non-linear third-order texture descriptor. Our goal is to approximate these tensors as sparse conic combinations of atoms from a learned dictionary. Apart from the significant benefits to tensor compression that this framework offers, our experiments demonstrate that the sparse coefficients produced by this scheme lead to better aggregation of high-dimensional data and showcase superior performance on two common computer vision tasks compared to the state of the art.",
        "A1": " study third-order supersymmetric tensor descriptors in the context of dictionary learning and sparse coding",
        "A2": "novel non-linear third-order texture descriptor",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "better aggregation of high-dimensional data and showcase superior performance",
        "A7": "",
        "A83": "showcase superior performance ",
        "A82": " better aggregation of high-dimensional data",
        "A81": " the significant benefits to tensor compression",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "approximate these tensors as sparse conic combinations of atoms from a learned dictionary",
        "A53": "Super-symmetric tensors",
        "A43": "a novel non-linear third-order texture descriptor",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 148440843
    },
    {
        "Abstract": "For people first impressions of someone are of determining importance. They are hard to alter through further information. This begs the question if a computer can reach the same judgement. Earlier research has already pointed out that age, gender, and average attractiveness can be estimated with reasonable precision. We improve the state of-the-art, but also predict - based on someone's known preferences - how much that particular person is attracted to a novel face. Our computational pipeline comprises a face detector, convolutional neural networks for the extraction of deep features, standard support vector regression for gender, age and facial beauty, and - as the main novelties - visual regularized collaborative filtering to infer interperson preferences as well as a novel regression technique for handling visual queries without rating history. We validate the method using a very large dataset from a dating site as well as images from celebrities. Our experiments yield convincing results, i.e. we predict 76% of the ratings correctly solely based on an image, and reveal some sociologically relevant conclusions. We also validate our collaborative filtering solution on the standard MovieLens rating dataset, augmented with movie posters, to predict an individuals movie rating. We demonstrate our algorithms on howhot.io which went viral around the Internet with more than 50 million pictures evaluated in the first month.",
        "A1": "",
        "A2": " We improve the state of-the-art, but also predict - based on someone's known preferences ",
        "A41": "Our computational pipeline comprises a face detector, convolutional neural networks for the extraction of deep features, standard support vector regression for gender, age and facial beauty, and - as the main novelties - visual regularized collaborative filtering to infer interperson preferences as well as a novel regression technique for handling visual queries without rating history. ",
        "A51": " convolutional neural networks",
        "A61": "We improve the state of-the-art, but also predict - based on someone's known preferences",
        "A10": "",
        "A7": "validate our collaborative filtering solution on the standard MovieLens rating dataset, augmented with movie posters, to predict an individuals movie rating.",
        "A83": "more than 50 million pictures evaluated in the first month.",
        "A82": "reveal some sociologically relevant conclusions",
        "A81": "we predict 76% of the ratings correctly solely based on an image",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " convolutional neural networks",
        "A42": "",
        "A45": "",
        "am_id": 43368261
    },
    {
        "Abstract": "We propose an explicitly discriminative and 'simple' approach to generate invariance to nuisance transformations modeled as unitary. In practice, the approach works well to handle non-unitary transformations as well. Our theoretical results extend the reach of a recent theory of invariance to discriminative and kernelized features based on unitary kernels. As a special case, a single common framework can be used to generate subject-specific pose-invariant features for face recognition and vice-versa for pose estimation. We show that our main proposed method (DIKF) can perform well under very challenging large-scale semisynthetic face matching and pose estimation protocols with unaligned faces using no landmarking whatsoever. We additionally benchmark on CMU MPIE and outperform previous work in almost all cases on off-angle face matching while we are on par with the previous state-of-the-art on the LFW unsupervised and image-restricted protocols, without any low-level image descriptors other than raw-pixels.",
        "A1": "generate invariance to nuisance transformations modeled as unitary",
        "A2": "",
        "A41": "generate subject-specific pose-invariant features for face recognition and vice-versa for pose estimation",
        "A51": "",
        "A61": "",
        "A10": "outperform previous work in almost all cases on off-angle face matchin",
        "A7": "CMU MPIE ",
        "A83": "outperform previous work in almost all cases on off-angle face matching",
        "A82": " pose estimation protocols with unaligned faces using no landmarking whatsoever",
        "A81": "perform well under very challenging large-scale semisynthetic face matching",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 325182317
    },
    {
        "Abstract": "Convolutional neural nets (CNNs) have demonstrated remarkable performance in recent history. Such approaches tend to work in a \"unidirectional\" bottom-up feed-forward fashion. However, practical experience and biological evidence tells us that feedback plays a crucial role, particularly for detailed spatial understanding tasks. This work explores \"bidirectional\" architectures that also reason with top-down feedback: neural units are influenced by both lower and higher-level units. We do so by treating units as rectified latent variables in a quadratic energy function, which can be seen as a hierarchical Rectified Gaussian model (RGs) [39]. We show that RGs can be optimized with a quadratic program (QP), that can in turn be optimized with a recurrent neural network (with rectified linear units). This allows RGs to be trained with GPU-optimized gradient descent. From a theoretical perspective, RGs help establish a connection between CNNs and hierarchical probabilistic models. From a practical perspective, RGs are well suited for detailed spatial tasks that can benefit from top-down reasoning. We illustrate them on the challenging task of keypoint localization under occlusions, where local bottom-up evidence may be misleading. We demonstrate state-of-the-art results on challenging benchmarks.",
        "A1": "This work explores \"bidirectional\" architectures that also reason with top-down feedback: neural units are influenced by both lower and higher-level units",
        "A2": "However, practical experience and biological evidence tells us that feedback plays a crucial role",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Rectified Gaussian model",
        "A42": " We do so by treating units as rectified latent variables in a quadratic energy function, which can be seen as a hierarchical Rectified Gaussian model",
        "A45": "",
        "am_id": 489658559
    },
    {
        "Abstract": "We propose a novel method for detecting horizontal vanishing points and the zenith vanishing point in man-made environments. The dominant trend in existing methods is to first find candidate vanishing points, then remove outliers by enforcing mutual orthogonality. Our method reverses this process: we propose a set of horizon line candidates and score each based on the vanishing points it contains. A key element of our approach is the use of global image context, extracted with a deep convolutional network, to constrain the set of candidates under consideration. Our method does not make a Manhattan-world assumption and can operate effectively on scenes with only a single horizontal vanishing point. We evaluate our approach on three benchmark datasets and achieve state-of the-art performance on each. In addition, our approach is significantly faster than the previous best method.",
        "A1": "detecting horizontal vanishing points and the zenith vanishing point in man-made environments",
        "A2": "detecting horizontal vanishing points and the zenith vanishing point in man-made environments",
        "A41": "a novel method for detecting horizontal vanishing points and the zenith vanishing point in man-made environments",
        "A51": " the use of global image context, extracted with a deep convolutional network, to constrain the set of candidates under consideration",
        "A61": "The dominant trend in existing methods is to first find candidate vanishing points, then remove outliers by enforcing mutual orthogonality. Our method reverses this process: we propose a set of horizon line candidates and score each based on the vanishing points it contains. ",
        "A10": "achieve state-of the-art performance on each",
        "A7": "We evaluate our approach on three benchmark datasets ",
        "A83": "",
        "A82": "",
        "A81": "our approach is significantly faster than the previous best method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 129968142
    },
    {
        "Abstract": "This paper proposes a field model for repairing 3D shapes constructed from multi-view RGB data. Specifically, we represent a 3D shape in a Markov random field (MRF) in which the geometric information is encoded by random binary variables and the appearance information is retrieved from a set of RGB images captured at multiple viewpoints. The local priors in the MRF model capture the local structures of object shapes and are learnt from 3D shape templates using a convolutional deep belief network. Repairing a 3D shape is formulated as the maximum a posteriori (MAP) estimation in the corresponding MRF. Variational mean field approximation technique is adopted for the MAP estimation. The proposed method was evaluated on both artificial data and real data obtained from reconstruction of practical scenes. Experimental results have shown the robustness and efficiency of the proposed method in repairing noisy and incomplete 3D shapes.",
        "A1": "This paper proposes a field model for repairing 3D shapes constructed from multi-view RGB data. ",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "The proposed method was evaluated on both artificial data and real data obtained from reconstruction of practical scenes.",
        "A83": "",
        "A82": "",
        "A81": " Experimental results have shown the robustness and efficiency of the proposed method in repairing noisy and incomplete 3D shapes.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "multi-view RGB data",
        "A42": "The local priors in the MRF model capture the local structures of object shapes and are learnt from 3D shape templates using a convolutional deep belief network. ",
        "A45": "The proposed method was evaluated on both artificial data and real data obtained from reconstruction of practical scenes.",
        "am_id": 49351110
    },
    {
        "Abstract": "In many sub-fields, researchers collect datasets of human ground truth that are used to create a new algorithm. For example, in research on image perception, datasets have been collected for topics such as what makes an image aesthetic or memorable. Despite high costs for human data collection, datasets are infrequently reused beyond their own fields of interest. Moreover, the algorithms built from them are domain-specific (predict a small set of attributes) and usually unconnected to one another. In this paper, we present a paradigm for building generalized and expandable models of human image perception. First, we fuse multiple fragmented and partially-overlapping datasets through data imputation. We then create a theoretically-structured statistical model of human image perception that is fit to the fused datasets. The resulting model has many advantages. (1) It is generalized, going beyond the content of the constituent datasets, and can be easily expanded by fusing additional datasets. (2) It provides a new ontology usable as a network to expand human data in a cost-effective way. (3) It can guide the design of a generalized computational algorithm for multi-dimensional visual perception. Indeed, experimental results show that a model-based algorithm outperforms state-of-the-art methods on predicting visual sentiment, visual realism and interestingness. Our paradigm can be used in various visual tasks (e.g., video summarization).",
        "A1": "we present a paradigm for building generalized and expandable models of human image perception",
        "A2": "we present a paradigm for building generalized and expandable models of human image perception",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "a model-based algorithm outperforms state-of-the-art methods on predicting visual sentiment, visual realism and interestingness",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Our paradigm can be used in various visual tasks (e.g., video summarization)",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " (1) It is generalized, going beyond the content of the constituent datasets, and can be easily expanded by fusing additional datasets. (2) It provides a new ontology usable as a network to expand human data in a cost-effective way. (3) It can guide the design of a generalized computational algorithm for multi-dimensional visual perception",
        "A52": "",
        "A42": "a theoretically-structured statistical model of human image perception that is fit to the fused datasets",
        "A45": "",
        "am_id": 29366453
    },
    {
        "Abstract": "While convolutional neural networks (CNN) have been excellent for object recognition, the greater spatial variability in scene images typically meant that the standard full-image CNN features are suboptimal for scene classification. In this paper, we investigate a framework allowing greater spatial flexibility, in which the Fisher vector (FV) encoded distribution of local CNN features, obtained from a multitude of region proposals per image, is considered instead. The CNN features are computed from an augmented pixel-wise representation comprising multiple modalities of RGB, HHA and surface normals, as extracted from RGB-D data. More significantly, we make two postulates: (1) component sparsity - that only a small variety of region proposals and their corresponding FV GMM components contribute to scene discriminability, and (2) modal non-sparsity - within these discriminative components, all modalities have important contribution. In our framework, these are implemented through regularization terms applying group lasso to GMM components and exclusive group lasso across modalities. By learning and combining regressors for both proposal-based FV features and global CNN features, we were able to achieve state-of-the-art scene classification performance on the SUNRGBD Dataset and NYU Depth Dataset V2.",
        "A1": " investigate a framework",
        "A2": "achieve state-of-the-art scene classification performance on the SUNRGBD Dataset and NYU Depth Dataset V2.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieve state-of-the-art scene classification performance on the SUNRGBD Dataset and NYU Depth Dataset V2.",
        "A7": " By learning and combining regressors for both proposal-based FV features and global CNN features",
        "A83": "",
        "A82": "",
        "A81": "achieve state-of-the-art scene classification performance on the SUNRGBD Dataset and NYU Depth Dataset V2.",
        "A64": "",
        "A54": " CNN ",
        "A44": " allowing greater spatial flexibility",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 173371509
    },
    {
        "Abstract": "It is well-established by cognitive neuroscience that human perception of objects constitutes a complex process, where object appearance information is combined with evidence about the so-called object affordances, namely the types of actions that humans typically perform when interacting with them. This fact has recently motivated the sensorimotor approach to the challenging task of automatic object recognition, where both information sources are fused to improve robustness. In this work, the aforementioned paradigm is adopted, surpassing current limitations of sensorimotor object recognition research. Specifically, the deep learning paradigm is introduced to the problem for the first time, developing a number of novel neuro-biologically and neuro-physiologically inspired architectures that utilize state-of-the-art neural networks for fusing the available information sources in multiple ways. The proposed methods are evaluated using a large RGB-D corpus, which is specifically collected for the task of sensorimotor object recognition and is made publicly available. Experimental results demonstrate the utility of affordance information to object recognition, achieving an up to 29% relative error reduction by its inclusion.",
        "A1": "he sensorimotor approach to the challenging task of automatic object recognition, where both information sources are fused to improve robustness.",
        "A2": "In this work, the aforementioned paradigm is adopted, surpassing current limitations of sensorimotor object recognition research.",
        "A41": "The proposed methods are evaluated using a large RGB-D corpus, ",
        "A51": " neuro-biologically and neuro-physiologically inspired architectures that utilize state-of-the-art neural networks",
        "A61": "Experimental results demonstrate the utility of affordance information to object recognition, achieving an up to 29% relative error reduction by its inclusion.",
        "A10": ". Specifically, the deep learning paradigm is introduced to the problem for the first time, developing a number of novel neuro-biologically and neuro-physiologically inspired architectures that utilize state-of-the-art neural networks for fusing the available information sources in multiple ways.",
        "A7": "The proposed methods are evaluated using a large RGB-D corpus, which is specifically collected for the task of sensorimotor object recognition and is made publicly available.",
        "A83": "",
        "A82": "",
        "A81": "Experimental results demonstrate the utility of affordance information to object recognition, achieving an up to 29% relative error reduction by its inclusion.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 12506170
    },
    {
        "Abstract": "This paper establishes the existence of observable footprints that reveal the causal dispositions of the object categories appearing in collections of images. We achieve this goal in two steps. First, we take a learning approach to observational causal discovery, and build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution. Second, we use our causal direction classifier to effectively distinguish between features of objects and features of their contexts in collections of static images. Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.",
        "A1": "This paper establishes the existence of observable footprints",
        "A2": " reveal the causal dispositions of the object categories appearing in collections of images. ",
        "A41": "a learning approach to observational causal discovery,",
        "A51": "build a classifier that achieves state-of-the-art performance on finding the causal direction between pairs of random variables, given samples from their joint distribution",
        "A61": "",
        "A10": "Our experiments demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts, and by the same token, the existence of observable signals that reveal the causal dispositions of objects.",
        "A7": "Our experiments ",
        "A83": "",
        "A82": " the existence of observable signals that reveal the causal dispositions of objects.",
        "A81": "demonstrate the existence of a relation between the direction of causality and the difference between objects and their contexts,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 260772311
    },
    {
        "Abstract": "Time-of-flight (TOF) depth cameras provide robust depth inference at low power requirements in a wide variety of consumer and industrial applications. These cameras reconstruct a single depth frame from a given set of infrared (IR) frames captured over a very short exposure period. Operating in this mode the camera essentially forgets all information previously captured - and performs depth inference from scratch for every frame. We challenge this practice and propose using previously captured information when inferring depth. An inherent problem we have to address is camera motion over this longer period of collecting observations. We derive a probabilistic framework combining a simple but robust model of camera and object motion, together with an observation model. This combination allows us to integrate information over multiple frames while remaining robust to rapid changes. Operating the camera in this manner has implications in terms of both computational efficiency and how information should be captured. We address these two issues and demonstrate a realtime TOF system with robust temporal integration that improves depth accuracy over strong baseline methods including adaptive spatio-temporal filters.",
        "A1": "using previously captured information when inferring depth",
        "A2": "using previously captured information when inferring depth",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We address these two issues and demonstrate a realtime TOF system with robust temporal integration that improves depth accuracy over strong baseline methods including adaptive spatio-temporal filters.",
        "A64": "",
        "A54": "",
        "A44": "e derive a probabilistic framework combining a simple but robust model of camera and object motion, together with an observation model. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 137244900
    },
    {
        "Abstract": "Matching local geometric features on real-world depth images is a challenging task due to the noisy, low-resolution, and incomplete nature of 3D scan data. These difficulties limit the performance of current state-of-art methods, which are typically based on histograms over geometric properties. In this paper, we present 3DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3D data. To amass training data for our model, we propose a self-supervised feature learning method that leverages the millions of correspondence labels found in existing RGB-D reconstructions. Experiments show that our descriptor is not only able to match local geometry in new scenes for reconstruction, but also generalize to different tasks and spatial scales (e.g. instance-level object model alignment for the Amazon Picking Challenge, and mesh surface correspondence). Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin. Code, data, benchmarks, and pre-trained models are available online at http://3dmatch.cs.princeton.edu.",
        "A1": "Matching local geometric features on real-world depth images is a challenging task due to the noisy, low-resolution, and incomplete nature of 3D scan data.",
        "A2": "Matching local geometric features on real-world depth images is a challenging task due to the noisy, low-resolution, and incomplete nature of 3D scan data.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin.",
        "A7": "",
        "A83": "",
        "A82": "Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin.",
        "A81": "Experiments show that our descriptor is not only able to match local geometry in new scenes for reconstruction, but also generalize to different tasks and spatial scales (e.g. instance-level object model alignment for the Amazon Picking Challenge, and mesh surface correspondence). ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Results show that 3DMatch consistently outperforms other state-of-the-art approaches by a significant margin.",
        "A52": " To amass training data for our model, we propose a self-supervised feature learning method that leverages the millions of correspondence labels found in existing RGB-D reconstructions. ",
        "A42": "In this paper, we present 3DMatch, a data-driven model that learns a local volumetric patch descriptor for establishing correspondences between partial 3D data.",
        "A45": "",
        "am_id": 32000134
    },
    {
        "Abstract": "Visual recognition of wet surfaces and their degrees of wetness is important for many computer vision applications. It can inform slippery spots on a road to autonomous vehicles, muddy areas of a trail to humanoid robots, and the freshness of groceries to us. In the past, monochromatic appearance change, the fact that surfaces darken when wet, has been modeled to recognize wet surfaces. In this paper, we show that color change, particularly in its spectral behavior, carries rich information about a wet surface. We derive an analytical spectral appearance model of wet surfaces that expresses the characteristic spectral sharpening due to multiple scattering and absorption in the surface. We derive a novel method for estimating key parameters of this spectral appearance model, which enables the recovery of the original surface color and the degree of wetness from a single observation. Applied to a multispectral image, the method estimates the spatial map of wetness together with the dry spectral distribution of the surface. To our knowledge, this work is the first to model and leverage the spectral characteristics of wet surfaces to revert its appearance. We conduct comprehensive experimental validation with a number of wet real surfaces. The results demonstrate the accuracy of our model and the effectiveness of our method for surface wetness and color estimation.",
        "A1": "show that color change, particularly in its spectral behavior, carries rich information about a wet surface",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "comprehensive experimental validation with a number of wet real surfaces",
        "A83": "",
        "A82": "",
        "A81": "the accuracy of our model and the effectiveness of our method for surface wetness and color estimation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the first to model and leverage the spectral characteristics of wet surfaces to revert its appearance",
        "A52": "monochromatic appearance change, the fact that surfaces darken when wet, has been modeled to recognize wet surfaces",
        "A42": "an analytical spectral appearance model of wet surfaces that expresses the characteristic spectral sharpening due to multiple scattering and absorption in the surface",
        "A45": "",
        "am_id": 448448321
    },
    {
        "Abstract": "Detecting faces with occlusions is a challenging task due to two main reasons: 1) the absence of large datasets of masked faces, and 2) the absence of facial cues from the masked regions. To address these two issues, this paper first introduces a dataset, denoted as MAFA, with 30, 811 Internet images and 35, 806 masked faces. Faces in the dataset have various orientations and occlusion degrees, while at least one part of each face is occluded by mask. Based on this dataset, we further propose LLE-CNNs for masked face detection, which consist of three major modules. The Proposal module first combines two pre-trained CNNs to extract candidate facial regions from the input image and represent them with high dimensional descriptors. After that, the Embedding module is incorporated to turn such descriptors into a similarity-based descriptor by using locally linear embedding (LLE) algorithm and the dictionaries trained on a large pool of synthesized normal faces, masked faces and non-faces. In this manner, many missing facial cues can be largely recovered and the influences of noisy cues introduced by diversified masks can be greatly alleviated. Finally, the Verification module is incorporated to identify candidate facial regions and refine their positions by jointly performing the classification and regression tasks within a unified CNN. Experimental results on the MAFA dataset show that the proposed approach remarkably outperforms 6 state-of-the-arts by at least 15.6%.",
        "A1": "To address these two issues, ",
        "A2": " 1) the absence of large datasets of masked faces, and 2) the absence of facial cues from the masked regions. ",
        "A41": "LLE-CNNs",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the proposed approach remarkably outperforms 6 state-of-the-arts by at least 15.6%.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": " locally linear embedding (LLE) algorithm ",
        "A62": "",
        "A52": "",
        "A42": "The Proposal module",
        "A45": "a dataset, denoted as MAFA, with 30, 811 Internet images and 35, 806 masked faces.",
        "am_id": 98453917
    },
    {
        "Abstract": "In our overly-connected world, the automatic recognition of virality - the quality of an image or video to be rapidly and widely spread in social networks - is of crucial importance, and has recently awaken the interest of the computer vision community. Concurrently, recent progress in deep learning architectures showed that global pooling strategies allow the extraction of activation maps, which highlight the parts of the image most likely to contain instances of a certain class. We extend this concept by introducing a pooling layer that learns the size of the support area to be averaged: the learned top-N average (LENA) pooling. We hypothesize that the latent concepts (feature maps) describing virality may require such a rich pooling strategy. We assess the effectiveness of the LENA layer by appending it on top of a convolutional siamese architecture and evaluate its performance on the task of predicting and localizing virality. We report experiments on two publicly available datasets annotated for virality and show that our method outperforms state-of-the-art approaches.",
        "A1": "We extend this concept by introducing a pooling layer that learns the size of the support area to be averaged:",
        "A2": "We extend this concept by introducing a pooling layer that learns the size of the support area to be averaged",
        "A41": ". We extend this concept by introducing a pooling layer that learns the size of the support area to be averaged: the learned top-N average (LENA) pooling.",
        "A51": " recent progress in deep learning architectures",
        "A61": "",
        "A10": "",
        "A7": "on two publicly available datasets annotated for virality ",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms state-of-the-art approache",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 323414119
    },
    {
        "Abstract": "Speckle refers to the granular patterns that occur in ultrasound images due to wave interference. Speckle removal can greatly improve the visibility of the underlying structures in an ultrasound image and enhance subsequent post processing. We present a novel framework for speckle removal based on low-rank non-local filtering. Our approach works by first computing a guidance image that assists in the selection of candidate patches for non-local filtering in the face of significant speckles. The candidate patches are further refined using a low-rank minimization estimated using a truncated weighted nuclear norm (TWNN) and structured sparsity. We show that the proposed filtering framework produces results that outperform state-of-the-art methods both qualitatively and quantitatively. This framework also provides better segmentation results when used for pre-processing ultrasound images.",
        "A1": "present a novel framework for speckle removal based on low-rank non-local filtering",
        "A2": "improve the visibility of the underlying structures in an ultrasound image and enhance subsequent post processing",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "qualitatively and quantitatively",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "produces results that outperform state-of-the-art methods both qualitatively and quantitatively",
        "A54": "low-rank non-local filtering",
        "A44": "speckle removal",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 160653577
    },
    {
        "Abstract": "The ability to amplify or reduce subtle image changes over time is useful in contexts such as video editing, medical video analysis, product quality control and sports. In these contexts there is often large motion present which severely distorts current video amplification methods that magnify change linearly. In this work we propose a method to cope with large motions while still magnifying small changes. We make the following two observations: i) large motions are linear on the temporal scale of the small changes, ii) small changes deviate from this linearity. We ignore linear motion and propose to magnify acceleration. Our method is pure Eulerian and does not require any optical flow, temporal alignment or region annotations. We link temporal second-order derivative filtering to spatial acceleration magnification. We apply our method to moving objects where we show motion magnification and color magnification. We provide quantitative as well as qualitative evidence for our method while comparing to the state-of-the-art.",
        "A1": "we propose a method to cope with large motions while still magnifying small changes",
        "A2": " there is often large motion present which severely distorts current video amplification methods that magnify change linearly",
        "A41": " i) large motions are linear on the temporal scale of the small changes, ii) small changes deviate from this linearity",
        "A51": " Our method is pure Eulerian and does not require any optical flow, temporal alignment or region annotations",
        "A61": "We ignore linear motion and propose to magnify acceleration",
        "A10": "We provide quantitative as well as qualitative evidence for our method while comparing to the state-of-the-art.",
        "A7": "We apply our method to moving objects where we show motion magnification and color magnification.",
        "A83": "",
        "A82": "",
        "A81": "We provide quantitative as well as qualitative evidence for our method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 264673176
    },
    {
        "Abstract": "We address the problem of instance-level semantic segmentation, which aims at jointly detecting, segmenting and classifying every individual object in an image. In this context, existing methods typically propose candidate objects, usually as bounding boxes, and directly predict a binary mask within each such proposal. As a consequence, they cannot recover from errors in the object candidate generation process, such as too small or shifted boxes. In this paper, we introduce a novel object segment representation based on the distance transform of the object masks. We then design an object mask network (OMN) with a new residual-deconvolution architecture that infers such a representation and decodes it into the final binary object mask. This allows us to predict masks that go beyond the scope of the bounding boxes and are thus robust to inaccurate object candidates. We integrate our OMN into a Multitask Network Cascade framework, and learn the resulting boundary-aware instance segmentation (BAIS) network in an end-to-end manner. Our experiments on the PASCAL VOC 2012 and the Cityscapes datasets demonstrate the benefits of our approach, which outperforms the state-of-the-art in both object proposal generation and instance segmentation.",
        "A1": "In this paper, we introduce a novel object segment representation based on the distance transform of the object masks.",
        "A2": "",
        "A41": "In this paper, we introduce a novel object segment representation based on the distance transform of the object masks.",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Our experiments on the PASCAL VOC 2012 and the Cityscapes datasets demonstrate the benefits of our approach, ",
        "A83": "",
        "A82": "",
        "A81": "which outperforms the state-of-the-art in both object proposal generation and instance segmentation.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 474714629
    },
    {
        "Abstract": "Most existing hashing methods resort to binary codes for similarity search, owing to the high efficiency of computation and storage. However, binary codes lack enough capability in similarity preservation, resulting in less desirable performance. To address this issue, we propose an asymmetric multi-valued hashing method supported by two different non-binary embeddings. (1) A real-valued embedding is used for representing the newly-coming query. (2) A multi-integer-embedding is employed for compressing the whole database, which is modeled by binary sparse representation with fixed sparsity. With these two non-binary embeddings, the similarities between data points can be preserved precisely. To perform meaningful asymmetric similarity computation for efficient semantic search, these embeddings are jointly learnt by preserving the label-based similarity. Technically, this results in a mixed integer programming problem, which is efficiently solved by alternative optimization. Extensive experiments on three multilabel datasets demonstrate that our approach not only outperforms the existing binary hashing methods in search accuracy, but also retains their query and storage efficiency.",
        "A1": " propose an asymmetric multi-valued hashing method ",
        "A2": " binary codes lack enough capability in similarity preservation, resulting in less desirable performance.",
        "A41": " an asymmetric multi-valued hashing method supported by two different non-binary embeddings. ",
        "A51": " two different non-binary embeddings. (1) A real-valued embedding is used for representing the newly-coming query. (2) A multi-integer-embedding is employed for compressing the whole database, which is modeled by binary sparse representation with fixed sparsity.",
        "A61": "",
        "A10": "",
        "A7": " experiments on three multilabel datasets demonstrate ",
        "A83": "",
        "A82": "",
        "A81": "our approach not only outperforms the existing binary hashing methods in search accuracy, but also retains their query and storage efficiency.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 271851674
    },
    {
        "Abstract": "Compact coding has been widely applied to approximate nearest neighbor search for large-scale image retrieval, due to its computation efficiency and retrieval quality. This paper presents a compact coding solution with a focus on the deep learning to quantization approach, which improves retrieval quality by end-to-end representation learning and compact encoding and has already shown the superior performance over the hashing solutions for similarity retrieval. We propose Deep Visual-Semantic Quantization (DVSQ), which is the first approach to learning deep quantization models from labeled image data as well as the semantic information underlying general text domains. The main contribution lies in jointly learning deep visual-semantic embeddings and visual-semantic quantizers using carefully-designed hybrid networks and well-specified loss functions. DVSQ enables efficient and effective image retrieval by supporting maximum inner-product search, which is computed based on learned codebooks with fast distance table lookup. Comprehensive empirical evidence shows that DVSQ can generate compact binary codes and yield state-of-the-art similarity retrieval performance on standard benchmarks.",
        "A1": "presents a compact coding solution with a focus on the deep learning to quantization approach",
        "A2": "",
        "A41": "a compact coding solution with a focus on the deep learning to quantization approach, which improves retrieval quality by end-to-end representation learning and compact encoding and has already shown the superior performance over the hashing solutions for similarity retrieval",
        "A51": "Compact coding",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "DVSQ can generate compact binary codes and yield state-of-the-art similarity retrieval performance on standard benchmarks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 423565130
    },
    {
        "Abstract": "Query expansion is a popular method to improve the quality of image retrieval with both conventional and CNN representations. It has been so far limited to global image similarity. This work focuses on diffusion, a mechanism that captures the image manifold in the feature space. An efficient off-line stage allows optional reduction in the number of stored regions. In the on-line stage, the proposed handling of unseen queries in the indexing stage removes additional computation to adjust the precomputed data. We perform diffusion through a sparse linear system solver, yielding practical query times well below one second. Experimentally, we observe a significant boost in performance of image retrieval with compact CNN descriptors on standard benchmarks, especially when the query object covers only a small part of the image. Small objects have been a common failure case of CNN-based retrieval.",
        "A1": "improve the quality of image retrieval",
        "A2": "",
        "A41": "diffusion, a mechanism that captures the image manifold in the feature space",
        "A51": "",
        "A61": "",
        "A10": "perform diffusion through a sparse linear system solver, yielding practical query times",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "a significant boost",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 47606218
    },
    {
        "Abstract": "In domain adaptation, maximum mean discrepancy (MMD) has been widely adopted as a discrepancy metric between the distributions of source and target domains. However, existing MMD-based domain adaptation methods generally ignore the changes of class prior distributions, i.e., class weight bias across domains. This remains an open problem but ubiquitous for domain adaptation, which can be caused by changes in sample selection criteria and application scenarios. We show that MMD cannot account for class weight bias and results in degraded domain adaptation performance. To address this issue, a weighted MMD model is proposed in this paper. Specifically, we introduce class-specific auxiliary weights into the original MMD for exploiting the class prior probability on source and target domains, whose challenge lies in the fact that the class label in target domain is unavailable. To account for it, our proposed weighted MMD model is defined by introducing an auxiliary weight for each class in the source domain, and a classification EM algorithm is suggested by alternating between assigning the pseudo-labels, estimating auxiliary weights and updating model parameters. Extensive experiments demonstrate the superiority of our weighted MMD over conventional MMD for domain adaptation.",
        "A1": "In domain adaptation, maximum mean discrepancy (MMD) has been widely adopted as a discrepancy metric between the distributions of source and target domains.",
        "A2": "However, existing MMD-based domain adaptation methods generally ignore the changes of class prior distributions, i.e., class weight bias across domains.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " Extensive experiments demonstrate the superiority of our weighted MMD over conventional MMD for domain adaptation.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "To account for it, our proposed weighted MMD model is defined by introducing an auxiliary weight for each class in the source domain, and a classification EM algorithm is suggested by alternating between assigning the pseudo-labels, estimating auxiliary weights and updating model parameters.",
        "A42": "To address this issue, a weighted MMD model is proposed in this paper. Specifically, we introduce class-specific auxiliary weights into the original MMD for exploiting the class prior probability on source and target domains, whose challenge lies in the fact that the class label in target domain is unavailable.",
        "A45": "",
        "am_id": 356624894
    },
    {
        "Abstract": "This paper addresses video summarization, or the problem of distilling a raw video into a shorter form while still capturing the original story. We show that visual representations supervised by freeform language make a good fit for this application by extending a recent submodular summarization approach [9] with representativeness and interestingness objectives computed on features from a joint vision-language embedding space. We perform an evaluation on two diverse datasets, UT Egocentric [18] and TV Episodes [45], and show that our new objectives give improved summarization ability compared to standard visual features alone. Our experiments also show that the vision-language embedding need not be trained on domainspecific data, but can be learned from standard still image vision-language datasets and transferred to video. A further benefit of our model is the ability to guide a summary using freeform text input at test time, allowing user customization.",
        "A1": "This paper addresses video summarization, or the problem of distilling a raw video into a shorter form while still capturing the original story.",
        "A2": "video summarization, or the problem of distilling a raw video into a shorter form while still capturing the original story",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our new objectives give improved summarization ability compared to standard visual features alone.",
        "A7": "We perform an evaluation on two diverse datasets, UT Egocentric [18] and TV Episodes [45]",
        "A83": "",
        "A82": "the vision-language embedding need not be trained on domainspecific data, but can be learned from standard still image vision-language datasets and transferred to video",
        "A81": " our new objectives give improved summarization ability compared to standard visual features alone",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the ability to guide a summary using freeform text input at test time, allowing user customization.",
        "A52": "a recent submodular summarization approach [9] with representativeness and interestingness objectives computed on features from a joint vision-language embedding space",
        "A42": "",
        "A45": "",
        "am_id": 15101391
    },
    {
        "Abstract": "We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation). For example, given images and captions of siamese cat and tiger cat, we generate language that describes the siamese cat in a way that distinguishes it from tiger cat. Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts. We first apply our technique to a justification task, namely to describe why an image contains a particular fine-grained category as opposed to another closely-related category of the CUB-200-2011 dataset. We then study discriminative image captioning to generate language that uniquely refers to one of two semantically-similar images in the COCO dataset. Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning reveal that our approach outperforms baseline generative and speaker-listener approaches for discrimination.",
        "A1": " introduce an inference technique",
        "A2": "",
        "A41": "an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation)",
        "A51": "",
        "A61": "Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts.",
        "A10": "",
        "A7": "Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning",
        "A83": "",
        "A82": "",
        "A81": "our approach outperforms baseline generative and speaker-listener approaches for discrimination",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 2179272
    },
    {
        "Abstract": "Compositionality and contextuality are key building blocks of intelligence. They allow us to compose known concepts to generate new and complex ones. However, traditional learning methods do not model both these properties and require copious amounts of labeled data to learn new concepts. A large fraction of existing techniques, e.g., using late fusion, compose concepts but fail to model contextuality. For example, red in red wine is different from red in red tomatoes. In this paper, we present a simple method that respects contextuality in order to compose classifiers of known visual concepts. Our method builds upon the intuition that classifiers lie in a smooth space where compositional transforms can be modeled. We show how it can generalize to unseen combinations of concepts. Our results on composing attributes, objects as well as composing subject, predicate, and objects demonstrate its strong generalization performance compared to baselines. Finally, we present detailed analysis of our method and highlight its properties.",
        "A1": "we present a simple method that respects contextuality in order to compose classifiers of known visual concepts",
        "A2": "traditional learning methods do not model both these properties and require copious amounts of labeled data to learn new concepts",
        "A41": "a simple method that respects contextuality in order to compose classifiers of known visual concepts",
        "A51": " the intuition that classifiers lie in a smooth space where compositional transforms can be modeled",
        "A61": "model contextuality.",
        "A10": "",
        "A7": " show how it can generalize to unseen combinations of concepts",
        "A83": "",
        "A82": "we present detailed analysis of our method and highlight its properties",
        "A81": "demonstrate its strong generalization performance compared to baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 173053805
    },
    {
        "Abstract": "We propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images. Key to our approach is the generation and scoring of a number of pose proposals per image, which allows us to predict 2D and 3D pose of multiple people simultaneously. Hence, our approach does not require an approximate localization of the humans for initialization. Our architecture, named LCR-Net, contains 3 main components: 1) the pose proposal generator that suggests potential poses at different locations in the image, 2) a classifier that scores the different pose proposals, and 3) a regressor that refines pose proposals both in 2D and 3D. All three stages share the convolutional feature layers and are trained jointly. The final pose estimation is obtained by integrating over neighboring pose hypotheses, which is shown to improve over a standard non maximum suppression algorithm. Our approach significantly outperforms the state of the art in 3D pose estimation on Human3.6M, a controlled environment. Moreover, it shows promising results on real images for both single and multi-person subsets of the MPII 2D pose benchmark.",
        "A1": " propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images",
        "A2": " propose an end-to-end architecture for joint 2D and 3D human pose estimation in natural images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " significantly outperforms the state of the art in 3D pose estimation on Human3.6M, a controlled environment",
        "A7": "in 3D pose estimation on Human3.6M",
        "A83": "",
        "A82": " significantly outperforms the state of the art in 3D pose estimation on Human3.6M, a controlled environment",
        "A81": "it shows promising results on real images for both single and multi-person subsets of the MPII 2D pose benchmark.",
        "A64": "",
        "A54": "",
        "A44": "an end-to-end architecture for joint 2D and 3D human pose estimation in natural images",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 362281706
    },
    {
        "Abstract": "This paper addresses the challenge of 3D human pose estimation from a single color image. Despite the general success of the end-to-end learning paradigm, top performing approaches employ a two-step solution consisting of a Convolutional Network (ConvNet) for 2D joint localization and a subsequent optimization step to recover 3D pose. In this paper, we identify the representation of 3D pose as a critical issue with current ConvNet approaches and make two important contributions towards validating the value of end-to-end learning for this task. First, we propose a fine discretization of the 3D space around the subject and train a ConvNet to predict per voxel likelihoods for each joint. This creates a natural representation for 3D pose and greatly improves performance over the direct regression of joint coordinates. Second, to further improve upon initial estimates, we employ a coarse-to-fine prediction scheme. This step addresses the large dimensionality increase and enables iterative refinement and repeated processing of the image features. The proposed approach outperforms all state-of-the-art methods on standard benchmarks achieving a relative error reduction greater than 30% on average. Additionally, we investigate using our volumetric representation in a related architecture which is suboptimal compared to our end-to-end approach, but is of practical interest, since it enables training when no image with corresponding 3D groundtruth is available, and allows us to present compelling results for in-the-wild images.",
        "A1": "This paper addresses the challenge of ",
        "A2": "This paper addresses the challenge of ",
        "A41": "end-to-end learning for this task",
        "A51": "a fine discretization of the 3D space around the subject",
        "A61": "",
        "A10": "achieving a relative error reduction greater than 30% on average",
        "A7": "on standard benchmarks",
        "A83": "",
        "A82": "achieving a relative error reduction greater than 30% on average",
        "A81": "outperforms all state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 470253377
    },
    {
        "Abstract": "We present an approach for weakly supervised learning of human actions. Given a set of videos and an ordered list of the occurring actions, the goal is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries. To address this task, we propose a combination of a discriminative representation of subactions, modeled by a recurrent neural network, and a coarse probabilistic model to allow for a temporal alignment and inference over long sequences. While this system alone already generates good results, we show that the performance can be further improved by approximating the number of subactions to the characteristics of the different action classes. To this end, we adapt the number of subaction classes by iterating realignment and reestimation during training. The proposed system is evaluated on two benchmark datasets, the Breakfast and the Hollywood extended dataset, showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment.",
        "A1": "to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries",
        "A2": "weakly supervised learning of human actions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " two benchmark datasets, the Breakfast and the Hollywood extended dataset",
        "A83": "",
        "A82": "",
        "A81": "showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "recurrent neural network",
        "A42": "a combination of a discriminative representation of subactions, modeled by a recurrent neural network, and a coarse probabilistic model to allow for a temporal alignment and inference over long sequences",
        "A45": "",
        "am_id": 460112022
    },
    {
        "Abstract": "The large pose discrepancy between two face images is one of the key challenges in face recognition. Conventional approaches for pose-invariant face recognition either perform face frontalization on, or learn a pose-invariant representation from, a non-frontal face image. We argue that it is more desirable to perform both tasks jointly to allow them to leverage each other. To this end, this paper proposes Disentangled Representation learning-Generative Adversarial Network (DR-GAN) with three distinct novelties. First, the encoder-decoder structure of the generator allows DR-GAN to learn a generative and discriminative representation, in addition to image synthesis. Second, this representation is explicitly disentangled from other face variations such as pose, through the pose code provided to the decoder and pose estimation in the discriminator. Third, DR-GAN can take one or multiple images as the input, and generate one unified representation along with an arbitrary number of synthetic images. Quantitative and qualitative evaluation on both controlled and in-the-wild databases demonstrate the superiority of DR-GAN over the state of the art.",
        "A1": "Conventional approaches for pose-invariant face recognition either perform face frontalization on, or learn a pose-invariant representation from, a non-frontal face image.",
        "A2": "The large pose discrepancy between two face images is one of the key challenges in face recognition.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Quantitative and qualitative evaluation on both controlled and in-the-wild databases demonstrate the superiority of DR-GAN over the state of the art.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Third, DR-GAN can take one or multiple images as the input, and generate one unified representation along with an arbitrary number of synthetic images. ",
        "A52": "First, the encoder-decoder structure of the generator allows DR-GAN to learn a generative and discriminative representation, in addition to image synthesis. Second, this representation is explicitly disentangled from other face variations such as pose, through the pose code provided to the decoder and pose estimation in the discriminator.",
        "A42": "To this end, this paper proposes Disentangled Representation learning-Generative Adversarial Network (DR-GAN) with three distinct novelties.",
        "A45": "",
        "am_id": 133775978
    },
    {
        "Abstract": "This paper proposes a novel tracker which is controlled by sequentially pursuing actions learned by deep reinforcement learning. In contrast to the existing trackers using deep networks, the proposed tracker is designed to achieve a light computation as well as satisfactory tracking accuracy in both location and scale. The deep network to control actions is pre-trained using various training sequences and fine-tuned during tracking for online adaptation to target and background changes. The pre-training is done by utilizing deep reinforcement learning as well as supervised learning. The use of reinforcement learning enables even partially labeled data to be successfully utilized for semi-supervised learning. Through evaluation of the OTB dataset, the proposed tracker is validated to achieve a competitive performance that is three times faster than state-of-the-art, deep network-based trackers. The fast version of the proposed method, which operates in real-time on GPU, outperforms the state-of-the-art real-time trackers.",
        "A1": "proposes a novel tracker which is controlled by sequentially pursuing actions learned by deep reinforcement learning",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed tracker is validated to achieve a competitive performance that is three times faster than state-of-the-art, deep network-based trackers.",
        "A7": "Through evaluation of the OTB dataset",
        "A83": "",
        "A82": "",
        "A81": "the proposed tracker is validated to achieve a competitive performance that is three times faster than state-of-the-art, deep network-based trackers.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the proposed tracker is designed to achieve a light computation as well as satisfactory tracking accuracy in both location and scale",
        "A52": " is controlled by sequentially pursuing actions learned by deep reinforcement learning",
        "A42": " a novel tracker which is controlled by sequentially pursuing actions learned by deep reinforcement learning.",
        "A45": "",
        "am_id": 87507886
    },
    {
        "Abstract": "Correlation filter (CF) based trackers have recently gained a lot of popularity due to their impressive performance on benchmark datasets, while maintaining high frame rates. A significant amount of recent research focuses on the incorporation of stronger features for a richer representation of the tracking target. However, this only helps to discriminate the target from background within a small neighborhood. In this paper, we present a framework that allows the explicit incorporation of global context within CF trackers. We reformulate the original optimization problem and provide a closed form solution for single and multi-dimensional features in the primal and dual domain. Extensive experiments demonstrate that this framework significantly improves the performance of many CF trackers with only a modest impact on frame rate.",
        "A1": "present a framework that allows the explicit incorporation of global context within CF trackers",
        "A2": "We reformulate the original optimization problem and provide a closed form solution for single and multi-dimensional features in the primal and dual domain",
        "A41": "a closed form solution",
        "A51": "Correlation filter",
        "A61": " improves the performance of many CF trackers with only a modest impact on frame rate",
        "A10": "improves the performance of many CF trackers",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "this framework significantly improves the performance of many CF trackers with only a modest impact on frame rate",
        "A64": "",
        "A54": "",
        "A44": "a framework that allows the explicit incorporation of global context within CF trackers",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 43049267
    },
    {
        "Abstract": "We propose a direct monocular SLAM algorithm based on the Normalised Information Distance (NID) metric. In contrast to current state-of-the-art direct methods based on photometric error minimisation, our information-theoretic NID metric provides robustness to appearance variation due to lighting, weather and structural changes in the scene. We demonstrate successful localisation and mapping across changes in lighting with a synthetic indoor scene, and across changes in weather (direct sun, rain, snow) using real-world data collected from a vehicle-mounted camera. Our approach runs in real-time on a consumer GPU using OpenGL, and provides comparable localisation accuracy to state-of-the-art photometric methods but significantly outperforms both direct and feature-based methods in robustness to appearance changes.",
        "A1": "",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "provides comparable localisation accuracy to state-of-the-art photometric methods but significantly outperforms both direct and feature-based methods in robustness to appearance changes",
        "A7": "using real-world data collected from a vehicle-mounted camera",
        "A83": "",
        "A82": "",
        "A81": "successful localisation and mapping across changes in lighting with a synthetic indoor scene, and across changes in weather (direct sun, rain, snow)",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "our information-theoretic NID metric provides robustness to appearance variation due to lighting, weather and structural changes in the scene",
        "A53": " the Normalised Information Distance (NID) metric",
        "A43": "a direct monocular SLAM algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 488564907
    },
    {
        "Abstract": "We present a learning framework for abstracting complex shapes by learning to assemble objects using 3D volumetric primitives. In addition to generating simple and geometrically interpretable explanations of 3D objects, our framework also allows us to automatically discover and exploit consistent structure in the data. We demonstrate that using our method allows predicting shape representations which can be leveraged for obtaining a consistent parsing across the instances of a shape collection and constructing an interpretable shape similarity measure. We also examine applications for image-based prediction as well as shape manipulation.",
        "A1": " present a learning framework for abstracting complex shapes",
        "A2": " present a learning framework for abstracting complex shapes",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "can be leveraged for obtaining a consistent parsing across the instances of a shape collection and constructing an interpretable shape similarity measure",
        "A81": "using our method allows predicting shape representations",
        "A64": "our framework also allows us to automatically discover and exploit consistent structure in the data",
        "A54": "by learning to assemble objects using 3D volumetric primitives",
        "A44": "a learning framework for abstracting complex shapes",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 202775396
    },
    {
        "Abstract": "This paper proposes an algorithm that turns a regular video capturing urban scenes into a high-quality endless animation, known as a Cinemagraph. The creation of a Cinemagraph usually requires a static camera in a carefully configured scene. The task becomes challenging for a regular video with a moving camera and objects. Our approach first warps an input video into the viewpoint of a reference camera. Based on the warped video, we propose effective temporal analysis algorithms to detect regions with static geometry and dynamic appearance, where geometric modeling is reliable and visually attractive animations can be created. Lastly, the algorithm applies a sequence of video processing techniques to produce a Cinemagraph movie. We have tested the proposed approach on numerous challenging real scenes. To our knowledge, this work is the first to automatically generate Cinemagraph animations from regular movies in the wild.",
        "A1": "",
        "A2": "This paper proposes an algorithm that turns a regular video capturing urban scenes into a high-quality endless animation, known as a Cinemagraph",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "To our knowledge, this work is the first to automatically generate Cinemagraph animations from regular movies in the wild",
        "A7": " We have tested the proposed approach on numerous challenging real scenes",
        "A83": "",
        "A82": "To our knowledge, this work is the first to automatically generate Cinemagraph animations from regular movies in the wild",
        "A81": " where geometric modeling is reliable and visually attractive animations can be created",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "Our approach first warps an input video into the viewpoint of a reference camera. Based on the warped video, we propose effective temporal analysis algorithms to detect regions with static geometry and dynamic appearance, where geometric modeling is reliable and visually attractive animations can be created",
        "A53": "the warped video",
        "A43": "an algorithm that turns a regular video capturing urban scenes into a high-quality endless animation, known as a Cinemagraph",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 165176407
    },
    {
        "Abstract": "We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.",
        "A1": "propose a novel deep convolutional neural network architecture inspired by Inception",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "more efficient use of model parameters",
        "A7": " ImageNet dataset",
        "A83": "",
        "A82": "",
        "A81": "more efficient",
        "A64": " inspired by Inception",
        "A54": "convolutional neural network",
        "A44": "a novel deep convolutional neural network architecture inspired by Inception",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 259510837
    },
    {
        "Abstract": "In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity. The core idea is to equip each original convolutional layer with another low-cost collaborative layer (LCCL), and the element-wise multiplication of the ReLU outputs of these two parallel layers produces the layer-wise output. The combined layer is potentially more discriminative than the original convolutional layer, and its inference is faster for two reasons: 1) the zero cells of the LCCL feature maps will remain zero after element-wise multiplication, and thus it is safe to skip the calculation of the corresponding high-cost convolution in the original convolutional layer; 2) LCCL is very fast if it is implemented as a 1 &#x00D7; 1 convolution or only a single filter shared by all channels. Extensive experiments on the CIFAR-10, CIFAR-100 and ILSCRC-2012 benchmarks show that our proposed network structure can accelerate the inference process by 32% on average with negligible performance drop.",
        "A1": "In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " Extensive experiments on the CIFAR-10, CIFAR-100 and ILSCRC-2012 benchmarks show that our proposed network structure can accelerate the inference process by 32% on average with negligible performance drop.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " Extensive experiments on the CIFAR-10, CIFAR-100 and ILSCRC-2012 benchmarks show that our proposed network structure can accelerate the inference process by 32% on average with negligible performance drop.",
        "A52": "",
        "A42": "In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity. ",
        "A45": "",
        "am_id": 125764472
    },
    {
        "Abstract": "Dense captioning is a newly emerging computer vision topic for understanding images with dense language descriptions. The goal is to densely detect visual concepts (e.g., objects, object parts, and interactions between them) from images, labeling each with a short descriptive phrase. We identify two key challenges of dense captioning that need to be properly addressed when tackling the problem. First, dense visual concept annotations in each image are associated with highly overlapping target regions, making accurate localization of each visual concept challenging. Second, the large amount of visual concepts makes it hard to recognize each of them by appearance alone. We propose a new model pipeline based on two novel ideas, joint inference and context fusion, to alleviate these two challenges. We design our model architecture in a methodical manner and thoroughly evaluate the variations in architecture. Our final model, compact and efficient, achieves state-of-the-art accuracy on Visual Genome [23] for dense captioning with a relative gain of 73% compared to the previous best algorithm. Qualitative experiments also reveal the semantic capabilities of our model in dense captioning.",
        "A1": "he goal is to densely detect visual concepts (e.g., objects, object parts, and interactions between them) from images, labeling each with a short descriptive phrase.",
        "A2": "We identify two key challenges of dense captioning that need to be properly addressed when tackling the problem.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our final model, compact and efficient, achieves state-of-the-art accuracy on Visual Genome [23] for dense captioning with a relative gain of 73% compared to the previous best algorithm.",
        "A7": "We design our model architecture in a methodical manner and thoroughly evaluate the variations in architecture.",
        "A83": "",
        "A82": "",
        "A81": "Our final model, compact and efficient, achieves state-of-the-art accuracy on Visual Genome [23] for dense captioning with a relative gain of 73% compared to the previous best algorithm. ",
        "A64": "",
        "A54": "",
        "A44": " First, dense visual concept annotations in each image are associated with highly overlapping target regions, making accurate localization of each visual concept challenging.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 307689072
    },
    {
        "Abstract": "When building artificial intelligence systems that can reason and answer questions about visual data, we need diagnostic tests to analyze our progress and discover short-comings. Existing benchmarks for visual question answering can help, but have strong biases that models can exploit to correctly answer questions without reasoning. They also conflate multiple sources of error, making it hard to pinpoint model weaknesses. We present a diagnostic dataset that tests a range of visual reasoning abilities. It contains minimal biases and has detailed annotations describing the kind of reasoning each question requires. We use this dataset to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations.",
        "A1": "When building artificial intelligence systems that can reason and answer questions about visual data",
        "A2": "we need diagnostic tests to analyze our progress and discover short-comings. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "providing novel insights into their abilities and limitations.",
        "A7": "minimal biases and has detailed annotations describing the kind of reasoning each question requires.",
        "A83": "",
        "A82": "",
        "A81": "We use this dataset to analyze a variety of modern visual reasoning systems,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "They also conflate multiple sources of error, making it hard to pinpoint model weaknesses",
        "A52": "strong biases that models can exploit to correctly answer questions without reasoning.",
        "A42": "Existing benchmarks for visual question",
        "A45": "",
        "am_id": 343491836
    },
    {
        "Abstract": "In this paper, a self-learning approach is proposed towards solving scene-specific pedestrian detection problem without any human annotation involved. The self-learning approach is deployed as progressive steps of object discovery, object enforcement, and label propagation. In the learning procedure, object locations in each frame are treated as latent variables that are solved with a progressive latent model (PLM). Compared with conventional latent models, the proposed PLM incorporates a spatial regularization term to reduce ambiguities in object proposals and to enforce object localization, and also a graph-based label propagation to discover harder instances in adjacent frames. With the difference of convex (DC) objective functions, PLM can be efficiently optimized with a concave-convex programming and thus guaranteeing the stability of self-learning. Extensive experiments demonstrate that even without annotation the proposed self-learning approach outperforms weakly supervised learning approaches, while achieving comparable performance with transfer learning and fully supervised approaches.",
        "A1": "towards solving scene-specific pedestrian detection problem without any human annotation involved",
        "A2": "a self-learning approach is proposed towards solving scene-specific pedestrian detection problem without any human annotation involved. ",
        "A41": "towards solving scene-specific pedestrian detection problem without any human annotation involved",
        "A51": "progressive latent model ",
        "A61": "Compared with conventional latent models, the proposed PLM incorporates a spatial regularization term to reduce ambiguities in object proposals and to enforce object localization, and also a graph-based label propagation to discover harder instances in adjacent frames. ",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "PLM can be efficiently optimized with a concave-convex programming and thus guaranteeing the stability of self-learning. ",
        "A81": "Compared with conventional latent models, the proposed PLM incorporates a spatial regularization term to reduce ambiguities in object proposals and to enforce object localization, and also a graph-based label propagation to discover harder instances in adjacent frames. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 378186744
    },
    {
        "Abstract": "In this work, we study a poorly understood trade-off between accuracy and runtime costs for deep semantic video segmentation. While recent work has demonstrated advantages of learning to speed-up deep activity detection, it is not clear if similar advantages will hold for our very different segmentation loss function, which is defined over individual pixels across the frames. In deep video segmentation, the most time consuming step represents the application of a CNN to every frame for assigning class labels to every pixel, typically taking 6-9 times of the video footage. This motivates our new budget-aware framework that learns to optimally select a small subset of frames for pixelwise labeling by a CNN, and then efficiently interpolates the obtained segmentations to yet unprocessed frames. This interpolation may use either a simple optical-flow guided mapping of pixel labels, or another significantly less complex and thus faster CNN. We formalize the frame selection as a Markov Decision Process, and specify a Long Short-Term Memory (LSTM) network to model a policy for selecting the frames. For training the LSTM, we develop a policy-gradient reinforcement-learning approach for approximating the gradient of our non-decomposable and non-differentiable objective. Evaluation on two benchmark video datasets show that our new framework is able to significantly reduce computation time, and maintain competitive video segmentation accuracy under varying budgets.",
        "A1": "we study a poorly understood trade-off between accuracy and runtime costs for deep semantic video segmentation",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our new framework is able to significantly reduce computation time, and maintain competitive video segmentation accuracy under varying budgets.",
        "A7": "two benchmark video datasets",
        "A83": "",
        "A82": "",
        "A81": "our new framework is able to significantly reduce computation time, and maintain competitive video segmentation accuracy under varying budgets.",
        "A64": "",
        "A54": "deep video segmentation",
        "A44": "new budget-aware framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 175197514
    },
    {
        "Abstract": "We introduce a Deep Stochastic IOC RNN Encoder-decoder framework, DESIRE, for the task of future predictions of multiple interacting agents in dynamic scenes. DESIRE effectively predicts future locations of objects in multiple scenes by 1) accounting for the multi-modal nature of the future prediction (i.e., given the same context, future may vary), 2) foreseeing the potential future outcomes and make a strategic prediction based on that, and 3) reasoning not only from the past motion history, but also from the scene context as well as the interactions among the agents. DESIRE achieves these in a single end-to-end trainable neural network model, while being computationally efficient. The model first obtains a diverse set of hypothetical future prediction samples employing a conditional variational auto-encoder, which are ranked and refined by the following RNN scoring-regression module. Samples are scored by accounting for accumulated future rewards, which enables better long-term strategic decisions similar to IOC frameworks. An RNN scene context fusion module jointly captures past motion histories, the semantic scene context and interactions among multiple agents. A feedback mechanism iterates over the ranking and refinement to further boost the prediction accuracy. We evaluate our model on two publicly available datasets: KITTI and Stanford Drone Dataset. Our experiments show that the proposed model significantly improves the prediction accuracy compared to other baseline methods.",
        "A1": " introduce a Deep Stochastic IOC RNN Encoder-decoder framework, DESIRE",
        "A2": "future predictions of multiple interacting agents in dynamic scenes",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the proposed model significantly improves the prediction accuracy compared to other baseline methods.",
        "A7": "We evaluate our model on two publicly available datasets: KITTI and Stanford Drone Dataset.",
        "A83": "",
        "A82": "",
        "A81": "the proposed model significantly improves the prediction accuracy compared to other baseline methods.",
        "A64": "DESIRE effectively predicts future locations of objects in multiple scenes",
        "A54": "a single end-to-end trainable neural network model",
        "A44": "a Deep Stochastic IOC RNN Encoder-decoder framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the proposed model significantly improves the prediction accuracy compared to other baseline methods.",
        "A52": "",
        "A42": " a single end-to-end trainable neural network model",
        "A45": "",
        "am_id": 346653452
    },
    {
        "Abstract": "Objects appear to scale differently in natural images. This fact requires methods dealing with object-centric tasks (e.g. object proposal) to have robust performance over variances in object scales. In the paper, we present a novel segment proposal framework, namely FastMask, which takes advantage of hierarchical features in deep convolutional neural networks to segment multi-scale objects in one shot. Innovatively, we adapt segment proposal network into three different functional components (body, neck and head). We further propose a weight-shared residual neck module as well as a scale-tolerant attentional head module for efficient one-shot inference. On MS COCO benchmark, the proposed FastMask outperforms all state-of-the-art segment proposal methods in average recall being 2~5 times faster. Moreover, with a slight trade-off in accuracy, FastMask can segment objects in near real time (~13 fps) with 800&#x00D7;600 resolution images, demonstrating its potential in practical applications. Our implementation is available on https://github.com/voidrank/FastMask.",
        "A1": "",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "in average recall being 2~5 times faster",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "demonstrating its potential in practical applications",
        "A64": "adapt segment proposal network into three different functional components",
        "A54": "hierarchical features in deep convolutional neural networks",
        "A44": "to segment multi-scale objects in one shot",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 9052416
    },
    {
        "Abstract": "Accurate estimation of camera matrices is an important step in structure from motion algorithms. In this paper we introduce a novel rank constraint on collections of fundamental matrices in multi-view settings. We show that in general, with the selection of proper scale factors, a matrix formed by stacking fundamental matrices between pairs of images has rank 6. Moreover, this matrix forms the symmetric part of a rank 3 matrix whose factors relate directly to the corresponding camera matrices. We use this new characterization to produce better estimations of fundamental matrices by optimizing an L1-cost function using Iterative Re-weighted Least Squares and Alternate Direction Method of Multiplier. We further show that this procedure can improve the recovery of camera locations, particularly in multi-view settings in which fewer images are available.",
        "A1": "a novel rank constraint on collections of fundamental matrices in multi-view settings",
        "A2": "Accurate estimation of camera matrices",
        "A41": " a novel rank constraint on collections of fundamental matrices in multi-view settings.",
        "A51": " the selection of proper scale factors",
        "A61": "this procedure can improve the recovery of camera locations, particularly in multi-view settings in which fewer images are available",
        "A10": "this procedure can improve the recovery of camera locations, particularly in multi-view settings in which fewer images are available",
        "A7": "",
        "A83": "",
        "A82": "this procedure can improve the recovery of camera locations, particularly in multi-view settings in which fewer images are available",
        "A81": " produce better estimations of fundamental matrices by optimizing an L1-cost function using Iterative Re-weighted Least Squares and Alternate Direction Method of Multiplier",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 85490452
    },
    {
        "Abstract": "Given a single photo of a room and a large database of furniture CAD models, our goal is to reconstruct a scene that is as similar as possible to the scene depicted in the photograph, and composed of objects drawn from the database. We present a completely automatic system to address this IM2CAD problem that produces high quality results on challenging imagery from interior home design and remodeling websites. Our approach iteratively optimizes the placement and scale of objects in the room to best match scene renderings to the input photo, using image comparison metrics trained via deep convolutional neural nets. By operating jointly on the full scene at once, we account for inter-object occlusions. We also show the applicability of our method in standard scene understanding benchmarks where we obtain significant improvement.",
        "A1": "present a completely automatic system to address this IM2CAD problem",
        "A2": "produces high quality results on challenging imagery from interior home design and remodeling websites",
        "A41": "a completely automatic system to address this IM2CAD problem",
        "A51": "",
        "A61": "Our approach iteratively optimizes the placement and scale of objects in the room to best match scene renderings to the input photo, using image comparison metrics trained via deep convolutional neural nets",
        "A10": "reconstruct a scene that is as similar as possible to the scene depicted in the photograph, and composed of objects drawn from the database",
        "A7": "",
        "A83": "",
        "A82": "the applicability of our method in standard scene understanding benchmarks",
        "A81": "we account for inter-object occlusions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": null
    },
    {
        "Abstract": "In this paper we present a scalable approach for robustly computing a 3D surface mesh from multi-scale multi-view stereo point clouds that can handle extreme jumps of point density (in our experiments three orders of magnitude). The backbone of our approach is a combination of octree data partitioning, local Delaunay tetrahedralization and graph cut optimization. Graph cut optimization is used twice, once to extract surface hypotheses from local Delaunay tetrahedralizations and once to merge overlapping surface hypotheses even when the local tetrahedralizations do not share the same topology. This formulation allows us to obtain a constant memory consumption per sub-problem while at the same time retaining the density independent interpolation properties of the Delaunay-based optimization. On multiple public datasets, we demonstrate that our approach is highly competitive with the state-of-the-art in terms of accuracy, completeness and outlier resilience. Further, we demonstrate the multi-scale potential of our approach by processing a newly recorded dataset with 2 billion points and a point density variation of more than four orders of magnitude - requiring less than 9GB of RAM per process.",
        "A1": "present a scalable approach for robustly computing a 3D surface mesh from multi-scale multi-view stereo point clouds that can handle extreme jumps of point density",
        "A2": " extreme jumps of point density",
        "A41": "a combination of octree data partitioning, local Delaunay tetrahedralization and graph cut optimization",
        "A51": "Graph cut optimization",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "the multi-scale potential of our approach by processing a newly recorded dataset with 2 billion points and a point density variation of more than four orders of magnitude",
        "A81": "highly competitive with the state-of-the-art in terms of accuracy, completeness and outlier resilience",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 489305952
    },
    {
        "Abstract": "We introduce a novel approach to jointly estimate consistent depth and normal maps from 4D light fields, with two main contributions. First, we build a cost volume from focal stack symmetry. However, in contrast to previous approaches, we introduce partial focal stacks in order to be able to robustly deal with occlusions. This idea already yields significanly better disparity maps. Second, even recent sublabel-accurate methods for multi-label optimization recover only a piecewise flat disparity map from the cost volume, with normals pointing mostly towards the image plane. This renders normal maps recovered from these approaches unsuitable for potential subsequent applications. We therefore propose regularization with a novel prior linking depth to normals, and imposing smoothness of the resulting normal field. We then jointly optimize over depth and normals to achieve estimates for both which surpass previous work in accuracy on a recent benchmark.",
        "A1": "jointly estimate consistent depth and normal maps from 4D light fields",
        "A2": "jointly estimate consistent depth and normal maps from 4D light fields",
        "A41": "partial focal stacks ",
        "A51": "",
        "A61": "yields significanly better disparity maps",
        "A10": " surpass previous work in accuracy on a recent benchmark",
        "A7": "build a cost volume from focal stack symmetry",
        "A83": "",
        "A82": "normal maps recovered from these approaches unsuitable for potential subsequent applications",
        "A81": "yields significanly better disparity maps",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "surpass previous work in accuracy",
        "A52": "",
        "A42": "regularization with a novel prior linking depth to normals",
        "A45": "",
        "am_id": 25566137
    },
    {
        "Abstract": "Past research on facial expressions have used relatively limited datasets, which makes it unclear whether current methods can be employed in real world. In this paper, we present a novel database, RAF-DB, which contains about 30000 facial images from thousands of individuals. Each image has been individually labeled about 40 times, then EM algorithm was used to filter out unreliable labels. Crowdsourcing reveals that real-world faces often express compound emotions, or even mixture ones. For all we know, RAF-DB is the first database that contains compound expressions in the wild. Our cross-database study shows that the action units of basic emotions in RAF-DB are much more diverse than, or even deviate from, those of lab-controlled ones. To address this problem, we propose a new DLP-CNN (Deep Locality-Preserving CNN) method, which aims to enhance the discriminative power of deep features by preserving the locality closeness while maximizing the inter-class scatters. The benchmark experiments on the 7-class basic expressions and 11-class compound expressions, as well as the additional experiments on SFEW and CK+ databases, show that the proposed DLP-CNN outperforms the state-of-the-art handcrafted features and deep learning based methods for the expression recognition in the wild.",
        "A1": "present a novel database",
        "A2": "In this paper, we present a novel database, RAF-DB, which contains about 30000 facial images from thousands of individuals. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Past research on facial expressions have used relatively limited datasets, which makes it unclear whether current methods can be employed in real world. ",
        "A7": "The benchmark experiments on the 7-class basic expressions and 11-class compound expressions, as well as the additional experiments on SFEW and CK+ databases",
        "A83": "",
        "A82": "the proposed DLP-CNN outperforms the state-of-the-art handcrafted features and deep learning based methods for the expression recognition in the wild.",
        "A81": " In this paper, we present a novel database, RAF-DB, which contains about 30000 facial images from thousands of individuals.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "research on facial expressions",
        "am_id": 465914824
    },
    {
        "Abstract": "Machine learning techniques, namely convolutional neural networks (CNN) and regression forests, have recently shown great promise in performing 6-DoF localization of monocular images. However, in most cases image-sequences, rather only single images, are readily available. To this extent, none of the proposed learning-based approaches exploit the valuable constraint of temporal smoothness, often leading to situations where the per-frame error is larger than the camera motion. In this paper we propose a recurrent model for performing 6-DoF localization of video-clips. We find that, even by considering only short sequences (20 frames), the pose estimates are smoothed and the localization error can be drastically reduced. Finally, we consider means of obtaining probabilistic pose estimates from our model. We evaluate our method on openly-available real-world autonomous driving and indoor localization datasets.",
        "A1": " propose a recurrent model for performing 6-DoF localization of video-clips",
        "A2": "the per-frame error is larger than the camera motion",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " the pose estimates are smoothed and the localization error can be drastically reduced",
        "A7": "on openly-available real-world autonomous driving and indoor localization datasets",
        "A83": "",
        "A82": "",
        "A81": " the pose estimates are smoothed and the localization error can be drastically reduced",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "exploit the valuable constraint of temporal smoothness",
        "A52": "convolutional neural networks (CNN) and regression forests",
        "A42": " a recurrent model for performing 6-DoF localization of video-clips",
        "A45": "",
        "am_id": 10862980
    },
    {
        "Abstract": "Data association problems are an important component of many computer vision applications, with multi-object tracking being one of the most prominent examples. A typical approach to data association involves finding a graph matching or network flow that minimizes a sum of pairwise association costs, which are often either hand-crafted or learned as linear functions of fixed features. In this work, we demonstrate that it is possible to learn features for network-flow-based data association via backpropagation, by expressing the optimum of a smoothed network flow problem as a differentiable function of the pairwise association costs. We apply this approach to multi-object tracking with a network flow formulation. Our experiments demonstrate that we are able to successfully learn all cost functions for the association problem in an end-to-end fashion, which outperform hand-crafted costs in all settings. The integration and combination of various sources of inputs becomes easy and the cost functions can be learned entirely from data, alleviating tedious hand-designing of costs.",
        "A1": "",
        "A2": "demonstrate that it is possible to learn features for network-flow-based data association via backpropagation",
        "A41": "learn features for network-flow-based data association via backpropagation",
        "A51": "",
        "A61": "alleviating tedious hand-designing of costs",
        "A10": "successfully learn all cost functions for the association problem in an end-to-end fashion",
        "A7": "apply this approach to multi-object tracking with a network flow formulation",
        "A83": "",
        "A82": "",
        "A81": "it is possible to learn features for network-flow-based data association via backpropagation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 30726039
    },
    {
        "Abstract": "We propose StyleBank, which is composed of multiple convolution filter banks and each filter bank explicitly represents one style, for neural image style transfer. To transfer an image to a specific style, the corresponding filter bank is operated on top of the intermediate feature embedding produced by a single auto-encoder. The StyleBank and the auto-encoder are jointly learnt, where the learning is conducted in such a way that the auto-encoder does not encode any style information thanks to the flexibility introduced by the explicit filter bank representation. It also enables us to conduct incremental learning to add a new image style by learning a new filter bank while holding the auto-encoder fixed. The explicit style representation along with the flexible network design enables us to fuse styles at not only the image level, but also the region level. Our method is the first style transfer network that links back to traditional texton mapping methods, and hence provides new understanding on neural style transfer. Our method is easy to train, runs in real-time, and produces results that qualitatively better or at least comparable to existing methods.",
        "A1": "To transfer an image to a specific style, the corresponding filter bank is operated on top of the intermediate feature embedding produced by a single auto-encoder.",
        "A2": "The StyleBank and the auto-encoder are jointly learnt, where the learning is conducted in such a way that the auto-encoder does not encode any style information thanks to the flexibility introduced by the explicit filter bank representation. It also enables us to conduct incremental learning to add a new image style by learning a new filter bank while holding the auto-encoder fixed.",
        "A41": "We propose StyleBank, which is composed of multiple convolution filter banks and each filter bank explicitly represents one style, for neural image style transfer.",
        "A51": "",
        "A61": "Our method is easy to train, runs in real-time, and produces results that qualitatively better or at least comparable to existing methods.",
        "A10": "Our method is easy to train, runs in real-time, and produces results that qualitatively better or at least comparable to existing methods.",
        "A7": "",
        "A83": "",
        "A82": "Our method is easy to train, runs in real-time, and produces results that qualitatively better or at least comparable to existing methods.",
        "A81": "Our method is the first style transfer network that links back to traditional texton mapping methods, and hence provides new understanding on neural style transfer.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 124277078
    },
    {
        "Abstract": "Compositing is one of the most common operations in photo editing. To generate realistic composites, the appearances of foreground and background need to be adjusted to make them compatible. Previous approaches to harmonize composites have focused on learning statistical relationships between hand-crafted appearance features of the foreground and background, which is unreliable especially when the contents in the two layers are vastly different. In this work, we propose an end-to-end deep convolutional neural network for image harmonization, which can capture both the context and semantic information of the composite images during harmonization. We also introduce an efficient way to collect large-scale and high-quality training data that can facilitate the training process. Experiments on the synthesized dataset and real composite images show that the proposed network outperforms previous state-of-the-art methods.",
        "A1": "To generate realistic composites",
        "A2": "Previous approaches to harmonize composites have focused on learning statistical relationships between hand-crafted appearance features of the foreground and background, which is unreliable especially when the contents in the two layers are vastly different",
        "A41": "an efficient way to collect large-scale and high-quality training data that can facilitate the training process",
        "A51": "",
        "A61": "",
        "A10": " the proposed network outperforms previous state-of-the-art methods.",
        "A7": " Experiments on the synthesized dataset and real composite images ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "which can capture both the context and semantic information of the composite images during harmonization",
        "A54": "",
        "A44": " an end-to-end deep convolutional neural network for image harmonization",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 379229074
    },
    {
        "Abstract": "Most contemporary approaches to instance segmentation use complex pipelines involving conditional random fields, recurrent neural networks, object proposals, or template matching schemes. In this paper, we present a simple yet powerful end-to-end convolutional neural network to tackle this task. Our approach combines intuitions from the classical watershed transform and modern deep learning to produce an energy map of the image where object instances are unambiguously represented as energy basins. We then perform a cut at a single energy level to directly yield connected components corresponding to object instances. Our model achieves more than double the performance over the state-of-the-art on the challenging Cityscapes Instance Level Segmentation task.",
        "A1": "present a simple yet powerful end-to-end convolutional neural network",
        "A2": "Most contemporary approaches to instance segmentation use complex pipelines",
        "A41": "a simple yet powerful end-to-end convolutional neural network ",
        "A51": " combines intuitions from the classical watershed transform and modern deep learning",
        "A61": " perform a cut at a single energy level",
        "A10": "achieves more than double the performance over the state-of-the-art",
        "A7": "challenging Cityscapes Instance Level Segmentation task",
        "A83": "",
        "A82": "",
        "A81": "achieves more than double the performance over the state-of-the-art",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 366493984
    },
    {
        "Abstract": "This paper addresses the problem of unsupervised video summarization, formulated as selecting a sparse subset of video frames that optimally represent the input video. Our key idea is to learn a deep summarizer network to minimize distance between training videos and a distribution of their summarizations, in an unsupervised way. Such a summarizer can then be applied on a new video for estimating its optimal summarization. For learning, we specify a novel generative adversarial framework, consisting of the summarizer and discriminator. The summarizer is the autoencoder long short-term memory network (LSTM) aimed at, first, selecting video frames, and then decoding the obtained summarization for reconstructing the input video. The discriminator is another LSTM aimed at distinguishing between the original video and its reconstruction from the summarizer. The summarizer LSTM is cast as an adversary of the discriminator, i.e., trained so as to maximally confuse the discriminator. This learning is also regularized for sparsity. Evaluation on four benchmark datasets, consisting of videos showing diverse events in first-and third-person views, demonstrates our competitive performance in comparison to fully supervised state-of-the-art approaches.",
        "A1": "This paper addresses the problem of unsupervised video summarization, formulated as selecting a sparse subset of video frames that optimally represent the input video. ",
        "A2": "This paper addresses the problem of unsupervised video summarization, formulated as selecting a sparse subset of video frames that optimally represent the input video. ",
        "A41": " Our key idea is to learn a deep summarizer network to minimize distance between training videos and a distribution of their summarizations, in an unsupervised way",
        "A51": "LSTM",
        "A61": "Evaluation on four benchmark datasets, consisting of videos showing diverse events in first-and third-person views, demonstrates our competitive performance in comparison to fully supervised state-of-the-art approaches.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 122415807
    },
    {
        "Abstract": "We introduce Spatio-Temporal Vector of Locally Max Pooled Features (ST-VLMPF), a super vector-based encoding method specifically designed for local deep features encoding. The proposed method addresses an important problem of video understanding: how to build a video representation that incorporates the CNN features over the entire video. Feature assignment is carried out at two levels, by using the similarity and spatio-temporal information. For each assignment we build a specific encoding, focused on the nature of deep features, with the goal to capture the highest feature responses from the highest neuron activation of the network. Our ST-VLMPF clearly provides a more reliable video representation than some of the most widely used and powerful encoding approaches (Improved Fisher Vectors and Vector of Locally Aggregated Descriptors), while maintaining a low computational complexity. We conduct experiments on three action recognition datasets: HMDB51, UCF50 and UCF101. Our pipeline obtains state-of-the-art results.",
        "A1": "introduce Spatio-Temporal Vector of Locally Max Pooled Features (ST-VLMPF),",
        "A2": " how to build a video representation that incorporates the CNN features over the entire video",
        "A41": "specifically designed for local deep features encoding",
        "A51": "the similarity and spatio-temporal information",
        "A61": " a more reliable video representation",
        "A10": "",
        "A7": " on three action recognition datasets: HMDB51, UCF50 and UCF101",
        "A83": "",
        "A82": "",
        "A81": "state-of-the-art results.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 248003023
    },
    {
        "Abstract": "In recent years, there has been a renewed interest in jointly modeling perception and action. At the core of this investigation is the idea of modeling affordances. However, when it comes to predicting affordances, even the state of the art approaches still do not use any ConvNets. Why is that? Unlike semantic or 3D tasks, there still does not exist any large-scale dataset for affordances. In this paper, we tackle the challenge of creating one of the biggest dataset for learning affordances. We use seven sitcoms to extract a diverse set of scenes and how actors interact with different objects in the scenes. Our dataset consists of more than 10K scenes and 28K ways humans can interact with these 10K images. We also propose a two-step approach to predict affordances in a new scene. In the first step, given a location in the scene we classify which of the 30 pose classes is the likely affordance pose. Given the pose class and the scene, we then use a Variational Autoencoder (VAE) [23] to extract the scale and deformation of the pose. The VAE allows us to sample the distribution of possible poses at test time. Finally, we show the importance of large-scale data in learning a generalizable and robust model of affordances.",
        "A1": "In this paper, we tackle the challenge of creating one of the biggest dataset for learning affordances",
        "A2": "the challenge of creating one of the biggest dataset for learning affordances",
        "A41": "propose a two-step approach to predict affordances in a new scene",
        "A51": "Our dataset consists of more than 10K scenes and 28K ways humans can interact with these 10K images.",
        "A61": "there still does not exist any large-scale dataset for affordances. ",
        "A10": "We use seven sitcoms to extract a diverse set of scenes and how actors interact with different objects in the scenes",
        "A7": "We also propose a two-step approach to predict affordances in a new scene",
        "A83": "",
        "A82": "",
        "A81": "show the importance of large-scale data in learning a generalizable and robust model of affordances.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 17327382
    },
    {
        "Abstract": "Referring expressions are natural language constructions used to identify particular objects within a scene. In this paper, we propose a unified framework for the tasks of referring expression comprehension and generation. Our model is composed of three modules: speaker, listener, and reinforcer. The speaker generates referring expressions, the listener comprehends referring expressions, and the reinforcer introduces a reward function to guide sampling of more discriminative expressions. The listener-speaker modules are trained jointly in an end-to-end learning framework, allowing the modules to be aware of one another during learning while also benefiting from the discriminative reinforcer's feedback. We demonstrate that this unified framework and training achieves state-of-the-art results for both comprehension and generation on three referring expression datasets.",
        "A1": "a unified framework for the tasks of referring expression comprehension and generation",
        "A2": "referring expression comprehension and generation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Referring expressions",
        "A7": "unified framework and training",
        "A83": "",
        "A82": "",
        "A81": "both comprehension and generation on three referring expression datasets",
        "A64": "",
        "A54": "",
        "A44": "a unified framework for the tasks of referring expression comprehension and generation",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "composed of three modules: speaker, listener, and reinforcer",
        "A45": "",
        "am_id": 153222092
    },
    {
        "Abstract": "We describe a system to detect objects in three-dimensional space using video and inertial sensors (accelerometer and gyrometer), ubiquitous in modern mobile platforms from phones to drones. Inertials afford the ability to impose class-specific scale priors for objects, and provide a global orientation reference. A minimal sufficient representation, the posterior of semantic (identity) and syntactic (pose) attributes of objects in space, can be decomposed into a geometric term, which can be maintained by a localization-and-mapping filter, and a likelihood function, which can be approximated by a discriminatively-trained convolutional neural network The resulting system can process the video stream causally in real time, and provides a representation of objects in the scene that is persistent: Confidence in the presence of objects grows with evidence, and objects previously seen are kept in memory even when temporarily occluded, with their return into view automatically predicted to prime re-detection.",
        "A1": "We describe a system to detect objects in three-dimensional space using video and inertial sensors",
        "A2": "detect objects in three-dimensional space",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "discriminatively-trained convolutional neural network",
        "A44": "a system to detect objects in three-dimensional space using video and inertial sensors",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 46910833
    },
    {
        "Abstract": "Recently, skeleton based action recognition gains more popularity due to cost-effective depth sensors coupled with real-time skeleton estimation algorithms. Traditional approaches based on handcrafted features are limited to represent the complexity of motion patterns. Recent methods that use Recurrent Neural Networks (RNN) to handle raw skeletons only focus on the contextual dependency in the temporal domain and neglect the spatial configurations of articulated skeletons. In this paper, we propose a novel two-stream RNN architecture to model both temporal dynamics and spatial configurations for skeleton based action recognition. We explore two different structures for the temporal stream: stacked RNN and hierarchical RNN. Hierarchical RNN is designed according to human body kinematics. We also propose two effective methods to model the spatial structure by converting the spatial graph into a sequence of joints. To improve generalization of our model, we further exploit 3D transformation based data augmentation techniques including rotation and scaling transformation to transform the 3D coordinates of skeletons during training. Experiments on 3D action recognition benchmark datasets show that our method brings a considerable improvement for a variety of actions, i.e., generic actions, interaction activities and gestures.",
        "A1": " In this paper, we propose a novel two-stream RNN architecture to model both temporal dynamics and spatial configurations for skeleton based action recognition.",
        "A2": "We explore two different structures for the temporal stream: stacked RNN and hierarchical RNN.",
        "A41": "We also propose two effective methods to model the spatial structure by converting the spatial graph into a sequence of joints.",
        "A51": "3D transformation based data augmentation techniques including rotation and scaling transformation",
        "A61": "Traditional approaches based on handcrafted features are limited to represent the complexity of motion patterns. Recent methods that use Recurrent Neural Networks (RNN) to handle raw skeletons only focus on the contextual dependency in the temporal domain and neglect the spatial configurations of articulated skeletons.",
        "A10": "Traditional approaches based on handcrafted features are limited to represent the complexity of motion patterns. Recent methods that use Recurrent Neural Networks (RNN) to handle raw skeletons only focus on the contextual dependency in the temporal domain and neglect the spatial configurations of articulated skeletons.",
        "A7": "To improve generalization of our model, we further exploit 3D transformation based data augmentation techniques including rotation and scaling transformation to transform the 3D coordinates of skeletons during training.",
        "A83": "gestures",
        "A82": "interaction activities",
        "A81": "generic actions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 268228855
    },
    {
        "Abstract": "Long Short-Term Memory (LSTM) networks have shown superior performance in 3D human action recognition due to their power in modeling the dynamics and dependencies in sequential data. Since not all joints are informative for action analysis and the irrelevant joints often bring a lot of noise, we need to pay more attention to the informative ones. However, original LSTM does not have strong attention capability. Hence we propose a new class of LSTM network, Global Context-Aware Attention LSTM (GCA-LSTM), for 3D action recognition, which is able to selectively focus on the informative joints in the action sequence with the assistance of global contextual information. In order to achieve a reliable attention representation for the action sequence, we further propose a recurrent attention mechanism for our GCA-LSTM network, in which the attention performance is improved iteratively. Experiments show that our end-to-end network can reliably focus on the most informative joints in each frame of the skeleton sequence. Moreover, our network yields state-of-the-art performance on three challenging datasets for 3D action recognition.",
        "A1": " original LSTM does not have strong attention capability.",
        "A2": "propose a new class of LSTM network, Global Context-Aware Attention LSTM (GCA-LSTM), for 3D action recognition",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our network yields state-of-the-art performance on three challenging datasets for 3D action recognition.",
        "A7": "Experiments",
        "A83": "",
        "A82": "our network yields state-of-the-art performance on three challenging datasets for 3D action recognition.",
        "A81": " our end-to-end network can reliably focus on the most informative joints in each frame of the skeleton sequence",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " our end-to-end network can reliably focus on the most informative joints in each frame of the skeleton sequence",
        "A52": "",
        "A42": "a new class of LSTM network, Global Context-Aware Attention LSTM (GCA-LSTM), for 3D action recognition, which is able to selectively focus on the informative joints in the action sequence with the assistance of global contextual information",
        "A45": "",
        "am_id": 241057755
    },
    {
        "Abstract": "Tracking multiple persons in a monocular video of a crowded scene is a challenging task. Humans can master it even if they loose track of a person locally by re-identifying the same person based on their appearance. Care must be taken across long distances, as similar-looking persons need not be identical. In this work, we propose a novel graph-based formulation that links and clusters person hypotheses over time by solving an instance of a minimum cost lifted multicut problem. Our model generalizes previous works by introducing a mechanism for adding long-range attractive connections between nodes in the graph without modifying the original set of feasible solutions. This allows us to reward tracks that assign detections of similar appearance to the same person in a way that does not introduce implausible solutions. To effectively match hypotheses over longer temporal gaps we develop new deep architectures for re-identification of people. They combine holistic representations extracted with deep networks and body pose layout obtained with a state-of-the-art pose estimation model. We demonstrate the effectiveness of our formulation by reporting a new state-of-the-art for the MOT16 benchmark. The code and pre-trained models are publicly available.",
        "A1": " we propose a novel graph-based formulation that links and clusters person hypotheses over time by solving an instance of a minimum cost lifted multicut problem.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " MOT16 benchmark.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "They combine holistic representations extracted with deep networks and body pose layout obtained with a state-of-the-art pose estimation model. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "Our model generalizes previous works by introducing a mechanism for adding long-range attractive connections between nodes in the graph without modifying the original set of feasible solutions.",
        "A45": "",
        "am_id": 243476808
    },
    {
        "Abstract": "We propose a method for multi-person detection and 2-D pose estimation that achieves state-of-art results on the challenging COCO keypoints task. It is a simple, yet powerful, top-down approach consisting of two stages. In the first stage, we predict the location and scale of boxes which are likely to contain people, for this we use the Faster RCNN detector. In the second stage, we estimate the keypoints of the person potentially contained in each proposed bounding box. For each keypoint type we predict dense heatmaps and offsets using a fully convolutional ResNet. To combine these outputs we introduce a novel aggregation procedure to obtain highly localized keypoint predictions. We also use a novel form of keypoint-based Non-Maximum-Suppression (NMS), instead of the cruder box-level NMS, and a novel form of keypoint-based confidence score estimation, instead of box-level scoring. Trained on COCO data alone, our final system achieves average precision of 0.649 on the COCO test-dev set and the 0.643 test-standard sets, outperforming the winner of the 2016 COCO keypoints challenge and other recent state-of-art. Further, by using additional in-house labeled data we obtain an even higher average precision of 0.685 on the test-dev set and 0.673 on the test-standard set, more than 5% absolute improvement compared to the previous best performing method on the same dataset.",
        "A1": "We propose a method for multi-person detection and 2-D pose estimation that achieves state-of-art results on the challenging COCO keypoints task.",
        "A2": "the challenging COCO keypoints task",
        "A41": " for multi-person detection and 2-D pose estimation that achieves state-of-art results on the challenging COCO keypoints task",
        "A51": "",
        "A61": "We also use a novel form of keypoint-based Non-Maximum-Suppression (NMS), instead of the cruder box-level NMS, and a novel form of keypoint-based confidence score estimation, instead of box-level scoring.",
        "A10": "more than 5% absolute improvement compared to the previous best performing method on the same dataset.",
        "A7": "Trained on COCO data alone",
        "A83": "more than 5% absolute improvement compared to the previous best performing method on the same dataset.",
        "A82": "we obtain an even higher average precision of 0.685 on the test-dev set and 0.673 on the test-standard set",
        "A81": "our final system achieves average precision of 0.649 on the COCO test-dev set and the 0.643 test-standard sets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "COCO test-dev set and the 0.643 test-standard sets",
        "am_id": 129780323
    },
    {
        "Abstract": "Light field (LF) capture and processing are important in an expanding range of computer vision applications, offering rich textural and depth information and simplification of conventionally complex tasks. Although LF cameras are commercially available, no existing device offers wide field-of-view (FOV) imaging. This is due in part to the limitations of fisheye lenses, for which a fundamentally constrained entrance pupil diameter severely limits depth sensitivity. In this work we describe a novel, compact optical design that couples a monocentric lens with multiple sensors using microlens arrays, allowing LF capture with an unprecedented FOV. Leveraging capabilities of the LF representation, we propose a novel method for efficiently coupling the spherical lens and planar sensors, replacing expensive and bulky fiber bundles. We construct a single-sensor LF camera prototype, rotating the sensor relative to a fixed main lens to emulate a wide-FOV multi-sensor scenario. Finally, we describe a processing toolchain, including a convenient spherical LF parameterization, and demonstrate depth estimation and post-capture refocus for indoor and outdoor panoramas with 15 &#x00D7; 15 &#x00D7; 1600 &#x00D7; 200 pixels (72 MPix) and a 138&#x00B0; FOV.",
        "A1": "describe a novel, compact optical design ",
        "A2": "offers wide field-of-view (FOV) imaging",
        "A41": " a novel method for efficiently coupling the spherical lens and planar sensors",
        "A51": "",
        "A61": ", replacing expensive and bulky fiber bundles. We construct a single-sensor LF camera prototype,",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 385020995
    },
    {
        "Abstract": "Co-occurrence Filter (CoF) is a boundary preserving filter. It is based on the Bilateral Filter (BF) but instead of using a Gaussian on the range values to preserve edges it relies on a co-occurrence matrix. Pixel values that co-occur frequently in the image (i.e., inside textured regions) will have a high weight in the co-occurrence matrix. This, in turn, means that such pixel pairs will be averaged and hence smoothed, regardless of their intensity differences. On the other hand, pixel values that rarely co-occur (i.e., across texture boundaries) will have a low weight in the co-occurrence matrix. As a result, they will not be averaged and the boundary between them will be preserved. The CoF therefore extends the BF to deal with boundaries, not just edges. It learns co-occurrences directly from the image. We can achieve various filtering results by directing it to learn the co-occurrence matrix from a part of the image, or a different image. We give the definition of the filter, discuss how to use it with color images and show several use cases.",
        "A1": "give the definition of the filter, discuss how to use it with color images and show several use cases.",
        "A2": "give the definition of the filter, discuss how to use it with color images and show several use cases.",
        "A41": "Bilateral Filter (BF)",
        "A51": "co-occurrence matrix",
        "A61": "",
        "A10": "the boundary between them will be preserved",
        "A7": "",
        "A83": "",
        "A82": " learns co-occurrences directly from the image",
        "A81": "achieve various filtering results ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": " co-occurrence matrix",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 219392569
    },
    {
        "Abstract": "We propose to jointly learn a Discriminative Bayesian dictionary along a linear classifier using coupled Beta-Bernoulli Processes. Our representation model uses separate base measures for the dictionary and the classifier, but associates them to the class-specific training data using the same Bernoulli distributions. The Bernoulli distributions control the frequency with which the factors (e.g. dictionary atoms) are used in data representations, and they are inferred while accounting for the class labels in our approach. To further encourage discrimination in the dictionary, our model uses separate (sets of) Bernoulli distributions to represent data from different classes. Our approach adaptively learns the association between the dictionary atoms and the class labels while tailoring the classifier to this relation with a joint inference over the dictionary and the classifier. Once a test sample is represented over the dictionary, its representation is accurately labelled by the classifier due to the strong coupling between the dictionary and the classifier. We derive the Gibbs Sampling equations for our joint representation model and test our approach for face, object, scene and action recognition to establish its effectiveness.",
        "A1": "learn a Discriminative Bayesian dictionary",
        "A2": "",
        "A41": "Our representation model uses separate base measures for the dictionary and the classifier, but associates them to the class-specific training data using the same Bernoulli distributions",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " We derive the Gibbs Sampling equations for our joint representation model and test our approach for face, object, scene and action recognition to establish its effectiveness.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": ", our model uses separate (sets of) Bernoulli distributions to represent data from different classes. ",
        "A45": "",
        "am_id": 43568242
    },
    {
        "Abstract": "Several machine learning tasks require to represent the data using only a sparse set of interest points. An ideal detector is able to find the corresponding interest points even if the data undergo a transformation typical for a given domain. Since the task is of high practical interest in computer vision, many hand-crafted solutions were proposed. In this paper, we ask a fundamental question: can we learn such detectors from scratch? Since it is often unclear what points are interesting, human labelling cannot be used to find a truly unbiased solution. Therefore, the task requires an unsupervised formulation. We are the first to propose such a formulation: training a neural network to rank points in a transformation-invariant manner. Interest points are then extracted from the top/bottom quantiles of this ranking. We validate our approach on two tasks: standard RGB image interest point detection and challenging cross-modal interest point detection between RGB and depth images. We quantitatively show that our unsupervised method performs better or on-par with baselines.",
        "A1": " find the corresponding interest points even if the data undergo a transformation typical for a given domain",
        "A2": "it is often unclear what points are interesting, human labelling cannot be used to find a truly unbiased solution",
        "A41": "training a neural network to rank points in a transformation-invariant manner",
        "A51": "",
        "A61": "learn such detectors from scratch",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our unsupervised method performs better or on-par with baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 27460993
    },
    {
        "Abstract": "We propose a multigrid extension of convolutional neural networks (CNNs). Rather than manipulating representations living on a single spatial grid, our network layers operate across scale space, on a pyramid of grids. They consume multigrid inputs and produce multigrid outputs, convolutional filters themselves have both within-scale and cross-scale extent. This aspect is distinct from simple multiscale designs, which only process the input at different scales. Viewed in terms of information flow, a multigrid network passes messages across a spatial pyramid. As a consequence, receptive field size grows exponentially with depth, facilitating rapid integration of context. Most critically, multigrid structure enables networks to learn internal attention and dynamic routing mechanisms, and use them to accomplish tasks on which modern CNNs fail. Experiments demonstrate wide-ranging performance advantages of multigrid. On CIFAR and ImageNet classification tasks, flipping from a single grid to multigrid within the standard CNN paradigm improves accuracy, while being compute and parameter efficient. Multigrid is independent of other architectural choices, we show synergy in combination with residual connections. Multigrid yields dramatic improvement on a synthetic semantic segmentation dataset. Most strikingly, relatively shallow multigrid networks can learn to directly perform spatial transformation tasks, where, in contrast, current CNNs fail. Together, our results suggest that continuous evolution of features on a multigrid pyramid is a more powerful alternative to existing CNN designs on a flat grid.",
        "A1": "We propose a multigrid extension of convolutional neural networks (CNNs). ",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ogether, our results suggest that continuous evolution of features on a multigrid pyramid is a more powerful alternative to existing CNN designs on a flat grid.",
        "A7": "",
        "A83": "",
        "A82": "Most strikingly, relatively shallow multigrid networks can learn to directly perform spatial transformation tasks, where, in contrast, current CNNs fail. ",
        "A81": "Multigrid yields dramatic improvement on a synthetic semantic segmentation dataset.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 364052845
    },
    {
        "Abstract": "Deep convolutional neutral networks have achieved great success on image recognition tasks. Yet, it is non-trivial to transfer the state-of-the-art image recognition networks to videos as per-frame evaluation is too slow and unaffordable. We present deep feature flow, a fast and accurate framework for video recognition. It runs the expensive convolutional sub-network only on sparse key frames and propagates their deep feature maps to other frames via a flow field. It achieves significant speedup as flow computation is relatively fast. The end-to-end training of the whole architecture significantly boosts the recognition accuracy. Deep feature flow is flexible and general. It is validated on two recent large scale video datasets. It makes a large step towards practical video recognition. Code would be released.",
        "A1": "We present deep feature flow, a fast and accurate framework for video recognition",
        "A2": " it is non-trivial to transfer the state-of-the-art image recognition networks to videos as per-frame evaluation is too slow and unaffordable",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "It makes a large step towards practical video recognition. Code would be released",
        "A7": "two recent large scale video datasets",
        "A83": " Deep feature flow is flexible and general",
        "A82": " The end-to-end training of the whole architecture significantly boosts the recognition accuracy",
        "A81": "It achieves significant speedup as flow computation is relatively fast",
        "A64": " It achieves significant speedup as flow computation is relatively fast. The end-to-end training of the whole architecture significantly boosts the recognition accuracy. Deep feature flow is flexible and general.",
        "A54": " It runs the expensive convolutional sub-network only on sparse key frames and propagates their deep feature maps to other frames via a flow field",
        "A44": "We present deep feature flow, a fast and accurate framework for video recognition",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 483689485
    },
    {
        "Abstract": "This work aims to build pixel-to-pixel correspondences between images from the same visual class but with different geometries and visual similarities. This task is particularly challenging because (i) their visual content is similar only on the high-level structure, and (ii) background clutters keep bringing in noises. To address these problems, this paper proposes an object-aware method to estimate per-pixel correspondences from semantic to low-level by learning a classifier for each selected discriminative grid cell and guiding the localization of every pixel under the semantic constraint. Specifically, an Object-aware Hierarchical Graph (OHG) model is constructed to regulate matching consistency from one coarse grid cell containing whole object(s), to fine grid cells covering smaller semantic elements, and finally to every pixel. A guidance layer is introduced as the semantic constraint on local structure matching. In addition, we propose to learn the important high-level structure for each grid cell in an &#x201C;objectness-driven&#x201D; way as an alternative to handcrafted descriptors in defining a better visual similarity. The proposed method has been extensively evaluated on various challenging benchmarks and real-world images. The results show that our method significantly outperforms the state-of-the-arts in terms of semantic flow accuracy.",
        "A1": "build pixel-to-pixel correspondences between images from the same visual class but with different geometries and visual similarities.",
        "A2": "build pixel-to-pixel correspondences between images from the same visual class but with different geometries and visual similarities.",
        "A41": "an object-aware method to estimate per-pixel correspondences from semantic to low-level",
        "A51": " learning a classifier for each selected discriminative grid cell and guiding the localization of every pixel under the semantic constraint",
        "A61": "",
        "A10": "significantly outperforms the state-of-the-arts in terms of semantic flow accuracy",
        "A7": "The proposed method has been extensively evaluated on various challenging benchmarks and real-world images.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "A guidance layer is introduced as the semantic constraint on local structure matching. ",
        "A42": "an Object-aware Hierarchical Graph (OHG) model is constructed to regulate matching consistency from one coarse grid cell containing whole object(s), to fine grid cells covering smaller semantic elements, and finally to every pixel",
        "A45": "",
        "am_id": 432616664
    },
    {
        "Abstract": "In most state-of-the-art hashing-based visual search systems, local image descriptors of an image are first aggregated as a single feature vector. This feature vector is then subjected to a hashing function that produces a binary hash code. In previous work, the aggregating and the hashing processes are designed independently. In this paper, we propose a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly. Specifically, our joint optimization produces aggregated representations that can be better reconstructed by some binary codes. This leads to more discriminative binary hash codes and improved retrieval accuracy. In addition, we also propose a fast version of the recently-proposed Binary Autoencoder to be used in our proposed framework. We perform extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features. Our results suggest that the proposed framework achieves significant improvements over the state of the art.",
        "A1": "hashing-based visual search systems",
        "A2": "the aggregating and the hashing processes are designed independently",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "extensive retrieval experiments on several benchmark datasets with both SIFT and convolutional features",
        "A83": "",
        "A82": "",
        "A81": "the proposed framework achieves significant improvements over the state of the art",
        "A64": "feature aggregating and hashing are designed simultaneously and optimized jointly",
        "A54": "Binary Autoencoder",
        "A44": "a novel framework where feature aggregating and hashing are designed simultaneously and optimized jointly",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 373106015
    },
    {
        "Abstract": "This work is about recognizing human activities occurring in videos at distinct semantic levels, including individual actions, interactions, and group activities. The recognition is realized using a two-level hierarchy of Long ShortTerm Memory (LSTM) networks, forming a feed-forward deep architecture, which can be trained end-to-end. In comparison with existing architectures of LSTMs, we make two key contributions giving the name to our approach as Confidence-Energy Recurrent Network - CERN. First, instead of using the common softmax layer for prediction, we specify a novel energy layer (EL) for estimating the energy of our predictions. Second, rather than finding the common minimum-energy class assignment, which may be numerically unstable under uncertainty, we specify that the EL additionally computes the p-values of the solutions, and in this way estimates the most confident energy minimum. The evaluation on the Collective Activity and Volleyball datasets demonstrates: (i) advantages of our two contributions relative to the common softmax and energy-minimization formulations and (ii) a superior performance relative to the state-of-the-art approaches.",
        "A1": "This work is about recognizing human activities occurring in videos at distinct semantic levels, including individual actions, interactions, and group activities. ",
        "A2": "This work is about recognizing human activities occurring in videos at distinct semantic levels, including individual actions, interactions, and group activities. ",
        "A41": "Confidence-Energy Recurrent Network - CERN",
        "A51": "",
        "A61": " (i) advantages of our two contributions relative to the common softmax and energy-minimization formulations and (ii) a superior performance relative to the state-of-the-art approaches.",
        "A10": " (i) advantages of our two contributions relative to the common softmax and energy-minimization formulations and (ii) a superior performance relative to the state-of-the-art approaches.",
        "A7": "The evaluation on the Collective Activity and Volleyball datasets",
        "A83": "",
        "A82": " a superior performance relative to the state-of-the-art approaches.",
        "A81": " (i) advantages of our two contributions relative to the common softmax and energy-minimization formulations",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "the Collective Activity and Volleyball datasets ",
        "am_id": 349844801
    },
    {
        "Abstract": "We present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task. It inherits all the merits of FCNs for semantic segmentation [29] and instance mask proposal [5]. It performs instance mask prediction and classification jointly. The underlying convolutional representation is fully shared between the two sub-tasks, as well as between all regions of interest. The network architecture is highly integrated and efficient. It achieves state-of-the-art performance in both accuracy and efficiency. It wins the COCO 2016 segmentation competition by a large margin. Code would be released at https://github.com/daijifeng001/TA-FCN.",
        "A1": "present the first fully convolutional end-to-end solution for instance-aware semantic segmentation task",
        "A2": "It wins the COCO 2016 segmentation competition by a large margin",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "It achieves state-of-the-art performance in both accuracy and efficiency. It wins the COCO 2016 segmentation competition by a large margin",
        "A7": " It inherits all the merits of FCNs for semantic segmentation [29] and instance mask proposal [5]",
        "A83": "The network architecture is highly integrated and efficient. It achieves state-of-the-art performance in both accuracy and efficiency",
        "A82": "It performs instance mask prediction and classification jointly",
        "A81": "It inherits all the merits of FCNs for semantic segmentation [29] and instance mask proposal [5]",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 20451989
    },
    {
        "Abstract": "Confidence measures estimate unreliable disparity assignments performed by a stereo matching algorithm and, as recently proved, can be used for several purposes. This paper aims at increasing, by means of a deep network, the effectiveness of state-of-the-art confidence measures exploiting the local consistency assumption. We exhaustively evaluated our proposal on 23 confidence measures, including 5 top-performing ones based on random-forests and CNNs, training our networks with two popular stereo algorithms and a small subset (25 out of 194 frames) of the KITTI 2012 dataset. Experimental results show that our approach dramatically increases the effectiveness of all the 23 confidence measures on the remaining frames. Moreover, without re-training, we report a further cross-evaluation on KITTI 2015 and Middlebury 2014 confirming that our proposal provides remarkable improvements for each confidence measure even when dealing with significantly different input data. To the best of our knowledge, this is the first method to move beyond conventional pixel-wise confidence estimation.",
        "A1": "This paper aims at increasing, by means of a deep network, the effectiveness of state-of-the-art confidence measures exploiting the local consistency assumption.",
        "A2": "increasing, by means of a deep network, the effectiveness of state-of-the-art confidence measures exploiting the local consistency assumption.",
        "A41": "exhaustively evaluated our proposal on 23 confidence measures",
        "A51": "Confidence measures estimate unreliable disparity assignments performed by a stereo matching algorithm ",
        "A61": "by means of a deep network",
        "A10": "this is the first method to move beyond conventional pixel-wise confidence estimation.",
        "A7": "exhaustively evaluated our proposal on 23 confidence measures, including 5 top-performing ones based on random-forests and CNNs, training our networks with two popular stereo algorithms and a small subset (25 out of 194 frames) of the KITTI 2012 dataset. ",
        "A83": "",
        "A82": "proposal provides remarkable improvements for each confidence measure even when dealing with significantly different input data.",
        "A81": "Experimental results show that our approach dramatically increases the effectiveness of all the 23 confidence measures on the remaining frames. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 432854362
    },
    {
        "Abstract": "Estimating human pose, shape, and motion from images and videos are fundamental challenges with many applications. Recent advances in 2D human pose estimation use large amounts of manually-labeled training data for learning convolutional neural networks (CNNs). Such data is time consuming to acquire and difficult to extend. Moreover, manual labeling of 3D pose, depth and motion is impractical. In this work we present SURREAL (Synthetic hUmans foR REAL tasks): a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data. We generate more than 6 million frames together with ground truth pose, depth maps, and segmentation masks. We show that CNNs trained on our synthetic dataset allow for accurate human depth estimation and human part segmentation in real RGB images. Our results and the new dataset open up new possibilities for advancing person analysis using cheap and large-scale synthetic data.",
        "A1": "In this work we present SURREAL (Synthetic hUmans foR REAL tasks): a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data.",
        "A2": "Recent advances in 2D human pose estimation use large amounts of manually-labeled training data for learning convolutional neural networks (CNNs). Such data is time consuming to acquire and difficult to extend.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We generate more than 6 million frames together with ground truth pose, depth maps, and segmentation masks. ",
        "A83": "",
        "A82": " Our results and the new dataset open up new possibilities for advancing person analysis using cheap and large-scale synthetic data.",
        "A81": "We show that CNNs trained on our synthetic dataset allow for accurate human depth estimation and human part segmentation in real RGB images.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data. ",
        "am_id": 374006419
    },
    {
        "Abstract": "We present an approach that uses a multi-camera system to train fine-grained detectors for keypoints that are prone to occlusion, such as the joints of a hand. We call this procedure multiview bootstrapping: first, an initial keypoint detector is used to produce noisy labels in multiple views of the hand. The noisy detections are then triangulated in 3D using multiview geometry or marked as outliers. Finally, the reprojected triangulations are used as new labeled training data to improve the detector. We repeat this process, generating more labeled data in each iteration. We derive a result analytically relating the minimum number of views to achieve target true and false positive rates for a given detector. The method is used to train a hand keypoint detector for single images. The resulting keypoint detector runs in realtime on RGB images and has accuracy comparable to methods that use depth sensors. The single view detector, triangulated over multiple views, enables 3D markerless hand motion capture with complex object interactions.",
        "A1": "present an approach",
        "A2": "ain fine-grained detectors for keypoints that are prone to occlusion, such as the joints of a hand",
        "A41": " uses a multi-camera system to train fine-grained detectors for keypoints that are prone to occlusion",
        "A51": "irst, an initial keypoint detector is used to produce noisy labels in multiple views of the hand. The noisy detections are then triangulated in 3D using multiview geometry or marked as outliers. Finally, the reprojected triangulations are used as new labeled training data to improve the detector",
        "A61": "",
        "A10": "",
        "A7": "We repeat this process, generating more labeled data in each iteration",
        "A83": "",
        "A82": "",
        "A81": " result analytically relating the minimum number of views to achieve target true and false positive rates for a given detector. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 212491369
    },
    {
        "Abstract": "In this work, we introduce the challenging problem of joint multi-person pose estimation and tracking of an unknown number of persons in unconstrained videos. Existing methods for multi-person pose estimation in images cannot be applied directly to this problem, since it also requires to solve the problem of person association over time in addition to the pose estimation for each person. We therefore propose a novel method that jointly models multi-person pose estimation and tracking in a single formulation. To this end, we represent body joint detections in a video by a spatio-temporal graph and solve an integer linear program to partition the graph into sub-graphs that correspond to plausible body pose trajectories for each person. The proposed approach implicitly handles occlusion and truncation of persons. Since the problem has not been addressed quantitatively in the literature, we introduce a challenging Multi-Person PoseTrack dataset, and also propose a completely unconstrained evaluation protocol that does not make any assumptions about the scale, size, location or the number of persons. Finally, we evaluate the proposed approach and several baseline methods on our new dataset.",
        "A1": "ntroduce the challenging problem of joint multi-person pose estimation and tracking of an unknown number of persons in unconstrained videos. ",
        "A2": "joint multi-person pose estimation and tracking of an unknown number of persons in unconstrained videos",
        "A41": " a novel method that jointly models multi-person pose estimation and tracking in a single formulation",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "introduce a challenging Multi-Person PoseTrack dataset, and also propose a completely unconstrained evaluation protocol that does not make any assumptions about the scale, size, location or the number of persons. Finally, we evaluate the proposed approach and several baseline methods on our new dataset.",
        "A83": "",
        "A82": "",
        "A81": "propose a novel method that jointly models multi-person pose estimation and tracking in a single formulation.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 365275087
    },
    {
        "Abstract": "As autonomous vehicles become an every-day reality, high-accuracy pedestrian detection is of paramount practical importance. Pedestrian detection is a highly researched topic with mature methods, but most datasets (for both training and evaluation) focus on common scenes of people engaged in typical walking poses on sidewalks. But performance is most crucial for dangerous scenarios that are rarely observed, such as children playing in the street and people using bicycles/skateboards in unexpected ways. Such in-the-tail data is notoriously hard to observe, making both training and testing difficult. To analyze this problem, we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset. Even given a dedicated collection effort, it is relatively small by contemporary standards (&#x2248; 1000 images). To explore large-scale data-driven learning, we explore the use of synthetic data generated by a game engine. A significant challenge is selected the right priors or parameters for synthesis: we would like realistic data with realistic poses and object configurations. Inspired by Generative Adversarial Networks, we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset (that fools the classifier), which we deem Synthetic Imposters. We demonstrate that this pipeline allows one to generate realistic (or adverserial) training data by making use of rendering/animation engines. Interestingly, we also demonstrate that such data can be used to rank algorithms, suggesting that Synthetic Imposters can also be used for in-the-tail validation at test-time, a notoriously difficult challenge for real-world deployment.",
        "A1": "Pedestrian detection",
        "A2": "we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "We demonstrate that this pipeline allows one to generate realistic (or adverserial) training data by making use of rendering/animation engines. ",
        "A82": "we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset (that fools the classifier), which we deem Synthetic Imposters. ",
        "A81": " we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "most datasets (for both training and evaluation) focus on common scenes of people engaged in typical walking poses on sidewalks. But performance is most crucial for dangerous scenarios that are rarely observed, such as children playing in the street and people using bicycles/skateboards in unexpected ways. ",
        "am_id": 17089133
    },
    {
        "Abstract": "Effective integration of local and global contextual information is crucial for dense labeling problems. Most existing methods based on an encoder-decoder architecture simply concatenate features from earlier layers to obtain higher-frequency details in the refinement stages. However, there are limits to the quality of refinement possible if ambiguous information is passed forward. In this paper we propose Gated Feedback Refinement Network (G-FRNet), an end-to-end deep learning framework for dense labeling tasks that addresses this limitation of existing methods. Initially, G-FRNet makes a coarse prediction and then it progressively refines the details by efficiently integrating local and global contextual information during the refinement stages. We introduce gate units that control the information passed forward in order to filter out ambiguity. Experiments on three challenging dense labeling datasets (CamVid, PASCAL VOC 2012, and Horse-Cow Parsing) show the effectiveness of our method. Our proposed approach achieves state-of-the-art results on the CamVid and Horse-Cow Parsing datasets, and produces competitive results on the PASCAL VOC 2012 dataset.",
        "A1": "Effective integration of local and global contextual information is crucial for dense labeling problems. ",
        "A2": "However, there are limits to the quality of refinement possible if ambiguous information is passed forward.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experiments on three challenging dense labeling datasets (CamVid, PASCAL VOC 2012, and Horse-Cow Parsing) ",
        "A83": "",
        "A82": "produces competitive results on the PASCAL VOC 2012 dataset.",
        "A81": "show the effectiveness of our method. Our proposed approach achieves state-of-the-art results on the CamVid and Horse-Cow Parsing datasets",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "We introduce gate units that control the information passed forward in order to filter out ambiguity. ",
        "A42": "In this paper we propose Gated Feedback Refinement Network (G-FRNet), an end-to-end deep learning framework for dense labeling tasks that addresses this limitation of existing methods.",
        "A45": "",
        "am_id": 496743591
    },
    {
        "Abstract": "There have been remarkable improvements in the semantic labelling task in the recent years. However, the state of the art methods rely on large-scale pixel-level annotations. This paper studies the problem of training a pixel-wise semantic labeller network from image-level annotations of the present object classes. Recently, it has been shown that high quality seeds indicating discriminative object regions can be obtained from image-level labels. Without additional information, obtaining the full extent of the object is an inherently ill-posed problem due to co-occurrences. We propose using a saliency model as additional information and hereby exploit prior knowledge on the object extent and image statistics. We show how to combine both information sources in order to recover 80% of the fully supervised performance - which is the new state of the art in weakly supervised training for pixel-wise semantic labelling.",
        "A1": "propose using a saliency model as additional information and hereby exploit prior knowledge on the object extent and image statistics",
        "A2": "training a pixel-wise semantic labeller network from image-level annotations of the present object classes",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "recover 80% of the fully supervised performance - which is the new state of the art in weakly supervised training for pixel-wise semantic labelling",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "recover 80% of the fully supervised performance - which is the new state of the art in weakly supervised training for pixel-wise semantic labelling",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "how to combine both information sources in order to recover 80% of the fully supervised performance - which is the new state of the art in weakly supervised training for pixel-wise semantic labelling",
        "A52": "the object extent and image statistics",
        "A42": "a saliency model as additional information and hereby exploit prior knowledge on the object extent and image statistics",
        "A45": "",
        "am_id": 97848116
    },
    {
        "Abstract": "This paper focuses on a novel and challenging vision task, dense video captioning, which aims to automatically describe a video clip with multiple informative and diverse caption sentences. The proposed method is trained without explicit annotation of fine-grained sentence to video region-sequence correspondence, but is only based on weak video-level sentence annotations. It differs from existing video captioning systems in three technical aspects. First, we propose lexical fully convolutional neural networks (Lexical-FCN) with weakly supervised multi-instance multi-label learning to weakly link video regions with lexical labels. Second, we introduce a novel submodular maximization scheme to generate multiple informative and diverse region-sequences based on the Lexical-FCN outputs. A winner-takes-all scheme is adopted to weakly associate sentences to region-sequences in the training phase. Third, a sequence-to-sequence learning based language model is trained with the weakly supervised information obtained through the association process. We show that the proposed method can not only produce informative and diverse dense captions, but also outperform state-of-the-art single video captioning methods by a large margin.",
        "A1": "This paper focuses on a novel and challenging vision task, dense video captioning, which aims to automatically describe a video clip with multiple informative and diverse caption sentences.",
        "A2": "",
        "A41": "The proposed method is trained without explicit annotation of fine-grained sentence to video region-sequence correspondence, but is only based on weak video-level sentence annotations. ",
        "A51": "The proposed method is trained without explicit annotation of fine-grained sentence to video region-sequence correspondence, but is only based on weak video-level sentence annotations. ",
        "A61": " We show that the proposed method can not only produce informative and diverse dense captions, but also outperform state-of-the-art single video captioning methods by a large margin.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 78179355
    },
    {
        "Abstract": "Zero-shot recognition aims to accurately recognize objects of unseen classes by using a shared visual-semantic mapping between the image feature space and the semantic embedding space. This mapping is learned on training data of seen classes and is expected to have transfer ability to unseen classes. In this paper, we tackle this problem by exploiting the intrinsic relationship between the semantic space manifold and the transfer ability of visual-semantic mapping. We formalize their connection and cast zero-shot recognition as a joint optimization problem. Motivated by this, we propose a novel framework for zero-shot recognition, which contains dual visual-semantic mapping paths. Our analysis shows this framework can not only apply prior semantic knowledge to infer underlying semantic manifold in the image feature space, but also generate optimized semantic embedding space, which can enhance the transfer ability of the visual-semantic mapping to unseen classes. The proposed method is evaluated for zero-shot recognition on four benchmark datasets, achieving outstanding results.",
        "A1": "Zero-shot recognition",
        "A2": "This mapping is learned on training data of seen classes and is expected to have transfer ability to unseen classes.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " is evaluated for zero-shot recognition on four benchmark datasets,",
        "A83": "",
        "A82": " can not only apply prior semantic knowledge to infer underlying semantic manifold in the image feature space, but also generate optimized semantic embedding space, which can enhance the transfer ability of the visual-semantic mapping to unseen classes.",
        "A81": "achieving outstanding results.",
        "A64": "",
        "A54": "",
        "A44": "a novel framework for zero-shot recognition, which contains dual visual-semantic mapping paths.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 618212
    },
    {
        "Abstract": "Composite function minimization captures a wide spectrum of applications in both computer vision and machine learning. It includes bound constrained optimization and cardinality regularized optimization as special cases. This paper proposes and analyzes a new Matrix Splitting Method (MSM) for minimizing composite functions. It can be viewed as a generalization of the classical Gauss-Seidel method and the Successive Over-Relaxation method for solving linear systems in the literature. Incorporating a new Gaussian elimination procedure, the matrix splitting method achieves state-of-the-art performance. For convex problems, we establish the global convergence, convergence rate, and iteration complexity of MSM, while for non-convex problems, we prove its global convergence. Finally, we validate the performance of our matrix splitting method on two particular applications: nonnegative matrix factorization and cardinality regularized sparse coding. Extensive experiments show that our method outperforms existing composite function minimization techniques in term of both efficiency and efficacy.",
        "A1": "Composite function minimization",
        "A2": "Composite function minimization",
        "A41": "Incorporating a new Gaussian elimination procedure",
        "A51": "classical Gauss-Seidel method and the Successive Over-Relaxation method for solving linear systems",
        "A61": "",
        "A10": "our method outperforms existing composite function minimization techniques in term of both efficiency and efficacy",
        "A7": "nonnegative matrix factorization and cardinality regularized sparse coding",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms existing composite function minimization techniques in term of both efficiency and efficacy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 18796734
    },
    {
        "Abstract": "With the tremendous advances made by Convolutional Neural Networks (ConvNets) on object recognition, we can now easily obtain adequately reliable machine-labeled annotations easily from predictions by off-the-shelf ConvNets. In this work, we present an abstraction memory based framework for few-shot learning, building upon machine-labeled image annotations. Our method takes large-scale machine-annotated dataset (e.g., OpenImages) as an external memory bank. In the external memory bank, the information is stored in the memory slots in the form of key-value, in which image feature is regarded as the key and the label embedding serves as the value. When queried by the few-shot examples, our model selects visually similar data from the external memory bank and writes the useful information obtained from related external data into another memory bank, i.e., abstraction memory. Long Short-Term Memory (LSTM) controllers and attention mechanisms are utilized to guarantee the data written to the abstraction memory correlates with the query example. The abstraction memory concentrates information from the external memory bank to make the few-shot recognition effective. In the experiments, we first confirm that our model can learn to conduct few-shot object recognition on clean human-labeled data from the ImageNet dataset. Then, we demonstrate that with our model, machine-labeled image annotations are very effective and abundant resources for performing object recognition on novel categories. Experimental results show that our proposed model with machine-labeled annotations achieves great results, with only a 1% difference in accuracy between the machine-labeled annotations and the human-labeled annotations.",
        "A1": "present an abstraction memory based framework",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "demonstrate that with our model, machine-labeled image annotations are very effective and abundant resources for performing object recognition on novel categories. ",
        "A83": "",
        "A82": "",
        "A81": "Experimental results show that our proposed model with machine-labeled annotations achieves great results, with only a 1% difference in accuracy between the machine-labeled annotations and the human-labeled annotations.",
        "A64": "",
        "A54": "an abstraction memory based",
        "A44": "an abstraction memory based framework for few-shot learning, building upon machine-labeled image annotations. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 33150617
    },
    {
        "Abstract": "Most of the conventional face hallucination methods assume the input image is sufficiently large and aligned, and all require the input image to be noise-free. Their performance degrades drastically if the input image is tiny, unaligned, and contaminated by noise. In this paper, we introduce a novel transformative discriminative autoencoder to 8X super-resolve unaligned noisy and tiny (16X16) low-resolution face images. In contrast to encoder-decoder based autoencoders, our method uses decoder-encoder-decoder networks. We first employ a transformative discriminative decoder network to upsample and denoise simultaneously. Then we use a transformative encoder network to project the intermediate HR faces to aligned and noise-free LR faces. Finally, we use the second decoder to generate hallucinated HR images. Our extensive evaluations on a very large face dataset show that our method achieves superior hallucination results and outperforms the state-of-the-art by a large margin of 1.82dB PSNR.",
        "A1": "introduce a novel transformative discriminative autoencoder",
        "A2": " Their performance degrades drastically if the input image is tiny, unaligned, and contaminated by noise",
        "A41": "a novel transformative discriminative autoencoder to 8X super-resolve unaligned noisy and tiny (16X16) low-resolution face images. ",
        "A51": "decoder-encoder-decoder networks",
        "A61": "In contrast to encoder-decoder based autoencoders, our method uses decoder-encoder-decoder networks",
        "A10": "outperforms the state-of-the-art by a large margin of 1.82dB PSNR.",
        "A7": "Our extensive evaluations on a very large face dataset",
        "A83": "",
        "A82": "outperforms the state-of-the-art by a large margin of 1.82dB PSNR.",
        "A81": "our method achieves superior hallucination results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a very large face dataset",
        "am_id": 1153054
    },
    {
        "Abstract": "In recent years, deep neural networks have emerged as a dominant machine learning tool for a wide variety of application domains. However, training a deep neural network requires a large amount of labeled data, which is an expensive process in terms of time, labor and human expertise. Domain adaptation or transfer learning algorithms address this challenge by leveraging labeled data in a different, but related source domain, to develop a model for the target domain. Further, the explosive growth of digital data has posed a fundamental challenge concerning its storage and retrieval. Due to its storage and retrieval efficiency, recent years have witnessed a wide application of hashing in a variety of computer vision applications. In this paper, we first introduce a new dataset, Office-Home, to evaluate domain adaptation algorithms. The dataset contains images of a variety of everyday objects from multiple domains. We then propose a novel deep learning framework that can exploit labeled source data and unlabeled target data to learn informative hash codes, to accurately classify unseen target data. To the best of our knowledge, this is the first research effort to exploit the feature learning capabilities of deep neural networks to learn representative hash codes to address the domain adaptation problem. Our extensive empirical studies on multiple transfer tasks corroborate the usefulness of the framework in learning efficient hash codes which outperform existing competitive baselines for unsupervised domain adaptation.",
        "A1": "",
        "A2": "the domain adaptation problem",
        "A41": "exploit the feature learning capabilities of deep neural networks to learn representative hash codes to address the domain adaptation problem",
        "A51": "",
        "A61": " this is the first research effort to exploit the feature learning capabilities of deep neural networks to learn representative hash codes to address the domain adaptation problem. ",
        "A10": "hash codes which outperform existing competitive baselines for unsupervised domain adaptation",
        "A7": "multiple transfer tasks",
        "A83": "",
        "A82": "hash codes which outperform existing competitive baselines for unsupervised domain adaptation",
        "A81": "the usefulness of the framework in learning efficient hash codes ",
        "A64": "exploit labeled source data and unlabeled target data to learn informative hash codes, to accurately classify unseen target data",
        "A54": "labeled source data and unlabeled target data",
        "A44": "a novel deep learning framework that can exploit labeled source data and unlabeled target data to learn informative hash codes, to accurately classify unseen target data",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "The dataset contains images of a variety of everyday objects from multiple domains.",
        "am_id": 349274265
    },
    {
        "Abstract": "We address the problem of estimating human pose and body shape from 3D scans over time. Reliable estimation of 3D body shape is necessary for many applications including virtual try-on, health monitoring, and avatar creation for virtual reality. Scanning bodies in minimal clothing, however, presents a practical barrier to these applications. We address this problem by estimating body shape under clothing from a sequence of 3D scans. Previous methods that have exploited body models produce smooth shapes lacking personalized details. We contribute a new approach to recover a personalized shape of the person. The estimated shape deviates from a parametric model to fit the 3D scans. We demonstrate the method using high quality 4D data as well as sequences of visual hulls extracted from multi-view images. We also make available BUFF, a new 4D dataset that enables quantitative evaluation (http://buff.is.tue.mpg.de). Our method outperforms the state of the art in both pose estimation and shape estimation, qualitatively and quantitatively.",
        "A1": "",
        "A2": " the problem of estimating human pose and body shape from 3D scans over time. Reliable estimation of 3D body shape is necessary for many applications including virtual try-on, health monitoring, and avatar creation for virtual reality. Scanning bodies in minimal clothing",
        "A41": "a new approach to recover a personalized shape of the person. The estimated shape deviates from a parametric model to fit the 3D scans",
        "A51": "",
        "A61": "",
        "A10": " Our method outperforms the state of the art in both pose estimation and shape estimation, qualitatively and quantitatively.",
        "A7": "We demonstrate the method using high quality 4D data as well as sequences of visual hulls extracted from multi-view images. We also make available BUFF, a new 4D dataset that enables quantitative evaluation (http://buff.is.tue.mpg.de)",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 376453892
    },
    {
        "Abstract": "3D Human articulated pose recovery from monocular image sequences is very challenging due to the diverse appearances, viewpoints, occlusions, and also the human 3D pose is inherently ambiguous from the monocular imagery. It is thus critical to exploit rich spatial and temporal long-range dependencies among body joints for accurate 3D pose sequence prediction. Existing approaches usually manually design some elaborate prior terms and human body kinematic constraints for capturing structures, which are often insufficient to exploit all intrinsic structures and not scalable for all scenarios. In contrast, this paper presents a Recurrent 3D Pose Sequence Machine(RPSM) to automatically learn the image-dependent structural constraint and sequence-dependent temporal context by using a multi-stage sequential refinement. At each stage, our RPSM is composed of three modules to predict the 3D pose sequences based on the previously learned 2D pose representations and 3D poses: (i) a 2D pose module extracting the image-dependent pose representations, (ii) a 3D pose recurrent module regressing 3D poses and (iii) a feature adaption module serving as a bridge between module (i) and (ii) to enable the representation transformation from 2D to 3D domain. These three modules are then assembled into a sequential prediction framework to refine the predicted poses with multiple recurrent stages. Extensive evaluations on the Human3.6M dataset and HumanEva-I dataset show that our RPSM outperforms all state-of-the-art approaches for 3D pose estimation.",
        "A1": "presents a Recurrent 3D Pose Sequence Machine(RPSM) to automatically learn the image-dependent structural constraint and sequence-dependent temporal context by using a multi-stage sequential refinement",
        "A2": "Existing approaches usually manually design some elaborate prior terms and human body kinematic constraints for capturing structures, which are often insufficient to exploit all intrinsic structures and not scalable for all scenarios.",
        "A41": "a Recurrent 3D Pose Sequence Machine(RPSM) to automatically learn the image-dependent structural constraint and sequence-dependent temporal context by using a multi-stage sequential refinement.",
        "A51": "the previously learned 2D pose representations and 3D poses",
        "A61": " automatically learn the image-dependent structural constraint and sequence-dependent temporal context by using a multi-stage sequential refinement",
        "A10": "our RPSM outperforms all state-of-the-art approaches for 3D pose estimation",
        "A7": "Extensive evaluations on the Human3.6M dataset and HumanEva-I dataset",
        "A83": "",
        "A82": "",
        "A81": "our RPSM outperforms all state-of-the-art approaches for 3D pose estimation",
        "A64": "",
        "A54": "the previously learned 2D pose representations and 3D poses",
        "A44": "a sequential prediction framework to refine the predicted poses with multiple recurrent stages",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "the Human3.6M dataset and HumanEva-I dataset ",
        "am_id": 19451542
    },
    {
        "Abstract": "Actions are more than just movements and trajectories: we cook to eat and we hold a cup to drink from it. A thorough understanding of videos requires going beyond appearance modeling and necessitates reasoning about the sequence of activities, as well as the higher-level constructs such as intentions. But how do we model and reason about these? We propose a fully-connected temporal CRF model for reasoning over various aspects of activities that includes objects, actions, and intentions, where the potentials are predicted by a deep network. End-to-end training of such structured models is a challenging endeavor: For inference and learning we need to construct mini-batches consisting of whole videos, leading to mini-batches with only a few videos. This causes high-correlation between data points leading to breakdown of the backprop algorithm. To address this challenge, we present an asynchronous variational inference method that allows efficient end-to-end training. Our method achieves a classification mAP of 22.4% on the Charades [42] benchmark, outperforming the state-of-the-art (17.2% mAP), and offers equal gains on the task of temporal localization.",
        "A1": "To address this challenge, we present an asynchronous variational inference method that allows efficient end-to-end training. ",
        "A2": " This causes high-correlation between data points leading to breakdown of the backprop algorithm.",
        "A41": " an asynchronous variational inference method that allows efficient end-to-end training. ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": " a fully-connected temporal CRF model for reasoning over various aspects of activities that includes objects, actions, and intentions, ",
        "A45": "",
        "am_id": 285216709
    },
    {
        "Abstract": "We consider the task of automated estimation of facial expression intensity. This involves estimation of multiple output variables (facial action units - AUs) that are structurally dependent. Their structure arises from statistically induced co-occurrence patterns of AU intensity levels. Modeling this structure is critical for improving the estimation performance, however, this performance is bounded by the quality of the input features extracted from face images. The goal of this paper is to model these structures and estimate complex feature representations simultaneously by combining conditional random field (CRF) encoded AU dependencies with deep learning. To this end, we propose a novel Copula CNN deep learning approach for modeling multivariate ordinal variables. Our model accounts for ordinal structure in output variables and their non-linear dependencies via copula functions modeled as cliques of a CRF. These are jointly optimized with deep CNN feature encoding layers using a newly introduced balanced batch iterative training algorithm. We demonstrate the effectiveness of our approach on the task of AU intensity estimation on two benchmark datasets. We show that joint learning of the deep features and the target output structure results in significant performance gains compared to existing structured deep models and deep models for analysis of facial expressions.",
        "A1": "We consider the task of automated estimation of facial expression intensity.",
        "A2": "This involves estimation of multiple output variables (facial action units - AUs) that are structurally dependent. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " Our model accounts for ordinal structure in output variables and their non-linear dependencies via copula functions modeled as cliques of a CRF. These are jointly optimized with deep CNN feature encoding layers using a newly introduced balanced batch iterative training algorithm.",
        "A7": "",
        "A83": "",
        "A82": " We demonstrate the effectiveness of our approach on the task of AU intensity estimation on two benchmark datasets.",
        "A81": "joint learning of the deep features and the target output structure results in significant performance gains compared to existing structured deep models and deep models for analysis of facial expressions.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "joint learning of the deep features and the target output structure results in significant performance gains compared to existing structured deep models and deep models for analysis of facial expressions.",
        "A52": " Our model accounts for ordinal structure in output variables and their non-linear dependencies via copula functions modeled as cliques of a CRF.",
        "A42": " Our model accounts for ordinal structure in output variables and their non-linear dependencies via copula functions modeled as cliques of a CRF.",
        "A45": "",
        "am_id": 452548902
    },
    {
        "Abstract": "Magnetic Resonance Imaging (MRI) offers high-resolution in vivo imaging and rich functional and anatomical multimodality tissue contrast. In practice, however, there are challenges associated with considerations of scanning costs, patient comfort, and scanning time that constrain how much data can be acquired in clinical or research studies. In this paper, we explore the possibility of generating high-resolution and multimodal images from low-resolution single-modality imagery. We propose the weakly-supervised joint convolutional sparse coding to simultaneously solve the problems of super-resolution (SR) and cross-modality image synthesis. The learning process requires only a few registered multimodal image pairs as the training set. Additionally, the quality of the joint dictionary learning can be improved using a larger set of unpaired images. To combine unpaired data from different image resolutions/modalities, a hetero-domain image alignment term is proposed. Local image neighborhoods are naturally preserved by operating on the whole image domain (as opposed to image patches) and using joint convolutional sparse coding. The paired images are enhanced in the joint learning process with unpaired data and an additional maximum mean discrepancy term, which minimizes the dissimilarity between their feature distributions. Experiments show that the proposed method outperforms state-of-the-art techniques on both SR reconstruction and simultaneous SR and cross-modality synthesis.",
        "A1": "explore the possibility of generating high-resolution and multimodal images from low-resolution single-modality imagery",
        "A2": " In practice, however, there are challenges associated with considerations of scanning costs, patient comfort, and scanning time that constrain how much data can be acquired in clinical or research studies",
        "A41": "propose the weakly-supervised joint convolutional sparse coding to simultaneously solve the problems",
        "A51": "super-resolution (SR) and cross-modality image synthesis",
        "A61": "The learning process requires only a few registered multimodal image pairs as the training set. Additionally, the quality of the joint dictionary learning can be improved using a larger set of unpaired images. ",
        "A10": "the proposed method outperforms state-of-the-art techniques on both SR reconstruction and simultaneous SR and cross-modality synthesis.",
        "A7": " Experiments",
        "A83": "",
        "A82": "",
        "A81": "the proposed method outperforms state-of-the-art techniques on both SR reconstruction and simultaneous SR and cross-modality synthesis.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 409157557
    },
    {
        "Abstract": "Random forest has emerged as a powerful classification technique with promising results in various vision tasks including image classification, pose estimation and object detection. However, current techniques have shown little improvements in visual tracking as they mostly rely on piece wise orthogonal hyperplanes to create decision nodes and lack a robust incremental learning mechanism that is much needed for online tracking. In this paper, we propose a discriminative tracker based on a novel incremental oblique random forest. Unlike conventional orthogonal decision trees that use a single feature and heuristic measures to obtain a split at each node, we propose to use a more powerful proximal SVM to obtain oblique hyperplanes to capture the geometric structure of the data better. The resulting decision surface is not restricted to be axis aligned and hence has the ability to represent and classify the input data better. Furthermore, in order to generalize to online tracking scenarios, we derive incremental update steps that enable the hyperplanes in each node to be updated recursively, efficiently and in a closed-form fashion. We demonstrate the effectiveness of our method using two large scale benchmark datasets (OTB-51 and OTB-100) and show that our method gives competitive results on several challenging cases by relying on simple HOG features as well as in combination with more sophisticated deep neural network based models. The implementations of the proposed random forest are available at https://github.com/ZhangLeUestc/ Incremental-Oblique-Random-Forest.",
        "A1": "propose a discriminative tracker based on a novel incremental oblique random forest",
        "A2": "current techniques have shown little improvements in visual tracking",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "using two large scale benchmark datasets (OTB-51 and OTB-100)",
        "A83": "",
        "A82": "",
        "A81": "our method gives competitive results on several challenging cases by relying on simple HOG features as well as in combination with more sophisticated deep neural network based models",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Unlike conventional orthogonal decision trees that use a single feature and heuristic measures to obtain a split at each node, we propose to use a more powerful proximal SVM to obtain oblique hyperplanes to capture the geometric structure of the data better. ",
        "A52": "a novel incremental oblique random forest",
        "A42": "a discriminative tracker based on a novel incremental oblique random forest",
        "A45": "",
        "am_id": 134224337
    },
    {
        "Abstract": "One of the most frequently applied low-level operations in computer vision is the conversion of an RGB camera image into its luminance representation. This is also one of the most incorrectly applied operations. Even our most trusted softwares, Matlab and OpenCV, do not perform luminance conversion correctly. In this paper, we examine the main factors that make proper RGB to luminance conversion difficult, in particular: 1) incorrect white-balance, 2) incorrect gamma/tone-curve correction, and 3) incorrect equations. Our analysis shows errors up to 50% for various colors are not uncommon. As a result, we argue that for most computer vision problems there is no need to attempt luminance conversion, instead, there are better alternatives depending on the task.",
        "A1": "argue that for most computer vision problems there is no need to attempt luminance conversion",
        "A2": "",
        "A41": "there is no need to attempt luminance conversion",
        "A51": "",
        "A61": "there are better alternatives depending on the task",
        "A10": "errors up to 50% for various colors are not uncommon",
        "A7": "we examine the main factors that make proper RGB to luminance conversion difficult, in particular",
        "A83": "incorrect equations",
        "A82": "incorrect gamma/tone-curve correction",
        "A81": "incorrect white-balance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 216123466
    },
    {
        "Abstract": "Estimating dense visual correspondences between objects with intra-class variation, deformations and background clutter remains a challenging problem. Thanks to the breakthrough of CNNs there are new powerful features available. Despite their easy accessibility and great success, existing semantic flow methods could not significantly benefit from these without extensive additional training. We introduce a novel method for semantic matching with pre-trained CNN features which is based on convolutional feature pyramids and activation guided feature selection. For the final matching we propose a sparse graph matching framework where each salient feature selects among a small subset of nearest neighbors in the target image. To improve our method in the unconstrained setting without bounding box annotations we introduce novel object proposal based matching constraints. Furthermore, we show that the sparse matching can be transformed into a dense correspondence field. Extensive experimental evaluations on benchmark datasets show that our method significantly outperforms existing semantic matching methods.",
        "A1": "introduce a novel method for semantic matching with pre-trained CNN features ",
        "A2": " existing semantic flow methods could not significantly benefit from these without extensive additional training",
        "A41": "a novel method for semantic matching with pre-trained CNN features ",
        "A51": "convolutional feature pyramids and activation guided feature selection",
        "A61": "",
        "A10": "existing semantic flow methods could not significantly benefit from these without extensive additional training",
        "A7": "Extensive experimental evaluations on benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "our method significantly outperforms existing semantic matching methods.",
        "A64": "each salient feature selects among a small subset of nearest neighbors in the target image",
        "A54": "",
        "A44": " a sparse graph matching framework ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 180503386
    },
    {
        "Abstract": "Many computer vision problems require optimization of binary non-submodular energies. In this context, iterative submodularization techniques based on trust region (LSA-TR) and auxiliary functions (LSA-AUX) have been recently proposed [9]. They achieve state-of-the-art-results on a number of computer vision applications. In this paper we extend the LSA-AUX framework in two directions. First, unlike LSA-AUX which selects auxiliary functions based solely on the current solution, we propose to incorporate several additional criteria. This results in tighter bounds for configurations that are more likely or closer to the current solution. Second, we propose move-making extensions of LSA-AUX which achieve tighter bounds by restricting the search space. Finally, we evaluate our methods on several applications. We show that for each application at least one of our extensions significantly outperforms the original LSA-AUX. Moreover, the best extension of LSA-AUX is comparable to or better than LSA-TR on five out of six applications, achieving state-of-the-arts results on four out of six applications.",
        "A1": "extend the LSA-AUX framework in two directions",
        "A2": "computer vision problems",
        "A41": "incorporate several additional criteria",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "several applications",
        "A83": "",
        "A82": "the best extension of LSA-AUX is comparable to or better than LSA-TR on five out of six applications",
        "A81": "significantly outperforms the original LSA-AUX",
        "A64": "",
        "A54": "the current solution",
        "A44": " LSA-AUX",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 447610849
    },
    {
        "Abstract": "Human pose estimation and semantic part segmentation are two complementary tasks in computer vision. In this paper, we propose to solve the two tasks jointly for natural multi-person images, in which the estimated pose provides object-level shape prior to regularize part segments while the part-level segments constrain the variation of pose locations. Specifically, we first train two fully convolutional neural networks (FCNs), namely Pose FCN and Part FCN, to provide initial estimation of pose joint potential and semantic part potential. Then, to refine pose joint location, the two types of potentials are fused with a fully-connected conditional random field (FCRF), where a novel segment-joint smoothness term is used to encourage semantic and spatial consistency between parts and joints. To refine part segments, the refined pose and the original part potential are integrated through a Part FCN, where the skeleton feature from pose serves as additional regularization cues for part segments. Finally, to reduce the complexity of the FCRF, we induce human detection boxes and infer the graph inside each box, making the inference forty times faster. Since theres no dataset that contains both part segments and pose labels, we extend the PASCAL VOC part dataset [6] with human pose joints and perform extensive experiments to compare our method against several most recent strategies. We show that our algorithm surpasses competing methods by 10.6% in pose estimation with much faster speed and by 1.5% in semantic part segmentation.",
        "A1": "propose to solve the two tasks jointly for natural multi-person images",
        "A2": "Human pose estimation and semantic part segmentation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "that our algorithm surpasses competing methods by 10.6% in pose estimation with much faster speed and by 1.5% in semantic part segmentation.",
        "A7": "extend the PASCAL VOC part dataset [6] with human pose joints and perform extensive experiments to compare our method against several most recent strategies",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 122589490
    },
    {
        "Abstract": "We propose Deep Feature Interpolation (DFI), a new datadriven baseline for automatic high-resolution image transformation. As the name suggests, DFI relies only on simple linear interpolation of deep convolutional features from pre-trained convnets. We show that despite its simplicity, DFI can perform high-level semantic transformations like &#x201C;make older/younger&#x201D;, &#x201C;make bespectacled&#x201D;, &#x201C;add smile&#x201D;, among others, surprisingly well-sometimes even matching or outperforming the state-of-the-art. This is particularly unexpected as DFI requires no specialized network architecture or even any deep network to be trained for these tasks. DFI therefore can be used as a new baseline to evaluate more complex algorithms and provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.",
        "A1": "propose Deep Feature Interpolation (DFI), a new datadriven baseline for automatic high-resolution image transformation",
        "A2": "provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning",
        "A41": "Deep Feature Interpolation (DFI)",
        "A51": "simple linear interpolation of deep convolutional features from pre-trained convnets",
        "A61": "provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.",
        "A10": "provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.",
        "A7": "provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.",
        "A83": "",
        "A82": " surprisingly well-sometimes even matching or outperforming the state-of-the-art",
        "A81": " DFI therefore can be used as a new baseline to evaluate more complex algorithms and provides a practical answer to the question of which image transformation tasks are still challenging after the advent of deep learning.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 325367918
    },
    {
        "Abstract": "Deep networks have shown impressive performance on many computer vision tasks. Recently, deep convolutional neural networks (CNNs) have been used to learn discriminative texture representations. One of the most successful approaches is Bilinear CNN model that explicitly captures the second order statistics within deep features. However, these networks cut off the first order information flow in the deep network and make gradient back-propagation difficult. We propose an effective fusion architecture - FASON that combines second order information flow and first order information flow. Our method allows gradients to back-propagate through both flows freely and can be trained effectively. We then build a multi-level deep architecture to exploit the first and second order information within different convolutional layers. Experiments show that our method achieves improvements over state-of-the-art methods on several benchmark datasets.",
        "A1": "allows gradients to back-propagate through both flows freely and can be trained effectively",
        "A2": "cut off the first order information flow in the deep network and make gradient back-propagation difficult",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our method achieves improvements over state-of-the-art methods on several benchmark datasets",
        "A7": "on several benchmark datasets",
        "A83": "",
        "A82": "",
        "A81": "our method achieves improvements over state-of-the-art methods",
        "A64": "combines second order information flow and first order information flow",
        "A54": "",
        "A44": "FASON",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 473557768
    },
    {
        "Abstract": "The attention mechanisms in deep neural networks are inspired by humans attention that sequentially focuses on the most relevant parts of the information over time to generate prediction output. The attention parameters in those models are implicitly trained in an end-to-end manner, yet there have been few trials to explicitly incorporate human gaze tracking to supervise the attention models. In this paper, we investigate whether attention models can benefit from explicit human gaze labels, especially for the task of video captioning. We collect a new dataset called VAS, consisting of movie clips, and corresponding multiple descriptive sentences along with human gaze tracking data. We propose a video captioning model named Gaze Encoding Attention Network (GEAN) that can leverage gaze tracking information to provide the spatial and temporal attention for sentence generation. Through evaluation of language similarity metrics and human assessment via Amazon mechanical Turk, we demonstrate that spatial attentions guided by human gaze data indeed improve the performance of multiple captioning methods. Moreover, we show that the proposed approach achieves the state-of-the-art performance for both gaze prediction and video captioning not only in our VAS dataset but also in standard datasets (e.g. LSMDC [24] and Hollywood2 [18]).",
        "A1": "we investigate whether attention models can benefit from explicit human gaze labels, especially for the task of video captioning. ",
        "A2": "et there have been few trials to explicitly incorporate human gaze tracking to supervise the attention models.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we show that the proposed approach achieves the state-of-the-art performance for both gaze prediction and video captioning not only in our VAS dataset but also in standard datasets",
        "A7": "evaluation of language similarity metrics and human assessment via Amazon mechanical Turk",
        "A83": "",
        "A82": "we show that the proposed approach achieves the state-of-the-art performance for both gaze prediction and video captioning not only in our VAS dataset but also in standard datasets",
        "A81": "spatial attentions guided by human gaze data indeed improve the performance of multiple captioning methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "a video captioning model named Gaze Encoding Attention Network (GEAN) that can leverage gaze tracking information to provide the spatial and temporal attention for sentence generation.",
        "A45": "",
        "am_id": 213359860
    },
    {
        "Abstract": "The research focus of designing local patch descriptors has gradually shifted from handcrafted ones (e.g., SIFT) to learned ones. In this paper, we propose to learn high performance descriptor in Euclidean space via the Convolutional Neural Network (CNN). Our method is distinctive in four aspects: (i) We propose a progressive sampling strategy which enables the network to access billions of training samples in a few epochs. (ii) Derived from the basic concept of local patch matching problem, we empha-size the relative distance between descriptors. (iii) Extra supervision is imposed on the intermediate feature maps. (iv) Compactness of the descriptor is taken into account. The proposed network is named as L2-Net since the output descriptor can be matched in Euclidean space by L2 distance. L2-Net achieves state-of-the-art performance on the Brown datasets [16], Oxford dataset [18] and the newly proposed Hpatches dataset [11]. The good generalization ability shown by experiments indicates that L2-Net can serve as a direct substitution of the existing handcrafted descriptors. The pre-trained L2-Net is publicly available.",
        "A1": "learn high performance descriptor in Euclidean space via the Convolutional Neural Network ",
        "A2": "local patch descriptors has gradually shifted from handcrafted ones ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Brown datasets [16], Oxford dataset [18] and the newly proposed Hpatches dataset [11]",
        "A83": "pre-trained L2-Net is publicly available",
        "A82": "good generalization ability ",
        "A81": "achieves state-of-the-art performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Compactness of the descriptor",
        "A52": "Convolutional Neural Network ",
        "A42": "learn high performance descriptor in Euclidean space via the Convolutional Neural Network ",
        "A45": "",
        "am_id": 168648337
    },
    {
        "Abstract": "Image-set classification has recently generated great popularity due to its widespread applications in computer vision. The great challenges arise from effectively and efficiently measuring the similarity between image sets with high inter-class ambiguity and huge intra-class variability. In this paper, we propose deep match kernels (DMK) to directly measure the similarity between image sets in the match kernel framework. Specifically, we build deep local match kernels between images upon arc-cosine kernels, which can faithfully characterize the similarity between images by mimicking deep neural networks, we introduce anchors to aggregate those deep local match kernels into a global match kernel between image sets, which is learned in a supervised way by kernel alignment and therefore more discriminative. The DMK provides the first match kernel framework for image-set classification, which removes specific assumptions usually required in previous approaches and is computationally more efficient. We conduct extensive experiments on four datasets for three diverse image-set classification tasks. The DMK achieves high performance and consistently surpasses state-of-the-art methods, showing its great effectiveness for image-set classification.",
        "A1": "propose deep match kernels (DMK) to directly measure the similarity between image sets in the match kernel framework",
        "A2": "effectively and efficiently measuring the similarity between image sets with high inter-class ambiguity and huge intra-class variability",
        "A41": "deep match kernels (DMK) to directly measure the similarity between image sets in the match kernel framework",
        "A51": "",
        "A61": "DMK provides the first match kernel framework for image-set classification, which removes specific assumptions usually required in previous approaches and is computationally more efficient",
        "A10": "",
        "A7": "extensive experiments on four datasets for three diverse image-set classification tasks",
        "A83": "",
        "A82": "",
        "A81": "achieves high performance and consistently surpasses state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 282491109
    },
    {
        "Abstract": "In this paper, we study learning visual classifiers from unstructured text descriptions at part precision with no training images. We propose a learning framework that is able to connect text terms to its relevant parts and suppress connections to non-visual text terms without any part-text annotations. For instance, this learning process enables terms like beak to be sparsely linked to the visual representation of parts like head, while reduces the effect of non-visual terms like migrate on classifier prediction. Images are encoded by a part-based CNN that detect bird parts and learn part-specific representation. Part-based visual classifiers are predicted from text descriptions of unseen visual classifiers to facilitate classification without training images (also known as zero-shot recognition). We performed our experiments on CUBirds 2011 dataset and improves the state-of-the-art text-based zero-shot recognition results from 34.7% to 43.6%. We also created large scale benchmarks on North American Bird Images augmented with text descriptions, where we also show that our approach outperforms existing methods. Our code, data, and models are publically available link [1].",
        "A1": "propose a learning framework",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We also created large scale benchmarks on North American Bird Images augmented with text descriptions, where we also show that our approach outperforms existing methods",
        "A7": "experiments on CUBirds 2011 dataset",
        "A83": "",
        "A82": "our approach outperforms existing methods",
        "A81": "improves the state-of-the-art text-based zero-shot recognition results from 34.7% to 43.6%",
        "A64": "this learning process enables terms like beak to be sparsely linked to the visual representation of parts like head, while reduces the effect of non-visual terms like migrate on classifier prediction",
        "A54": "",
        "A44": "a learning framework that is able to connect text terms to its relevant parts and suppress connections to non-visual text terms without any part-text annotations",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 77424276
    },
    {
        "Abstract": "Visual attention has been successfully applied in structural prediction tasks such as visual captioning and question answering. Existing visual attention models are generally spatial, i.e., the attention is modeled as spatial probabilities that re-weight the last conv-layer feature map of a CNN encoding an input image. However, we argue that such spatial attention does not necessarily conform to the attention mechanism - a dynamic feature extractor that combines contextual fixations over time, as CNN features are naturally spatial, channel-wise and multi-layer. In this paper, we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN. In the task of image captioning, SCA-CNN dynamically modulates the sentence generation context in multi-layer feature maps, encoding where (i.e., attentive spatial locations at multiple layers) and what (i.e., attentive channels) the visual attention is. We evaluate the proposed SCA-CNN architecture on three benchmark image captioning datasets: Flickr8K, Flickr30K, and MSCOCO. It is consistently observed that SCA-CNN significantly outperforms state-of-the-art visual attention-based image captioning methods.",
        "A1": "we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "It is consistently observed that SCA-CNN significantly outperforms state-of-the-art visual attention-based image captioning methods.",
        "A7": "We evaluate the proposed SCA-CNN architecture on three benchmark image captioning datasets: Flickr8K, Flickr30K, and MSCOCO. ",
        "A83": "",
        "A82": "",
        "A81": "It is consistently observed that SCA-CNN significantly outperforms state-of-the-art visual attention-based image captioning methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Spatial and Channel-wise Attentions in a CNN",
        "A42": "we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN.",
        "A45": "",
        "am_id": 281311887
    },
    {
        "Abstract": "In this work, we introduce a new kind of spatial partition trees for efficient nearest-neighbor search. Our approach first identifies a set of useful data splitting directions, and then learns a codebook that can be used to encode such directions. We use the product-quantization idea in order to make the effective codebook large, the evaluation of scalar products between the query and the encoded splitting direction very fast, and the encoding itself compact. As a result, the proposed data srtucture (Product Split tree) achieves compact clustering of data points, while keeping the traversal very efficient. In the nearest-neighbor search experiments on high-dimensional data, product split trees achieved state-of-the-art performance, demonstrating better speed-accuracy tradeoff than other spatial partition trees.",
        "A1": "introduce a new kind of spatial partition trees",
        "A2": "",
        "A41": "Our approach first identifies a set of useful data splitting directions, and then learns a codebook that can be used to encode such directions.",
        "A51": "the product-quantization idea",
        "A61": "",
        "A10": "for efficient nearest-neighbor search.",
        "A7": "the nearest-neighbor search experiments on high-dimensional data",
        "A83": "",
        "A82": "demonstrating better speed-accuracy tradeoff than other spatial partition trees.",
        "A81": "product split trees achieved state-of-the-art performance",
        "A64": "",
        "A54": "",
        "A44": "the proposed data srtucture (Product Split tree)",
        "A63": "",
        "A53": "",
        "A43": "the product-quantization idea",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a set of useful data",
        "am_id": 404438705
    },
    {
        "Abstract": "Zero-shot image classification using auxiliary information, such as attributes describing discriminative object properties, requires time-consuming annotation by domain experts. We instead propose a method that relies on human gaze as auxiliary information, exploiting that even non-expert users have a natural ability to judge class membership. We present a data collection paradigm that involves a discrimination task to increase the information content obtained from gaze data. Our method extracts discriminative descriptors from the data and learns a compatibility function between image and gaze using three novel gaze embeddings: Gaze Histograms (GH), Gaze Features with Grid (GFG) and Gaze Features with Sequence (GFS). We introduce two new gaze-annotated datasets for fine-grained image classification and show that human gaze data is indeed class discriminative, provides a competitive alternative to expert-annotated attributes, and outperforms other baselines for zero-shot image classification.",
        "A1": "non-expert users have a natural ability to judge class membership",
        "A2": "",
        "A41": " a method that relies on human gaze as auxiliary information",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "two new gaze-annotated datasets",
        "A83": "",
        "A82": "",
        "A81": " outperforms other baselines",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 176072729
    },
    {
        "Abstract": "Visual narrative is often a combination of explicit information and judicious omissions, relying on the viewer to supply missing details. In comics, most movements in time and space are hidden in the gutters between panels. To follow the story, readers logically connect panels together by inferring unseen actions through a process called closure. While computers can now describe the content of natural images, in this paper we examine whether they can understand the closure-driven narratives conveyed by stylized artwork and dialogue in comic book panels. We collect a dataset, COMICS, that consists of over 1.2 million panels (120 GB) paired with automatic textbox transcriptions. An in-depth analysis of COMICS demonstrates that neither text nor image alone can tell a comic book story, so a computer must understand both modalities to keep up with the plot. We introduce three cloze-style tasks that ask models to predict narrative and character-centric aspects of a panel given n preceding panels as context. Various deep neural architectures underperform human baselines on these tasks, suggesting that COMICS contains fundamental challenges for both vision and language.",
        "A1": " examine whether they can understand the closure-driven narratives conveyed by stylized artwork and dialogue in comic book panels.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We introduce three cloze-style tasks that ask models to predict narrative and character-centric aspects of a panel given n preceding panels as context",
        "A83": "",
        "A82": "",
        "A81": "Various deep neural architectures underperform human baselines on these tasks, suggesting that COMICS contains fundamental challenges for both vision and language.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "a dataset, COMICS, that consists of over 1.2 million panels (120 GB) paired with automatic textbox transcriptions",
        "am_id": 113308729
    },
    {
        "Abstract": "We investigate a principle way to progressively mine discriminative object regions using classification networks to address the weakly-supervised semantic segmentation problems. Classification networks are only responsive to small and sparse discriminative regions from the object of interest, which deviates from the requirement of the segmentation task that needs to localize dense, interior and integral regions for pixel-wise inference. To mitigate this gap, we propose a new adversarial erasing approach for localizing and expanding object regions progressively. Starting with a single small object region, our proposed approach drives the classification network to sequentially discover new and complement object regions by erasing the current mined regions in an adversarial manner. These localized regions eventually constitute a dense and complete object region for learning semantic segmentation. To further enhance the quality of the discovered regions by adversarial erasing, an online prohibitive segmentation learning approach is developed to collaborate with adversarial erasing by providing auxiliary segmentation supervision modulated by the more reliable classification scores. Despite its apparent simplicity, the proposed approach achieves 55.0% and 55.7% mean Intersection-over-Union (mIoU) scores on PASCAL VOC 2012 val and test sets, which are the new state-of-the-arts.",
        "A1": "We investigate a principle way to progressively mine discriminative object regions using classification networks to address the weakly-supervised semantic segmentation problems. ",
        "A2": " Classification networks are only responsive to small and sparse discriminative regions from the object of interest, which deviates from the requirement of the segmentation task that needs to localize dense, interior and integral regions for pixel-wise inference.",
        "A41": "a new adversarial erasing approach",
        "A51": "",
        "A61": " Starting with a single small object region, our proposed approach drives the classification network to sequentially discover new and complement object regions by erasing the current mined regions in an adversarial manner.",
        "A10": "Despite its apparent simplicity, the proposed approach achieves 55.0% and 55.7% mean Intersection-over-Union (mIoU) scores on PASCAL VOC 2012 val and test sets, which are the new state-of-the-arts.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " PASCAL VOC 2012 val and test sets",
        "am_id": 273734682
    },
    {
        "Abstract": "Recently, plugging trainable structural layers into deep convolutional neural networks (CNNs) as image representations has made promising progress. However, there has been little work on inserting parametric probability distributions, which can effectively model feature statistics, into deep CNNs in an end-to-end manner. This paper proposes a Global Gaussian Distribution embedding Network (G<sup>2</sup>DeNet) to take a step towards addressing this problem. The core of G<sup>2</sup>DeNet is a novel trainable layer of a global Gaussian as an image representation plugged into deep CNNs for end-to-end learning. The challenge is that the proposed layer involves Gaussian distributions whose space is not a linear space, which makes its forward and backward propagations be non-intuitive and non-trivial. To tackle this issue, we employ a Gaussian embedding strategy which respects the structures of both Riemannian manifold and smooth group of Gaussians. Based on this strategy, we construct the proposed global Gaussian embedding layer and decompose it into two sub-layers: the matrix partition sub-layer decoupling the mean vector and covariance matrix entangled in the embedding matrix, and the square-rooted, symmetric positive definite matrix sub-layer. In this way, we can derive the partial derivatives associated with the proposed structural layer and thus allow backpropagation of gradients. Experimental results on large scale region classification and fine-grained recognition tasks show that G2DeNet is superior to its counterparts, capable of achieving state-of-the-art performance.",
        "A1": " to take a step towards addressing this problem",
        "A2": "inserting parametric probability distributions",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Experimental results on large scale region classification and fine-grained recognition tasks show that G2DeNet is superior to its counterparts, capable of achieving state-of-the-art performance.",
        "A7": "large scale region classification and fine-grained recognition ",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "G2DeNet",
        "A45": "",
        "am_id": 200518887
    },
    {
        "Abstract": "Learning based methods have shown very promising results for the task of depth estimation in single images. However, most existing approaches treat depth prediction as a supervised regression problem and as a result, require vast quantities of corresponding ground truth depth data for training. Just recording quality depth data in a range of environments is a challenging problem. In this paper, we innovate beyond existing approaches, replacing the use of explicit depth data during training with easier-to-obtain binocular stereo footage. We propose a novel training objective that enables our convolutional neural network to learn to perform single image depth estimation, despite the absence of ground truth depth data. Ex-ploiting epipolar geometry constraints, we generate disparity images by training our network with an image reconstruction loss. We show that solving for image reconstruction alone results in poor quality depth images. To overcome this problem, we propose a novel training loss that enforces consistency between the disparities produced relative to both the left and right images, leading to improved performance and robustness compared to existing approaches. Our method produces state of the art results for monocular depth estimation on the KITTI driving dataset, even outperforming supervised methods that have been trained with ground truth depth.",
        "A1": " innovate beyond existing approaches, replacing the use of explicit depth data during training with easier-to-obtain binocular stereo footage",
        "A2": " Just recording quality depth data in a range of environments ",
        "A41": "a novel training loss that enforces consistency between the disparities produced relative to both the left and right images, ",
        "A51": "",
        "A61": " leading to improved performance and robustness compared to existing approaches",
        "A10": " even outperforming supervised methods that have been trained with ground truth depth.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " Our method produces state of the art results for monocular depth estimation on the KITTI driving dataset, ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 175947568
    },
    {
        "Abstract": "Superpixel segmentation of 2D image has been widely used in many computer vision tasks. However, limited to the Gaussian imaging principle, there is not a thorough segmentation solution to the ambiguity in defocus and occlusion boundary areas. In this paper, we consider the essential element of image pixel, i.e., rays in the light space and propose light field superpixel (LFSP) segmentation to eliminate the ambiguity. The LFSP is first defined mathematically and then a refocus-invariant metric named LFSP self-similarity is proposed to evaluate the segmentation performance. By building a clique system containing 80 neighbors in light field, a robust refocus-invariant LFSP segmentation algorithm is developed. Experimental results on both synthetic and real light field datasets demonstrate the advantages over the state-of-the-arts in terms of traditional evaluation metrics. Additionally the LFSP self-similarity evaluation under different light field refocus levels shows the refocus-invariance of the proposed algorithm.",
        "A1": "we consider the essential element of image pixel, i.e., rays in the light space and propose light field superpixel (LFSP) segmentation to eliminate the ambiguity.",
        "A2": "limited to the Gaussian imaging principle, there is not a thorough segmentation solution to the ambiguity in defocus and occlusion boundary areas.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Experimental results on both synthetic and real light field datasets demonstrate the advantages over the state-of-the-arts in terms of traditional evaluation metrics.",
        "A83": "",
        "A82": "Experimental results on both synthetic and real light field datasets demonstrate the advantages over the state-of-the-arts in terms of traditional evaluation metrics. ",
        "A81": "Additionally the LFSP self-similarity evaluation under different light field refocus levels shows the refocus-invariance of the proposed algorithm.",
        "A64": " By building a clique system containing 80 neighbors in light field, a robust refocus-invariant LFSP segmentation algorithm is developed. ",
        "A54": "",
        "A44": "is proposed to evaluate the segmentation performance.",
        "A63": " In this paper, we consider the essential element of image pixel, i.e., rays in the light space and propose light field superpixel (LFSP) segmentation to eliminate the ambiguity.",
        "A53": "",
        "A43": "By building a clique system containing 80 neighbors in light field, a robust refocus-invariant LFSP segmentation algorithm is developed.",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 133520961
    },
    {
        "Abstract": "Visible watermarking is a widely-used technique for marking and protecting copyrights of many millions of images on the web, yet it suffers from an inherent security flaw-watermarks are typically added in a consistent manner to many images. We show that this consistency allows to automatically estimate the watermark and recover the original images with high accuracy. Specifically, we present a generalized multi-image matting algorithm that takes a watermarked image collection as input and automatically estimates the foreground (watermark), its alpha matte, and the background (original) images. Since such an attack relies on the consistency of watermarks across image collection, we explore and evaluate how it is affected by various types of inconsistencies in the watermark embedding that could potentially be used to make watermarking more secured. We demonstrate the algorithm on stock imagery available on the web, and provide extensive quantitative analysis on synthetic watermarked data. A key takeaway message of this paper is that visible watermarks should be designed to not only be robust against removal from a single image, but to be more resistant to mass-scale removal from image collections as well.",
        "A1": "show that this consistency allows to automatically estimate the watermark and recover the original images with high accuracy",
        "A2": "Visible watermarking is a widely-used technique for marking and protecting copyrights of many millions of images on the web, yet it suffers from an inherent security flaw-watermarks are typically added in a consistent manner to many images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We demonstrate the algorithm on stock imagery available on the web, and provide extensive quantitative analysis on synthetic watermarked data.",
        "A83": "",
        "A82": "",
        "A81": "visible watermarks should be designed to not only be robust against removal from a single image, but to be more resistant to mass-scale removal from image collections as well",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "the consistency of watermarks across image collection",
        "A43": "a generalized multi-image matting algorithm that takes a watermarked image collection as input and automatically estimates the foreground (watermark), its alpha matte, and the background (original) images",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 77172381
    },
    {
        "Abstract": "This paper presents the first snapshot hyperspectral light field imager in practice. Specifically, we design a novel hybrid camera system to obtain two complementary measurements that sample the angular and spectral dimensions respectively. To recover the full 5D hyperspectral light field from the severely undersampled measurements, we then propose an efficient computational reconstruction algorithm by exploiting the large correlations across the angular and spectral dimensions through self-learned dictionaries. Simulation on an elaborate hyperspectral light field dataset validates the effectiveness of the proposed approach. Hardware experimental results demonstrate that, for the first time to our knowledge, a 5D hyperspectral light field containing 9x9 angular views and 27 spectral bands can be acquired in a single shot.",
        "A1": "presents the first snapshot hyperspectral light field imager in practice.",
        "A2": "recover the full 5D hyperspectral light field",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Simulation on an elaborate hyperspectral light field dataset",
        "A83": "",
        "A82": " for the first time to our knowledge, a 5D hyperspectral light field containing 9x9 angular views and 27 spectral bands can be acquired in a single shot.",
        "A81": "validates the effectiveness of the proposed approach",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "efficient computational reconstruction algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 1700244
    },
    {
        "Abstract": "Semantic image inpainting is a challenging task where large missing regions have to be filled based on the available visual data. Existing methods which extract information from only a single image generally produce unsatisfactory results due to the lack of high level context. In this paper, we propose a novel method for semantic image inpainting, which generates the missing content by conditioning on the available data. Given a trained generative model, we search for the closest encoding of the corrupted image in the latent image manifold using our context and prior losses. This encoding is then passed through the generative model to infer the missing content. In our method, inference is possible irrespective of how the missing content is structured, while the state-of-the-art learning based method requires specific information about the holes in the training phase. Experiments on three datasets show that our method successfully predicts information in large missing regions and achieves pixel-level photorealism, significantly outperforming the state-of-the-art methods.",
        "A1": "",
        "A2": "Semantic image inpainting",
        "A41": "generates the missing content by conditioning on the available data",
        "A51": "generative model",
        "A61": "inference is possible irrespective of how the missing content is structured",
        "A10": "",
        "A7": "Experiments on three datasets",
        "A83": "",
        "A82": "successfully predicts information in large missing regions",
        "A81": "achieves pixel-level photorealism",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 238488658
    },
    {
        "Abstract": "We show that the matching problem that underlies optical flow requires multiple strategies, depending on the amount of image motion and other factors. We then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. This type of training produces a network that displays multiple strategies depending on the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks.",
        "A1": "We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. ",
        "A2": "",
        "A41": ". We propose a metric learning method, which selects suitable negative samples based on the nature of the true match.",
        "A51": "the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks.",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "e propose a metric learning method, which selects suitable negative samples based on the nature of the true match. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 175122409
    },
    {
        "Abstract": "We present a generative attribute controller (GAC), a novel functionality for generating or editing an image while intuitively controlling large variations of an attribute. This controller is based on a novel generative model called the conditional filtered generative adversarial network (CFGAN), which is an extension of the conventional conditional GAN (CGAN) that incorporates a filtering architecture into the generator input. Unlike the conventional CGAN, which represents an attribute directly using an observable variable (e.g., the binary indicator of attribute presence) so its controllability is restricted to attribute labeling (e.g., restricted to an ON or OFF control), the CFGAN has a filtering architecture that associates an attribute with a multi-dimensional latent variable, enabling latent variations of the attribute to be represented. We also define the filtering architecture and training scheme considering controllability, enabling the variations of the attribute to be intuitively controlled using typical controllers (radio buttons and slide bars). We evaluated our CFGAN on MNIST, CUB, and CelebA datasets and show that it enables large variations of an attribute to be not only represented but also intuitively controlled while retaining identity. We also show that the learned latent space has enough expressive power to conduct attribute transfer and attribute-based image retrieval.",
        "A1": "generating or editing an image while intuitively controlling large variations of an attribute.",
        "A2": "generating or editing an image while intuitively controlling large variations of an attribute.",
        "A41": "a generative attribute controller (GAC)",
        "A51": "a novel generative model called the conditional filtered generative adversarial network (CFGAN)",
        "A61": "Unlike the conventional CGAN, which represents an attribute directly using an observable variable (e.g., the binary indicator of attribute presence) so its controllability is restricted to attribute labeling (e.g., restricted to an ON or OFF control), the CFGAN has a filtering architecture that associates an attribute with a multi-dimensional latent variable, enabling latent variations of the attribute to be represented. ",
        "A10": "We evaluated our CFGAN on MNIST, CUB, and CelebA datasets and show that it enables large variations of an attribute to be not only represented but also intuitively controlled while retaining identity. We also show that the learned latent space has enough expressive power to conduct attribute transfer and attribute-based image retrieval.",
        "A7": "We evaluated our CFGAN on MNIST, CUB, and CelebA datasets and show that it enables large variations of an attribute to be not only represented but also intuitively controlled while retaining identity. ",
        "A83": "We also show that the learned latent space has enough expressive power to conduct attribute transfer and attribute-based image retrieval.",
        "A82": "We evaluated our CFGAN on MNIST, CUB, and CelebA datasets and show that it enables large variations of an attribute to be not only represented but also intuitively controlled while retaining identity.",
        "A81": " We also define the filtering architecture and training scheme considering controllability, enabling the variations of the attribute to be intuitively controlled using typical controllers (radio buttons and slide bars).",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 260460799
    },
    {
        "Abstract": "In this paper, we address a haze removal problem from a single nighttime image, even in the presence of varicolored and non-uniform illumination. The core idea lies in a novel maximum reflectance prior. We first introduce the nighttime hazy imaging model, which includes a local ambient illumination item in both direct attenuation term and scattering term. Then, we propose a simple but effective image prior, maximum reflectance prior, to estimate the varying ambient illumination. The maximum reflectance prior is based on a key observation: for most daytime haze-free image patches, each color channel has very high intensity at some pixels. For the nighttime haze image, the local maximum intensities at each color channel are mainly contributed by the ambient illumination. Therefore, we can directly estimate the ambient illumination and transmission map, and consequently restore a high quality haze-free image. Experimental results on various nighttime hazy images demonstrate the effectiveness of the proposed approach. In particular, our approach has the advantage of computational efficiency, which is 10-100 times faster than state-of-the-art methods.",
        "A1": "haze removal problem from a single nighttime image",
        "A2": "in the presence of varicolored and non-uniform illumination",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "10-100 times faster than state-of-the-art methods",
        "A7": "Experimental results on various nighttime hazy images ",
        "A83": "",
        "A82": "",
        "A81": "computational efficiency, which is 10-100 times faster than state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "a key observation: for most daytime haze-free image patches, each color channel has very high intensity at some pixels",
        "A42": "the nighttime hazy imaging model, which includes a local ambient illumination item in both direct attenuation term and scattering term",
        "A45": "",
        "am_id": 17266968
    },
    {
        "Abstract": "We introduce a novel technique for knowledge transfer, where knowledge from a pretrained deep neural network (DNN) is distilled and transferred to another DNN. As the DNN performs a mapping from the input space to the output space through many layers sequentially, we define the distilled knowledge to be transferred in terms of flow between layers, which is calculated by computing the inner product between features from two layers. When we compare the student DNN and the original network with the same size as the student DNN but trained without a teacher network, the proposed method of transferring the distilled knowledge as the flow between two layers exhibits three important phenomena: (1) the student DNN that learns the distilled knowledge is optimized much faster than the original model, (2) the student DNN outperforms the original DNN, and (3) the student DNN can learn the distilled knowledge from a teacher DNN that is trained at a different task, and the student DNN outperforms the original DNN that is trained from scratch.",
        "A1": " knowledge transfer",
        "A2": "",
        "A41": "a novel technique for knowledge transfer",
        "A51": "deep neural network (DNN) ",
        "A61": "",
        "A10": "the student DNN outperforms the original DNN",
        "A7": "",
        "A83": "the student DNN can learn the distilled knowledge from a teacher DNN that is trained at a different task",
        "A82": "the student DNN outperforms the original DNN",
        "A81": " the student DNN that learns the distilled knowledge is optimized much faster than the original model",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 324235672
    },
    {
        "Abstract": "Translating or rotating an input image should not affect the results of many computer vision tasks. Convolutional neural networks (CNNs) are already translation equivariant: input image translations produce proportionate feature map translations. This is not the case for rotations. Global rotation equivariance is typically sought through data augmentation, but patch-wise equivariance is more difficult. We present Harmonic Networks or H-Nets, a CNN exhibiting equivariance to patch-wise translation and 360-rotation. We achieve this by replacing regular CNN filters with circular harmonics, returning a maximal response and orientation for every receptive field patch. H-Nets use a rich, parameter-efficient and fixed computational complexity representation, and we show that deep feature maps within the network encode complicated rotational invariants. We demonstrate that our layers are general enough to be used in conjunction with the latest architectures and techniques, such as deep supervision and batch normalization. We also achieve state-of-the-art classification on rotated-MNIST, and competitive results on other benchmark challenges.",
        "A1": "We present Harmonic Networks or H-Nets, a CNN exhibiting equivariance to patch-wise translation and 360-rotation",
        "A2": "Convolutional neural networks (CNNs) are already translation equivariant: input image translations produce proportionate feature map translations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "We also achieve state-of-the-art classification on rotated-MNIST, and competitive results on other benchmark challenges.",
        "A7": " We achieve this by replacing regular CNN filters with circular harmonics, returning a maximal response and orientation for every receptive field patch",
        "A83": "",
        "A82": "our layers are general enough to be used in conjunction with the latest architectures and techniques",
        "A81": "deep feature maps within the network encode complicated rotational invariants",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 181367986
    },
    {
        "Abstract": "We propose the residual expansion (RE) algorithm: a global (or near-global) optimization method for nonconvex least squares problems. Unlike most existing nonconvex optimization techniques, the RE algorithm is not based on either stochastic or multi-point searches, therefore, it can achieve fast global optimization. Moreover, the RE algorithm is easy to implement and successful in high-dimensional optimization. The RE algorithm exhibits excellent empirical performance in terms of k-means clustering, point-set registration, optimized product quantization, and blind image deblurring.",
        "A1": "propose the residual expansion (RE) algorithm",
        "A2": "nonconvex least squares problems",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "nonconvex least squares problems",
        "A83": "exhibits excellent empirical performance in terms of k-means clustering, point-set registration, optimized product quantization, and blind image deblurring",
        "A82": "easy to implement and successful in high-dimensional optimization",
        "A81": "it can achieve fast global optimization",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "the RE algorithm is not based on either stochastic or multi-point searches",
        "A53": "",
        "A43": "the residual expansion (RE) algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 220918100
    },
    {
        "Abstract": "Effective image and sentence matching depends on how to well measure their global visual-semantic similarity. Based on the observation that such a global similarity arises from a complex aggregation of multiple local similarities between pairwise instances of image (objects) and sentence (words), we propose a selective multimodal Long Short-Term Memory network (sm-LSTM) for instance-aware image and sentence matching. The sm-LSTM includes a multimodal context-modulated attention scheme at each timestep that can selectively attend to a pair of instances of image and sentence, by predicting pairwise instance-aware saliency maps for image and sentence. For selected pairwise instances, their representations are obtained based on the predicted saliency maps, and then compared to measure their local similarity. By similarly measuring multiple local similarities within a few timesteps, the sm-LSTM sequentially aggregates them with hidden states to obtain a final matching score as the desired global similarity. Extensive experiments show that our model can well match image and sentence with complex content, and achieve the state-of-the-art results on two public benchmark datasets.",
        "A1": "we propose a selective multimodal Long Short-Term Memory network (sm-LSTM)",
        "A2": "that can selectively attend to a pair of instances of image and sentence, by predicting pairwise instance-aware saliency maps for image and sentence.",
        "A41": " a selective multimodal Long Short-Term Memory network (sm-LSTM) ",
        "A51": "that can selectively attend to a pair of instances of image and sentence, by predicting pairwise instance-aware saliency maps for image and sentence. ",
        "A61": "",
        "A10": " Extensive experiments show that our model can well match image and sentence with complex content, and achieve the state-of-the-art results on two public benchmark datasets.",
        "A7": "Extensive experiments ",
        "A83": "",
        "A82": "and achieve the state-of-the-art results on two public benchmark datasets.",
        "A81": "our model can well match image and sentence with complex content",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 425684849
    },
    {
        "Abstract": "Current CNN based object detectors need initialization from pre-trained ImageNet classification models, which are usually time-consuming. In this paper, we present a fully convolutional feature mimic framework to train very efficient CNN based detectors, which do not need ImageNet pre-training and achieve competitive performance as the large and slow models. We add supervision from high-level features of the large networks in training to help the small network better learn object representation. More specifically, we conduct a mimic method for the features sampled from the entire feature map and use a transform layer to map features from the small network onto the same dimension of the large network. In training the small network, we optimize the similarity between features sampled from the same region on the feature maps of both networks. Extensive experiments are conducted on pedestrian and common object detection tasks using VGG, Inception and ResNet. On both Caltech and Pascal VOC, we show that the modified 2.5\u00d7 accelerated Inception network achieves competitive performance as the full Inception Network. Our faster model runs at 80 FPS for a 1000\u00d71500 large input with only a minor degradation of performance on Caltech.",
        "A1": "train very efficient CNN based detectors",
        "A2": "Current CNN based object detectors need initialization from pre-trained ImageNet classification models, which are usually time-consuming",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "achieves competitive performance as the full Inception Network",
        "A7": " Extensive experiments are conducted on pedestrian and common object detection tasks using VGG, Inception and ResNet",
        "A83": "",
        "A82": "Our faster model runs at 80 FPS for a 1000\u00d71500 large input",
        "A81": "the modified 2.5\u00d7 accelerated Inception network achieves competitive performance as the full Inception Network",
        "A64": "conduct a mimic method for the features sampled from the entire feature map",
        "A54": "CNN",
        "A44": " add supervision from high-level features of the large networks in training to help the small network better learn object representation",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 463183122
    },
    {
        "Abstract": "This paper strives to track a target object in a video. Rather than specifying the target in the first frame of a video by a bounding box, we propose to track the object based on a natural language specification of the target, which provides a more natural human-machine interaction as well as a means to improve tracking results. We define three variants of tracking by language specification: one relying on lingual target specification only, one relying on visual target specification based on language, and one leveraging their joint capacity. To show the potential of tracking by natural language specification we extend two popular tracking datasets with lingual descriptions and report experiments. Finally, we also sketch new tracking scenarios in surveillance and other live video streams that become feasible with a lingual specification of the target.",
        "A1": "This paper strives to track a target object in a video. ",
        "A2": "",
        "A41": "rack the object based on a natural language specification of the target",
        "A51": "",
        "A61": "specifying the target in the first frame of a video by a bounding box",
        "A10": "provides a more natural human-machine interaction as well as a means to improve tracking results",
        "A7": "we extend two popular tracking datasets with lingual descriptions and report experiments",
        "A83": "provides a more natural human-machine interaction as well as a means to improve tracking results",
        "A82": "other live video streams that become feasible with a lingual specification of the target.",
        "A81": "new tracking scenarios in surveillance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "two popular tracking datasets",
        "am_id": 68193101
    },
    {
        "Abstract": "Recently, there has been a lot of interest in automatically generating descriptions for an image. Most existing language-model based approaches for this task learn to generate an image description word by word in its original word order. However, for humans, it is more natural to locate the objects and their relationships first, and then elaborate on each object, describing notable attributes. We present a coarse-to-fine method that decomposes the original image description into a skeleton sentence and its attributes, and generates the skeleton sentence and attribute phrases separately. By this decomposition, our method can generate more accurate and novel descriptions than the previous state-of-the-art. Experimental results on the MS-COCO and a larger scale Stock3M datasets show that our algorithm yields consistent improvements across different evaluation metrics, especially on the SPICE metric, which has much higher correlation with human ratings than the conventional metrics. Furthermore, our algorithm can generate descriptions with varied length, benefiting from the separate control of the skeleton and attributes. This enables image description generation that better accommodates user preferences.",
        "A1": "We present a coarse-to-fine method that decomposes the original image description into a skeleton sentence and its attributes, and generates the skeleton sentence and attribute phrases separately",
        "A2": "",
        "A41": "decomposes the original image description into a skeleton sentence and its attributes, and generates the skeleton sentence and attribute phrases separately",
        "A51": "coarse-to-fine",
        "A61": "",
        "A10": "",
        "A7": " the MS-COCO and a larger scale Stock3M datasets",
        "A83": "",
        "A82": "our algorithm can generate descriptions with varied length",
        "A81": "our algorithm yields consistent improvements across different evaluation metrics",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 230881143
    },
    {
        "Abstract": "This paper combines three contributions to establish a new state-of-the-art in dynamic scene recognition. First, we present a novel ConvNet architecture based on temporal residual units that is fully convolutional in spacetime. Our model augments spatial ResNets with convolutions across time to hierarchically add temporal residuals as the depth of the network increases. Second, existing approaches to video-based recognition are categorized and a baseline of seven previously top performing algorithms is selected for comparative evaluation on dynamic scenes. Third, we introduce a new and challenging video database of dynamic scenes that more than doubles the size of those previously available. This dataset is explicitly split into two subsets of equal size that contain videos with and without camera motion to allow for systematic study of how this variable interacts with the defining dynamics of the scene per se. Our evaluations verify the particular strengths and weaknesses of the baseline algorithms with respect to various scene classes and camera motion parameters. Finally, our temporal ResNet boosts recognition performance and establishes a new state-of-the-art on dynamic scene recognition, as well as on the complementary task of action recognition.",
        "A1": "This paper combines three contributions to establish a new state-of-the-art in dynamic scene recognition.",
        "A2": "to establish a new state-of-the-art in dynamic scene recognition",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "boosts recognition performance and establishes a new state-of-the-art on dynamic scene recognition, as well as on the complementary task of action recognition.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "temporal residual units that is fully convolutional in spacetime.",
        "A42": "augments spatial ResNets with convolutions across time to hierarchically add temporal residuals as the depth of the network increases",
        "A45": "explicitly split into two subsets of equal size that contain videos with and without camera motion to allow for systematic study of how this variable interacts with the defining dynamics of the scene per se",
        "am_id": 3694874
    },
    {
        "Abstract": "Understanding the simultaneously very diverse and intricately fine-grained set of possible human actions is a critical open problem in computer vision. Manually labeling training videos is feasible for some action classes but doesnt scale to the full long-tailed distribution of actions. A promising way to address this is to leverage noisy data from web queries to learn new actions, using semi-supervised or webly-supervised approaches. However, these methods typically do not learn domain-specific knowledge, or rely on iterative hand-tuned data labeling policies. In this work, we instead propose a reinforcement learning-based formulation for selecting the right examples for training a classifier from noisy web search results. Our method uses Q-learning to learn a data labeling policy on a small labeled training dataset, and then uses this to automatically label noisy web data for new visual concepts. Experiments on the challenging Sports-1M action recognition benchmark as well as on additional fine-grained and newly emerging action classes demonstrate that our method is able to learn good labeling policies for noisy data and use this to learn accurate visual concept classifiers.",
        "A1": "propose a reinforcement learning-based formulation for selecting the right examples for training a classifier from noisy web search results",
        "A2": "Understanding the simultaneously very diverse and intricately fine-grained set of possible human actions",
        "A41": "method uses Q-learning to learn a data labeling policy on a small labeled training dataset, and then uses this to automatically label noisy web data for new visual concepts",
        "A51": "Q-learning ",
        "A61": "",
        "A10": "",
        "A7": "Experiments on the challenging Sports-1M action recognition benchmark as well as on additional fine-grained and newly emerging action classes",
        "A83": "",
        "A82": "",
        "A81": "our method is able to learn good labeling policies for noisy data and use this to learn accurate visual concept classifiers",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 132456170
    },
    {
        "Abstract": "Time-of-flight depth imaging and transient imaging are two imaging modalities that have recently received a lot of interest. Despite much research, existing hardware systems are limited either in terms of temporal resolution or are prohibitively expensive. Arrays of Single Photon Avalanche Diodes (SPADs) promise to fill this gap by providing higher temporal resolution at an affordable cost. Unfortunately SPAD arrays are to date only available in relatively small resolutions. In this work we aim to overcome the spatial resolution limit of SPAD arrays by employing a compressive sensing camera design. Using a DMD and custom optics, we achieve an image resolution of up to 800\u00c3\u2014400 on SPAD Arrays of resolution 64\u00c3\u201432. Using our new data fitting model for the time histograms, we suppress the noise while abstracting the phase and amplitude information, so as to realize a temporal resolution of a few tens of picoseconds.",
        "A1": "overcome the spatial resolution limit of SPAD arrays by employing a compressive sensing camera design.",
        "A2": "he spatial resolution limit of SPAD arrays by employing a compressive sensing camera design",
        "A41": "",
        "A51": "DMD and custom optics",
        "A61": "xisting hardware systems are limited either in terms of temporal resolution or are prohibitively expensive",
        "A10": "existing hardware systems are limited either in terms of temporal resolution or are prohibitively expensive.",
        "A7": "",
        "A83": "",
        "A82": "achieve an image resolution of up to 800\u00c3\u2014400 on SPAD Arrays of resolution 64\u00c3\u201432",
        "A81": "realize a temporal resolution of a few tens of picoseconds.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 80620201
    },
    {
        "Abstract": "The goal of this paper is to take a single 2D image of a scene and recover the 3D structure in terms of a small set of factors: a layout representing the enclosing surfaces as well as a set of objects represented in terms of shape and pose. We propose a convolutional neural network-based approach to predict this representation and benchmark it on a large dataset of indoor scenes. Our experiments evaluate a number of practical design questions, demonstrate that we can infer this representation, and quantitatively and qualitatively demonstrate its merits compared to alternate representations.",
        "A1": " to take a single 2D image of a scene and recover the 3D structure in terms of a small set of factors",
        "A2": "",
        "A41": "a convolutional neural network-based approach to predict this representation and benchmark it ",
        "A51": "a large dataset of indoor scenes",
        "A61": "",
        "A10": "",
        "A7": "Our experiments evaluate a number of practical design questions",
        "A83": "",
        "A82": "quantitatively and qualitatively demonstrate its merits compared to alternate representations.",
        "A81": " we can infer this representation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 149893194
    },
    {
        "Abstract": "We propose a deep learning algorithm for single-image depth estimation based on the Fourier frequency domain analysis. First, we develop a convolutional neural network structure and propose a new loss function, called depth-balanced Euclidean loss, to train the network reliably for a wide range of depths. Then, we generate multiple depth map candidates by cropping input images with various cropping ratios. In general, a cropped image with a small ratio yields depth details more faithfully, while that with a large ratio provides the overall depth distribution more reliably. To take advantage of these complementary properties, we combine the multiple candidates in the frequency domain. Experimental results demonstrate that proposed algorithm provides the state-of-art performance. Furthermore, through the frequency domain analysis, we validate the efficacy of the proposed algorithm in most frequency bands.",
        "A1": " propose a deep learning algorithm for single-image depth estimation",
        "A2": " single-image depth estimation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "validate the efficacy of the proposed algorithm in most frequency bands",
        "A7": " frequency domain analysis",
        "A83": "",
        "A82": "",
        "A81": "validate the efficacy of the proposed algorithm in most frequency bands",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": " generate multiple depth map candidates by cropping input images with various cropping ratios",
        "A53": "convolutional neural network",
        "A43": "a deep learning algorithm for single-image depth estimation based on the Fourier frequency domain analysis",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 498746963
    },
    {
        "Abstract": "Person re-identification is a challenging retrieval task that requires matching a person's acquired image across non-overlapping camera views. In this paper we propose an effective approach that incorporates both the fine and coarse pose information of the person to learn a discriminative embedding. In contrast to the recent direction of explicitly modeling body parts or correcting for misalignment based on these, we show that a rather straightforward inclusion of acquired camera view and/or the detected joint locations into a convolutional neural network helps to learn a very effective representation. To increase retrieval performance, re-ranking techniques based on computed distances have recently gained much attention. We propose a new unsupervised and automatic re-ranking framework that achieves state-of-the-art re-ranking performance. We show that in contrast to the current state-of-the-art re-ranking methods our approach does not require to compute new rank lists for each image pair (e.g., based on reciprocal neighbors) and performs well by using simple direct rank list based comparison or even by just using the already computed euclidean distances between the images. We show that both our learned representation and our re-ranking method achieve state-of-the-art performance on a number of challenging surveillance image and video datasets. Code is available at https://github.com/pse-ecn.",
        "A1": "Person re-identification",
        "A2": "learn a very effective representation",
        "A41": "an effective approach that incorporates both the fine and coarse pose information of the person to learn a discriminative embedding",
        "A51": "computed distances",
        "A61": "",
        "A10": "",
        "A7": "e show that in contrast to the current state-of-the-art re-ranking methods our approach does not require to compute new rank lists for each image pair (e.g., based on reciprocal neighbors) and performs well by using simple direct rank list based comparison or even by just using the already computed euclidean distances between the images",
        "A83": "",
        "A82": " We show that both our learned representation and our re-ranking method achieve state-of-the-art performance on a number of challenging surveillance image and video datasets",
        "A81": "We show that in contrast to the current state-of-the-art re-ranking methods our approach does not require to compute new rank lists for each image pair (e.g., based on reciprocal neighbors) and performs well by using simple direct rank list based comparison or even by just using the already computed euclidean distances between the images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 86327100
    },
    {
        "Abstract": "This work addresses the problem of estimating the full body 3D human pose and shape from a single color image. This is a task where iterative optimization-based solutions have typically prevailed, while Convolutional Networks (ConvNets) have suffered because of the lack of training data and their low resolution 3D predictions. Our work aims to bridge this gap and proposes an efficient and effective direct prediction method based on ConvNets. Central part to our approach is the incorporation of a parametric statistical body shape model (SMPL) within our end-to-end framework. This allows us to get very detailed 3D mesh results, while requiring estimation only of a small number of parameters, making it friendly for direct network prediction. Interestingly, we demonstrate that these parameters can be predicted reliably only from 2D keypoints and masks. These are typical outputs of generic 2D human analysis ConvNets, allowing us to relax the massive requirement that images with 3D shape ground truth are available for training. Simultaneously, by maintaining differentiability, at training time we generate the 3D mesh from the estimated parameters and optimize explicitly for the surface using a 3D per-vertex loss. Finally, a differentiable renderer is employed to project the 3D mesh to the image, which enables further refinement of the network, by optimizing for the consistency of the projection with 2D annotations (i.e., 2D keypoints or masks). The proposed approach outperforms previous baselines on this task and offers an attractive solution for direct prediction of3D shape from a single color image.",
        "A1": "This work addresses the problem of estimating the full body 3D human pose and shape from a single color image. ",
        "A2": "This work addresses the problem of estimating the full body 3D human pose and shape from a single color image. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " The proposed approach outperforms previous baselines on this task and offers an attractive solution for direct prediction of3D shape from a single color image.",
        "A52": " Our work aims to bridge this gap and proposes an efficient and effective direct prediction method based on ConvNets",
        "A42": "Central part to our approach is the incorporation of a parametric statistical body shape model (SMPL) within our end-to-end framework. ",
        "A45": "",
        "am_id": 163259382
    },
    {
        "Abstract": "Interactive image segmentation is characterized by multimodality. When the user clicks on a door, do they intend to select the door or the whole house? We present an end-to-end learning approach to interactive image segmentation that tackles this ambiguity. Our architecture couples two convolutional networks. The first is trained to synthesize a diverse set of plausible segmentations that conform to the user's input. The second is trained to select among these. By selecting a single solution, our approach retains compatibility with existing interactive segmentation interfaces. By synthesizing multiple diverse solutions before selecting one, the architecture is given the representational power to explore the multimodal solution space. We show that the proposed approach outperforms existing methods for interactive image segmentation, including prior work that applied convolutional networks to this problem, while being much faster.",
        "A1": "We present an end-to-end learning approach to interactive image segmentation that tackles this ambiguity.",
        "A2": "Interactive image segmentation is characterized by multimodality.",
        "A41": "an end-to-end learning approach to interactive image segmentation that tackles this ambiguity",
        "A51": "two convolutional networks. The first is trained to synthesize a diverse set of plausible segmentations that conform to the user's input. The second is trained to select among these.",
        "A61": "the proposed approach outperforms existing methods for interactive image segmentation, including prior work that applied convolutional networks to this problem, while being much faster.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 228494407
    },
    {
        "Abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called \"perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",
        "A1": " To answer these questions,",
        "A2": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. ",
        "A83": "perceptual similarity is an emergent property shared across deep visual representations.",
        "A82": " this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised).",
        "A81": "We find that deep features outperform all previous metrics by large margins on our dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "we introduce a new dataset of human perceptual similarity judgments.",
        "am_id": 305134116
    },
    {
        "Abstract": "Extraction of local feature descriptors is a vital stage in the solution pipelines for numerous computer vision tasks. Learning-based approaches improve performance in certain tasks, but still cannot replace handcrafted features in general. In this paper, we improve the learning of local feature descriptors by optimizing the performance of descriptor matching, which is a common stage that follows descriptor extraction in local feature based pipelines, and can be formulated as nearest neighbor retrieval. Specifically, we directly optimize a ranking-based retrieval performance metric, Average Precision, using deep neural networks. This general-purpose solution can also be viewed as a listwise learning to rank approach, which is advantageous compared to recent local ranking approaches. On standard benchmarks, descriptors learned with our formulation achieve state-of-the-art results in patch verification, patch retrieval, and image matching,",
        "A1": " improve the learning of local feature descriptors",
        "A2": "Learning-based approaches improve performance in certain tasks, but still cannot replace handcrafted features in general",
        "A41": "This general-purpose solution can also be viewed as a listwise learning to rank approach",
        "A51": "follows descriptor extraction in local feature based pipelines",
        "A61": "improve the learning of local feature descriptors by optimizing the performance of descriptor matching",
        "A10": "achieve state-of-the-art results",
        "A7": "patch verification, patch retrieval, and image matching",
        "A83": "",
        "A82": "",
        "A81": "achieve state-of-the-art results",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 156079373
    },
    {
        "Abstract": "This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos. We do so by adding an extra channel to the image in the input of a convolutional neural network (CNN), which contains a Gaussian centered in each of the extreme points. The CNN learns to transform this information into a segmentation of an object that matches those extreme points. We demonstrate the usefulness of this approach for guided segmentation (grabcut-style), interactive segmentation, video object segmentation, and dense segmentation annotation. We show that we obtain the most precise results to date, also with less user input, in an extensive and varied selection of benchmarks and datasets. All our models and code are publicly available on http://www.vision.ee.ethz.ch/~cvlsegmentation/dextr/.",
        "A1": "This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos",
        "A2": "This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos",
        "A41": "This paper explores the use of extreme points in an object (left-most, right-most, top, bottom pixels) as input to obtain precise object segmentation for images and videos.",
        "A51": "convolutional neural network (CNN)",
        "A61": "We demonstrate the usefulness of this approach for guided segmentation (grabcut-style), interactive segmentation, video object segmentation, and dense segmentation annotation.",
        "A10": "We show that we obtain the most precise results to date, also with less user input",
        "A7": "",
        "A83": "",
        "A82": "with less user input",
        "A81": "we obtain the most precise results to date",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 366838887
    },
    {
        "Abstract": "We address the problem of disentanglement of factors that generate a given data into those that are correlated with the labeling and those that are not. Our solution is simpler than previous solutions and employs adversarial training. First, the part of the data that is correlated with the labels is extracted by training a classifier. Then, the other part is extracted such that it enables the reconstruction of the original data but does not contain label information. The utility of the new method is demonstrated on visual datasets as well as on financial data. Our code is available at https://github.com/naamahadad/A-Two-Step-Disentanglement-Method.",
        "A1": "address the problem of disentanglement of factors that generate a given data into those that are correlated with the labeling and those that are not",
        "A2": "simpler than previous solutions and employs adversarial training",
        "A41": "employs adversarial training",
        "A51": "First, the part of the data that is correlated with the labels is extracted by training a classifier. Then, the other part is extracted such that it enables the reconstruction of the original data but does not contain label information",
        "A61": "simpler than previous solutions",
        "A10": "The utility of the new method is demonstrated on visual datasets as well as on financial data",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 196780568
    },
    {
        "Abstract": "In this work, we study 3D object detection from RGBD data in both indoor and outdoor scenes. While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances of 3D data, we directly operate on raw point clouds by popping up RGB-D scans. However, a key challenge of this approach is how to efficiently localize objects in point clouds of large-scale scenes (region proposal). Instead of solely relying on 3D proposals, our method leverages both mature 2D object detectors and advanced 3D deep learning for object localization, achieving efficiency as well as high recall for even small objects. Benefited from learning directly in raw point clouds, our method is also able to precisely estimate 3D bounding boxes even under strong occlusion or with very sparse points. Evaluated on KITTI and SUN RGB-D 3D detection benchmarks, our method outperforms the state of the art by remarkable margins while having real-time capability.",
        "A1": "we study 3D object detection from RGBD data in both indoor and outdoor scenes",
        "A2": "3D object detection from RGBD data in both indoor and outdoor scenes",
        "A41": "we directly operate on raw point clouds by popping up RGB-D scans",
        "A51": "mature 2D object detectors and advanced 3D deep learning for object localization",
        "A61": "While previous methods focus on images or 3D voxels, often obscuring natural 3D patterns and invariances of 3D data, we directly operate on raw point clouds by popping up RGB-D scans",
        "A10": "our method outperforms the state of the art by remarkable margins while having real-time capability",
        "A7": "valuated on KITTI and SUN RGB-D 3D detection benchmarks",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms the state of the art by remarkable margins while having real-time capability",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 104600256
    },
    {
        "Abstract": "Relative attribute models can compare images in terms of all detected properties or attributes, exhaustively predicting which image is fancier, more natural, and so on without any regard to ordering. However, when humans compare images, certain differences will naturally stick out and come to mind first. These most noticeable differences, or prominent differences, are likely to be described first. In addition, many differences, although present, may not be mentioned at all. In this work, we introduce and model prominent differences, a rich new functionality for comparing images. We collect instance-level annotations of most noticeable differences, and build a model trained on relative attribute features that predicts prominent differences for unseen pairs. We test our model on the challenging UT-Zap50K shoes and LFW10 faces datasets, and outperform an array of baseline methods. We then demonstrate how our prominence model improves two vision tasks, image search and description generation, enabling more natural communication between people and vision systems.",
        "A1": "",
        "A2": "These most noticeable differences, or prominent differences, are likely to be described first. In addition, many differences, although present, may not be mentioned at all. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "outperform an array of baseline methods. ",
        "A7": " test our model on the challenging UT-Zap50K shoes and LFW10 faces datasets",
        "A83": "",
        "A82": "",
        "A81": "how our prominence model improves two vision tasks, image search and description generation, enabling more natural communication between people and vision systems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " relative attribute features",
        "A42": "a model trained on relative attribute features that predicts prominent differences for unseen pairs.",
        "A45": "",
        "am_id": 180132566
    },
    {
        "Abstract": "In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as a single unit, we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. This allows us to flexibly adapt to expressions containing different types of information in an end-to-end framework. In our model, which we call the Modular Attention Network (MAttNet), two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components. Module weights combine scores from all three modules dynamically to output an overall score. Experiments show that MAttNet outperforms previous state-of-the-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks. Demo1 and code2 are provided.",
        "A1": "In this paper, we address referring expression comprehension",
        "A2": " localizing an image region described by a natural language expression",
        "A41": "which we call the Modular Attention Network (MAttNet)",
        "A51": " two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components. Module weights combine scores from all three modules dynamically to output an overall score.",
        "A61": "",
        "A10": " Experiments show that MAttNet outperforms previous state-of-the-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experiments show that MAttNet outperforms previous state-of-the-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "While most recent work treats expressions as a single unit, we propose to decompose them into three modular components",
        "A52": "While most recent work treats expressions as a single unit, we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. ",
        "A42": "(MAttNet)",
        "A45": "",
        "am_id": 293737246
    },
    {
        "Abstract": "Most image captioning models focus on one-line (single image) captioning, where the correlations like relevance and diversity among group images (e.g., within the same album or event) are simply neglected, resulting in less accurate and diverse captions. Recent works mainly consider imposing the diversity during the online inference only, which neglect the correlation among visual structures in offline training. In this paper, we propose a novel group-based image captioning scheme (termed GroupCap), which jointly models the structured relevance and diversity among group images towards an optimal collaborative captioning. In particular, we first propose a visual tree parser (VP-Tree) to construct the structured semantic correlations within individual images. Then, the relevance and diversity among images are well modeled by exploiting the correlations among their tree structures. Finally, such correlations are modeled as constraints and sent into the LSTM-based captioning generator. We adopt an end-to-end formulation to train the visual tree parser, the structured relevance and diversity constraints, as well as the LSTM based captioning model jointly. To facilitate quantitative evaluation, we further release two group captioning datasets derived from the MS-COCO benchmark, serving as the first of their kind. Quantitative results show that the proposed GroupCap model outperforms the state-of-the-art and alternative approaches.",
        "A1": "propose a novel group-based image captioning scheme",
        "A2": "neglect the correlation among visual structures in offline training",
        "A41": "a visual tree parser (VP-Tree) to construct the structured semantic correlations within individual images",
        "A51": " LSTM",
        "A61": "Recent works mainly consider imposing the diversity during the online inference only",
        "A10": "",
        "A7": "further release two group captioning datasets derived from the MS-COCO benchmark",
        "A83": "",
        "A82": "",
        "A81": "the proposed GroupCap model outperforms the state-of-the-art and alternative approaches.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 461839216
    },
    {
        "Abstract": "Localizing text in the wild is challenging in the situations of complicated geometric layout of the targets like random orientation and large aspect ratio. In this paper, we propose a geometry-aware modeling approach tailored for scene text representation with an end-to-end learning scheme. In our approach, a novel Instance Transformation Network (ITN) is presented to learn the geometry-aware representation encoding the unique geometric configurations of scene text instances with in-network transformation embedding, resulting in a robust and elegant framework to detect words or text lines at one pass. An end-to-end multi-task learning strategy with transformation regression, text/non-text classification and coordinates regression is adopted in the ITN. Experiments on the benchmark datasets demonstrate the effectiveness of the proposed approach in detecting scene text in various geometric configurations.",
        "A1": "Localizing text in the wild",
        "A2": " approach tailored for scene text representation with an end-to-end learning scheme",
        "A41": "a geometry-aware modeling approach",
        "A51": " tailored for scene text representation with an end-to-end learning scheme",
        "A61": "",
        "A10": "Experiments on the benchmark datasets demonstrate the effectiveness",
        "A7": " a geometry-aware modeling approach tailored for scene text representation with an end-to-end learning scheme",
        "A83": "",
        "A82": "detect words or text lines at one pass",
        "A81": "detecting scene text in various geometric configurations",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "An end-to-end multi-task learning strategy with transformation regression, text/non-text classification and coordinates regression is adopted",
        "A43": " a novel Instance Transformation Network (ITN) is presented to learn the geometry-aware representation",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "demonstrate the effectiveness of the proposed approach in detecting scene text in various geometric configurations",
        "am_id": 471949319
    },
    {
        "Abstract": "Automatic saliency prediction in 360\u00b0 videos is critical for viewpoint guidance applications (e.g., Facebook 360 Guide). We propose a spatial-temporal network which is (1) weakly-supervised trained and (2) tailor-made for 360\u00b0 viewing sphere. Note that most existing methods are less scalable since they rely on annotated saliency map for training. Most importantly, they convert 360\u00b0 sphere to 2D images (e.g., a single equirectangular image or multiple separate Normal Field-of-View (NFoV) images) which introduces distortion and image boundaries. In contrast, we propose a simple and effective Cube Padding (CP) technique as follows. Firstly, we render the 360\u00b0 view on six faces of a cube using perspective projection. Thus, it introduces very little distortion. Then, we concatenate all six faces while utilizing the connectivity between faces on the cube for image padding (i.e., Cube Padding) in convolution, pooling, convolutional LSTM layers. In this way, CP introduces no image boundary while being applicable to almost all Convolutional Neural Network (CNN) structures. To evaluate our method, we propose Wild-360, a new 360\u00b0 video saliency dataset, containing challenging videos with saliency heatmap annotations. In experiments, our method outperforms baseline methods in both speed and quality.",
        "A1": "propose a spatial-temporal network",
        "A2": "Automatic saliency prediction in 360\u00b0 videos",
        "A41": " a spatial-temporal network which is (1) weakly-supervised trained and (2) tailor-made for 360\u00b0 viewing sphere",
        "A51": "",
        "A61": "a simple and effective Cube Padding (CP) technique",
        "A10": "outperforms baseline methods in both speed and quality",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our method outperforms baseline methods in both speed and quality",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " a new 360\u00b0 video saliency dataset",
        "am_id": 136619421
    },
    {
        "Abstract": "Spatiotemporal feature learning in videos is a fundamental problem in computer vision. This paper presents a new architecture, termed as Appearance-and-Relation Network (ARTNet), to learn video representation in an end-to-end manner. ARTNets are constructed by stacking multiple generic building blocks, called as SMART, whose goal is to simultaneously model appearance and relation from RGB input in a separate and explicit manner. Specifically, SMART blocks decouple the spatiotemporal learning module into an appearance branch for spatial modeling and a relation branch for temporal modeling. The appearance branch is implemented based on the linear combination of pixels or filter responses in each frame, while the relation branch is designed based on the multiplicative interactions between pixels or filter responses across multiple frames. We perform experiments on three action recognition benchmarks: Kinetics, UCF101, and HMDB51, demonstrating that SMART blocks obtain an evident improvement over 3D convolutions for spatiotemporal feature learning. Under the same training setting, ARTNets achieve superior performance on these three datasets to the existing state-of-the-art methods.1",
        "A1": " presents a new architecture",
        "A2": "to learn video representation in an end-to-end manner",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "ARTNets achieve superior performance on these three datasets to the existing state-of-the-art methods.1",
        "A7": "We perform experiments on three action recognition benchmarks: Kinetics, UCF101, and HMDB51, demonstrating that SMART blocks obtain an evident improvement over 3D convolutions for spatiotemporal feature learning. ",
        "A83": "",
        "A82": "",
        "A81": "ARTNets achieve superior performance on these three datasets to the existing state-of-the-art methods.1",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "Kinetics, UCF101, and HMDB51, ",
        "am_id": 75446445
    },
    {
        "Abstract": "We present MorphNet, an approach to automate the design of neural network structures. MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers. In contrast to previous approaches, our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance. When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint.",
        "A1": "present MorphNet, an approach to automate the design of neural network structures",
        "A2": "",
        "A41": "an approach to automate the design of neural network structures",
        "A51": "MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers",
        "A61": "our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance",
        "A10": "our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 218569688
    },
    {
        "Abstract": "We propose a new error measure for matching pixels that is based on co-occurrence statistics. The measure relies on a co-occurrence matrix that counts the number of times pairs of pixel values co-occur within a window. The error incurred by matching a pair of pixels is inversely proportional to the probability that their values co-occur together, and not their color difference. This measure also works with features other than color, e.g. deep features. We show that this improves the state-of-the-art performance of template matching on standard benchmarks. We then propose an embedding scheme that maps the input image to an embedded image such that the Euclidean distance between pixel values in the embedded space resembles the co-occurrence statistics in the original space. This lets us run existing vision algorithms on the embedded images and enjoy the power of co-occurrence statistics for free. We demonstrate this on two algorithms, the Lucas-Kanade image registration and the Kernelized Correlation Filter (KCF) tracker. Experiments show that performance of each algorithm improves by about 10%.",
        "A1": "propose a new error measure for matching pixels that is based on co-occurrence statistics.",
        "A2": "propose a new error measure for matching pixels that is based on co-occurrence statistics.",
        "A41": " a new error measure for matching pixels that is based on co-occurrence statistics",
        "A51": "relies on a co-occurrence matrix that counts the number of times pairs of pixel values co-occur within a window.",
        "A61": "",
        "A10": "",
        "A7": "demonstrate this on two algorithms, the Lucas-Kanade image registration and the Kernelized Correlation Filter (KCF) tracker",
        "A83": "This lets us run existing vision algorithms on the embedded images and enjoy the power of co-occurrence statistics for free.",
        "A82": "We show that this improves the state-of-the-art performance of template matching on standard benchmarks.",
        "A81": " that performance of each algorithm improves by about 10%.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 205565927
    },
    {
        "Abstract": "Most recent semantic segmentation methods train deep convolutional neural networks with fully annotated masks requiring pixel-accuracy for good quality training. Common weakly-supervised approaches generate full masks from partial input (e.g. scribbles or seeds) using standard interactive segmentation methods as preprocessing. But, errors in such masks result in poorer training since standard loss functions (e.g. cross-entropy) do not distinguish seeds from potentially mislabeled other pixels. Inspired by the general ideas in semi-supervised learning, we address these problems via a new principled loss function evaluating network output with criteria standard in \"shallow\" segmentation, e.g. normalized cut. Unlike prior work, the cross entropy part of our loss evaluates only seeds where labels are known while normalized cut softly evaluates consistency of all pixels. We focus on normalized cut loss where dense Gaussian kernel is efficiently implemented in linear time by fast Bilateral filtering. Our normalized cut loss approach to segmentation brings the quality of weakly-supervised training significantly closer to fully supervised methods.",
        "A1": " But, errors in such masks result in poorer training since standard loss functions (e.g. cross-entropy) do not distinguish seeds from potentially mislabeled other pixels. ",
        "A2": "Inspired by the general ideas in semi-supervised learning, we address these problems via a new principled loss function evaluating network output with criteria standard in \"shallow\" segmentation, e.g. normalized cut.",
        "A41": "we address these problems via a new principled loss function evaluating network output with criteria standard in \"shallow\" segmentation, e.g. normalized cut. ",
        "A51": " Inspired by the general ideas in semi-supervised learning, ",
        "A61": " Unlike prior work, the cross entropy part of our loss evaluates only seeds where labels are known while normalized cut softly evaluates consistency of all pixels.",
        "A10": "",
        "A7": " Inspired by the general ideas in semi-supervised learning, we address these problems via a new principled loss function evaluating network output with criteria standard in \"shallow\" segmentation, e.g. normalized cut.",
        "A83": "Our normalized cut loss approach to segmentation brings the quality of weakly-supervised training significantly closer to fully supervised methods.",
        "A82": "We focus on normalized cut loss where dense Gaussian kernel is efficiently implemented in linear time by fast Bilateral filtering. ",
        "A81": "the cross entropy part of our loss evaluates only seeds where labels are known while normalized cut softly evaluates consistency of all pixels.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "fast Bilateral filtering",
        "A42": " We focus on normalized cut loss where dense Gaussian kernel is efficiently implemented in linear time by fast Bilateral filtering. ",
        "A45": "",
        "am_id": 5805261
    },
    {
        "Abstract": "Bundle adjustment is a nonlinear refinement method for camera poses and 3D structure requiring sufficiently good initialization. In recent years, it was experimentally observed that useful minima can be reached even from arbitrary initialization for affine bundle adjustment problems (and fixed-rank matrix factorization instances in general). The key success factor lies in the use of the variable projection (VarPro) method, which is known to have a wide basin of convergence for such problems. In this paper, we propose the Pseudo Object Space Error (pOSE), which is an objective with cameras represented as a hybrid between the affine and projective models. This formulation allows us to obtain 3D reconstructions that are close to the true projective reconstructions while retaining a bilinear problem structure suitable for the VarPro method. Experimental results show that using pOSE has a high success rate to yield faithful 3D reconstructions from random initializations, taking one step towards initialization-free structure from motion.",
        "A1": "",
        "A2": "",
        "A41": "propose the Pseudo Object Space Error (pOSE), which is an objective with cameras represented as a hybrid between the affine and projective models",
        "A51": "",
        "A61": "obtain 3D reconstructions that are close to the true projective reconstructions",
        "A10": "s a high success rate to yield faithful 3D reconstructions from random initializations, taking one step towards initialization-free structure from motion.",
        "A7": "",
        "A83": "",
        "A82": "using pOSE has a high success rate to yield faithful 3D reconstructions from random initializations",
        "A81": "useful minima can be reached even from arbitrary initialization for affine bundle adjustment problems",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "obtain 3D reconstructions that are close to the true projective reconstructions",
        "A53": "",
        "A43": "the Pseudo Object Space Error (pOSE), which is an objective with cameras represented as a hybrid between the affine and projective models",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 208850812
    },
    {
        "Abstract": "Most existing 3D object recognition algorithms focus on leveraging the strong discriminative power of deep learning models with softmax loss for the classification of 3D data, while learning discriminative features with deep metric learning for 3D object retrieval is more or less neglected. In the paper, we study variants of deep metric learning losses for 3D object retrieval, which did not receive enough attention from this area. First, two kinds of representative losses, triplet loss and center loss, are introduced which could learn more discriminative features than traditional classification loss. Then, we propose a novel loss named triplet-center loss, which can further enhance the discriminative power of the features. The proposed triplet-center loss learns a center for each class and requires that the distances between samples and centers from the same class are closer than those from different classes. Extensive experimental results on two popular 3D object retrieval benchmarks and two widely-adopted sketch-based 3D shape retrieval benchmarks consistently demonstrate the effectiveness of our proposed loss, and significant improvements have been achieved compared with the state-of-the-arts.",
        "A1": "study variants of deep metric learning losses for 3D object retrieval",
        "A2": "learning discriminative features with deep metric learning for 3D object retrieval is more or less neglected",
        "A41": "propose a novel loss named triplet-center loss",
        "A51": "deep metric learning losses for 3D object retrieval",
        "A61": "The proposed triplet-center loss learns a center for each class and requires that the distances between samples and centers from the same class are closer than those from different classes",
        "A10": "significant improvements have been achieved compared with the state-of-the-arts",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " the effectiveness of our proposed loss",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 253861126
    },
    {
        "Abstract": "3D shape completion from partial point clouds is a fundamental problem in computer vision and computer graphics. Recent approaches can be characterized as either data-driven or learning-based. Data-driven approaches rely on a shape model whose parameters are optimized to fit the observations. Learning-based approaches, in contrast, avoid the expensive optimization step and instead directly predict the complete shape from the incomplete observations using deep neural networks. However, full supervision is required which is often not available in practice. In this work, we propose a weakly-supervised learning-based approach to 3D shape completion which neither requires slow optimization nor direct supervision. While we also learn a shape prior on synthetic data, we amortize, i.e., learn, maximum likelihood fitting using deep neural networks resulting in efficient shape completion without sacrificing accuracy. Tackling 3D shape completion of cars on ShapeNet [5] and KITTI [18], we demonstrate that the proposed amortized maximum likelihood approach is able to compete with a fully supervised baseline and a state-of-the-art data-driven approach while being significantly faster. On ModelNet [49], we additionally show that the approach is able to generalize to other object categories as well.",
        "A1": " we propose a weakly-supervised learning-based approach to 3D shape completion which neither requires slow optimization nor direct supervision",
        "A2": " Learning-based approaches, in contrast, avoid the expensive optimization step and instead directly predict the complete shape from the incomplete observations using deep neural networks. However, full supervision is required which is often not available in practice",
        "A41": "a weakly-supervised learning-based approach to 3D shape completion ",
        "A51": "using deep neural networks",
        "A61": "neither requires slow optimization nor direct supervision",
        "A10": " the proposed amortized maximum likelihood approach is able to compete with a fully supervised baseline and a state-of-the-art data-driven approach while being significantly faster",
        "A7": "Tackling 3D shape completion of cars on ShapeNet [5] and KITTI [18], ",
        "A83": "",
        "A82": "the approach is able to generalize to other object categories as well.",
        "A81": "the proposed amortized maximum likelihood approach is able to compete with a fully supervised baseline and a state-of-the-art data-driven approach while being significantly faster.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 140156613
    },
    {
        "Abstract": "Multi-layer light field displays are a type of computational three-dimensional (3D) display which has recently gained increasing interest for its holographic-like effect and natural compatibility with 2D displays. However, the major shortcoming, depth limitation, still cannot be overcome in the traditional light field modeling and reconstruction based on multi-layer liquid crystal displays (LCDs). Considering this disadvantage, our paper incorporates a salience guided depth optimization over a limited display range to calibrate the displayed depth and present the maximum area of salience region for multi-layer light field display. Different from previously reported cascaded light field displays that use the fixed initialization plane as the depth center of display content, our method automatically calibrates the depth initialization based on the salience results derived from the proposed contrast enhanced salience detection method. Experiments demonstrate that the proposed method provides a promising advantage in visual perception for the compressive light field displays from both software simulation and prototype demonstration.",
        "A1": "our paper incorporates a salience guided depth optimization over a limited display range to calibrate the displayed depth and present the maximum area of salience region for multi-layer light field display",
        "A2": " the major shortcoming, depth limitation, still cannot be overcome in the traditional light field modeling and reconstruction based on multi-layer liquid crystal displays (LCDs)",
        "A41": " a salience guided depth optimization over a limited display range to calibrate the displayed depth and present the maximum area of salience region for multi-layer light field display",
        "A51": "the salience results derived from the proposed contrast enhanced salience detection method",
        "A61": " our method automatically calibrates the depth initialization based on the salience results derived from the proposed contrast enhanced salience detection method",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "the proposed method provides a promising advantage in visual perception for the compressive light field displays from both software simulation and prototype demonstration",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 220152311
    },
    {
        "Abstract": "Recently, there has been a paradigm shift in stereo matching with learning-based methods achieving the best results on all popular benchmarks. The success of these methods is due to the availability of training data with ground truth; training learning-based systems on these datasets has allowed them to surpass the accuracy of conventional approaches based on heuristics and assumptions. Many of these assumptions, however, had been validated extensively and hold for the majority of possible inputs. In this paper, we generate a matching volume leveraging both data with ground truth and conventional wisdom. We accomplish this by coalescing diverse evidence from a bidirectional matching process via random forest classifiers. We show that the resulting matching volume estimation method achieves similar accuracy to purely data-driven alternatives on benchmarks and that it generalizes to unseen data much better. In fact, the results we submitted to the KITTI and ETH3D benchmarks were generated using a classifier trained on the Middlebury 2014 dataset.",
        "A1": "In this paper, we generate a matching volume leveraging both data with ground truth and conventional wisdom.",
        "A2": "Many of these assumptions, however, had been validated extensively and hold for the majority of possible inputs.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We accomplish this by coalescing diverse evidence from a bidirectional matching process via random forest classifiers. ",
        "A83": "",
        "A82": "the results we submitted to the KITTI and ETH3D benchmarks were generated using a classifier trained on the Middlebury 2014 dataset.",
        "A81": " the resulting matching volume estimation method achieves similar accuracy to purely data-driven alternatives on benchmarks and that it generalizes to unseen data much better.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 431101508
    },
    {
        "Abstract": "This paper proposes learning disentangled but complementary face features with a minimal supervision by face identification. Specifically, we construct an identity Distilling and Dispelling Autoencoder (D2AE) framework that adversarially learns the identity-distilled features for identity verification and the identity-dispelled features to fool the verification system. Thanks to the design of two-stream cues, the learned disentangled features represent not only the identity or attribute but the complete input image. Comprehensive evaluations further demonstrate that the proposed features not only preserve state-of-the-art identity verification performance on LFW, but also acquire comparable discriminative power for face attribute recognition on CelebA and LFWA. Moreover, the proposed system is ready to semantically control the face generation/editing based on various identities and attributes in an unsupervised manner.",
        "A1": "",
        "A2": "This paper proposes learning disentangled but complementary face features with a minimal supervision by face identification",
        "A41": "learning disentangled but complementary face features with a minimal supervision by face identification",
        "A51": "",
        "A61": "we construct an identity Distilling and Dispelling Autoencoder (D2AE) framework that adversarially learns the identity-distilled features for identity verification and the identity-dispelled features to fool the verification system",
        "A10": "the proposed features not only preserve state-of-the-art identity verification performance on LFW, but also acquire comparable discriminative power for face attribute recognition on CelebA and LFWA",
        "A7": "Comprehensive evaluations further",
        "A83": "",
        "A82": "the proposed system is ready to semantically control the face generation/editing based on various identities and attributes in an unsupervised manner",
        "A81": "the proposed features not only preserve state-of-the-art identity verification performance on LFW, but also acquire comparable discriminative power for face attribute recognition on CelebA and LFWA",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 120402083
    },
    {
        "Abstract": "Random data augmentation is a critical technique to avoid overfitting in training deep models. Yet, data augmentation and network training are often two isolated processes in most settings, yielding to a suboptimal training. Why not jointly optimize the two? We propose adversarial data augmentation to address this limitation. The key idea is to design a generator (e.g. an augmentation network) that competes against a discriminator (e.g. a target network) by generating hard examples online. The generator explores weaknesses of the discriminator, while the discriminator learns from hard augmentations to achieve better performance. A reward/penalty strategy is also proposed for efficient joint training. We investigate human pose estimation and carry out comprehensive ablation studies to validate our method. The results prove that our method can effectively improve state-of-the-art models without additional data effort.",
        "A1": " propose adversarial data augmentation",
        "A2": " address this limitation",
        "A41": "The key idea is to design a generator",
        "A51": "Random data augmentation is a critical technique to avoid overfitting in training deep models.",
        "A61": " jointly optimize the two",
        "A10": "effectively improve state-of-the-art models without additional data effort.",
        "A7": " human pose estimation and carry out comprehensive ablation studies",
        "A83": "",
        "A82": "A reward/penalty strategy is also proposed for efficient joint training",
        "A81": "effectively improve state-of-the-art models without additional data effort.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 54001286
    },
    {
        "Abstract": "Understanding human motion behavior is critical for autonomous moving platforms (like self-driving cars and social robots) if they are to navigate human-centric environments. This is challenging because human motion is inherently multimodal: given a history of human motion paths, there are many socially plausible ways that people could move in the future. We tackle this problem by combining tools from sequence prediction and generative adversarial networks: a recurrent sequence-to-sequence model observes motion histories and predicts future behavior, using a novel pooling mechanism to aggregate information across people. We predict socially plausible futures by training adversarially against a recurrent discriminator, and encourage diverse predictions with a novel variety loss. Through experiments on several datasets we demonstrate that our approach outperforms prior work in terms of accuracy, variety, collision avoidance, and computational complexity.",
        "A1": " a recurrent sequence-to-sequence model observes motion histories and predicts future behavio",
        "A2": "Understanding human motion behavior is critical for autonomous moving platforms ",
        "A41": "combining tools from sequence prediction and generative adversarial networks",
        "A51": "a recurrent sequence-to-sequence model observes motion histories and predicts future behavior",
        "A61": "novel pooling mechanism",
        "A10": "",
        "A7": "experiments on several datasets",
        "A83": "",
        "A82": "",
        "A81": "approach outperforms prior work in terms of accuracy, variety, collision avoidance, and computational complexity.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 226421257
    },
    {
        "Abstract": "Existing person re-identification (re-id) methods either assume the availability of well-aligned person bounding box images as model input or rely on constrained attention selection mechanisms to calibrate misaligned images. They are therefore sub-optimal for re-id matching in arbitrarily aligned person images potentially with large human pose variations and unconstrained auto-detection errors. In this work, we show the advantages of jointly learning attention selection and feature representation in a Convolutional Neural Network (CNN) by maximising the complementary information of different levels of visual attention subject to re-id discriminative learning constraints. Specifically, we formulate a novel Harmonious Attention CNN (HA-CNN) model for joint learning of soft pixel attention and hard regional attention along with simultaneous optimisation of feature representations, dedicated to optimise person re-id in uncontrolled (misaligned) images. Extensive comparative evaluations validate the superiority of this new HA-CNN model for person re-id over a wide variety of state-of-the-art methods on three large-scale benchmarks including CUHK03, Market-1501, and DukeMTMC-ReID.",
        "A1": "re-id matching in arbitrarily aligned person images",
        "A2": "re-id matching in arbitrarily aligned person images",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "on three large-scale benchmarks including CUHK03, Market-1501, and DukeMTMC-ReID",
        "A83": "",
        "A82": "",
        "A81": "the superiority of this new HA-CNN model for person re-id",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "dedicated to optimise person re-id in uncontrolled (misaligned) images",
        "A52": "joint learning of soft pixel attention and hard regional attention",
        "A42": "Harmonious Attention CNN",
        "A45": "",
        "am_id": 261926373
    },
    {
        "Abstract": "Rotation-invariant face detection, i.e. detecting faces with arbitrary rotation-in-plane (RIP) angles, is widely required in unconstrained applications but still remains as a challenging task, due to the large variations of face appearances. Most existing methods compromise with speed or accuracy to handle the large RIP variations. To address this problem more efficiently, we propose Progressive Calibration Networks (PCN) to perform rotation-invariant face detection in a coarse-to-fine manner. PCN consists of three stages, each of which not only distinguishes the faces from non-faces, but also calibrates the RIP orientation of each face candidate to upright progressively. By dividing the calibration process into several progressive steps and only predicting coarse orientations in early stages, PCN can achieve precise and fast calibration. By performing binary classification of face vs. non-face with gradually decreasing RIP ranges, PCN can accurately detect faces with full 360\u00c2\u00b0 RIP angles. Such designs lead to a real-time rotation-invariant face detector. The experiments on multi-oriented FDDB and a challenging subset of WIDER FACE containing rotated faces in the wild show that our PCN achieves quite promising performance.",
        "A1": "we propose Progressive Calibration Networks (PCN) to perform rotation-invariant face detection in a coarse-to-fine manner",
        "A2": "Most existing methods compromise with speed or accuracy to handle the large RIP variations",
        "A41": "Progressive Calibration Networks (PCN)",
        "A51": "",
        "A61": "our PCN achieves quite promising performance.",
        "A10": " PCN achieves quite promising performance.",
        "A7": "The experiments on multi-oriented FDDB and a challenging subset of WIDER FACE containing rotated faces in the wild",
        "A83": "",
        "A82": " PCN achieves quite promising performance.",
        "A81": "To address this problem more efficiently, we propose Progressive Calibration Networks (PCN) to perform rotation-invariant face detection in a coarse-to-fine manner",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 190843899
    },
    {
        "Abstract": "This paper proposes a deep neural network (DNN) for piece-wise planar depthmap reconstruction from a single RGB image. While DNNs have brought remarkable progress to single-image depth prediction, piece-wise planar depthmap reconstruction requires a structured geometry representation, and has been a difficult task to master even for DNNs. The proposed end-to-end DNN learns to directly infer a set of plane parameters and corresponding plane segmentation masks from a single RGB image. We have generated more than 50,000 piece-wise planar depthmaps for training and testing from ScanNet, a large-scale RGBD video database. Our qualitative and quantitative evaluations demonstrate that the proposed approach outperforms baseline methods in terms of both plane segmentation and depth estimation accuracy. To the best of our knowledge, this paper presents the first end-to-end neural architecture for piece-wise planar reconstruction from a single RGB image. Code and data are available at https://github.com/art-programmer/PlaneNet.",
        "A1": "single-image depth prediction",
        "A2": "piece-wise planar depthmap reconstruction",
        "A41": "a deep neural network (DNN) for piece-wise planar depthmap reconstruction",
        "A51": "",
        "A61": "directly infer a set of plane parameters",
        "A10": "",
        "A7": "ScanNet",
        "A83": "",
        "A82": "both plane segmentation and depth estimation accuracy",
        "A81": "outperforms baseline methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 379952294
    },
    {
        "Abstract": "Adversarial learning has been successfully embedded into deep networks to learn transferable features, which reduce distribution discrepancy between the source and target domains. Existing domain adversarial networks assume fully shared label space across domains. In the presence of big data, there is strong motivation of transferring both classification and representation models from existing large-scale domains to unknown small-scale domains. This paper introduces partial transfer learning, which relaxes the shared label space assumption to that the target label space is only a subspace of the source label space. Previous methods typically match the whole source domain to the target domain, which are prone to negative transfer for the partial transfer problem. We present Selective Adversarial Network (SAN), which simultaneously circumvents negative transfer by selecting out the outlier source classes and promotes positive transfer by maximally matching the data distributions in the shared label space. Experiments demonstrate that our models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets.",
        "A1": "This paper introduces partial transfer learning, which relaxes the shared label space assumption to that the target label space is only a subspace of the source label space. ",
        "A2": "Previous methods typically match the whole source domain to the target domain, which are prone to negative transfer for the partial transfer problem.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "models exceed state-of-the-art results for partial transfer learning tasks on several benchmark datasets.",
        "A52": "selecting out the outlier source classes and promotes positive transfer by maximally matching the data distributions in the shared label space",
        "A42": "Selective Adversarial Network (SAN)",
        "A45": "",
        "am_id": 284073105
    },
    {
        "Abstract": "Deep neural networks have proved very successful on archetypal tasks for which large training sets are available, but when the training data are scarce, their performance suffers from overfitting. Many existing methods of reducing overfitting are data-independent. Data-dependent regularizations are mostly motivated by the observation that data of interest lie close to a manifold, which is typically hard to parametrize explicitly. These methods usually only focus on the geometry of the input data, and do not necessarily encourage the networks to produce geometrically meaningful features. To resolve this, we propose the Low-Dimensional-Manifold-regularized neural Network (LDMNet), which incorporates a feature regularization method that focuses on the geometry of both the input data and the output features. In LDMNet, we regularize the network by encouraging the combination of the input data and the output features to sample a collection of low dimensional manifolds, which are searched efficiently without explicit parametrization. To achieve this, we directly use the manifold dimension as a regularization term in a variational functional. The resulting Euler-Lagrange equation is a Laplace-Beltrami equation over a point cloud, which is solved by the point integral method without increasing the computational complexity. In the experiments, we show that LDMNet significantly outperforms widely-used regularizers. Moreover, LDMNet can extract common features of an object imaged via different modalities, which is very useful in real-world applications such as cross-spectral face recognition.",
        "A1": "reducing overfitting",
        "A2": "Deep neural networks have proved very successful on archetypal tasks for which large training sets are available, but when the training data are scarce, their performance suffers from overfitting.",
        "A41": "we propose the Low-Dimensional-Manifold-regularized neural Network (LDMNet), which incorporates a feature regularization method that focuses on the geometry of both the input data and the output features.",
        "A51": "",
        "A61": " Data-dependent regularizations are mostly motivated by the observation that data of interest lie close to a manifold, which is typically hard to parametrize explicitly. These methods usually only focus on the geometry of the input data, and do not necessarily encourage the networks to produce geometrically meaningful features. ",
        "A10": "DMNet significantly outperforms widely-used regularizers.",
        "A7": "",
        "A83": "",
        "A82": "LDMNet can extract common features of an object imaged via different modalities",
        "A81": "LDMNet significantly outperforms widely-used regularizers. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 362589576
    },
    {
        "Abstract": "Research on learning suitable feature descriptors for Computer Vision has recently shifted to deep learning where the biggest challenge lies with the formulation of appropriate loss functions, especially since the descriptors to be learned are not known at training time. While approaches such as Siamese and triplet losses have been applied with success, it is still not well understood what makes a good loss function. In this spirit, this work demonstrates that many commonly used losses suffer from a range of problems. Based on this analysis, we introduce mixed-context losses and scale-aware sampling, two methods that when combined enable networks to learn consistently scaled descriptors for the first time.",
        "A1": "introduce mixed-context losses and scale-aware sampling",
        "A2": "enable networks to learn consistently scaled descriptors for the first time",
        "A41": "mixed-context losses and scale-aware sampling",
        "A51": "",
        "A61": "",
        "A10": "nable networks to learn consistently scaled descriptors for the first time",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 210650550
    },
    {
        "Abstract": "We present a framework for learning single-view shape and pose prediction without using direct supervision for either. Our approach allows leveraging multi-view observations from unknown poses as supervisory signal during training. Our proposed training setup enforces geometric consistency between the independently predicted shape and pose from two views of the same instance. We consequently learn to predict shape in an emergent canonical (view-agnostic) frame along with a corresponding pose predictor. We show empirical and qualitative results using the ShapeNet dataset and observe encouragingly competitive performance to previous techniques which rely on stronger forms of supervision. We also demonstrate the applicability of our framework in a realistic setting which is beyond the scope of existing techniques: using a training dataset comprised of online product images where the underlying shape and pose are unknown.",
        "A1": "leveraging multi-view observations from unknown poses as supervisory signal during training. ",
        "A2": "for learning single-view shape and pose prediction without using direct supervision for either",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "demonstrate the applicability of our framework in a realistic setting which is beyond the scope of existing techniques: using a training dataset comprised of online product images where the underlying shape and pose are unknown.",
        "A7": "show empirical and qualitative results using the ShapeNet dataset and observe encouragingly competitive performance to previous techniques which rely on stronger forms of supervision",
        "A83": "",
        "A82": "demonstrate the applicability of our framework in a realistic setting which is beyond the scope of existing techniques: using a training dataset comprised of online product images where the underlying shape and pose are unknown.",
        "A81": "show empirical and qualitative results using the ShapeNet dataset and observe encouragingly competitive performance to previous techniques which rely on stronger forms of supervision",
        "A64": "Our proposed training setup enforces geometric consistency between the independently predicted shape and pose from two views of the same instance. ",
        "A54": "",
        "A44": "a framework for learning single-view shape and pose prediction without using direct supervision for either. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 260930804
    },
    {
        "Abstract": "As demand for advanced photographic applications on hand-held devices grows, these electronics require the capture of high quality depth. However, under low-light conditions, most devices still suffer from low imaging quality and inaccurate depth acquisition. To address the problem, we present a robust depth estimation method from a short burst shot with varied intensity (i.e., Auto Bracketing) or strong noise (i.e., High ISO). We introduce a geometric transformation between flow and depth tailored for burst images, enabling our learning-based multi-view stereo matching to be performed effectively. We then describe our depth estimation pipeline that incorporates the geometric transformation into our residual-flow network. It allows our framework to produce an accurate depth map even with a bracketed image sequence. We demonstrate that our method outperforms state-of-the-art methods for various datasets captured by a smartphone and a DSLR camera. Moreover, we show that the estimated depth is applicable for image quality enhancement and photographic editing.",
        "A1": " we present a robust depth estimation method from a short burst shot with varied intensity (i.e., Auto Bracketing) or strong noise (i.e., High ISO",
        "A2": "under low-light conditions, most devices still suffer from low imaging quality and inaccurate depth acquisition",
        "A41": "a robust depth estimation method from a short burst shot with varied intensity (i.e., Auto Bracketing) ",
        "A51": "a short burst shot with varied intensity (i.e., Auto Bracketing) or strong noise (i.e., High ISO",
        "A61": "method outperforms state-of-the-art methods for various datasets captured by a smartphone and a DSLR camera",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "the estimated depth is applicable for image quality enhancement and photographic editing",
        "A81": " our method outperforms state-of-the-art methods for various datasets captured by a smartphone and a DSLR camera. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 306354794
    },
    {
        "Abstract": "We propose a novel way to measure and understand convolutional neural networks by quantifying the amount of input signal they let in. To do this, an autoencoder (AE) was fine-tuned on gradients from a pre-trained classifier with fixed parameters. We compared the reconstructed samples from AEs that were fine-tuned on a set of image classifiers (AlexNet, VGG16, ResNet-50, and Inception v3) and found substantial differences. The AE learns which aspects of the input space to preserve and which ones to ignore, based on the information encoded in the backpropagated gradients. Measuring the changes in accuracy when the signal of one classifier is used by a second one, a relation of total order emerges. This order depends directly on each classifier's input signal but it does not correlate with classification accuracy or network size. Further evidence of this phenomenon is provided by measuring the normalized mutual information between original images and auto-encoded reconstructions from different fine-tuned AEs. These findings break new ground in the area of neural network understanding, opening a new way to reason, debug, and interpret their results. We present four concrete examples in the literature where observations can now be explained in terms of the input signal that a model uses.",
        "A1": "measure and understand convolutional neural networks",
        "A2": "",
        "A41": "a novel way to measure and understand convolutional neural networks",
        "A51": "quantifying the amount of input signal they let in",
        "A61": "",
        "A10": "",
        "A7": "We compared the reconstructed samples from AEs that were fine-tuned on a set of image classifiers",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 422016389
    },
    {
        "Abstract": "Deep Learning has led to a dramatic leap in SuperResolution (SR) performance in the past few years. However, being supervised, these SR methods are restricted to specific training data, where the acquisition of the low-resolution (LR) images from their high-resolution (HR) counterparts is predetermined (e.g., bicubic downscaling), without any distracting artifacts (e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images, however, rarely obey these restrictions, resulting in poor SR results by SotA (State of the Art) methods. In this paper we introduce \"Zero-Shot\" SR, which exploits the power of Deep Learning, but does not rely on prior training. We exploit the internal recurrence of information inside a single image, and train a small image-specific CNN at test time, on examples extracted solely from the input image itself. As such, it can adapt itself to different settings per image. This allows to perform SR of real old photos, noisy images, biological data, and other images where the acquisition process is unknown or non-ideal. On such images, our method outperforms SotA CNN-based SR methods, as well as previous unsupervised SR methods. To the best of our knowledge, this is the first unsupervised CNN-based SR method.",
        "A1": " In this paper we introduce \"Zero-Shot\" SR, which exploits the power of Deep Learning, but does not rely on prior training",
        "A2": "However, being supervised, these SR methods are restricted to specific training data, where the acquisition of the low-resolution (LR) images from their high-resolution (HR) counterparts is predetermined (e.g., bicubic downscaling), without any distracting artifacts (e.g., sensor noise, image compression, non-ideal PSF, etc). ",
        "A41": "\"Zero-Shot\" SR, ",
        "A51": "We exploit the internal recurrence of information inside a single image, and train a small image-specific CNN at test time, on examples extracted solely from the input image itself. As such, it can adapt itself to different settings per image. This allows to perform SR of real old photos, noisy images, biological data, and other images where the acquisition process is unknown or non-ideal. ",
        "A61": "In this paper we introduce \"Zero-Shot\" SR, which exploits the power of Deep Learning, but does not rely on prior training.",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " On such images, our method outperforms SotA CNN-based SR methods, as well as previous unsupervised SR methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 48823582
    },
    {
        "Abstract": "Delineation of curvilinear structures is an important problem in Computer Vision with multiple practical applications. With the advent of Deep Learning, many current approaches on automatic delineation have focused on finding more powerful deep architectures, but have continued using the habitual pixel-wise losses such as binary cross-entropy. In this paper we claim that pixel-wise losses alone are unsuitable for this problem because of their inability to reflect the topological impact of mistakes in the final prediction. We propose a new loss term that is aware of the higher-order topological features of linear structures. We also exploit a refinement pipeline that iteratively applies the same model over the previous delineation to refine the predictions at each step, while keeping the number of parameters and the complexity of the model constant. When combined with the standard pixel-wise loss, both our new loss term and an iterative refinement boost the quality of the predicted delineations, in some cases almost doubling the accuracy as compared to the same classifier trained with the binary cross-entropy alone. We show that our approach outperforms state-of-the-art methods on a wide range of data, from microscopy to aerial images.",
        "A1": " propose a new loss term that is aware of the higher-order topological features of linear structures.",
        "A2": "In this paper we claim that pixel-wise losses alone are unsuitable for this problem because of their inability to reflect the topological impact of mistakes in the final prediction",
        "A41": " propose a new loss term that is aware of the higher-order topological features of linear structures.",
        "A51": "",
        "A61": " in some cases almost doubling the accuracy as compared to the same classifier trained with the binary cross-entropy alone. ",
        "A10": "We show that our approach outperforms state-of-the-art methods on a wide range of data, from microscopy to aerial images.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 294161646
    },
    {
        "Abstract": "A prominent property of natural images is that groups of similar patches within them tend to lie on low-dimensional subspaces. This property has been previously used for image denoising, with particularly notable success via weighted nuclear norm minimization (WNNM). In this paper, we extend the WNNM method into a general image restoration algorithm, capable of handling arbitrary degradations (e.g. blur, missing pixels, etc.). Our approach is based on a novel regularization term which simultaneously penalizes for high weighted nuclear norm values of all the patch groups in the image. Our regularizer is isolated from the data-term, thus enabling convenient treatment of arbitrary degradations. Furthermore, it exploits the fractal property of natural images, by accounting for patch similarities also across different scales of the image. We propose a variable splitting method for solving the resulting optimization problem. This leads to an algorithm that is quite different from \"plug-and-play\" techniques, which solve image-restoration problems using a sequence of denoising steps. As we verify through extensive experiments, our algorithm achieves state of the art results in deblurring and inpainting, outperforming even the recent deep net based methods.",
        "A1": "",
        "A2": "capable of handling arbitrary degradations (e.g. blur, missing pixels, etc.). ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our algorithm achieves state of the art results in deblurring and inpainting, outperforming even the recent deep net based methods.",
        "A7": "extensive experiments,",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "Our approach is based on a novel regularization term which simultaneously penalizes for high weighted nuclear norm values of all the patch groups in the image. ",
        "A43": "we extend the WNNM method into a general image restoration algorithm, capable of handling arbitrary degradations (e.g. blur, missing pixels, etc.). ",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 22120112
    },
    {
        "Abstract": "We propose a new end-to-end single image dehazing method, called Densely Connected Pyramid Dehazing Network (DCPDN), which can jointly learn the transmission map, atmospheric light and dehazing all together. The end-to-end learning is achieved by directly embedding the atmospheric scattering model into the network, thereby ensuring that the proposed method strictly follows the physics-driven scattering model for dehazing. Inspired by the dense network that can maximize the information flow along features from different levels, we propose a new edge-preserving densely connected encoder-decoder structure with multi-level pyramid pooling module for estimating the transmission map. This network is optimized using a newly introduced edge-preserving loss function. To further incorporate the mutual structural information between the estimated transmission map and the dehazed result, we propose a joint-discriminator based on generative adversarial network framework to decide whether the corresponding dehazed image and the estimated transmission map are real or fake. An ablation study is conducted to demonstrate the effectiveness of each module evaluated at both estimated transmission map and dehazed result. Extensive experiments demonstrate that the proposed method achieves significant improvements over the state-of-the-art methods. Code and dataset is made available at: https://github.com/hezhangsprinter/DCPDN",
        "A1": "propose a new end-to-end single image dehazing method, called Densely Connected Pyramid Dehazing Network (DCPDN)",
        "A2": "jointly learn the transmission map, atmospheric light and dehazing all together",
        "A41": "a new end-to-end single image dehazing method, called Densely Connected Pyramid Dehazing Network (DCPDN)",
        "A51": "directly embedding the atmospheric scattering model into the network",
        "A61": "can jointly learn the transmission map, atmospheric light and dehazing all together.",
        "A10": "can jointly learn the transmission map, atmospheric light and dehazing all together",
        "A7": "Extensive experiments demonstrate that the proposed method achieves significant improvements over the state-of-the-art methods",
        "A83": "",
        "A82": "",
        "A81": "achieves significant improvements over the state-of-the-art methods",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 41498837
    },
    {
        "Abstract": "In this paper, we propose an efficient algorithm to directly restore a clear image from a hazy input. The proposed algorithm hinges on an end-to-end trainable neural network that consists of an encoder and a decoder. The encoder is exploited to capture the context of the derived input images, while the decoder is employed to estimate the contribution of each input to the final dehazed result using the learned representations attributed to the encoder. The constructed network adopts a novel fusion-based strategy which derives three inputs from an original hazy image by applying White Balance (WB), Contrast Enhancing (CE), and Gamma Correction (GC). We compute pixel-wise confidence maps based on the appearance differences between these different inputs to blend the information of the derived inputs and preserve the regions with pleasant visibility. The final dehazed image is yielded by gating the important features of the derived inputs. To train the network, we introduce a multi-scale approach such that the halo artifacts can be avoided. Extensive experimental results on both synthetic and real-world images demonstrate that the proposed algorithm performs favorably against the state-of-the-art algorithms.",
        "A1": "restore a clear image from a hazy input",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "synthetic and real-world images",
        "A83": "",
        "A82": " halo artifacts can be avoided",
        "A81": "performs favorably against the state-of-the-art algorithms",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "hinges on an end-to-end trainable neural network that consists of an encoder and a decoder",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 200046430
    },
    {
        "Abstract": "Using deep learning, this paper addresses the problem of joint object boundary detection and boundary motion estimation in videos, which we named boundary flow estimation. Boundary flow is an important mid-level visual cue as boundaries characterize objects' spatial extents, and the flow indicates objects' motions and interactions. Yet, most prior work on motion estimation has focused on dense object motion or feature points that may not necessarily reside on boundaries. For boundary flow estimation, we specify a new fully convolutional Siamese network (FCSN) that jointly estimates object-level boundaries in two consecutive frames. Boundary correspondences in the two frames are predicted by the same FCSN with a new, unconventional deconvolution approach. Finally, the boundary flow estimate is improved with an edgelet-based filtering. Evaluation is conducted on three tasks: boundary detection in videos, boundary flow estimation, and optical flow estimation. On boundary detection, we achieve the state-of-the-art performance on the benchmark VSB100 dataset. On boundary flow estimation, we present the first results on the Sintel training dataset. For optical flow estimation, we run the recent approach CPM-Flow but on the augmented input with our boundary-flow matches, and achieve significant performance improvement on the Sintel benchmark.",
        "A1": "joint object boundary detection and boundary motion estimation in videos",
        "A2": "joint object boundary detection and boundary motion estimation in videos",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "boundary detection in videos, boundary flow estimation, and optical flow estimation",
        "A83": "achieve significant performance improvement on the Sintel benchmark",
        "A82": "we present the first results on the Sintel training dataset",
        "A81": "we achieve the state-of-the-art performance on the benchmark VSB100 dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Boundary correspondences in the two frames are predicted by the same FCSN with a new, unconventional deconvolution approach",
        "A52": "",
        "A42": "a new fully convolutional Siamese network (FCSN) that jointly estimates object-level boundaries in two consecutive frames",
        "A45": "",
        "am_id": 313403240
    },
    {
        "Abstract": "Object detection typically assumes that training and test data are drawn from an identical distribution, which, however, does not always hold in practice. Such a distribution mismatch will lead to a significant performance drop. In this work, we aim to improve the cross-domain robustness of object detection. We tackle the domain shift on two levels: 1) the image-level shift, such as image style, illumination, etc., and 2) the instance-level shift, such as object appearance, size, etc. We build our approach based on the recent state-of-the-art Faster R-CNN model, and design two domain adaptation components, on image level and instance level, to reduce the domain discrepancy. The two domain adaptation components are based on $$-divergence theory, and are implemented by learning a domain classifier in adversarial training manner. The domain classifiers on different levels are further reinforced with a consistency regularization to learn a domain-invariant region proposal network (RPN) in the Faster R-CNN model. We evaluate our newly proposed approach using multiple datasets including Cityscapes, KITTI, SIM10K, etc. The results demonstrate the effectiveness of our proposed approach for robust object detection in various domain shift scenarios.",
        "A1": "improve the cross-domain robustness of object detection",
        "A2": "distribution mismatch will lead to a significant performance drop",
        "A41": "",
        "A51": "R-CNN model,",
        "A61": "",
        "A10": "",
        "A7": "using multiple datasets including Cityscapes, KITTI, SIM10K",
        "A83": "",
        "A82": "",
        "A81": "The results demonstrate the effectiveness of our proposed approach for robust object detection in various domain shift scenarios.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 12964097
    },
    {
        "Abstract": "We propose an approach to learn image representations that consist of disentangled factors of variation without exploiting any manual labeling or data domain knowledge. A factor of variation corresponds to an image attribute that can be discerned consistently across a set of images, such as the pose or color of objects. Our disentangled representation consists of a concatenation of feature chunks, each chunk representing a factor of variation. It supports applications such as transferring attributes from one image to another, by simply mixing and unmixing feature chunks, and classification or retrieval based on one or several attributes, by considering a user-specified subset of feature chunks. We learn our representation without any labeling or knowledge of the data domain, using an autoencoder architecture with two novel training objectives: first, we propose an invariance objective to encourage that encoding of each attribute, and decoding of each chunk, are invariant to changes in other attributes and chunks, respectively; second, we include a classification objective, which ensures that each chunk corresponds to a consistently discernible attribute in the represented image, hence avoiding degenerate feature mappings where some chunks are completely ignored. We demonstrate the effectiveness of our approach on the MNIST, Sprites, and CelebA datasets.",
        "A1": "We propose an approach to learn image representations that consist of disentangled factors of variation without exploiting any manual labeling or data domain knowledge.",
        "A2": "We propose an approach to learn image representations that consist of disentangled factors of variation without exploiting any manual labeling or data domain knowledge.",
        "A41": "We propose an approach to learn image representations that consist of disentangled factors of variation without exploiting any manual labeling or data domain knowledge.",
        "A51": "",
        "A61": "We propose an approach to learn image representations that consist of disentangled factors of variation without exploiting any manual labeling or data domain knowledge.",
        "A10": "We demonstrate the effectiveness of our approach on the MNIST, Sprites, and CelebA datasets.",
        "A7": "We demonstrate the effectiveness of our approach on the MNIST, Sprites, and CelebA datasets.",
        "A83": "",
        "A82": "second, we include a classification objective, which ensures that each chunk corresponds to a consistently discernible attribute in the represented image, hence avoiding degenerate feature mappings where some chunks are completely ignored. ",
        "A81": "first, we propose an invariance objective to encourage that encoding of each attribute, and decoding of each chunk, are invariant to changes in other attributes and chunks, respectively",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 410211611
    },
    {
        "Abstract": "We study the problem of reconstructing an image from information stored at contour locations. We show that high-quality reconstructions with high fidelity to the source image can be obtained from sparse input, e.g., comprising less than 6% of image pixels. This is a significant improvement over existing contour-based reconstruction methods that require much denser input to capture subtle texture information and to ensure image quality. Our model, based on generative adversarial networks, synthesizes texture and details in regions where no input information is provided. The semantic knowledge encoded into our model and the sparsity of the input allows to use contours as an intuitive interface for semantically-aware image manipulation: local edits in contour domain translate to long-range and coherent changes in pixel space. We can perform complex structural changes such as changing facial expression by simple edits of contours. Our experiments demonstrate that humans as well as a face recognition system mostly cannot distinguish between our reconstructions and the source images.",
        "A1": "",
        "A2": "We study the problem of reconstructing an image from information stored at contour locations",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " humans as well as a face recognition system mostly cannot distinguish between our reconstructions and the source images.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " We can perform complex structural changes such as changing facial expression by simple edits of contours",
        "A52": "generative adversarial networks,",
        "A42": "Our model, based on generative adversarial networks, synthesizes texture and details in regions where no input information is provided.",
        "A45": "",
        "am_id": 56657776
    },
    {
        "Abstract": "This paper proposes a segmentation-free, automatic and efficient procedure to detect general geometric quadric forms in point clouds, where clutter and occlusions are inevitable. Our everyday world is dominated by man-made objects which are designed using 3D primitives (such as planes, cones, spheres, cylinders, etc.). These objects are also omnipresent in industrial environments. This gives rise to the possibility of abstracting 3D scenes through primitives, thereby positions these geometric forms as an integral part of perception and high level 3D scene understanding. As opposed to state-of-the-art, where a tailored algorithm treats each primitive type separately, we propose to encapsulate all types in a single robust detection procedure. At the center of our approach lies a closed form 3D quadric fit, operating in both primal & dual spaces and requiring as low as 4 oriented-points. Around this fit, we design a novel, local null-space voting strategy to reduce the 4-point case to 3. Voting is coupled with the famous RANSAC and makes our algorithm orders of magnitude faster than its conventional counterparts. This is the first method capable of performing a generic cross-type multi-object primitive detection in difficult scenes. Results on synthetic and real datasets support the validity of our method.",
        "A1": "proposes a segmentation-free, automatic and efficient procedure to detect general geometric quadric forms in point clouds, where clutter and occlusions are inevitable.",
        "A2": " encapsulate all types in a single robust detection procedure",
        "A41": " a segmentation-free, automatic and efficient procedure to detect general geometric quadric forms in point clouds",
        "A51": "a closed form 3D quadric fit, operating in both primal & dual spaces and requiring as low as 4 oriented-points.",
        "A61": "we design a novel, local null-space voting strategy to reduce the 4-point case to 3. Voting is coupled with the famous RANSAC and makes our algorithm orders of magnitude faster than its conventional counterparts. ",
        "A10": "This is the first method capable of performing a generic cross-type multi-object primitive detection in difficult scenes.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 19541095
    },
    {
        "Abstract": "Automated counting of people in crowd images is a challenging task. The major difficulty stems from the large diversity in the way people appear in crowds. In fact, features available for crowd discrimination largely depend on the crowd density to the extent that people are only seen as blobs in a highly dense scene. We tackle this problem with a growing CNN which can progressively increase its capacity to account for the wide variability seen in crowd scenes. Our model starts from a base CNN density regressor, which is trained in equivalence on all types of crowd images. In order to adapt with the huge diversity, we create two child regressors which are exact copies of the base CNN. A differential training procedure divides the dataset into two clusters and fine-tunes the child networks on their respective specialties. Consequently, without any hand-crafted criteria for forming specialties, the child regressors become experts on certain types of crowds. The child networks are again split recursively, creating two experts at every division. This hierarchical training leads to a CNN tree, where the child regressors are more fine experts than any of their parents. The leaf nodes are taken as the final experts and a classifier network is then trained to predict the correct specialty for a given test image patch. The proposed model achieves higher count accuracy on major crowd datasets. Further, we analyse the characteristics of specialties mined automatically by our method.",
        "A1": "Automated counting of people in crowd images",
        "A2": "the large diversity in the way people appear in crowds",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "progressively increase its capacity to account for the wide variability seen in crowd scenes",
        "A7": "The proposed model achieves higher count accuracy on major crowd datasets.",
        "A83": "",
        "A82": "",
        "A81": "higher count accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "we analyse the characteristics of specialties mined automatically by our method.",
        "A53": " This hierarchical training leads to a CNN tree, where the child regressors are more fine experts than any of their parents",
        "A43": "without any hand-crafted criteria for forming specialties, the child regressors become experts on certain types of crowds",
        "A62": "",
        "A52": "a base CNN density regressor",
        "A42": "a growing CNN which can progressively increase its capacity to account for the wide variability seen in crowd scenes",
        "A45": "major crowd datasets",
        "am_id": 296156575
    },
    {
        "Abstract": "Diagrams often depict complex phenomena and serve as a good test bed for visual and textual reasoning. However, understanding diagrams using natural image understanding approaches requires large training datasets of diagrams, which are very hard to obtain. Instead, this can be addressed as a matching problem either between labeled diagrams, images or both. This problem is very challenging since the absence of significant color and texture renders local cues ambiguous and requires global reasoning. We consider the problem of one-shot part labeling: labeling multiple parts of an object in a target image given only a single source image of that category. For this set-to-set matching problem, we introduce the Structured Set Matching Network (SSMN), a structured prediction model that incorporates convolutional neural networks. The SSMN is trained using global normalization to maximize local match scores between corresponding elements and a global consistency score among all matched elements, while also enforcing a matching constraint between the two sets. The SSMN significantly outperforms several strong baselines on three label transfer scenarios: diagram-to-diagram, evaluated on a new diagram dataset of over 200 categories; image-to-image, evaluated on a dataset built on top of the Pascal Part Dataset; and image-to-diagram, evaluated on transferring labels across these datasets.",
        "A1": "abeling multiple parts of an object in a target image given only a single source image of that category",
        "A2": "understanding diagrams",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The SSMN significantly outperforms several strong baselines on three label transfer scenarios",
        "A7": "on three label transfer scenarios: diagram-to-diagram, evaluated on a new diagram dataset of over 200 categories; image-to-image, evaluated on a dataset built on top of the Pascal Part Dataset; and image-to-diagram, evaluated on transferring labels across these datasets",
        "A83": "",
        "A82": "",
        "A81": "The SSMN significantly outperforms several strong baselines on three label transfer scenarios",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "The SSMN significantly outperforms several strong baselines on three label transfer scenarios",
        "A52": " convolutional neural networks",
        "A42": "a structured prediction model that incorporates convolutional neural networks",
        "A45": "",
        "am_id": 250956859
    },
    {
        "Abstract": "Do visual tasks have a relationship, or are they unrelated? For instance, could having surface normals simplify estimating the depth of an image? Intuition answers these questions positively, implying existence of a structure among visual tasks. Knowing this structure has notable values; it is the concept underlying transfer learning and provides a principled way for identifying redundancies across tasks, e.g., to seamlessly reuse supervision among related tasks or solve many tasks in one system without piling up the complexity. We proposes a fully computational approach for modeling the structure of space of visual tasks. This is done via finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space. The product is a computational taxonomic map for task transfer learning. We study the consequences of this structure, e.g. nontrivial emerged relationships, and exploit them to reduce the demand for labeled data. We provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases.",
        "A1": "a fully computational approach for modeling the structure of space of visual tasks",
        "A2": "visual tasks",
        "A41": "finding (first and higher-order) transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D, and semantic tasks in a latent space",
        "A51": "",
        "A61": "",
        "A10": "provide a set of tools for computing and probing this taxonomical structure including a solver users can employ to find supervision policies for their use cases",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 455795771
    },
    {
        "Abstract": "In this work, we present a method for unsupervised domain adaptation. Many adversarial learning methods train domain classifier networks to distinguish the features as either a source or target and train a feature generator network to mimic the discriminator. Two problems exist with these methods. First, the domain classifier only tries to distinguish the features as a source or target and thus does not consider task-specific decision boundaries between classes. Therefore, a trained generator can generate ambiguous features near class boundaries. Second, these methods aim to completely match the feature distributions between different domains, which is difficult because of each domain's characteristics. To solve these problems, we introduce a new approach that attempts to align distributions of source and target by utilizing the task-specific decision boundaries. We propose to maximize the discrepancy between two classifiers' outputs to detect target samples that are far from the support of the source. A feature generator learns to generate target features near the support to minimize the discrepancy. Our method outperforms other methods on several datasets of image classification and semantic segmentation. The codes are available at https://github.com/mil-tokyo/MCD_DA",
        "A1": "present a method for unsupervised domain adaptation",
        "A2": "Two problems exist with these methods. First, the domain classifier only tries to distinguish the features as a source or target and thus does not consider task-specific decision boundaries between classes. Therefore, a trained generator can generate ambiguous features near class boundaries. Second, these methods aim to completely match the feature distributions between different domains, which is difficult because of each domain's characteristics. ",
        "A41": " a new approach that attempts to align distributions of source and target by utilizing the task-specific decision boundaries. We propose to maximize the discrepancy between two classifiers' outputs to detect target samples that are far from the support of the source",
        "A51": "",
        "A61": "maximize the discrepancy between two classifiers' outputs to detect target samples that are far from the support of the source",
        "A10": "",
        "A7": "several datasets of image classification and semantic segmentation",
        "A83": "",
        "A82": "",
        "A81": "Our method outperforms other methods ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 358253417
    },
    {
        "Abstract": "Visual Domain Adaptation is a problem of immense importance in computer vision. Previous approaches showcase the inability of even deep neural networks to learn informative representations across domain shift. This problem is more severe for tasks where acquiring hand labeled data is extremely hard and tedious. In this work, we focus on adapting the representations learned by segmentation networks across synthetic and real domains. Contrary to previous approaches that use a simple adversarial objective or superpixel information to aid the process, we propose an approach based on Generative Adversarial Networks (GANs) that brings the embeddings closer in the learned feature space. To showcase the generality and scalability of our approach, we show that we can achieve state of the art results on two challenging scenarios of synthetic to real domain adaptation. Additional exploratory experiments show that our approach: (1) generalizes to unseen domains and (2) results in improved alignment of source and target distributions.",
        "A1": " focus on adapting the representations learned by segmentation networks across synthetic and real domains",
        "A2": "the inability of even deep neural networks to learn informative representations across domain shift",
        "A41": "an approach based on Generative Adversarial Networks (GANs) that brings the embeddings closer in the learned feature space",
        "A51": "Generative Adversarial Networks (GANs)",
        "A61": "we can achieve state of the art results on two challenging scenarios of synthetic to real domain adaptation",
        "A10": "can achieve state of the art results on two challenging scenarios of synthetic to real domain adaptation",
        "A7": "Additional exploratory experiments",
        "A83": "",
        "A82": "results in improved alignment of source and target distributions",
        "A81": "generalizes to unseen domains",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 438274465
    },
    {
        "Abstract": "Recent advances in multi-stage algorithms have shown great promise, but two important problems still remain. First of all, at inference time, information can't feed back from downstream to upstream. Second, at training time, end-to-end training is not possible if the overall pipeline involves non-differentiable functions, and so different stages can't be jointly optimized. In this paper, we propose a novel environment upgrade reinforcement learning framework to solve the feedback and joint optimization problems. Our framework re-links the downstream stage to the upstream stage by a reinforcement learning agent. While training the agent to improve final performance by refining the upstream stage's output, we also upgrade the downstream stage (environment) according to the agent's policy. In this way, agent policy and environment are jointly optimized. We propose a training algorithm for this framework to address the different training demands of agent and environment. Experiments on instance segmentation and human pose estimation demonstrate the effectiveness of the proposed framework.",
        "A1": "we propose a novel environment upgrade reinforcement learning framework to solve the feedback and joint optimization problems",
        "A2": "agent policy and environment are jointly optimized. ",
        "A41": "we propose a novel environment upgrade reinforcement learning framework to solve the feedback and joint optimization problems",
        "A51": "a novel environment upgrade reinforcement learning framework",
        "A61": "agent policy and environment are jointly optimized",
        "A10": "Experiments on instance segmentation and human pose estimation demonstrate the effectiveness of the proposed framework.",
        "A7": "Experiments on instance segmentation and human pose estimation demonstrate the effectiveness of the proposed framework.",
        "A83": "upgrade the downstream stage (environment) according to the agent's policy.",
        "A82": "address the different training demands of agent and environment",
        "A81": "agent policy and environment are jointly optimized.",
        "A64": "agent policy and environment are jointly optimized. We propose a training algorithm for this framework to address the different training demands of agent and environment.",
        "A54": "a reinforcement learning agent",
        "A44": "we propose a novel environment upgrade reinforcement learning framework to solve the feedback and joint optimization problems",
        "A63": "agent policy and environment are jointly optimized",
        "A53": "a novel environment upgrade reinforcement learning framework",
        "A43": "we propose a novel environment upgrade reinforcement learning framework to solve the feedback and joint optimization problems",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 297931670
    },
    {
        "Abstract": "Many computer vision applications require robust estimation of the underlying geometry, in terms of camera motion and 3D structure of the scene. These robust methods often rely on running minimal solvers in a RANSAC framework. In this paper we show how we can make polynomial solvers based on the action matrix method faster, by careful selection of the monomial bases. These monomial bases have traditionally been based on a Grobner basis for the polynomial ideal. Here we describe how we can enumerate all such bases in an efficient way. We also show that going beyond Grobner bases leads to more efficient solvers in many cases. We present a novel basis sampling scheme that we evaluate on a number of problems.",
        "A1": " show how we can make polynomial solvers based on the action matrix method faster, by careful selection of the monomial bases",
        "A2": "describe how we can enumerate all such bases in an efficient way",
        "A41": "make polynomial solvers based on the action matrix method faster",
        "A51": "careful selection of the monomial bases",
        "A61": "leads to more efficient solvers in many cases",
        "A10": "make polynomial solvers based on the action matrix method faster",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 28717981
    },
    {
        "Abstract": "Unsupervised domain adaptation (UDA) conventionally assumes labeled source samples coming from a single underlying source distribution. Whereas in practical scenario, labeled data are typically collected from diverse sources. The multiple sources are different not only from the target but also from each other, thus, domain adaptater should not be modeled in the same way. Moreover, those sources may not completely share their categories, which further brings a new transfer challenge called category shift. In this paper, we propose a deep cocktail network (DCTN) to battle the domain and category shifts among multiple sources. Motivated by the theoretical results in [33], the target distribution can be represented as the weighted combination of source distributions, and, the multi-source UDA via DCTN is then performed as two alternating steps: i) It deploys multi-way adversarial learning to minimize the discrepancy between the target and each of the multiple source domains, which also obtains the source-specific perplexity scores to denote the possibilities that a target sample belongs to different source domains. ii) The multi-source category classifiers are integrated with the perplexity scores to classify target sample, and the pseudo-labeled target samples together with source samples are utilized to update the multi-source category classifier and the feature extractor. We evaluate DCTN in three domain adaptation benchmarks, which clearly demonstrate the superiority of our framework.",
        "A1": "Unsupervised domain adaptation (UDA) conventionally assumes labeled source samples coming from a single underlying source distribution.",
        "A2": "Whereas in practical scenario, labeled data are typically collected from diverse sources. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "We evaluate DCTN in three domain adaptation benchmarks, which clearly demonstrate the superiority of our framework.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Motivated by the theoretical results in [33], the target distribution can be represented as the weighted combination of source distributions",
        "A52": "i) It deploys multi-way adversarial learning to minimize the discrepancy between the target and each of the multiple source domains, which also obtains the source-specific perplexity scores to denote the possibilities that a target sample belongs to different source domains. ii) The multi-source category classifiers are integrated with the perplexity scores to classify target sample, and the pseudo-labeled target samples together with source samples are utilized to update the multi-source category classifier and the feature extractor. ",
        "A42": "we propose a deep cocktail network (DCTN) to battle the domain and category shifts among multiple sources.",
        "A45": "",
        "am_id": 173411373
    },
    {
        "Abstract": "Object detection is an important and challenging problem in computer vision. Although the past decade has witnessed major advances in object detection in natural scenes, such successes have been slow to aerial imagery, not only because of the huge variation in the scale, orientation and shape of the object instances on the earth's surface, but also due to the scarcity of well-annotated datasets of objects in aerial scenes. To advance object detection research in Earth Vision, also known as Earth Observation and Remote Sensing, we introduce a large-scale Dataset for Object deTection in Aerial images (DOTA). To this end, we collect 2806 aerial images from different sensors and platforms. Each image is of the size about 4000 \u00c3\u2014 4000 pixels and contains objects exhibiting a wide variety of scales, orientations, and shapes. These DOTA images are then annotated by experts in aerial image interpretation using 15 common object categories. The fully annotated DOTA images contains 188, 282 instances, each of which is labeled by an arbitrary (8 d.o.f.) quadrilateral. To build a baseline for object detection in Earth Vision, we evaluate state-of-the-art object detection algorithms on DOTA. Experiments demonstrate that DOTA well represents real Earth Vision applications and are quite challenging.",
        "A1": " To advance object detection research in Earth Vision, also known as Earth Observation and Remote Sensing",
        "A2": "Object detection",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "we evaluate state-of-the-art object detection algorithms on DOTA.",
        "A83": "",
        "A82": "",
        "A81": "DOTA well represents real Earth Vision applications and are quite challenging.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "DOTA",
        "A43": "state-of-the-art object detection algorithms",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "we introduce a large-scale Dataset for Object deTection in Aerial images (DOTA)",
        "am_id": 255717042
    },
    {
        "Abstract": "Several works have proposed to learn a two-path neural network that maps images and texts, respectively, to a same shared Euclidean space where geometry captures useful semantic relationships. Such a multi-modal embedding can be trained and used for various tasks, notably image captioning. In the present work, we introduce a new architecture of this type, with a visual path that leverages recent spaceaware pooling mechanisms. Combined with a textual path which is jointly trained from scratch, our semantic-visual embedding offers a versatile model. Once trained under the supervision of captioned images, it yields new state-of-the-art performance on cross-modal retrieval. It also allows the localization of new concepts from the embedding space into any input image, delivering state-of-the-art result on the visual grounding of phrases.",
        "A1": "introduce a new architecture of this type, with a visual path that leverages recent spaceaware pooling mechanisms",
        "A2": "offers a versatile model.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "yields new state-of-the-art performance on cross-modal retrieval",
        "A7": "trained under the supervision of captioned images",
        "A83": "allows the localization of new concepts from the embedding space into any input image",
        "A82": "yields new state-of-the-art performance on cross-modal retrieval",
        "A81": "state-of-the-art result on the visual grounding of phrases.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " yields new state-of-the-art performance on cross-modal retrieval. It ",
        "A52": " semantic-visual embedding ",
        "A42": "a new architecture of this type, with a visual path that leverages recent spaceaware pooling mechanisms. ",
        "A45": "",
        "am_id": 370559547
    },
    {
        "Abstract": "Object detection in wide area motion imagery (WAMI) has drawn the attention of the computer vision research community for a number of years. WAMI proposes a number of unique challenges including extremely small object sizes, both sparse and densely-packed objects, and extremely large search spaces (large video frames). Nearly all state-of-the-art methods in WAMI object detection report that appearance-based classifiers fail in this challenging data and instead rely almost entirely on motion information in the form of background subtraction or frame-differencing. In this work, we experimentally verify the failure of appearance-based classifiers in WAMI, such as Faster R-CNN and a heatmap-based fully convolutional neural network (CNN), and propose a novel two-stage spatio-temporal CNN which effectively and efficiently combines both appearance and motion information to significantly surpass the state-of-the-art in WAMI object detection. To reduce the large search space, the first stage (ClusterNet) takes in a set of extremely large video frames, combines the motion and appearance information within the convolutional architecture, and proposes regions of objects of interest (ROOBI). These ROOBI can contain from one to clusters of several hundred objects due to the large video frame size and varying object density in WAMI. The second stage (FoveaNet) then estimates the centroid location of all objects in that given ROOBI simultaneously via heatmap estimation. The proposed method exceeds state-of-the-art results on the WPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped objects, as well as being the first proposed method in wide area motion imagery to detect completely stationary objects.",
        "A1": "propose a novel two-stage spatio-temporal CNN ",
        "A2": " effectively and efficiently combines both appearance and motion information to significantly surpass the state-of-the-art in WAMI object detection.",
        "A41": "a novel two-stage spatio-temporal CNN which effectively and efficiently combines both appearance and motion information to significantly surpass the state-of-the-art in WAMI object detection. ",
        "A51": " the first stage (ClusterNet) takes in a set of extremely large video frames, combines the motion and appearance information within the convolutional architecture, and proposes regions of objects of interest (ROOBI). These ROOBI can contain from one to clusters of several hundred objects due to the large video frame size and varying object density in WAMI. The second stage (FoveaNet) then estimates the centroid location of all objects in that given ROOBI simultaneously via heatmap estimation. ",
        "A61": "CNN which effectively and efficiently combines both appearance and motion information to significantly surpass the state-of-the-art in WAMI object detection.",
        "A10": "The proposed method exceeds state-of-the-art results on the WPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped objects, as well as being the first proposed method in wide area motion imagery to detect completely stationary objects.",
        "A7": "WPAFB 2009 dataset",
        "A83": "",
        "A82": "",
        "A81": "The proposed method exceeds state-of-the-art results on the WPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped objects, as well as being the first proposed method in wide area motion imagery to detect completely stationary objects.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 270656997
    },
    {
        "Abstract": "Given a natural language query, a phrase grounding system aims to localize mentioned objects in an image. In weakly supevised scenario, mapping between image regions (i.e., proposals) and language is not available in the training set. Previous methods address this deficiency by training a grounding system via learning to reconstruct language information contained in input queries from predicted proposals. However, the optimization is solely guided by the reconstruction loss from the language modality, and ignores rich visual information contained in proposals and useful cues from external knowledge. In this paper, we explore the consistency contained in both visual and language modalities, and leverage complementary external knowledge to facilitate weakly supervised grounding. We propose a novel Knowledge Aided Consistency Network (KAC Net) which is optimized by reconstructing input query and proposal's information. To leverage complementary knowledge contained in the visual features, we introduce a Knowledge Based Pooling (KBP) gate to focus on query-related proposals. Experiments show that KAC Net provides a significant improvement on two popular datasets.",
        "A1": "In this paper, we explore the consistency contained in both visual and language modalities, and leverage complementary external knowledge to facilitate weakly supervised grounding.",
        "A2": "However, the optimization is solely guided by the reconstruction loss from the language modality, and ignores rich visual information contained in proposals and useful cues from external knowledge.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experiments show that KAC Net provides a significant improvement on two popular datasets.",
        "A64": "",
        "A54": "",
        "A44": "a novel Knowledge Aided Consistency Network",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 120292132
    },
    {
        "Abstract": "For object detection, the two-stage approach (e.g., Faster R-CNN) has been achieving the highest accuracy, whereas the one-stage approach (e.g., SSD) has the advantage of high efficiency. To inherit the merits of both while overcoming their disadvantages, in this paper, we propose a novel single-shot based detector, called RefineDet, that achieves better accuracy than two-stage methods and maintains comparable efficiency of one-stage methods. RefineDet consists of two inter-connected modules, namely, the anchor refinement module and the object detection module. Specifically, the former aims to (1) filter out negative anchors to reduce search space for the classifier, and (2) coarsely adjust the locations and sizes of anchors to provide better initialization for the subsequent regressor. The latter module takes the refined anchors as the input from the former to further improve the regression accuracy and predict multi-class label. Meanwhile, we design a transfer connection block to transfer the features in the anchor refinement module to predict locations, sizes and class labels of objects in the object detection module. The multitask loss function enables us to train the whole network in an end-to-end way. Extensive experiments on PASCAL VOC 2007, PASCAL VOC 2012, and MS COCO demonstrate that RefineDet achieves state-of-the-art detection accuracy with high efficiency. Code is available at https://github.com/sfzhang15/RefineDet.",
        "A1": "propose a novel single-shot based detector, called RefineDet, that achieves better accuracy than two-stage methods and maintains comparable efficiency of one-stage methods",
        "A2": "inherit the merits of both while overcoming their disadvantages",
        "A41": "RefineDet consists of two inter-connected modules, namely, the anchor refinement module and the object detection module",
        "A51": "the two-stage approach (e.g., Faster R-CNN) has been achieving the highest accuracy, whereas the one-stage approach (e.g., SSD) has the advantage of high efficiency",
        "A61": "inherit the merits of both while overcoming their disadvantages",
        "A10": "achieves better accuracy than two-stage methods and maintains comparable efficiency of one-stage methods",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 311427959
    },
    {
        "Abstract": "Thanks to the success of deep learning, cross-modal retrieval has made significant progress recently. However, there still remains a crucial bottleneck: how to bridge the modality gap to further enhance the retrieval accuracy. In this paper, we propose a self-supervised adversarial hashing (SSAH) approach, which lies among the early attempts to incorporate adversarial learning into cross-modal hashing in a self-supervised fashion. The primary contribution of this work is that two adversarial networks are leveraged to maximize the semantic correlation and consistency of the representations between different modalities. In addition, we harness a self-supervised semantic network to discover high-level semantic information in the form of multi-label annotations. Such information guides the feature learning process and preserves the modality relationships in both the common semantic space and the Hamming space. Extensive experiments carried out on three benchmark datasets validate that the proposed SSAH surpasses the state-of-the-art methods.",
        "A1": " bridge the modality gap to further enhance the retrieval accuracy",
        "A2": "two adversarial networks are leveraged to maximize the semantic correlation and consistency of the representations between different modalities",
        "A41": "self-supervised adversarial hashing (SSAH) approach",
        "A51": " two adversarial networks",
        "A61": "",
        "A10": "",
        "A7": "Extensive experiments carried out on three benchmark datasets",
        "A83": "",
        "A82": "preserves the modality relationships in both the common semantic space and the Hamming space",
        "A81": "guides the feature learning process",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 351710833
    },
    {
        "Abstract": "When learning functions on manifolds, we can improve performance by regularizing with respect to the intrinsic manifold geometry rather than the ambient space. However, when regularizing tensor learning, calculating the derivatives along this intrinsic geometry is not possible, and so existing approaches are limited to regularizing in Euclidean space. Our new method for intrinsically regularizing and learning tensors on Riemannian manifolds introduces a surrogate object to encapsulate the geometric characteristic of the tensor. Regularizing this instead allows us to learn non-symmetric and high-order tensors. We apply our approach to the relative attributes problem, and we demonstrate that explicitly regularizing high-order relationships between pairs of data points improves performance.",
        "A1": "Our new method for intrinsically regularizing and learning tensors on Riemannian manifolds introduces a surrogate object to encapsulate the geometric characteristic of the tensor",
        "A2": "explicitly regularizing high-order relationships between pairs of data points improves performance",
        "A41": "Our new method for intrinsically regularizing and learning tensors on Riemannian manifolds",
        "A51": " introduces a surrogate object to encapsulate the geometric characteristic of the tensor",
        "A61": "allows us to learn non-symmetric and high-order tensors. ",
        "A10": "that explicitly regularizing high-order relationships between pairs of data points improves performance",
        "A7": "We apply our approach to the relative attributes problem",
        "A83": "",
        "A82": "",
        "A81": "that explicitly regularizing high-order relationships between pairs of data points improves performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 494809942
    },
    {
        "Abstract": "A family of super deep networks, referred to as residual networks or ResNet [14], achieved record-beating performance in various visual tasks such as image recognition, object detection, and semantic segmentation. The ability to train very deep networks naturally pushed the researchers to use enormous resources to achieve the best performance. Consequently, in many applications super deep residual networks were employed for just a marginal improvement in performance. In this paper, we propose \u00e2\u02c6\u0160-ResNet that allows us to automatically discard redundant layers, which produces responses that are smaller than a threshold \u00e2\u02c6\u0160, without any loss in performance. The \u00e2\u02c6\u0160-ResNet architecture can be achieved using a few additional rectified linear units in the original ResNet. Our method does not use any additional variables nor numerous trials like other hyperparameter optimization techniques. The layer selection is achieved using a single training process and the evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. In some instances, we achieve about 80% reduction in the number of parameters.",
        "A1": "",
        "A2": " super deep residual networks were employed for just a marginal improvement in performance",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "80% reduction in the number of parameters",
        "A7": " the evaluation is performed on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets",
        "A83": "",
        "A82": "In some instances, we achieve about 80% reduction in the number of parameters",
        "A81": "produces responses that are smaller than a threshold \u00e2\u02c6\u0160, without any loss in performance",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "Our method does not use any additional variables nor numerous trials like other hyperparameter optimization techniques",
        "A52": "",
        "A42": "\u00e2\u02c6\u0160-ResNet that allows us to automatically discard redundant layers",
        "A45": "",
        "am_id": 343926852
    },
    {
        "Abstract": "We study how to synthesize novel views of human body from a single image. Though recent deep learning based methods work well for rigid objects, they often fail on objects with large articulation, like human bodies. The core step of existing methods is to fit a map from the observable views to novel views by CNNs; however, the rich articulation modes of human body make it rather challenging for CNNs to memorize and interpolate the data well. To address the problem, we propose a novel deep learning based pipeline that explicitly estimates and leverages the geometry of the underlying human body. Our new pipeline is a composition of a shape estimation network and an image generation network, and at the interface a perspective transformation is applied to generate a forward flow for pixel value transportation. Our design is able to factor out the space of data variation and makes learning at each step much easier. Empirically, we show that the performance for pose-varying objects can be improved dramatically. Our method can also be applied on real data captured by 3D sensors, and the flow generated by our methods can be used for generating high quality results in higher resolution.",
        "A1": "We study how to synthesize novel views of human body from a single image. ",
        "A2": " Though recent deep learning based methods work well for rigid objects, they often fail on objects with large articulation, like human bodies.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "Our new pipeline is a composition of a shape estimation network and an image generation network, and at the interface a perspective transformation is applied to generate a forward flow for pixel value transportation.",
        "A7": "",
        "A83": "",
        "A82": "Our method can also be applied on real data captured by 3D sensors, and the flow generated by our methods can be used for generating high quality results in higher resolution.",
        "A81": "Empirically, we show that the performance for pose-varying objects can be improved dramatically. ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 35566961
    },
    {
        "Abstract": "We propose a general framework for unsupervised domain adaptation, which allows deep neural networks trained on a source domain to be tested on a different target domain without requiring any training annotations in the target domain. This is achieved by adding extra networks and losses that help regularize the features extracted by the backbone encoder network. To this end we propose the novel use of the recently proposed unpaired image-to-image translation framework to constrain the features extracted by the encoder network. Specifically, we require that the features extracted are able to reconstruct the images in both domains. In addition we require that the distribution of features extracted from images in the two domains are indistinguishable. Many recent works can be seen as specific cases of our general framework. We apply our method for domain adaptation between MNIST, USPS, and SVHN datasets, and Amazon, Webcam and DSLR Office datasets in classification tasks, and also between GTA5 and Cityscapes datasets for a segmentation task. We demonstrate state of the art performance on each of these datasets.",
        "A1": " propose a general framework for unsupervised domain adaptation",
        "A2": "allows deep neural networks trained on a source domain to be tested on a different target domain",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "demonstrate state of the art performance on each of these datasets",
        "A7": "specific cases of our general framework",
        "A83": "between GTA5 and Cityscapes datasets for a segmentation task",
        "A82": "Amazon, Webcam and DSLR Office datasets in classification tasks",
        "A81": " apply our method for domain adaptation",
        "A64": " the features extracted are able to reconstruct the images in both domains",
        "A54": "the encoder network",
        "A44": "unpaired image-to-image translation framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": " DSLR Office datasets",
        "am_id": 98885784
    },
    {
        "Abstract": "Popular research areas like autonomous driving and augmented reality have renewed the interest in image-based camera localization. In this work, we address the task of predicting the 6D camera pose from a single RGB image in a given 3D environment. With the advent of neural networks, previous works have either learned the entire camera localization process, or multiple components of a camera localization pipeline. Our key contribution is to demonstrate and explain that learning a single component of this pipeline is sufficient. This component is a fully convolutional neural network for densely regressing so-called scene coordinates, defining the correspondence between the input image and the 3D scene space. The neural network is prepended to a new end-to-end trainable pipeline. Our system is efficient, highly accurate, robust in training, and exhibits outstanding generalization capabilities. It exceeds state-of-the-art consistently on indoor and outdoor datasets. Interestingly, our approach surpasses existing techniques even without utilizing a 3D model of the scene during training, since the network is able to discover 3D scene geometry automatically, solely from single-view constraints.",
        "A1": "we address the task of predicting the 6D camera pose from a single RGB image in a given 3D environment.",
        "A2": " the task of predicting the 6D camera pose from a single RGB image in a given 3D environment. ",
        "A41": "task of predicting the 6D camera pose from a single RGB image in a given 3D environment",
        "A51": "Popular research areas like autonomous driving and augmented reality have renewed the interest in image-based camera localization.",
        "A61": "previous works have either learned the entire camera localization process, or multiple components of a camera localization pipeline. ",
        "A10": "Our system is efficient, highly accurate, robust in training, and exhibits outstanding generalization capabilitie",
        "A7": "The neural network is prepended to a new end-to-end trainable pipeline.",
        "A83": "",
        "A82": "",
        "A81": "our approach surpasses existing techniques even without utilizing a 3D model of the scene during traini",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 365567995
    },
    {
        "Abstract": "It has been recently shown that a convolutional neural network can learn optical flow estimation with unsupervised learning. However, the performance of the unsupervised methods still has a relatively large gap compared to its supervised counterpart. Occlusion and large motion are some of the major factors that limit the current unsupervised learning of optical flow methods. In this work we introduce a new method which models occlusion explicitly and a new warping way that facilitates the learning of large motion. Our method shows promising results on Flying Chairs, MPI-Sintel and KITTI benchmark datasets. Especially on KITTI dataset where abundant unlabeled samples exist, our unsupervised method outperforms its counterpart trained with supervised learning.",
        "A1": "introduce a new method which models occlusion explicitly and a new warping way that facilitates the learning of large motion",
        "A2": "Occlusion and large motion",
        "A41": " a new method which models occlusion explicitly and a new warping way that facilitates the learning of large motion",
        "A51": "",
        "A61": "our unsupervised method outperforms its counterpart trained with supervised learning.",
        "A10": "",
        "A7": " on Flying Chairs, MPI-Sintel and KITTI benchmark datasets.",
        "A83": "",
        "A82": "",
        "A81": " our unsupervised method outperforms its counterpart trained with supervised learning.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 96039859
    },
    {
        "Abstract": "People detection methods are highly sensitive to occlusions between pedestrians, which are extremely frequent in many situations where cameras have to be mounted at a limited height. The reduction of camera prices allows for the generalization of static multi-camera set-ups. Using joint visual information from multiple synchronized cameras gives the opportunity to improve detection performance. In this paper, we present a new large-scale and high-resolution dataset. It has been captured with seven static cameras in a public open area, and unscripted dense groups of pedestrians standing and walking. Together with the camera frames, we provide an accurate joint (extrinsic and intrinsic) calibration, as well as 7 series of 400 annotated frames for detection at a rate of 2 frames per second. This results in over 40 000 bounding boxes delimiting every person present in the area of interest, for a total of more than 300 individuals. We provide a series of benchmark results using baseline algorithms published over the recent months for multi-view detection with deep neural networks, and trajectory estimation using a non-Markovian model.",
        "A1": " present a new large-scale and high-resolution dataset",
        "A2": " captured with seven static cameras in a public open area,",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "This results in over 40 000 bounding boxes delimiting every person present in the area of interest, for a total of more than 300 individuals",
        "A7": " provide an accurate joint (extrinsic and intrinsic) calibration, ",
        "A83": "trajectory estimation using a non-Markovian model",
        "A82": "provide a series of benchmark results using baseline algorithms published over the recent months for multi-view detection ",
        "A81": "boxes delimiting every person present in the area of interest, ",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "unscripted dense groups of pedestrians standing and walking.",
        "am_id": 394214670
    },
    {
        "Abstract": "Facial action units (AUs) play an important role in human emotion understanding. One big challenge for data-driven AU recognition approaches is the lack of enough AU annotations, since AU annotation requires strong domain expertise. To alleviate this issue, we propose a knowledge-driven method for jointly learning multiple AU classifiers without any AU annotation by leveraging prior probabilities on AUs, including expression-independent and expression-dependent AU probabilities. These prior probabilities are drawn from facial anatomy and emotion studies, and are independent of datasets. We incorporate the prior probabilities on AUs as the constraints into the objective function of multiple AU classifiers, and develop an efficient learning algorithm to solve the formulated problem. Experimental results on five benchmark expression databases demonstrate the effectiveness of the proposed method, especially its generalization ability, and the power of the prior probabilities.",
        "A1": "data-driven AU recognition approaches",
        "A2": "the lack of enough AU annotations",
        "A41": "a knowledge-driven method",
        "A51": "leveraging prior probabilities on AUs",
        "A61": "independent of datasets",
        "A10": "",
        "A7": " five benchmark expression databases",
        "A83": "the power of the prior probabilities",
        "A82": "its generalization ability",
        "A81": "the effectiveness of the proposed method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 405726165
    },
    {
        "Abstract": "Recently, remarkable advances have been achieved in 3D human pose estimation from monocular images because of the powerful Deep Convolutional Neural Networks (DCNNs). Despite their success on large-scale datasets collected in the constrained lab environment, it is difficult to obtain the 3D pose annotations for in-the-wild images. Therefore, 3D human pose estimation in the wild is still a challenge. In this paper, we propose an adversarial learning framework, which distills the 3D human pose structures learned from the fully annotated dataset to in-the-wild images with only 2D pose annotations. Instead of defining hard-coded rules to constrain the pose estimation results, we design a novel multi-source discriminator to distinguish the predicted 3D poses from the ground-truth, which helps to enforce the pose estimator to generate anthropometrically valid poses even with images in the wild. We also observe that a carefully designed information source for the discriminator is essential to boost the performance. Thus, we design a geometric descriptor, which computes the pairwise relative locations and distances between body joints, as a new information source for the discriminator. The efficacy of our adversarial learning framework with the new geometric descriptor has been demonstrated through extensive experiments on widely used public benchmarks. Our approach significantly improves the performance compared with previous state-of-the-art approaches.",
        "A1": "propose an adversarial learning framework",
        "A2": "distinguish the predicted 3D poses from the ground-truth",
        "A41": "adversarial learning framework with the new geometric descriptor",
        "A51": "adversarial learning framework with the new geometric descriptor",
        "A61": "Instead of defining hard-coded rules to constrain the pose estimation results, we design a novel multi-source discriminator to distinguish the predicted 3D poses from the ground-truth",
        "A10": "",
        "A7": "experiments on widely used public benchmarks",
        "A83": "",
        "A82": "",
        "A81": "Our approach significantly improves the performance compared with previous state-of-the-art approaches.",
        "A64": "",
        "A54": "the fully annotated dataset to in-the-wild images with only 2D pose annotations",
        "A44": "an adversarial learning framework,",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 483870967
    },
    {
        "Abstract": "Age estimation has wide applications in video surveillance, social networking, and human-computer interaction. Many of the published approaches simply treat age estimation as an exact age regression problem, and thus do not leverage a distribution's robustness in representing labels with ambiguity such as ages. In this paper, we propose a new loss function, called mean-variance loss, for robust age estimation via distribution learning. Specifically, the mean-variance loss consists of a mean loss, which penalizes difference between the mean of the estimated age distribution and the ground-truth age, and a variance loss, which penalizes the variance of the estimated age distribution to ensure a concentrated distribution. The proposed mean-variance loss and softmax loss are jointly embedded into Convolutional Neural Networks (CNNs) for age estimation. Experimental results on the FG-NET, MORPH Album II, CLAP2016, and AADB databases show that the proposed approach outperforms the state-of-the-art age estimation methods by a large margin, and generalizes well to image aesthetics assessment.",
        "A1": "propose a new loss function",
        "A2": " for robust age estimation via distribution learning",
        "A41": "Experimental results on the FG-NET, MORPH Album II, CLAP2016, and AADB databases",
        "A51": "CNNs",
        "A61": " the proposed approach outperforms the state-of-the-art age estimation methods ",
        "A10": " jointly embedded into Convolutional Neural Networks (CNNs) for age estimation.",
        "A7": " generalizes well to image aesthetics assessment.",
        "A83": "distribution and the ground-truth age, and a variance loss, which penalizes the variance of the estimated age",
        "A82": "leverage a distribution's robustness in representing labels with ambiguity such as ages.",
        "A81": "between the mean of the estimated age distributio",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 315904601
    },
    {
        "Abstract": "We present a novel method for co-registration of two independent statistical shape models. We solve the problem of aligning a face model to a skull model with stochastic optimization based on Markov Chain Monte Carlo (MCMC). We create a probabilistic joint face-skull model and show how to obtain a distribution of plausible face shapes given a skull shape. Due to environmental and genetic factors, there exists a distribution of possible face shapes arising from the same skull. We pose facial reconstruction as a conditional distribution of plausible face shapes given a skull shape. Because it is very difficult to obtain the distribution directly from MRI or CT data, we create a dataset of artificial face-skull pairs. To do this, we propose to combine three data sources of independent origin to model the joint face-skull distribution: a face shape model, a skull shape model and tissue depth marker information. For a given skull, we compute the posterior distribution of faces matching the tissue depth distribution with Metropolis-Hastings. We estimate the joint face-skull distribution from samples of the posterior. To find faces matching to an unknown skull, we estimate the probability of the face under the joint face-skull model. To our knowledge, we are the first to provide a whole distribution of plausible faces arising from a skull instead of only a single reconstruction. We show how the face-skull model can be used to rank a face dataset and on average successfully identify the correct match in top 30%. The face ranking even works when obtaining the face shapes from 2D images. We furthermore show how the face-skull model can be useful to estimate the skull position in an MR-image.",
        "A1": "present a novel method for co-registration of two independent statistical shape models",
        "A2": "co-registration of two independent statistical shape models",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "rank a face dataset and on average successfully identify the correct match in top 30%",
        "A83": "",
        "A82": " face-skull model can be useful to estimate the skull position in an MR-image",
        "A81": "face ranking even works when obtaining the face shapes from 2D images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the first to provide a whole distribution of plausible faces arising from a skull instead of only a single reconstruction",
        "A52": "Markov Chain Monte Carlo (MCMC)",
        "A42": "a novel method for co-registration of two independent statistical shape models",
        "A45": "",
        "am_id": 423937103
    },
    {
        "Abstract": "Multi-shot person re-identification (MsP-RID) utilizes multiple images from the same person to facilitate identification. Considering the fact that motion information may not be discriminative nor reliable enough for MsP-RID, this paper is focused on handling the large variations in the visual appearances through learning discriminative visual metrics for identification. Existing metric learning-based methods usually exploit pair-wise or triple-wise similarity constraints, that generally demands intensive optimization in metric learning, or leads to degraded performances by using sub-optimal solutions. In addition, as the training data are significantly imbalanced, the learning can be largely dominated by the negative pairs and thus produces unstable and non-discriminative results. In this paper, we propose a novel type of similarity constraint. It assigns the sample points to a set of reference points to produce a linear number of reference constraints. Several optimal transport-based schemes for reference constraint generation are proposed and studied. Based on those constraints, by utilizing a typical regressive metric learning model, the closed-form solution of the learned metric can be easily obtained. Extensive experiments and comparative studies on several public MsP-RID benchmarks have validated the effectiveness of our method and its significant superiority over the state-of-the-art MsP-RID methods in terms of both identification accuracy and running speed.",
        "A1": "learning discriminative visual metrics for identification",
        "A2": "handling the large variations in the visual appearances",
        "A41": "a novel type of similarity constraint",
        "A51": "optimal transport-based schemes",
        "A61": "",
        "A10": "",
        "A7": "public MsP-RID",
        "A83": "both identification accuracy and running speed",
        "A82": "its significant superiority over the state-of-the-art MsP-RID methods",
        "A81": "validated the effectiveness of our method",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 340505492
    },
    {
        "Abstract": "Recent work has shown that depth estimation from a stereo pair of images can be formulated as a supervised learning task to be resolved with convolutional neural networks (CNNs). However, current architectures rely on patch-based Siamese networks, lacking the means to exploit context information for finding correspondence in ill-posed regions. To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. The spatial pyramid pooling module takes advantage of the capacity of global context information by aggregating context in different scales and locations to form a cost volume. The 3D CNN learns to regularize cost volume using stacked multiple hourglass networks in conjunction with intermediate supervision. The proposed approach was evaluated on several benchmark datasets. Our method ranked first in the KITTI 2012 and 2015 leaderboards before March 18, 2018. The codes of PSMNet are available at: https://github.com/JiaRenChang/PSMNet.",
        "A1": "To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN. ",
        "A2": " To tackle this problem, we propose PSMNet, a pyramid stereo matching network consisting of two main modules: spatial pyramid pooling and 3D CNN.",
        "A41": "",
        "A51": " The proposed approach was evaluated on several benchmark datasets.",
        "A61": "",
        "A10": "",
        "A7": "The proposed approach was evaluated on several benchmark datasets.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "spatial pyramid pooling and 3D CNN",
        "A45": "",
        "am_id": 49510943
    },
    {
        "Abstract": "Finding views with good photo composition is a challenging task for machine learning methods. A key difficulty is the lack of well annotated large scale datasets. Most existing datasets only provide a limited number of annotations for good views, while ignoring the comparative nature of view selection. In this work, we present the first large scale Comparative Photo Composition dataset, which contains over one million comparative view pairs annotated using a cost-effective crowdsourcing workflow. We show that these comparative view annotations are essential for training a robust neural network model for composition. In addition, we propose a novel knowledge transfer framework to train a fast view proposal network, which runs at 75+ FPS and achieves state-of-the-art performance in image cropping and thumbnail generation tasks on three benchmark datasets. The superiority of our method is also demonstrated in a user study on a challenging experiment, where our method significantly outperforms the baseline methods in producing diversified well-composed views.",
        "A1": "Finding views with good photo composition",
        "A2": "the lack of well annotated large scale datasets",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our method significantly outperforms the baseline methods in producing diversified well-composed views",
        "A7": "",
        "A83": "",
        "A82": "The superiority of our method",
        "A81": "our method significantly outperforms the baseline methods in producing diversified well-composed views",
        "A64": "runs at 75+ FPS and achieves state-of-the-art performance in image cropping and thumbnail generation tasks on three benchmark datasets",
        "A54": "three benchmark datasets",
        "A44": "a novel knowledge transfer framework to train a fast view proposal network",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "the first large scale Comparative Photo Composition dataset, which contains over one million comparative view pairs annotated using a cost-effective crowdsourcing workflow",
        "am_id": 43262486
    },
    {
        "Abstract": "Recent works showed that Generative Adversarial Networks (GANs) can be successfully applied in unsupervised domain adaptation, where, given a labeled source dataset and an unlabeled target dataset, the goal is to train powerful classifiers for the target samples. In particular, it was shown that a GAN objective function can be used to learn target features indistinguishable from the source ones. In this work, we extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. While data augmentation in the image space is a well established technique in deep learning, feature augmentation has not yet received the same level of attention. We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features. Results show that both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks.",
        "A1": " extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation",
        "A2": " extend this framework by (i) forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation",
        "A41": "forcing the learned feature extractor to be domain-invariant, and (ii) training it through data augmentation in the feature space, namely performing feature augmentation. ",
        "A51": "Generative Adversarial Networks (GANs)",
        "A61": "",
        "A10": "",
        "A7": "We accomplish it by means of a feature generator trained by playing the GAN minimax game against source features",
        "A83": "",
        "A82": "",
        "A81": " both enforcing domain-invariance and performing feature augmentation lead to superior or comparable performance to state-of-the-art results in several unsupervised domain adaptation benchmarks.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 55564786
    },
    {
        "Abstract": "This paper introduces an online model for object detection in videos designed to run in real-time on low-powered mobile and embedded devices. Our approach combines fast single-image object detection with convolutional long short term memory (LSTM) layers to create an inter-weaved recurrent-convolutional architecture. Additionally, we propose an efficient Bottleneck-LSTM layer that significantly reduces computational cost compared to regular LSTMs. Our network achieves temporal awareness by using Bottleneck-LSTMs to refine and propagate feature maps across frames. This approach is substantially faster than existing detection methods in video, outperforming the fastest single-frame models in model size and computational cost while attaining accuracy comparable to much more expensive single-frame models on the Imagenet VID 2015 dataset. Our model reaches a real-time inference speed of up to 15 FPS on a mobile CPU.",
        "A1": "object detection in videos",
        "A2": "object detection in videos",
        "A41": "combines fast single-image object detection with convolutional long short term memory (LSTM) layers",
        "A51": "",
        "A61": "using Bottleneck-LSTMs",
        "A10": "a real-time inference speed of up to 15 FPS",
        "A7": "the Imagenet VID 2015 dataset",
        "A83": "",
        "A82": "",
        "A81": "reaches a real-time inference speed of up to 15 FPS on a mobile CPU",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 465705994
    },
    {
        "Abstract": "We address the problem of image segmentation from natural language descriptions. Existing deep learning-based methods encode image representations based on the output of the last convolutional layer. One general issue is that the resulting image representation lacks multi-scale semantics, which are key components in advanced segmentation systems. In this paper, we utilize the feature pyramids inherently existing in convolutional neural networks to capture the semantics at different scales. To produce suitable information flow through the path of feature hierarchy, we propose Recurrent Refinement Network (RRN) that takes pyramidal features as input to refine the segmentation mask progressively. Experimental results on four available datasets show that our approach outperforms multiple baselines and state-of-the-art1.",
        "A1": "utilize the feature pyramids inherently existing in convolutional neural networks to capture the semantics at different scales.",
        "A2": "the problem of image segmentation from natural language descriptions. ",
        "A41": "utilize the feature pyramids inherently existing in convolutional neural networks to capture the semantics at different scales. ",
        "A51": "RRN",
        "A61": "",
        "A10": "Existing deep learning-based methods encode image representations based on the output of the last convolutional layer.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experimental results on four available datasets show that our approach outperforms multiple baselines and state-of-the-art1.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 77889503
    },
    {
        "Abstract": "Evaluation metrics for image captioning face two challenges. Firstly, commonly used metrics such as CIDEr, METEOR, ROUGE and BLEU often do not correlate well with human judgments. Secondly, each metric has well known blind spots to pathological caption constructions, and rule-based metrics lack provisions to repair such blind spots once identified. For example, the newly proposed SPICE correlates well with human judgments, but fails to capture the syntactic structure of a sentence. To address these two challenges, we propose a novel learning based discriminative evaluation metric that is directly trained to distinguish between human and machine-generated captions. In addition, we further propose a data augmentation scheme to explicitly incorporate pathological transformations as negative examples during training. The proposed metric is evaluated with three kinds of robustness tests and its correlation with human judgments. Extensive experiments show that the proposed data augmentation scheme not only makes our metric more robust toward several pathological transformations, but also improves its correlation with human judgments. Our metric outperforms other metrics on both caption level human correlation in Flickr 8k and system level human correlation in COCO. The proposed approach could be served as a learning based evaluation metric that is complementary to existing rule-based metrics.",
        "A1": "",
        "A2": " Firstly, commonly used metrics such as CIDEr, METEOR, ROUGE and BLEU often do not correlate well with human judgments. Secondly, each metric has well known blind spots to pathological caption constructions, and rule-based metrics lack provisions to repair such blind spots once identified.",
        "A41": "a novel learning based discriminative evaluation metric ",
        "A51": "",
        "A61": "is directly trained to distinguish between human and machine-generated captions",
        "A10": "Our metric outperforms other metrics on both caption level human correlation in Flickr 8k and system level human correlation in COCO",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": " the proposed data augmentation scheme not only makes our metric more robust toward several pathological transformations, but also improves its correlation with human judgments",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 72906520
    },
    {
        "Abstract": "Existing methods to recognize actions in static images take the images at their face value, learning the appearances-objects, scenes, and body poses-that distinguish each action class. However, such models are deprived of the rich dynamic structure and motions that also define human activity. We propose an approach that hallucinates the unobserved future motion implied by a single snapshot to help static-image action recognition. The key idea is to learn a prior over short-term dynamics from thousands of unlabeled videos, infer the anticipated optical flow on novel static images, and then train discriminative models that exploit both streams of information. Our main contributions are twofold. First, we devise an encoder-decoder convolutional neural network and a novel optical flow encoding that can translate a static image into an accurate flow map. Second, we show the power of hallucinated flow for recognition, successfully transferring the learned motion into a standard two-stream network for activity recognition. On seven datasets, we demonstrate the power of the approach. It not only achieves state-of-the-art accuracy for dense optical flow prediction, but also consistently enhances recognition of actions and dynamic scenes.",
        "A1": "hallucinates the unobserved future motion implied by a single snapshot to help static-image action recognition",
        "A2": " such models are deprived of the rich dynamic structure and motions that also define human activity",
        "A41": " an approach that hallucinates the unobserved future motion implied by a single snapshot to help static-image action recognition",
        "A51": ", but also consistently enhances recognition of actions and dynamic scenes.",
        "A61": ", but also consistently enhances recognition of actions and dynamic scenes.",
        "A10": "the power of the approach. It not only achieves state-of-the-art accuracy for dense optical flow prediction, but also consistently enhances recognition of actions and dynamic scenes.",
        "A7": " First, we devise an encoder-decoder convolutional neural network and a novel optical flow encoding that can translate a static image into an accurate flow map. Second, we show the power of hallucinated flow for recognition, successfully transferring the learned motion into a standard two-stream network for activity recognition. ",
        "A83": "",
        "A82": "",
        "A81": "the power of the approach. It not only achieves state-of-the-art accuracy for dense optical flow prediction, but also consistently enhances recognition of actions and dynamic scenes.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "seven datasets",
        "am_id": 271322784
    },
    {
        "Abstract": "Image and sentence matching has made great progress recently, but it remains challenging due to the large visual-semantic discrepancy. This mainly arises from that the representation of pixel-level image usually lacks of high-level semantic information as in its matched sentence. In this work, we propose a semantic-enhanced image and sentence matching model, which can improve the image representation by learning semantic concepts and then organizing them in a correct semantic order. Given an image, we first use a multi-regional multi-label CNN to predict its semantic concepts, including objects, properties, actions, etc. Then, considering that different orders of semantic concepts lead to diverse semantic meanings, we use a context-gated sentence generation scheme for semantic order learning. It simultaneously uses the image global context containing concept relations as reference and the groundtruth semantic order in the matched sentence as supervision. After obtaining the improved image representation, we learn the sentence representation with a conventional LSTM, and then jointly perform image and sentence matching and sentence generation for model learning. Extensive experiments demonstrate the effectiveness of our learned semantic concepts and order, by achieving the state-of-the-art results on two public benchmark datasets.",
        "A1": "Image and sentence matching ",
        "A2": "improve the image representation",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "the effectiveness of our learned semantic concepts and order",
        "A7": "conventional LSTM",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "semantic-enhanced image and sentence matching model",
        "A45": "",
        "am_id": 21746403
    },
    {
        "Abstract": "Local feature detection is a fundamental task in computer vision, and hand-crafted feature detectors such as SIFT have shown success in applications including image-based localization and registration. Recent work has used features detected in texture images for precise global localization, but is limited by the performance of existing feature detectors on textures, as opposed to natural images. We propose an effective and scalable method for learning feature detectors for textures, which combines an existing \"ranking\" loss with an efficient fully-convolutional architecture as well as a new training-loss term that maximizes the \"peakedness\" of the response map. We demonstrate that our detector is more repeatable than existing methods, leading to improvements in a real-world texture-based localization application.",
        "A1": "We propose an effective and scalable method for learning feature detectors for textures",
        "A2": "Local feature detection",
        "A41": "an effective and scalable method for learning feature detectors for textures",
        "A51": "",
        "A61": "combines an existing \"ranking\" loss with an efficient fully-convolutional architecture as well as a new training-loss term that maximizes the \"peakedness\" of the response map",
        "A10": "We demonstrate that our detector is more repeatable than existing methods, leading to improvements in a real-world texture-based localization application.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 287580819
    },
    {
        "Abstract": "A key problem in blind image quality assessment (BIQA) is how to effectively model the properties of human visual system in a data-driven manner. In this paper, we propose a simple and efficient BIQA model based on a novel framework which consists of a fully convolutional neural network (FCNN) and a pooling network to solve this problem. In principle, FCNN is capable of predicting a pixel-by-pixel similar quality map only from a distorted image by using the intermediate similarity maps derived from conventional full-reference image quality assessment methods. The predicted pixel-by-pixel quality maps have good consistency with the distortion correlations between the reference and distorted images. Finally, a deep pooling network regresses the quality map into a score. Experiments have demonstrated that our predictions outperform many state-of-the-art BIQA methods.",
        "A1": "propose a simple and efficient BIQA model based on a novel framework",
        "A2": "model the properties of human visual system in a data-driven manner",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "our predictions outperform many state-of-the-art BIQA methods.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "our predictions outperform many state-of-the-art BIQA methods.",
        "A64": "",
        "A54": "",
        "A44": "consists of a fully convolutional neural network (FCNN) and a pooling network",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": " a novel framework",
        "A42": "simple and efficient BIQA model",
        "A45": "",
        "am_id": 212914763
    },
    {
        "Abstract": "We achieve tomography of 3D volumetric natural objects, where each projected 2D image corresponds to a different specimen. Each specimen has unknown random 3D orientation, location, and scale. This imaging scenario is relevant to microscopic and mesoscopic organisms, aerosols and hydrosols viewed naturally by a microscope. In-class scale variation inhibits prior single-particle reconstruction methods. We thus generalize tomographic recovery to account for all degrees of freedom of a similarity transformation. This enables geometric self-calibration in imaging of transparent objects. We make the computational load manageable and reach good quality reconstruction in a short time. This enables extraction of statistics that are important for a scientific study of specimen populations, specifically size distribution parameters. We apply the method to study of plankton.",
        "A1": "achieve tomography of 3D volumetric natural objects",
        "A2": "Each specimen has unknown random 3D orientation, location, and scale",
        "A41": "generalize tomographic recovery to account for all degrees of freedom of a similarity transformation.",
        "A51": "",
        "A61": "We make the computational load manageable and reach good quality reconstruction in a short time.",
        "A10": "",
        "A7": "",
        "A83": "We apply the method to study of plankton.",
        "A82": "This enables extraction of statistics that are important for a scientific study of specimen populations, specifically size distribution parameters. ",
        "A81": "We make the computational load manageable and reach good quality reconstruction in a short time.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 496417347
    },
    {
        "Abstract": "In this work, we address the task of weakly-supervised human action segmentation in long, untrimmed videos. Recent methods have relied on expensive learning models, such as Recurrent Neural Networks (RNN) and Hidden Markov Models (HMM). However, these methods suffer from expensive computational cost, thus are unable to be deployed in large scale. To overcome the limitations, the keys to our design are efficiency and scalability. We propose a novel action modeling framework, which consists of a new temporal convolutional network, named Temporal Convolutional Feature Pyramid Network (TCFPN), for predicting frame-wise action labels, and a novel training strategy for weakly-supervised sequence modeling, named Iterative Soft Boundary Assignment (ISBA), to align action sequences and update the network in an iterative fashion. The proposed framework is evaluated on two benchmark datasets, Breakfast and Hollywood Extended, with four different evaluation metrics. Extensive experimental results show that our methods achieve competitive or superior performance to state-of-the-art methods.",
        "A1": "",
        "A2": "address the task of weakly-supervised human action segmentation in long, untrimmed videos",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "The proposed framework is evaluated on two benchmark datasets, Breakfast and Hollywood Extended, with four different evaluation metrics.",
        "A83": "",
        "A82": "",
        "A81": " our methods achieve competitive or superior performance to state-of-the-art methods.",
        "A64": "consists of a new temporal convolutional network, named Temporal Convolutional Feature Pyramid Network (TCFPN), for predicting frame-wise action labels, and a novel training strategy for weakly-supervised sequence modeling, named Iterative Soft Boundary Assignment (ISBA), to align action sequences and update the network in an iterative fashion. ",
        "A54": "",
        "A44": " a novel action modeling framework",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 68933916
    },
    {
        "Abstract": "Video Question Answering (QA) is an important task in understanding video temporal structure. We observe that there are three unique attributes of video QA compared with image QA: (1) it deals with long sequences of images containing richer information not only in quantity but also in variety; (2) motion and appearance information are usually correlated with each other and able to provide useful attention cues to the other; (3) different questions require different number of frames to infer the answer. Based on these observations, we propose a motion-appearance co-memory network for video QA. Our networks are built on concepts from Dynamic Memory Network (DMN) and introduces new mechanisms for video QA. Specifically, there are three salient aspects: (1) a co-memory attention mechanism that utilizes cues from both motion and appearance to generate attention; (2) a temporal conv-deconv network to generate multi-level contextual facts; (3) a dynamic fact ensemble method to construct temporal representation dynamically for different questions. We evaluate our method on TGIF-QA dataset, and the results outperform state-of-the-art significantly on all four tasks of TGIF-QA.",
        "A1": "Video Question Answering (QA)",
        "A2": "Video Question Answering (QA)",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " on TGIF-QA dataset",
        "A83": "",
        "A82": "",
        "A81": " the results outperform state-of-the-art significantly on all four tasks of TGIF-QA.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Dynamic Memory Network (DMN)",
        "A42": "a motion-appearance co-memory network for video QA",
        "A45": "",
        "am_id": 153108967
    },
    {
        "Abstract": "This paper presents the first attempt at stereoscopic neural style transfer, which responds to the emerging demand for 3D movies or AR/VR. We start with a careful examination of applying existing monocular style transfer methods to left and right views of stereoscopic images separately. This reveals that the original disparity consistency cannot be well preserved in the final stylization results, which causes 3D fatigue to the viewers. To address this issue, we incorporate a new disparity loss into the widely adopted style loss function by enforcing the bidirectional disparity constraint in non-occluded regions. For a practical realtime solution, we propose the first feed-forward network by jointly training a stylization sub-network and a disparity sub-network, and integrate them in a feature level middle domain. Our disparity sub-network is also the first end-to-end network for simultaneous bidirectional disparity and occlusion mask estimation. Finally, our network is effectively extended to stereoscopic videos, by considering both temporal coherence and disparity consistency. We will show that the proposed method clearly outperforms the baseline algorithms both quantitatively and qualitatively.",
        "A1": "This paper presents the first attempt at stereoscopic neural style transfer, which responds to the emerging demand for 3D movies or AR/VR",
        "A2": "This reveals that the original disparity consistency cannot be well preserved in the final stylization results, which causes 3D fatigue to the viewers",
        "A41": "To address this issue, we incorporate a new disparity loss into the widely adopted style loss function by enforcing the bidirectional disparity constraint in non-occluded regions.",
        "A51": "For a practical realtime solution, we propose the first feed-forward network by jointly training a stylization sub-network and a disparity sub-network, and integrate them in a feature level middle domain.",
        "A61": "Our disparity sub-network is also the first end-to-end network for simultaneous bidirectional disparity and occlusion mask estimation",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "We will show that the proposed method clearly outperforms the baseline algorithms both quantitatively and qualitatively.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 222758281
    },
    {
        "Abstract": "We introduce a two-stream model for dynamic texture synthesis. Our model is based on pre-trained convolutional networks (ConvNets) that target two independent tasks: (i) object recognition, and (ii) optical flow prediction. Given an input dynamic texture, statistics of filter responses from the object recognition ConvNet encapsulate the per-frame appearance of the input texture, while statistics of filter responses from the optical flow ConvNet model its dynamics. To generate a novel texture, a randomly initialized input sequence is optimized to match the feature statistics from each stream of an example texture. Inspired by recent work on image style transfer and enabled by the two-stream model, we also apply the synthesis approach to combine the texture appearance from one texture with the dynamics of another to generate entirely novel dynamic textures. We show that our approach generates novel, high quality samples that match both the framewise appearance and temporal evolution of input texture. Finally, we quantitatively evaluate our texture synthesis approach with a thorough user study.",
        "A1": "object recognition, and (ii) optical flow prediction",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "Finally, we quantitatively evaluate our texture synthesis approach with a thorough user study.",
        "A83": "",
        "A82": "",
        "A81": "We show that our approach generates novel, high quality samples that match both the framewise appearance and temporal evolution of input texture.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "Our model is based on pre-trained",
        "A42": "We introduce a two-stream model for dynamic texture synthesis. ",
        "A45": "",
        "am_id": 203310203
    },
    {
        "Abstract": "Automatically describing open-domain videos with natural language are attracting increasing interest in the field of artificial intelligence. Most existing methods simply borrow ideas from image captioning and obtain a compact video representation from an ensemble of global image feature before feeding to an RNN decoder which outputs a sentence of variable length. However, it is not only arduous for the generator to focus on specific salient objects at different time given the global video representation, it is more formidable to capture the fine-grained motion information and the relation between moving instances for more subtle linguistic descriptions. In this paper, we propose a Trajectory Structured Attentional Encoder-Decoder (TSA-ED) neural network framework for more elaborate video captioning which works by integrating local spatial-temporal representation at trajectory level through structured attention mechanism. Our proposed method is based on a LSTM-based encoder-decoder framework, which incorporates an attention modeling scheme to adaptively learn the correlation between sentence structure and the moving objects in videos, and consequently generates more accurate and meticulous statement description in the decoding stage. Experimental results demonstrate that the feature representation and structured attention mechanism based on the trajectory cluster can efficiently obtain the local motion information in the video to help generate a more fine-grained video description, and achieve the state-of-the-art performance on the well-known Charades and MSVD datasets.",
        "A1": "propose a Trajectory Structured Attentional Encoder-Decoder (TSA-ED) neural network framework for more elaborate video captioning which works by integrating local spatial-temporal representation at trajectory level through structured attention mechanism.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "achieve the state-of-the-art performance on the well-known Charades and MSVD datasets.",
        "A81": "the feature representation and structured attention mechanism based on the trajectory cluster can efficiently obtain the local motion information in the video to help generate a more fine-grained video description",
        "A64": "",
        "A54": "LSTM-based encoder-decoder framework",
        "A44": "framework for more elaborate video captioning which works by integrating local spatial-temporal representation at trajectory level through structured attention mechanism.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 235658639
    },
    {
        "Abstract": "We demonstrate that many detection methods are designed to identify only a sufficently accurate bounding box, rather than the best available one. To address this issue we propose a simple and fast modification to the existing methods called Fitness NMS. This method is tested with the DeNet model and obtains a significantly improved MAP at greater localization accuracies without a loss in evaluation rate, and can be used in conjunction with Soft NMS for additional improvements. Next we derive a novel bounding box regression loss based on a set of IoU upper bounds that better matches the goal of IoU maximization while still providing good convergence properties. Following these novelties we investigate RoI clustering schemes for improving evaluation rates for the DeNet wide model variants and provide an analysis of localization performance at various input image dimensions. We obtain a MAP of 33.6%@79Hz and 41.8%@5Hz for MSCOCO and a Titan X (Maxwell). Source code available from: https://github.com/lachlants/denet",
        "A1": "To address this issue we propose a simple and fast modification to the existing methods called Fitness NMS. ",
        "A2": "We demonstrate that many detection methods are designed to identify only a sufficently accurate bounding box, rather than the best available one. ",
        "A41": " Fitness NMS",
        "A51": "This method is tested with the DeNet model and obtains a significantly improved MAP at greater localization accuracies without a loss in evaluation rate, and can be used in conjunction with Soft NMS for additional improvements. ",
        "A61": "",
        "A10": "a significantly improved MAP at greater localization accuracies without a loss in evaluation rate, and can be used in conjunction with Soft NMS for additional improvements. ",
        "A7": " DeNet model",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 164759642
    },
    {
        "Abstract": "Robust visual localization under a wide range of viewing conditions is a fundamental problem in computer vision. Handling the difficult cases of this problem is not only very challenging but also of high practical relevance, e.g., in the context of life-long localization for augmented reality or autonomous robots. In this paper, we propose a novel approach based on a joint 3D geometric and semantic understanding of the world, enabling it to succeed under conditions where previous approaches failed. Our method leverages a novel generative model for descriptor learning, trained on semantic scene completion as an auxiliary task. The resulting 3D descriptors are robust to missing observations by encoding high-level 3D geometric and semantic information. Experiments on several challenging large-scale localization datasets demonstrate reliable localization under extreme viewpoint, illumination, and geometry changes.",
        "A1": "propose a novel approach based on a joint 3D geometric and semantic understanding of the world",
        "A2": "Robust visual localization under a wide range of viewing conditions",
        "A41": "everages a novel generative model for descriptor learning",
        "A51": " a joint 3D geometric and semantic understanding of the world",
        "A61": "",
        "A10": "The resulting 3D descriptors are robust to missing observations by encoding high-level 3D geometric and semantic information",
        "A7": " several challenging large-scale localization datasets ",
        "A83": "geometry changes",
        "A82": "illumination",
        "A81": " localization under extreme viewpoint",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 462916479
    },
    {
        "Abstract": "Recently proposed robust 3D face alignment methods establish either dense or sparse correspondence between a 3D face model and a 2D facial image. The use of these methods presents new challenges as well as opportunities for facial texture analysis. In particular, by sampling the image using the fitted model, a facial UV can be created. Unfortunately, due to self-occlusion, such a UV map is always incomplete. In this paper, we propose a framework for training Deep Convolutional Neural Network (DCNN) to complete the facial UV map extracted from in-the-wild images. To this end, we first gather complete UV maps by fitting a 3D Morphable Model (3DMM) to various multiview image and video datasets, as well as leveraging on a new 3D dataset with over 3,000 identities. Second, we devise a meticulously designed architecture that combines local and global adversarial DCNNs to learn an identity-preserving facial UV completion model. We demonstrate that by attaching the completed UV to the fitted mesh and generating instances of arbitrary poses, we can increase pose variations for training deep face recognition/verification models, and minimise pose discrepancy during testing, which lead to better performance. Experiments on both controlled and in-the-wild UV datasets prove the effectiveness of our adversarial UV completion model. We achieve state-of-the-art verification accuracy, 94.05%, under the CFP frontal-profile protocol only by combining pose augmentation during training and pose discrepancy reduction during testing. We will release the first in-the-wild UV dataset (we refer as WildUV) that comprises of complete facial UV maps from 1,892 identities for research purposes.",
        "A1": " In this paper, we propose a framework for training Deep Convolutional Neural Network (DCNN) to complete the facial UV map extracted from in-the-wild images",
        "A2": "Unfortunately, due to self-occlusion, such a UV map is always incomplete.",
        "A41": " we propose a framework for training Deep Convolutional Neural Network (DCNN) to complete the facial UV map extracted from in-the-wild images",
        "A51": "a meticulously designed architecture that combines local and global adversarial DCNNs to learn an identity-preserving facial UV completion model",
        "A61": "by attaching the completed UV to the fitted mesh and generating instances of arbitrary poses, we can increase pose variations for training deep face recognition/verification models,",
        "A10": " increase pose variations for training deep face recognition/verification models,",
        "A7": "Experiments on both controlled and in-the-wild UV datasets ",
        "A83": " prove the effectiveness of our adversarial UV completion model",
        "A82": "We will release the first in-the-wild UV dataset (we refer as WildUV) that comprises of complete facial UV maps from 1,892 identities for research purposes",
        "A81": " We achieve state-of-the-art verification accuracy, 94.05%, under the CFP frontal-profile protocol only by combining pose augmentation during training and pose discrepancy reduction during testing",
        "A64": " release the first in-the-wild UV dataset (we refer as WildUV) that comprises of complete facial UV maps from 1,892 identities for research purposes.",
        "A54": " devise a meticulously designed architecture",
        "A44": " combines local and global adversarial DCNNs to learn an identity-preserving facial UV completion model",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " state-of-the-art verification accuracy, 94.05%, under the CFP frontal-profile protocol only by combining pose augmentation during training and pose discrepancy reduction during testing",
        "A52": "controlled and in-the-wild UV datasets ",
        "A42": "the effectiveness of our adversarial UV completion model",
        "A45": "",
        "am_id": 446079819
    },
    {
        "Abstract": "The topic of multi-person pose estimation has been largely improved recently, especially with the development of convolutional neural network. However, there still exist a lot of challenging cases, such as occluded keypoints, invisible keypoints and complex background, which cannot be well addressed. In this paper, we present a novel network structure called Cascaded Pyramid Network (CPN) which targets to relieve the problem from these \"hard\" keypoints. More specifically, our algorithm includes two stages: GlobalNet and RefineNet. GlobalNet is a feature pyramid network which can successfully localize the \"simple\" keypoints like eyes and hands but may fail to precisely recognize the occluded or invisible keypoints. Our RefineNet tries explicitly handling the \"hard\" keypoints by integrating all levels of feature representations from the GlobalNet together with an online hard keypoint mining loss. In general, to address the multi-person pose estimation problem, a top-down pipeline is adopted to first generate a set of human bounding boxes based on a detector, followed by our CPN for keypoint localization in each human bounding box. Based on the proposed algorithm, we achieve state-of-art results on the COCO keypoint benchmark, with average precision at 73.0 on the COCO test-dev dataset and 72.1 on the COCO test-challenge dataset, which is a 19% relative improvement compared with 60.5 from the COCO 2016 keypoint challenge. Code1 and the detection results for person used will be publicly available for further research.",
        "A1": "The topic of multi-person pose estimation has been largely improved recently, especially with the development of convolutional neural network. ",
        "A2": "However, there still exist a lot of challenging cases, such as occluded keypoints, invisible keypoints and complex background, which cannot be well addressed. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " Based on the proposed algorithm, we achieve state-of-art results on the COCO keypoint benchmark, with average precision at 73.0 on the COCO test-dev dataset and 72.1 on the COCO test-challenge dataset, which is a 19% relative improvement compared with 60.5 from the COCO 2016 keypoint challenge. ",
        "A52": "",
        "A42": "In this paper, we present a novel network structure called Cascaded Pyramid Network (CPN) which targets to relieve the problem from these \"hard\" keypoints.",
        "A45": "",
        "am_id": 116335947
    },
    {
        "Abstract": "Recent work has made significant progress in improving spatial resolution for pixelwise labeling with Fully Convolutional Network (FCN) framework by employing Dilated/Atrous convolution, utilizing multi-scale features and refining boundaries. In this paper, we explore the impact of global contextual information in semantic segmentation by introducing the Context Encoding Module, which captures the semantic context of scenes and selectively highlights class-dependent featuremaps. The proposed Context Encoding Module significantly improves semantic segmentation results with only marginal extra computation cost over FCN. Our approach has achieved new state-of-the-art results 51.7% mIoU on PASCAL-Context, 85.9% mIoU on PASCAL VOC 2012. Our single model achieves a final score of 0.5567 on ADE20K test set, which surpasses the winning entry of COCO-Place Challenge 2017. In addition, we also explore how the Context Encoding Module can improve the feature representation of relatively shallow networks for the image classification on CIFAR-10 dataset. Our 14 layer network has achieved an error rate of 3.45%, which is comparable with state-of-the-art approaches with over 10\u00c3\u2014 more layers. The source code for the complete system are publicly available1.",
        "A1": "explore the impact of global contextual information in semantic segmentation",
        "A2": "captures the semantic context of scenes and selectively highlights class-dependent featuremaps",
        "A41": "",
        "A51": "",
        "A61": "has achieved new state-of-the-art results 51.7% mIoU on PASCAL-Context, 85.9% mIoU on PASCAL VOC 2012",
        "A10": "surpasses the winning entry of COCO-Place Challenge 2017",
        "A7": "",
        "A83": "",
        "A82": "Our 14 layer network has achieved an error rate of 3.45%, which is comparable with state-of-the-art approaches with over 10\u00c3\u2014 more layers",
        "A81": "Our approach has achieved new state-of-the-art results 51.7% mIoU on PASCAL-Context, 85.9% mIoU on PASCAL VOC 2012. Our single model achieves a final score of 0.5567 on ADE20K test set, which surpasses the winning entry of COCO-Place Challenge 2017",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "achieves a final score of 0.5567 on ADE20K test set, which surpasses the winning entry of COCO-Place Challenge 2017",
        "A52": "",
        "A42": "the Context Encoding Module, which captures the semantic context of scenes and selectively highlights class-dependent featuremaps",
        "A45": "",
        "am_id": 264251218
    },
    {
        "Abstract": "Dense video captioning is a newly emerging task that aims at both localizing and describing all events in a video. We identify and tackle two challenges on this task, namely, (1) how to utilize both past and future contexts for accurate event proposal predictions, and (2) how to construct informative input to the decoder for generating natural event descriptions. First, previous works predominantly generate temporal event proposals in the forward direction, which neglects future video context. We propose a bidirectional proposal method that effectively exploits both past and future contexts to make proposal predictions. Second, different events ending at (nearly) the same time are indistinguishable in the previous works, resulting in the same captions. We solve this problem by representing each event with an attentive fusion of hidden states from the proposal module and video contents (e.g., C3D features). We further propose a novel context gating mechanism to balance the contributions from the current event and its surrounding contexts dynamically. We empirically show that our attentively fused event representation is superior to the proposal hidden states or video contents alone. By coupling proposal and captioning modules into one unified framework, our model outperforms the state-of-the-arts on the ActivityNet Captions dataset with a relative gain of over 100% (Meteor score increases from 4.82 to 9.65).",
        "A1": "We propose a bidirectional proposal method that effectively exploits both past and future contexts to make proposal predictions.",
        "A2": "We identify and tackle two challenges on this task, namely, (1) how to utilize both past and future contexts for accurate event proposal predictions, and (2) how to construct informative input to the decoder for generating natural event descriptions.",
        "A41": " We propose a bidirectional proposal method that effectively exploits both past and future contexts to make proposal predictions.",
        "A51": "",
        "A61": "We empirically show that our attentively fused event representation is superior to the proposal hidden states or video contents alone. By coupling proposal and captioning modules into one unified framework, our model outperforms the state-of-the-arts on the ActivityNet Captions dataset with a relative gain of over 100% (Meteor score increases from 4.82 to 9.65).",
        "A10": "We empirically show that our attentively fused event representation is superior to the proposal hidden states or video contents alone. By coupling proposal and captioning modules into one unified framework, our model outperforms the state-of-the-arts on the ActivityNet Captions dataset with a relative gain of over 100% (Meteor score increases from 4.82 to 9.65).",
        "A7": "By coupling proposal and captioning modules into one unified framework, our model outperforms the state-of-the-arts on the ActivityNet Captions dataset with a relative gain of over 100% (Meteor score increases from 4.82 to 9.65).",
        "A83": "We empirically show that our attentively fused event representation is superior to the proposal hidden states or video contents alone. By coupling proposal and captioning modules into one unified framework, our model outperforms the state-of-the-arts on the ActivityNet Captions dataset with a relative gain of over 100% (Meteor score increases from 4.82 to 9.65).",
        "A82": "We further propose a novel context gating mechanism to balance the contributions from the current event and its surrounding contexts dynamically.",
        "A81": "We solve this problem by representing each event with an attentive fusion of hidden states from the proposal module and video contents (e.g., C3D features)",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 339528134
    },
    {
        "Abstract": "Humans can quickly learn new visual concepts, perhaps because they can easily visualize or imagine what novel objects look like from different views. Incorporating this ability to hallucinate novel instances of new concepts might help machine vision systems perform better low-shot learning, i.e., learning concepts from few examples. We present a novel approach to low-shot learning that uses this idea. Our approach builds on recent progress in meta-learning (\"learning to learn\") by combining a meta-learner with a \"hallucinator\" that produces additional training examples, and optimizing both models jointly. Our hallucinator can be incorporated into a variety of meta-learners and provides significant gains: up to a 6 point boost in classification accuracy when only a single training example is available, yielding state-of-the-art performance on the challenging ImageNet low-shot classification benchmark.",
        "A1": " help machine vision systems perform better low-shot learning, i.e., learning concepts from few examples.",
        "A2": "",
        "A41": " a novel approach to low-shot learning that uses this idea",
        "A51": "recent progress in meta-learning (\"learning to learn\") by combining a meta-learner with a \"hallucinator\" that produces additional training examples, and optimizing both models jointly",
        "A61": "",
        "A10": " up to a 6 point boost in classification accuracy ",
        "A7": "when only a single training example is available",
        "A83": "",
        "A82": "state-of-the-art performance on the challenging ImageNet low-shot classification benchmark.",
        "A81": " up to a 6 point boost in classification accuracy when only a single training example is available",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 417353302
    },
    {
        "Abstract": "We present a method that gets as input an audio of violin or piano playing, and outputs a video of skeleton predictions which are further used to animate an avatar. The key idea is to create an animation of an avatar that moves their hands similarly to how a pianist or violinist would do, just from audio. Notably, it's not clear if body movement can be predicted from music at all and our aim in this work is to explore this possibility. In this paper, we present the first result that shows that natural body dynamics can be predicted. We built an LSTM network that is trained on violin and piano recital videos uploaded to the Internet. The predicted points are applied onto a rigged avatar to create the animation.",
        "A1": " present a method that gets as input an audio of violin or piano playing, and outputs a video of skeleton predictions which are further used to animate an avatar.",
        "A2": "gets as input an audio of violin or piano playing, and outputs a video of skeleton predictions which are further used to animate an avatar.",
        "A41": "a method that gets as input an audio of violin or piano playing, and outputs a video of skeleton predictions which are further used to animate an avatar",
        "A51": "LSTM network ",
        "A61": "",
        "A10": "",
        "A7": "The predicted points are applied onto a rigged avatar to create the animation.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 122799055
    },
    {
        "Abstract": "We address the problem of real-time 3D object detection from point clouds in the context of autonomous driving. Speed is critical as detection is a necessary component for safety. Existing approaches are, however, expensive in computation due to high dimensionality of point clouds. We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector that outputs oriented 3D object estimates decoded from pixel-wise neural network predictions. The input representation, network architecture, and model optimization are specially designed to balance high accuracy and real-time efficiency. We validate PIXOR on two datasets: the KITTI BEV object detection benchmark, and a large-scale 3D vehicle detection benchmark. In both datasets we show that the proposed detector surpasses other state-of-the-art methods notably in terms of Average Precision (AP), while still runs at 10 FPS.",
        "A1": "We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector that outputs oriented 3D object estimates decoded from pixel-wise neural network predictions.",
        "A2": "Existing approaches are, however, expensive in computation due to high dimensionality of point clouds. ",
        "A41": "We utilize the 3D data more efficiently by representing the scene from the Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector",
        "A51": " Bird's Eye View (BEV), and propose PIXOR, a proposal-free, single-stage detector that outputs oriented 3D object estimates decoded from pixel-wise neural network predictions.",
        "A61": " more efficiently",
        "A10": "We validate PIXOR on two datasets: the KITTI BEV object detection benchmark, and a large-scale 3D vehicle detection benchmark. In both datasets we show that the proposed detector surpasses other state-of-the-art methods notably in terms of Average Precision (AP), while still runs at 10 FPS.",
        "A7": " We validate PIXOR on two datasets: the KITTI BEV object detection benchmark, and a large-scale 3D vehicle detection benchmark. ",
        "A83": "",
        "A82": "",
        "A81": "In both datasets we show that the proposed detector surpasses other state-of-the-art methods notably in terms of Average Precision (AP), while still runs at 10 FPS.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "two datasets: the KITTI BEV object detection benchmark, and a large-scale 3D vehicle detection benchmark.",
        "am_id": 154941865
    },
    {
        "Abstract": "In this paper, we address an open problem of zero-shot learning. Its principle is based on learning a mapping that associates feature vectors extracted from i.e. images and attribute vectors that describe objects and/or scenes of interest. In turns, this allows classifying unseen object classes and/or scenes by matching feature vectors via mapping to a newly defined attribute vector describing a new class. Due to importance of such a learning task, there exist many methods that learn semantic, probabilistic, linear or piece-wise linear mappings. In contrast, we apply well-established kernel methods to learn a non-linear mapping between the feature and attribute spaces. We propose an easy learning objective inspired by the Linear Discriminant Analysis, Kernel-Target Alignment and Kernel Polarization methods [12, 8, 4] that promotes incoherence. We evaluate the performance of our algorithm on the Polynomial as well as shift-invariant Gaussian and Cauchy kernels. Despite simplicity of our approach, we obtain state-of-the-art results on several zero-shot learning datasets and benchmarks including a recent AWA2 dataset [45].",
        "A1": "address an open problem of zero-shot learning",
        "A2": "zero-shot learning",
        "A41": "well-established kernel methods to learn a non-linear mapping between the feature and attribute spaces",
        "A51": " Its principle is based on learning a mapping that associates feature vectors extracted from i.e. images and attribute vectors that describe objects and/or scenes of interest. ",
        "A61": "there exist many methods that learn semantic, probabilistic, linear or piece-wise linear mappings. In contrast, we apply well-established kernel methods to learn a non-linear mapping between the feature and attribute spaces. ",
        "A10": "",
        "A7": "the Polynomial as well as shift-invariant Gaussian and Cauchy kernels. ",
        "A83": "",
        "A82": "",
        "A81": "state-of-the-art results on several zero-shot learning datasets and benchmarks including a recent AWA2 dataset",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 271048831
    },
    {
        "Abstract": "Visual question answering (VQA) requires joint comprehension of images and natural language questions, where many questions can't be directly or clearly answered from visual content but require reasoning from structured human knowledge with confirmation from visual content. This paper proposes visual knowledge memory network (VKMN) to address this issue, which seamlessly incorporates structured human knowledge and deep visual features into memory networks in an end-to-end learning framework. Comparing to existing methods for leveraging external knowledge for supporting VQA, this paper stresses more on two missing mechanisms. First is the mechanism for integrating visual contents with knowledge facts. VKMN handles this issue by embedding knowledge triples (subject, relation, target) and deep visual features jointly into the visual knowledge features. Second is the mechanism for handling multiple knowledge facts expanding from question and answer pairs. VKMN stores joint embedding using key-value pair structure in the memory networks so that it is easy to handle multiple facts. Experiments show that the proposed method achieves promising results on both VQA v1.0 and v2.0 benchmarks, while outperforms state-of-the-art methods on the knowledge-reasoning related questions.",
        "A1": "This paper proposes visual knowledge memory network (VKMN) to address this issue, which seamlessly incorporates structured human knowledge and deep visual features into memory networks in an end-to-end learning framework.",
        "A2": "Visual question answering (VQA) requires joint comprehension of images and natural language questions, where many questions can't be directly or clearly answered from visual content but require reasoning from structured human knowledge with confirmation from visual content.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " First is the mechanism for integrating visual contents with knowledge facts. VKMN handles this issue by embedding knowledge triples (subject, relation, target) and deep visual features jointly into the visual knowledge features. Second is the mechanism for handling multiple knowledge facts expanding from question and answer pairs. ",
        "A7": "",
        "A83": "",
        "A82": "outperforms state-of-the-art methods on the knowledge-reasoning related questions.",
        "A81": "the proposed method achieves promising results on both VQA v1.0 and v2.0 benchmarks,",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 157601173
    },
    {
        "Abstract": "Fully convolutional neural network (FCN) has been dominating the game of face detection task for a few years with its congenital capability of sliding-window-searching with shared kernels, which boiled down all the redundant calculation, and most recent state-of-the-art methods such as Faster-RCNN, SSD, YOLO and FPN use FCN as their backbone. So here comes one question: Can we find a universal strategy to further accelerate FCN with higher accuracy, so could accelerate all the recent FCN-based methods? To analyze this, we decompose the face searching space into two orthogonal directions, 'scale' and 'spatial'. Only a few coordinates in the space expanded by the two base vectors indicate foreground. So if FCN could ignore most of the other points, the searching space and false alarm should be significantly boiled down. Based on this philosophy, a novel method named scale estimation and spatial attention proposal (S2AP) is proposed to pay attention to some specific scales in image pyramid and valid locations in each scales layer. Furthermore, we adopt a masked-convolution operation based on the attention result to accelerate FCN calculation. Experiments show that FCN-based method RPN can be accelerated by about 4\u00c3\u2014 with the help of S2AP and masked-FCN and at the same time it can also achieve the state-of-the-art on FDDB, AFW and MALF face detection benchmarks as well.",
        "A1": "Fully convolutional neural network (FCN) has been dominating the game of face detection task for a few years with its congenital capability of sliding-window-searching with shared kernels, which boiled down all the redundant calculation, and most recent state-of-the-art methods such as Faster-RCNN, SSD, YOLO and FPN use FCN as their backbone.",
        "A2": "So here comes one question: Can we find a universal strategy to further accelerate FCN with higher accuracy, so could accelerate all the recent FCN-based methods?",
        "A41": "Based on this philosophy, a novel method named scale estimation and spatial attention proposal (S2AP) is proposed to pay attention to some specific scales in image pyramid and valid locations in each scales layer.",
        "A51": "Only a few coordinates in the space expanded by the two base vectors indicate foreground. So if FCN could ignore most of the other points, the searching space and false alarm should be significantly boiled down.",
        "A61": "Experiments show that FCN-based method RPN can be accelerated by about 4\u00c3\u2014 with the help of S2AP and masked-FCN and at the same time it can also achieve the state-of-the-art on FDDB, AFW and MALF face detection benchmarks as well.",
        "A10": "Experiments show that FCN-based method RPN can be accelerated by about 4\u00c3\u2014 with the help of S2AP and masked-FCN and at the same time it can also achieve the state-of-the-art on FDDB, AFW and MALF face detection benchmarks as well.",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "Experiments show that FCN-based method RPN can be accelerated by about 4\u00c3\u2014 with the help of S2AP and masked-FCN and at the same time it can also achieve the state-of-the-art on FDDB, AFW and MALF face detection benchmarks as well.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 166168327
    },
    {
        "Abstract": "Detecting individual pedestrians in a crowd remains a challenging problem since the pedestrians often gather together and occlude each other in real-world scenarios. In this paper, we first explore how a state-of-the-art pedestrian detector is harmed by crowd occlusion via experimentation, providing insights into the crowd occlusion problem. Then, we propose a novel bounding box regression loss specifically designed for crowd scenes, termed repulsion loss. This loss is driven by two motivations: the attraction by target, and the repulsion by other surrounding objects. The repulsion term prevents the proposal from shifting to surrounding objects thus leading to more crowd-robust localization. Our detector trained by repulsion loss outperforms the state-of-the-art methods with a significant improvement in occlusion cases.",
        "A1": "Detecting individual pedestrians",
        "A2": "Detecting individual pedestrians in a crowd remains a challenging problem since the pedestrians often gather together and occlude each other in real-world scenarios",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " occlusion cases",
        "A83": "",
        "A82": "",
        "A81": "Our detector trained by repulsion loss outperforms the state-of-the-art methods with a significant improvement",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "This loss is driven by two motivations",
        "A53": "regression loss",
        "A43": "a novel bounding box regression loss",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 9434365
    },
    {
        "Abstract": "Generative Adversarial Nets (GANs) and Conditonal GANs (CGANs) show that using a trained network as loss function (discriminator) enables to synthesize highly structured outputs (e.g. natural images). However, applying a discriminator network as a universal loss function for common supervised tasks (e.g. semantic segmentation, line detection, depth estimation) is considerably less successful. We argue that the main difficulty of applying CGANs to supervised tasks is that the generator training consists of optimizing a loss function that does not depend directly on the ground truth labels. To overcome this, we propose to replace the discriminator with a matching network taking into account both the ground truth outputs as well as the generated examples. As a consequence, the generator loss function also depends on the targets of the training examples, thus facilitating learning. We demonstrate on three computer vision tasks that this approach can significantly outperform CGANs achieving comparable or superior results to task-specific solutions and results in stable training. Importantly, this is a general approach that does not require the use of task-specific loss functions.",
        "A1": "To overcome this, we propose to replace the discriminator with a matching network taking into account both the ground truth outputs as well as the generated examples",
        "A2": "However, applying a discriminator network as a universal loss function for common supervised tasks (e.g. semantic segmentation, line detection, depth estimation) is considerably less successful. We argue that the main difficulty of applying CGANs to supervised tasks is that the generator training consists of optimizing a loss function that does not depend directly on the ground truth labels.",
        "A41": "we propose to replace the discriminator with a matching network taking into account both the ground truth outputs as well as the generated examples.",
        "A51": "",
        "A61": "this approach can significantly outperform CGANs achieving comparable or superior results to task-specific solutions and results in stable training. Importantly, this is a general approach that does not require the use of task-specific loss functions.",
        "A10": "this approach can significantly outperform CGANs achieving comparable or superior results to task-specific solutions and results in stable training. Importantly, this is a general approach that does not require the use of task-specific loss functions.",
        "A7": "",
        "A83": "this is a general approach that does not require the use of task-specific loss functions.",
        "A82": " results in stable training. ",
        "A81": "this approach can significantly outperform CGANs achieving comparable or superior results to task-specific solutions",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 401270122
    },
    {
        "Abstract": "In this paper we propose a technique to adapt a convolutional neural network (CNN) based object counter to additional visual domains and object types while still preserving the original counting function. Domain-specific normalisation and scaling operators are trained to allow the model to adjust to the statistical distributions of the various visual domains. The developed adaptation technique is used to produce a singular patch-based counting regressor capable of counting various object types including people, vehicles, cell nuclei and wildlife. As part of this study a challenging new cell counting dataset in the context of tissue culture and patient diagnosis is constructed. This new collection, referred to as the Dublin Cell Counting (DCC) dataset, is the first of its kind to be made available to the wider computer vision community. State-of-the-art object counting performance is achieved in both the Shanghaitech (parts A and B) and Penguins datasets while competitive performance is observed on the TRANCOS and Modified Bone Marrow (MBM) datasets, all using a shared counting model.",
        "A1": "",
        "A2": "",
        "A41": "adapt a convolutional neural network (CNN) based object counter to additional visual domains and object types while still preserving the original counting function.",
        "A51": "a convolutional neural network (CNN) based",
        "A61": "",
        "A10": "",
        "A7": "Shanghaitech (parts A and B) and Penguins datasets while competitive performance is observed on the TRANCOS and Modified Bone Marrow (MBM) datasets",
        "A83": "",
        "A82": " competitive performance is observed ",
        "A81": "State-of-the-art object counting performance is achieved",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 79298788
    },
    {
        "Abstract": "Image cropping aims at improving the aesthetic quality of images by adjusting their composition. Most weakly supervised cropping methods (without bounding box supervision) rely on the sliding window mechanism. The sliding window mechanism requires fixed aspect ratios and limits the cropping region with arbitrary size. Moreover, the sliding window method usually produces tens of thousands of windows on the input image which is very time-consuming. Motivated by these challenges, we firstly formulate the aesthetic image cropping as a sequential decision-making process and propose a weakly supervised Aesthetics Aware Reinforcement Learning (A2-RL) framework to address this problem. Particularly, the proposed method develops an aesthetics aware reward function which especially benefits image cropping. Similar to human's decision making, we use a comprehensive state representation including both the current observation and the historical experience. We train the agent using the actor-critic architecture in an end-to-end manner. The agent is evaluated on several popular unseen cropping datasets. Experiment results show that our method achieves the state-of-the-art performance with much fewer candidate windows and much less time compared with previous weakly supervised methods.",
        "A1": "improving the aesthetic quality of images by adjusting their composition. ",
        "A2": "Image cropping aims at improving the aesthetic quality of images",
        "A41": "The sliding window mechanism requires fixed aspect ratios and limits the cropping region with arbitrary size. ",
        "A51": "the sliding window method usually produces tens of thousands of windows on the input image which is very time-consuming",
        "A61": "the proposed method develops an aesthetics aware reward function which especially benefits image cropping",
        "A10": "much fewer candidate windows and much less time compared with previous weakly supervised methods.",
        "A7": "We train the agent using the actor-critic architecture in an end-to-end manner. ",
        "A83": "",
        "A82": "",
        "A81": "our method achieves the state-of-the-art performance with much fewer candidate windows and much less time compared with previous weakly supervised methods.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 458866984
    },
    {
        "Abstract": "Autonomous agents need to reason about the world beyond their instantaneous sensory input. Integrating information over time, however, requires switching from an egocentric representation of a scene to an allocentric one, expressed in the world reference frame. It must also be possible to update the representation dynamically, which requires localizing and registering the sensor with respect to the world reference. In this paper, we develop a differentiable module that satisfies such requirements, while being robust, efficient, and suitable for integration in end-to-end deep networks. The module contains an allocentric spatial memory that can be accessed associatively by feeding to it the current sensory input, resulting in localization, and then updated using an LSTM or similar mechanism. We formulate efficient localization and registration of sensory information as a dual pair of convolution/deconvolution operators in memory space. The map itself is a 2.5D representation of an environment storing information that a deep neural network module learns to distill from RGBD input. The result is a map that contains multi-task information, different from classical approaches to mapping such as structure-from-motion. We present results using synthetic mazes, a dataset of hours of recorded gameplay of the classic game Doom, and the very recent Active Vision Dataset of real images captured from a robot.",
        "A1": "Integrating information over time, however, requires switching from an egocentric representation of a scene to an allocentric one, expressed in the world reference frame",
        "A2": " Integrating information over time, however, requires switching from an egocentric representation of a scene to an allocentric one, expressed in the world reference frame. It must also be possible to update the representation dynamically, which requires localizing and registering the sensor with respect to the world reference",
        "A41": "The module contains an allocentric spatial memory that can be accessed associatively by feeding to it the current sensory input, resulting in localization, and then updated using an LSTM or similar mechanism",
        "A51": "",
        "A61": "The map itself is a 2.5D representation of an environment storing information that a deep neural network module learns to distill from RGBD input. The result is a map that contains multi-task information, different from classical approaches to mapping such as structure-from-motion",
        "A10": "",
        "A7": "We present results using synthetic mazes, a dataset of hours of recorded gameplay of the classic game Doom, and the very recent Active Vision Dataset of real images captured from a robot.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": " The map itself is a 2.5D representation of an environment storing information that a deep neural network module learns to distill from RGBD input. The result is a map that contains multi-task information, different from classical approaches to mapping such as structure-from-motion",
        "A52": "",
        "A42": "The module contains an allocentric spatial memory that can be accessed associatively by feeding to it the current sensory input, resulting in localization, and then updated using an LSTM or similar mechanism",
        "A45": "",
        "am_id": 80192095
    },
    {
        "Abstract": "We propose MAD-GAN, an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode collapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample. Intuitively, to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. We perform extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation. In addition, we also show that MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the end, we show its efficacy on the unsupervised feature representation task.",
        "A1": "mode collapse",
        "A2": "mode collapse",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "we show its efficacy on the unsupervised feature representation task.",
        "A7": " extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN.",
        "A83": "",
        "A82": "MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset",
        "A81": "high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "the discriminator must learn to push different generators towards different identifiable modes",
        "A52": "GANs",
        "A42": "address the well known problem of mode collapse",
        "A45": "",
        "am_id": 229991220
    },
    {
        "Abstract": "Recently, there have been increasing demands to construct compact deep architectures to remove unnecessary redundancy and to improve the inference speed. While many recent works focus on reducing the redundancy by eliminating unneeded weight parameters, it is not possible to apply a single deep network for multiple devices with different resources. When a new device or circumstantial condition requires a new deep architecture, it is necessary to construct and train a new network from scratch. In this work, we propose a novel deep learning framework, called a nested sparse network, which exploits an n-in-1-type nested structure in a neural network. A nested sparse network consists of multiple levels of networks with a different sparsity ratio associated with each level, and higher level networks share parameters with lower level networks to enable stable nested learning. The proposed framework realizes a resource-aware versatile architecture as the same network can meet diverse resource requirements, i.e., anytime property. Moreover, the proposed nested network can learn different forms of knowledge in its internal networks at different levels, enabling multiple tasks using a single network, such as coarse-to-fine hierarchical classification. In order to train the proposed nested network, we propose efficient weight connection learning and channel and layer scheduling strategies. We evaluate our network in multiple tasks, including adaptive deep compression, knowledge distillation, and learning class hierarchy, and demonstrate that nested sparse networks perform competitively, but more efficiently, compared to existing methods.",
        "A1": "construct compact deep architectures",
        "A2": "a resource-aware versatile architecture",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "perform competitively, but more efficiently",
        "A7": "adaptive deep compression, knowledge distillation, and learning class hierarchy",
        "A83": "",
        "A82": "",
        "A81": "nested sparse networks perform competitively, but more efficiently, compared to existing methods",
        "A64": "n-in-1-type nested structure in a neural network",
        "A54": "multiple levels of networks with a different sparsity ratio associated with each level",
        "A44": "a nested sparse network, which exploits an n-in-1-type nested structure in a neural network",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 58459722
    },
    {
        "Abstract": "Conventional deep convolutional neural networks (CNNs) apply convolution operators uniformly in space across all feature maps for hundreds of layers - this incurs a high computational cost for real-time applications. For many problems such as object detection and semantic segmentation, we are able to obtain a low-cost computation mask, either from a priori problem knowledge, or from a low-resolution segmentation network. We show that such computation masks can be used to reduce computation in the high-resolution main network. Variants of sparse activation CNNs have previously been explored on small-scale tasks and showed no degradation in terms of object classification accuracy, but often measured gains in terms of theoretical FLOPs without realizing a practical speedup when compared to highly optimized dense convolution implementations. In this work, we leverage the sparsity structure of computation masks and propose a novel tiling-based sparse convolution algorithm. We verified the effectiveness of our sparse CNN on LiDAR-based 3D object detection, and we report significant wall-clock speed-ups compared to dense convolution without noticeable loss of accuracy.",
        "A1": "obtain a low-cost computation mask",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "significant wall-clock speed-ups ",
        "A7": "LiDAR-based 3D object detection",
        "A83": "",
        "A82": "",
        "A81": "significant wall-clock speed-ups compared to dense convolution without noticeable loss of accuracy",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "tiling",
        "A43": "a novel tiling-based sparse convolution algorithm",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 318936359
    },
    {
        "Abstract": "The way that information propagates in neural networks is of great importance. In this paper, we propose Path Aggregation Network (PANet) aiming at boosting information flow in proposal-based instance segmentation framework. Specifically, we enhance the entire feature hierarchy with accurate localization signals in lower layers by bottom-up path augmentation, which shortens the information path between lower layers and topmost feature. We present adaptive feature pooling, which links feature grid and all feature levels to make useful information in each level propagate directly to following proposal subnetworks. A complementary branch capturing different views for each proposal is created to further improve mask prediction. These improvements are simple to implement, with subtle extra computational overhead. Yet they are useful and make our PANet reach the 1st place in the COCO 2017 Challenge Instance Segmentation task and the 2nd place in Object Detection task without large-batch training. PANet is also state-of-the-art on MVD and Cityscapes.",
        "A1": " propose Path Aggregation Network (PANet) aiming at boosting information flow in proposal-based instance segmentation framework.",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "PANet is also state-of-the-art on MVD and Cityscapes.",
        "A7": " our PANet reach the 1st place in the COCO 2017 Challenge Instance Segmentation task and the 2nd place in Object Detection task without large-batch training.",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "proposal-based instance segmentation framework",
        "A42": " propose Path Aggregation Network (PANet) aiming at boosting information flow in proposal-based instance segmentation framework.",
        "A45": "",
        "am_id": 157761647
    },
    {
        "Abstract": "The world is covered with millions of buildings, and precisely knowing each instance's position and extents is vital to a multitude of applications. Recently, automated building footprint segmentation models have shown superior detection accuracy thanks to the usage of Convolutional Neural Networks (CNN). However, even the latest evolutions struggle to precisely delineating borders, which often leads to geometric distortions and inadvertent fusion of adjacent building instances. We propose to overcome this issue by exploiting the distinct geometric properties of buildings. To this end, we present Deep Structured Active Contours (DSAC), a novel framework that integrates priors and constraints into the segmentation process, such as continuous boundaries, smooth edges, and sharp corners. To do so, DSAC employs Active Contour Models (ACM), a family of constraint- and prior-based polygonal models. We learn ACM parameterizations per instance using a CNN, and show how to incorporate all components in a structured output model, making DSAC trainable end-to-end. We evaluate DSAC on three challenging building instance segmentation datasets, where it compares favorably against state-of-the-art. Code will be made available on https://github.com/dmarcosg/DSAC.",
        "A1": " precisely knowing each instance's position and extents",
        "A2": " However, even the latest evolutions struggle to precisely delineating borders, which often leads to geometric distortions and inadvertent fusion of adjacent building instances.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "e it compares favorably against state-of-the-art. ",
        "A7": "We evaluate DSAC on three challenging building instance segmentation datasets",
        "A83": "",
        "A82": "",
        "A81": "e it compares favorably against state-of-the-art. ",
        "A64": "",
        "A54": "integrates priors and constraints into the segmentation process",
        "A44": "we present Deep Structured Active Contours (DSAC), a novel framework that integrates priors and constraints into the segmentation process, such as continuous boundaries, smooth edges, and sharp corners.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 457201646
    },
    {
        "Abstract": "Interpretability of a deep neural network aims to explain the rationale behind its decisions and enable the users to understand the intelligent agents, which has become an important issue due to its importance in practical applications. To address this issue, we develop a Distillation Guided Routing method, which is a flexible framework to interpret a deep neural network by identifying critical data routing paths and analyzing the functional processing behavior of the corresponding layers. Specifically, we propose to discover the critical nodes on the data routing paths during network inferring prediction for individual input samples by learning associated control gates for each layer's output channel. The routing paths can, therefore, be represented based on the responses of concatenated control gates from all the layers, which reflect the network's semantic selectivity regarding to the input patterns and more detailed functional process across different layer levels. Based on the discoveries, we propose an adversarial sample detection algorithm by learning a classifier to discriminate whether the critical data routing paths are from real or adversarial samples. Experiments demonstrate that our algorithm can effectively achieve high defense rate with minor training overhead.",
        "A1": "propose an adversarial sample detection algorithm by learning a classifier to discriminate whether the critical data routing paths are from real or adversarial samples",
        "A2": "Interpretability of a deep neural network aims to explain the rationale behind its decisions and enable the users to understand the intelligent agents",
        "A41": "method, which is a flexible framework to interpret a deep neural network by identifying critical data routing paths and analyzing the functional processing behavior of the corresponding layers",
        "A51": " discover the critical nodes on the data routing paths during network inferring prediction for individual input samples by learning associated control gates for each layer's output channel",
        "A61": "",
        "A10": "effectively achieve high defense rate with minor training overhead",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "method, which is a flexible framework to interpret a deep neural network by identifying critical data routing paths and analyzing the functional processing behavior of the corresponding layers",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 194362328
    },
    {
        "Abstract": "We present a compact but effective CNN model for optical flow, called PWC-Net. PWC-Net has been designed according to simple and well-established principles: pyramidal processing, warping, and the use of a cost volume. Cast in a learnable feature pyramid, PWC-Net uses the current optical flow estimate to warp the CNN features of the second image. It then uses the warped features and features of the first image to construct a cost volume, which is processed by a CNN to estimate the optical flow. PWC-Net is 17 times smaller in size and easier to train than the recent FlowNet2 model. Moreover, it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015 benchmarks, running at about 35 fps on Sintel resolution (1024 \u00c3\u2014 436) images. Our models are available on our project website.",
        "A1": "present a compact but effective CNN model for optical flow, called PWC-Net",
        "A2": "",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015 benchmarks, running at about 35 fps on Sintel resolution (1024 \u00c3\u2014 436) images",
        "A7": "the MPI Sintel final pass and KITTI 2015 benchmarks",
        "A83": "",
        "A82": "",
        "A81": "it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015 benchmarks, running at about 35 fps on Sintel resolution (1024 \u00c3\u2014 436) images",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "PWC-Net is 17 times smaller in size and easier to train than the recent FlowNet2 model. Moreover, it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015 benchmarks",
        "A52": "",
        "A42": "a compact but effective CNN model for optical flow, called PWC-Net",
        "A45": "",
        "am_id": 23229150
    },
    {
        "Abstract": "Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal subnetwork including the classification branch and regression branch. In the inference phase, the proposed framework is formulated as a local one-shot detection task. We can pre-compute the template branch of the Siamese subnetwork and formulate the correlation layers as trivial convolution layers to perform online tracking. Benefit from the proposal refinement, traditional multi-scale test and online fine-tuning can be discarded. The Siamese-RPN runs at 160 FPS while achieving leading performance in VOT2015, VOT2016 and VOT2017 real-time challenges.",
        "A1": "",
        "A2": "most of these trackers can hardly get top performance with real-time speed",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "The Siamese-RPN runs at 160 FPS while achieving leading performance in VOT2015, VOT2016 and VOT2017 real-time challenges",
        "A7": "",
        "A83": "",
        "A82": "",
        "A81": "",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "it consists of Siamese subnetwork for feature extraction and region proposal subnetwork including the classification branch and regression branch",
        "A52": "",
        "A42": "the Siamese region proposal network",
        "A45": "",
        "am_id": 391900895
    },
    {
        "Abstract": "The tracking-by-detection framework consists of two stages, i.e., drawing samples around the target object in the first stage and classifying each sample as the target object or as background in the second stage. The performance of existing trackers using deep classification networks is limited by two aspects. First, the positive samples in each frame are highly spatially overlapped, and they fail to capture rich appearance variations. Second, there exists extreme class imbalance between positive and negative samples. This paper presents the VITAL algorithm to address these two problems via adversarial learning. To augment positive samples, we use a generative network to randomly generate masks, which are applied to adaptively dropout input features to capture a variety of appearance changes. With the use of adversarial learning, our network identifies the mask that maintains the most robust features of the target objects over a long temporal span. In addition, to handle the issue of class imbalance, we propose a high-order cost sensitive loss to decrease the effect of easy negative samples to facilitate training the classification network. Extensive experiments on benchmark datasets demonstrate that the proposed tracker performs favorably against state-of-the-art approaches.",
        "A1": "The tracking-by-detection framework consists of two stages, i.e., drawing samples around the target object in the first stage and classifying each sample as the target object or as background in the second stage. ",
        "A2": " The performance of existing trackers using deep classification networks is limited by two aspects.",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": " In addition, to handle the issue of class imbalance, we propose a high-order cost sensitive loss to decrease the effect of easy negative samples to facilitate training the classification network. ",
        "A7": "With the use of adversarial learning, our network identifies the mask that maintains the most robust features of the target objects over a long temporal span. ",
        "A83": "",
        "A82": "",
        "A81": "the proposed tracker performs favorably against state-of-the-art approaches.",
        "A64": "the proposed tracker performs favorably against state-of-the-art approaches.",
        "A54": "To augment positive samples, we use a generative network to randomly generate masks, which are applied to adaptively dropout input features to capture a variety of appearance changes. ",
        "A44": "The tracking-by-detection framework consists of two stages, i.e., drawing samples around the target object in the first stage and classifying each sample as the target object or as background in the second stage. ",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 225143619
    },
    {
        "Abstract": "Developing visual perception models for active agents and sensorimotor control in the physical world are cumbersome as existing algorithms are too slow to efficiently learn in real-time and robots are fragile and costly. This has given rise to learning-in-simulation which consequently casts a question on whether the results transfer to real-world. In this paper, we investigate developing real-world perception for active agents, propose Gibson Environment for this purpose, and showcase a set of perceptual tasks learned therein. Gibson is based upon virtualizing real spaces, rather than artificially designed ones, and currently includes over 1400 floor spaces from 572 full buildings. The main characteristics of Gibson are: I. being from the real-world and reflecting its semantic complexity, II. having an internal synthesis mechanism \"Goggles\" enabling deploying the trained models in real-world without needing domain adaptation, III. embodiment of agents and making them subject to constraints of physics and space.",
        "A1": " investigate developing real-world perception for active agents, propose Gibson Environment for this purpose, and showcase a set of perceptual tasks learned therein",
        "A2": "whether the results transfer to real-world",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": "",
        "A83": "embodiment of agents and making them subject to constraints of physics and space.",
        "A82": "having an internal synthesis mechanism \"Goggles\" enabling deploying the trained models in real-world without needing domain adaptation",
        "A81": "being from the real-world and reflecting its semantic complexity",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "existing algorithms are too slow to efficiently learn in real-time",
        "A62": "",
        "A52": "",
        "A42": "the trained models ",
        "A45": "",
        "am_id": 103008903
    },
    {
        "Abstract": "The problem of data augmentation in feature space is considered. A new architecture, denoted the FeATure TransfEr Network (FATTEN), is proposed for the modeling of feature trajectories induced by variations of object pose. This architecture exploits a parametrization of the pose manifold in terms of pose and appearance. This leads to a deep encoder/decoder network architecture, where the encoder factors into an appearance and a pose predictor. Unlike previous attempts at trajectory transfer, FATTEN can be efficiently trained end-to-end, with no need to train separate feature transfer functions. This is realized by supplying the decoder with information about a target pose and the use of a multi-task loss that penalizes category- and pose-mismatches. In result, FATTEN discourages discontinuous or non-smooth trajectories that fail to capture the structure of the pose manifold, and generalizes well on object recognition tasks involving large pose variation. Experimental results on the artificial ModelNet database show that it can successfully learn to map source features to target features of a desired pose, while preserving class identity. Most notably, by using feature space transfer for data augmentation (w.r.t. pose and depth) on SUN-RGBD objects, we demonstrate considerable performance improvements on one/few-shot object recognition in a transfer learning setup, compared to current state-of-the-art methods.",
        "A1": "the modeling of feature trajectories induced by variations of object pose",
        "A2": "The problem of data augmentation in feature space",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "considerable performance improvements on one/few-shot object recognition in a transfer learning setup",
        "A7": "Experimental results on the artificial ModelNet database",
        "A83": "",
        "A82": "considerable performance improvements on one/few-shot object recognition in a transfer learning setup",
        "A81": "it can successfully learn to map source features to target features of a desired pose",
        "A64": "FATTEN can be efficiently trained end-to-end, with no need to train separate feature transfer functions",
        "A54": "a parametrization of the pose manifold in terms of pose and appearance",
        "A44": "A new architecture, denoted the FeATure TransfEr Network (FATTEN), is proposed for the modeling of feature trajectories induced by variations of object pose",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 314505157
    },
    {
        "Abstract": "The outstanding performance of deep neural networks (DNNs), for the visual recognition task in particular, has been demonstrated on several large-scale benchmarks. This performance has immensely strengthened the line of research that aims to understand and analyze the driving reasons behind the effectiveness of these networks. One important aspect of this analysis has recently gained much attention, namely the reaction of a DNN to noisy input. This has spawned research on developing adversarial input attacks as well as training strategies that make DNNs more robust against these attacks. To this end, we derive in this paper exact analytic expressions for the first and second moments (mean and variance) of a small piecewise linear (PL) network (Affine, ReLU, Affine) subject to general Gaussian input. We experimentally show that these expressions are tight under simple linearizations of deeper PL-DNNs, especially popular architectures in the literature (e.g. LeNet and AlexNet). Extensive experiments on image classification show that these expressions can be used to study the behaviour of the output mean of the logits for each class, the interclass confusion and the pixel-level spatial noise sensitivity of the network. Moreover, we show how these expressions can be used to systematically construct targeted and non-targeted adversarial attacks.",
        "A1": "This performance has immensely strengthened the line of research that aims to understand and analyze the driving reasons behind the effectiveness of these networks.",
        "A2": "This has spawned research on developing adversarial input attacks as well as training strategies that make DNNs more robust against these attacks",
        "A41": "To this end, we derive in this paper exact analytic expressions for the first and second moments (mean and variance) of a small piecewise linear (PL) network (Affine, ReLU, Affine) subject to general Gaussian input.",
        "A51": "To this end, we derive in this paper exact analytic expressions for the first and second moments (mean and variance) of a small piecewise linear (PL) network (Affine, ReLU, Affine) subject to general Gaussian input.",
        "A61": "",
        "A10": "",
        "A7": "We experimentally show that these expressions are tight under simple linearizations of deeper PL-DNNs, especially popular architectures in the literature (e.g. LeNet and AlexNet).",
        "A83": "",
        "A82": "Moreover, we show how these expressions can be used to systematically construct targeted and non-targeted adversarial attacks.",
        "A81": "Extensive experiments on image classification show that these expressions can be used to study the behaviour of the output mean of the logits for each class, the interclass confusion and the pixel-level spatial noise sensitivity of the network.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 420759039
    },
    {
        "Abstract": "Volumetric grid is widely used for 3D deep learning due to its regularity. However the use of relatively lower order local approximation functions such as piece-wise constant function (occupancy grid) or piece-wise linear function (distance field) to approximate 3D shape means that it needs a very high-resolution grid to represent finer geometry details, which could be memory and computationally inefficient. In this work, we propose the PointGrid, a 3D convolutional network that incorporates a constant number of points within each grid cell thus allowing the network to learn higher order local approximation functions that could better represent the local geometry shape details. With experiments on popular shape recognition benchmarks, PointGrid demonstrates state-of-the-art performance over existing deep learning methods on both classification and segmentation.",
        "A1": "incorporates a constant number of points within each grid cell",
        "A2": "learn higher order local approximation functions that could better represent the local geometry shape details",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "state-of-the-art performance over existing deep learning methods on both classification and segmentation",
        "A7": "experiments on popular shape recognition benchmarks",
        "A83": "",
        "A82": "",
        "A81": "state-of-the-art performance over existing deep learning methods on both classification and segmentation",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "allowing the network to learn higher order local approximation functions",
        "A52": "",
        "A42": "a 3D convolutional network that incorporates a constant number of points within each grid cell",
        "A45": "",
        "am_id": 444965877
    },
    {
        "Abstract": "Synthesized medical images have several important applications, e.g., as an intermedium in cross-modality image registration and as supplementary training samples to boost the generalization capability of a classifier. Especially, synthesized computed tomography (CT) data can provide X-ray attenuation map for radiation therapy planning. In this work, we propose a generic cross-modality synthesis approach with the following targets: 1) synthesizing realistic looking 3D images using unpaired training data, 2) ensuring consistent anatomical structures, which could be changed by geometric distortion in cross-modality synthesis and 3) improving volume segmentation by using synthetic data for modalities with limited training samples. We show that these goals can be achieved with an end-to-end 3D convolutional neural network (CNN) composed of mutually-beneficial generators and segmentors for image synthesis and segmentation tasks. The generators are trained with an adversarial loss, a cycle-consistency loss, and also a shape-consistency loss, which is supervised by segmentors, to reduce the geometric distortion. From the segmentation view, the segmentors are boosted by synthetic data from generators in an online manner. Generators and segmentors prompt each other alternatively in an end-to-end training fashion. With extensive experiments on a dataset including a total of 4,496 CT and magnetic resonance imaging (MRI) cardiovascular volumes, we show both tasks are beneficial to each other and coupling these two tasks results in better performance than solving them exclusively.",
        "A1": " we propose a generic cross-modality synthesis approach ",
        "A2": "1) synthesizing realistic looking 3D images using unpaired training data, 2) ensuring consistent anatomical structures, which could be changed by geometric distortion in cross-modality synthesis and 3) improving volume segmentation by using synthetic data for modalities with limited training samples",
        "A41": "a generic cross-modality synthesis approach ",
        "A51": "",
        "A61": "",
        "A10": "",
        "A7": " experiments on a dataset including a total of 4,496 CT and magnetic resonance imaging (MRI) cardiovascular volumes",
        "A83": "",
        "A82": "",
        "A81": "both tasks are beneficial to each other and coupling these two tasks results in better performance than solving them exclusively.",
        "A64": "",
        "A54": "",
        "A44": "",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 187872602
    },
    {
        "Abstract": "This article presents for the first time a global method for registering 3D curves with 3D surfaces without requiring an initialization. The algorithm works with 2-tuples point+vector that consist in pairs of points augmented with the information of their tangents or normals. A closed-form solution for determining the alignment transformation from a pair of matching 2-tuples is proposed. In addition, the set of necessary conditions for two 2-tuples to match is derived. This allows fast search of correspondences that are used in an hypothesise-and-test framework for accomplishing global registration. Comparative experiments demonstrate that the proposed algorithm is the first effective solution for curve vs surface registration, with the method achieving accurate alignment in situations of small overlap and large percentage of outliers in a fraction of a second. The proposed framework is extended to the cases of curve vs curve and surface vs surface registration, with the former being particularly relevant since it is also a largely unsolved problem.",
        "A1": "presents for the first time a global method for registering 3D curves ",
        "A2": "without requiring an initialization. ",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "used in an hypothesise-and-test framework for accomplishing global registration.",
        "A7": "2-tuples point+vector that consist in pairs of points augmented ",
        "A83": "This allows fast search of correspondences",
        "A82": ", the set of necessary conditions for two 2-tuples to match is derived.",
        "A81": "A closed-form solution for determining the alignment transformation from a pair of matching 2-tuples is proposed. In addition, ",
        "A64": "The proposed framework is extended to the cases of curve vs curve and surface ",
        "A54": "achieving accurate alignment in situations of small overlap and large percentage of outliers in a fraction of a second. T",
        "A44": "accomplishing global registration.",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 14936702
    },
    {
        "Abstract": "Recurrent Neural Networks (RNNs) are powerful sequence modeling tools. However, when dealing with high dimensional inputs, the training of RNNs becomes computational expensive due to the large number of model parameters. This hinders RNNs from solving many important computer vision tasks, such as Action Recognition in Videos and Image Captioning. To overcome this problem, we propose a compact and flexible structure, namely Block-Term tensor decomposition, which greatly reduces the parameters of RNNs and improves their training efficiency. Compared with alternative low-rank approximations, such as tensortrain RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only more concise (when using the same rank), but also able to attain a better approximation to the original RNNs with much fewer parameters. On three challenging tasks, including Action Recognition in Videos, Image Captioning and Image Generation, BT-RNN outperforms TT-RNN and the standard RNN in terms of both prediction accuracy and convergence rate. Specifically, BT-LSTM utilizes 17,388 times fewer parameters than the standard LSTM to achieve an accuracy improvement over 15.6% in the Action Recognition task on the UCF11 dataset.",
        "A1": "when dealing with high dimensional inputs, the training of RNNs becomes computational expensive due to the large number of model parameters",
        "A2": "when dealing with high dimensional inputs, the training of RNNs becomes computational expensive",
        "A41": "",
        "A51": "",
        "A61": "",
        "A10": "BT-RNN outperforms TT-RNN and the standard RNN in terms of both prediction accuracy and convergence rate.",
        "A7": "Action Recognition in Videos, Image Captioning and Image Generation",
        "A83": "",
        "A82": "",
        "A81": "BT-LSTM utilizes 17,388 times fewer parameters than the standard LSTM to achieve an accuracy improvement over 15.6% in the Action Recognition task on the UCF11 dataset.",
        "A64": "Compared with alternative low-rank approximations, such as tensortrain RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only more concise (when using the same rank), but also able to attain a better approximation to the original RNNs with much fewer parameters",
        "A54": "RNNs",
        "A44": "we propose a compact and flexible structure, namely Block-Term tensor decomposition",
        "A63": "",
        "A53": "",
        "A43": "",
        "A62": "",
        "A52": "",
        "A42": "",
        "A45": "",
        "am_id": 235401761
    }
]